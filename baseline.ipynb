{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import pickle\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import gc\n",
    "\n",
    "from sam2.build_sam import build_sam2_video_predictor\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !sudo mount -t drvfs E: /mnt/g\n",
    "# mogrify -format jpg *.png && rm *.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"data/raw\"\n",
    "is_manual_annotation = False\n",
    "num_auto_points_per_tool = 10\n",
    "override_annotations = False\n",
    "\n",
    "annotation_dir = \"data/annotations/\" + \"manual\" if is_manual_annotation else \"data/annotations/\" + \"auto\"\n",
    "\n",
    "masks_dir = \"data/masks\"\n",
    "results_dir = \"data/results\"\n",
    "log_dir =  \"logs\"\n",
    "val_path = dataset_path + \"/SegSTRONGC_val/val\"\n",
    "test_path = dataset_path + \"/SegSTRONGC_test/test\"\n",
    "train_path = dataset_path + \"/SegSTRONGC_train\"\n",
    "models = [\"sam2.1_hiera_base_plus\", \"yolo11x-seg\"]\n",
    "model = models[1]\n",
    "\n",
    "val_dirs = [val_path + \"/\" + domain for domain in os.listdir(val_path)]\n",
    "test_dirs = [test_path + \"/\" + domain for domain in os.listdir(test_path)]\n",
    "train_dirs = [train_path + \"/\" + domain for domain in os.listdir(train_path)]\n",
    "\n",
    "\n",
    "sub_dirs = [path + \"/\" + sub_dir for path in val_dirs for sub_dir in os.listdir(path)]\n",
    "test_sub_dirs = [path + \"/\" + sub_dir for path in test_dirs for sub_dir in os.listdir(path)]\n",
    "train_sub_dirs = [path + \"/\" + sub_dir for path in train_dirs for sub_dir in os.listdir(path)]\n",
    "\n",
    "# ground truth is 'ground_truth'\n",
    "domains = ['bg_change', 'blood', 'low_brightness', 'regular', 'smoke']\n",
    "test_domains = ['bg_change', 'blood', 'low_brightness', 'regular', 'smoke']\n",
    "train_domains = ['regular']\n",
    "\n",
    "checkpoints = {\n",
    "    \"sam2.1_hiera_base_plus\": \"checkpoints/sam2.1_hiera_base_plus.pt\",\n",
    "    \"yolo11x-seg\": \"checkpoints/yolo11x-seg.pt\"\n",
    "}\n",
    "\n",
    "model_cfgs = {\n",
    "    \"sam2.1_hiera_base_plus\": \"configs/sam2.1/sam2.1_hiera_b+.yaml\",\n",
    "    \"yolo11x-seg\": None\n",
    "}\n",
    "\n",
    "num_images_per_domain = 300\n",
    "checkpoint = checkpoints[model]\n",
    "model_cfg = model_cfgs[model]\n",
    "\n",
    "logging.basicConfig(filename=log_dir + f'/{model}.log', level=logging.INFO, format='%(asctime)s - %(message)s', filemode='w')\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_paths(path, domain, is_left, num_images=300):\n",
    "    stereo_dir = \"left\" if is_left else \"right\"\n",
    "    image_paths = []\n",
    "\n",
    "    for i in range(num_images):\n",
    "        image_paths.append(path + \"/\" + domain + \"/\" + stereo_dir + \"/\" + str(i) + \".png\")\n",
    "\n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(TP, FP, FN):\n",
    "    return TP / (TP + FP + FN)\n",
    "\n",
    "def calculate_dsc(TP, FP, FN):\n",
    "    return 2 * TP / (2 * TP + FP + FN)\n",
    "\n",
    "def calculate_miou(pred_masks, gt_masks):\n",
    "    ious = []\n",
    "    for i in range(len(pred_masks)):\n",
    "        TP = np.logical_and(pred_masks[i], gt_masks[i])\n",
    "        FP = np.logical_and(pred_masks[i], np.logical_not(gt_masks[i]))\n",
    "        FN = np.logical_and(np.logical_not(pred_masks[i]), gt_masks[i])\n",
    "\n",
    "        iou = calculate_iou(np.sum(TP), np.sum(FP), np.sum(FN))\n",
    "        ious.append(iou)\n",
    "    \n",
    "    return np.mean(ious)\n",
    "\n",
    "def calculate_mdsc(pred_masks, gt_masks):\n",
    "    dscs = []\n",
    "    for i in range(len(pred_masks)):\n",
    "        TP = np.logical_and(pred_masks[i], gt_masks[i])\n",
    "        FP = np.logical_and(pred_masks[i], np.logical_not(gt_masks[i]))\n",
    "        FN = np.logical_and(np.logical_not(pred_masks[i]), gt_masks[i])\n",
    "\n",
    "        dsc = calculate_dsc(np.sum(TP), np.sum(FP), np.sum(FN))\n",
    "        dscs.append(dsc)\n",
    "    \n",
    "    return np.mean(dscs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations already exist. Skipping annotation process.\n"
     ]
    }
   ],
   "source": [
    "def manual_annotate(frame_path):\n",
    "    annotations = {0: []}\n",
    "    current_tool = 0\n",
    "    is_positive = True\n",
    "\n",
    "    window_name = \"Manual Annotation of Frame -\" + str(frame_path)\n",
    "    cv2.namedWindow(window_name)\n",
    "\n",
    "    def handle_mouse_click(event, x, y, flags, params):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            annotations[current_tool].append({\n",
    "                \"x\": x,\n",
    "                \"y\": y,\n",
    "                \"label\": 1 if is_positive else 0\n",
    "            })\n",
    "\n",
    "            if is_positive:\n",
    "                cv2.circle(frame, (x, y), 10, (0, 255, 0), -1)\n",
    "            else:\n",
    "                cv2.circle(frame, (x, y), 10, (0, 0, 255), -1)\n",
    "\n",
    "        cv2.imshow(window_name, frame)\n",
    "\n",
    "    cv2.setMouseCallback(window_name, handle_mouse_click)\n",
    "    frame = cv2.imread(frame_path)\n",
    "    original_frame = frame.copy()\n",
    "\n",
    "    while True:\n",
    "        frame = original_frame.copy()\n",
    "        for tool in annotations:\n",
    "            for annotation in annotations[tool]:\n",
    "                if annotation[\"label\"] == 1:\n",
    "                    cv2.circle(frame, (annotation[\"x\"], annotation[\"y\"]), 10, (0, 255, 0), -1)\n",
    "                else:\n",
    "                    cv2.circle(frame, (annotation[\"x\"], annotation[\"y\"]), 10, (0, 0, 255), -1)\n",
    "                \n",
    "        display_text = f\"Tool: {current_tool}, Mode: {'Positive' if is_positive else 'Negative'}\"\n",
    "        cv2.putText(frame, display_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "        cv2.imshow(window_name, frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if key == ord(\"n\"):\n",
    "            current_tool += 1\n",
    "            is_positive = True\n",
    "            annotations[current_tool] = []\n",
    "        elif key == ord(\"p\"):\n",
    "            is_positive = not is_positive\n",
    "        elif key == ord(\"c\"):\n",
    "            annotations[current_tool] = []\n",
    "        elif key == ord(\"s\"):\n",
    "            break\n",
    "\n",
    "    cv2.destroyWindow(window_name)\n",
    "    return annotations\n",
    "\n",
    "def auto_annotate(frame_path):\n",
    "    ground_truth_mask_path = None\n",
    "    annotations = {}\n",
    "    # annotations[current_tool].append({\n",
    "    #             \"x\": x,\n",
    "    #             \"y\": y,\n",
    "    #             \"label\": 1 if is_positive else 0\n",
    "    #         })\n",
    "\n",
    "    for domain in domains:\n",
    "        if domain in frame_path:\n",
    "            ground_truth_mask_path = frame_path.replace(domain, \"ground_truth\")\n",
    "            break\n",
    "    \n",
    "    if ground_truth_mask_path is None:\n",
    "        raise ValueError(\"Ground truth path not found.\")\n",
    "    else:\n",
    "        ground_truth_mask = cv2.imread(ground_truth_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        ground_truth_mask = (ground_truth_mask > 0).astype(np.bool_)\n",
    "        _, labels = cv2.connectedComponents(ground_truth_mask.astype(np.uint8))\n",
    "\n",
    "        # get unique labels, and get count for each label, then sort by count in descending order\n",
    "        unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "        sorted_labels = unique_labels[np.argsort(-counts)]\n",
    "\n",
    "        background_label = sorted_labels[0]\n",
    "        first_tool_label = sorted_labels[1]\n",
    "        second_tool_label = sorted_labels[2]    \n",
    "\n",
    "        #for each tool, get the centroid, and add num_auto_points - 1 sampled random points\n",
    "        annotations[0] = []\n",
    "        annotations[1] = []\n",
    "\n",
    "        for label, obj_id in [(first_tool_label, 0), (second_tool_label, 1)]:\n",
    "            mask = labels == label\n",
    "            mask = mask.astype(np.uint8)\n",
    "            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            contour = contours[0]\n",
    "            M = cv2.moments(contour)\n",
    "            cx = int(M['m10'] / M['m00'])\n",
    "            cy = int(M['m01'] / M['m00'])\n",
    "\n",
    "            annotations[obj_id].append({\n",
    "                \"x\": cx,\n",
    "                \"y\": cy,\n",
    "                \"label\": 1\n",
    "            })\n",
    "\n",
    "            label_indices = np.where(labels == label)\n",
    "            random_indices = np.random.choice(len(label_indices[0]), num_auto_points_per_tool - 1, replace=False)\n",
    "            for i in random_indices:\n",
    "                x = int(label_indices[1][i])\n",
    "                y = int(label_indices[0][i])\n",
    "                if ground_truth_mask[y, x]:\n",
    "                    annotations[obj_id].append({\n",
    "                        \"x\": x,\n",
    "                        \"y\": y,\n",
    "                        \"label\": 1\n",
    "                    })\n",
    "\n",
    "    # place these points on the frame and display once to verify\n",
    "    # frame = cv2.imread(frame_path)\n",
    "    # for tool in annotations:\n",
    "    #     for annotation in annotations[tool]:\n",
    "    #         cv2.circle(frame, (annotation[\"x\"], annotation[\"y\"]), 10, (0, 255, 0), -1)\n",
    "\n",
    "    # window_name = \"Auto Annotation of Frame -\" + str(frame_path)\n",
    "    # cv2.namedWindow(window_name)\n",
    "    # cv2.imshow(window_name, frame)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyWindow(window_name)\n",
    "\n",
    "    # plt.imshow(frame)\n",
    "    # plt.show()\n",
    "\n",
    "    return annotations\n",
    "\n",
    "def manual_annotate_first_frames(sub_dirs, domains, split):\n",
    "    print(f\"Total number of subdirs for {split}: {len(sub_dirs)}\")\n",
    "    for sub_dir in sub_dirs:\n",
    "        for domain in domains:\n",
    "            left_video_frames_path = sub_dir + \"/\" + domain + \"/left\"\n",
    "            right_video_frames_path = sub_dir + \"/\" + domain + \"/right\"\n",
    "\n",
    "            first_left_frame = left_video_frames_path + \"/0.jpg\"\n",
    "            first_right_frame = right_video_frames_path + \"/0.jpg\"\n",
    "\n",
    "            if is_manual_annotation:\n",
    "                left_annotations = manual_annotate(first_left_frame)\n",
    "                right_annotations = manual_annotate(first_right_frame)\n",
    "            else:\n",
    "                left_annotations = auto_annotate(first_left_frame)\n",
    "                right_annotations = auto_annotate(first_right_frame)\n",
    "\n",
    "            annotation_file = annotation_dir + f\"/{split}.json\"\n",
    "            if os.path.exists(annotation_file):\n",
    "                with open(annotation_file, \"r\") as f:\n",
    "                    all_annotations = json.load(f)\n",
    "            else:\n",
    "                all_annotations = {}\n",
    "\n",
    "            # print(left_annotations)\n",
    "            # print(right_annotations)\n",
    "            all_annotations[sub_dir + \"/\" + domain + \"/left\"] = left_annotations\n",
    "            all_annotations[sub_dir + \"/\" + domain + \"/right\"] = right_annotations\n",
    "\n",
    "            # print(all_annotations)\n",
    "\n",
    "            with open(annotation_file, \"w\") as f:\n",
    "                json.dump(all_annotations, f)\n",
    "\n",
    "            print(f\"Domain annotated: {first_left_frame}\")\n",
    "        print(f\"Subdir annotated: {sub_dir}\")\n",
    "\n",
    "if override_annotations:\n",
    "    manual_annotate_first_frames(sub_dirs, domains, \"val\")\n",
    "    print(\"Split annotated: val\")\n",
    "    manual_annotate_first_frames(test_sub_dirs, test_domains, \"test\")\n",
    "    print(\"Split annotated: test\")\n",
    "    manual_annotate_first_frames(train_sub_dirs, train_domains, \"train\")\n",
    "    print(\"Split annotated: train\")\n",
    "\n",
    "else:\n",
    "    print(\"Annotations already exist. Skipping annotation process.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# select the device for computation\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"using device: {device}\")\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    # use bfloat16 for the entire notebook\n",
    "    torch.autocast(\"cuda\", dtype=torch.bfloat16).__enter__()\n",
    "    # turn on tfloat32 for Ampere GPUs (https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices)\n",
    "    if torch.cuda.get_device_properties(0).major >= 8:\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "        torch.backends.cudnn.allow_tf32 = True\n",
    "elif device.type == \"mps\":\n",
    "    print(\n",
    "        \"\\nSupport for MPS devices is preliminary. SAM 2 is trained with CUDA and might \"\n",
    "        \"give numerically different outputs and sometimes degraded performance on MPS. \"\n",
    "        \"See e.g. https://github.com/pytorch/pytorch/issues/84936 for a discussion.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference(inference_model, frames_path, split):\n",
    "    mask_storage_data = {}\n",
    "    predicted_masks = []\n",
    "    \n",
    "    if inference_model == \"sam2.1_hiera_base_plus\":\n",
    "        print(f\"Loading annotations for split: {split}\")\n",
    "        try:\n",
    "            with open(annotation_dir + f\"/{split}.json\", \"r\") as f:\n",
    "                annotations = json.load(f)\n",
    "            print(f\"Successfully loaded annotations for {len(annotations)} items\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading annotations: {e}\")\n",
    "            logger.error(f\"Error loading annotations for split {split}: {e}\")\n",
    "            return\n",
    "\n",
    "        if annotations is None:\n",
    "            print(\"No annotations found for split\", split)\n",
    "            logger.warning(f\"No annotations found for split {split}\")\n",
    "            return None, None\n",
    "        \n",
    "        start = time.time()\n",
    "        print(f\"Initializing SAM for video...\")\n",
    "        sam2_predictor = build_sam2_video_predictor(model_cfg, checkpoint, device=device)\n",
    "\n",
    "        inference_state = sam2_predictor.init_state(\n",
    "            video_path = frames_path,\n",
    "        )\n",
    "        end = time.time()\n",
    "        print(f\"Initialization took {end - start:.2f} seconds.\")\n",
    "        logger.info(f\"SAM initialization for {frames_path} took {end - start:.2f} seconds.\")\n",
    "\n",
    "        current_annotations = annotations[frames_path]\n",
    "        print(f\"Found {len(current_annotations)} objects with annotations.\")\n",
    "        logger.info(f\"Processing {len(current_annotations)} objects with annotations for {frames_path}\")\n",
    "        \n",
    "        n_points = 0\n",
    "        for object in tqdm(current_annotations, desc=f\"Processing annotations for objects\"):\n",
    "            n_points += len(current_annotations[object])\n",
    "            for annotation in current_annotations[object]:\n",
    "                points = np.array([[int(annotation[\"x\"]), int(annotation[\"y\"])]], np.float32)\n",
    "                labels = np.array([annotation[\"label\"]], np.int32)\n",
    "                _, out_obj_ids, out_mask_logits = sam2_predictor.add_new_points_or_box(\n",
    "                    inference_state = inference_state,\n",
    "                    frame_idx = 0,\n",
    "                    obj_id = int(object),\n",
    "                    points = points,\n",
    "                    labels = labels,\n",
    "                )\n",
    "        print(f\"Added {n_points} annotation points across all objects.\")\n",
    "        logger.info(f\"Added {n_points} annotation points across all objects for {frames_path}\")\n",
    "\n",
    "        print(\"Starting mask propagation...\")\n",
    "        start = time.time()\n",
    "        video_segments = {}\n",
    "\n",
    "        n_frames = 0\n",
    "        for out_frame_idx, out_obj_ids, out_mask_logits in sam2_predictor.propagate_in_video(inference_state):\n",
    "            n_frames += 1\n",
    "            video_segments[out_frame_idx] = {\n",
    "                out_obj_id: (out_mask_logits[i] > 0.0).cpu().numpy()\n",
    "                for i, out_obj_id in enumerate(out_obj_ids)\n",
    "            }\n",
    "\n",
    "        end = time.time()\n",
    "        prop_time = end - start\n",
    "\n",
    "        print(f\"Mask propagation completed in {prop_time:.2f} seconds.\")\n",
    "        logger.info(f\"Mask propagation for {frames_path} took {prop_time:.2f} seconds.\")\n",
    "\n",
    "        print(\"Processing predicted masks...\")\n",
    "        for frame_idx, obj_dict in tqdm(video_segments.items(), desc=\"Processing video frames\"):\n",
    "            # it should have shape (1080, 1920)\n",
    "            # mask_storage_data[frame_idx] = []\n",
    "            overall_mask = np.zeros((1080, 1920), dtype=bool)\n",
    "\n",
    "            for obj_id, mask_array in obj_dict.items():\n",
    "                # mask_storage_data[frame_idx].append({\n",
    "                #     obj_id: mask_array\n",
    "                # })\n",
    "                \n",
    "                overall_mask = np.logical_or(overall_mask, mask_array.squeeze())\n",
    "\n",
    "            predicted_masks.append(overall_mask)\n",
    "            mask_storage_data[frame_idx] = overall_mask\n",
    "\n",
    "        sam2_predictor.reset_state(inference_state)\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            print(\"Empied CUDA cache.\")\n",
    "        print(\"SAM state reset.\")\n",
    "    elif inference_model == \"yolo11x-seg\":\n",
    "        start = time.time()\n",
    "        print(f\"Initializing Yolo for video...\")\n",
    "        yolo_model = YOLO(checkpoint)\n",
    "        end = time.time()\n",
    "        print(f\"Initialization took {end - start:.2f} seconds.\")\n",
    "        logger.info(f\"Yolo initialization for {frames_path} took {end - start:.2f} seconds.\")\n",
    "\n",
    "        print(\"Starting mask propagation...\")\n",
    "        start = time.time()\n",
    "\n",
    "        total_images = len(os.listdir(frames_path))\n",
    "        print(f\"Total images in video: {total_images}\")\n",
    "        logger.info(f\"Total images in video: {total_images}\")\n",
    "\n",
    "        video_result = []\n",
    "\n",
    "        for i in tqdm(range(total_images), desc=\"Propagating video frames\"):\n",
    "            frame_path = frames_path + f\"/{i}.jpg\"\n",
    "            # video_result.append(yolo_model(frame_path, max_det = 2))\n",
    "            video_result.append(yolo_model(frame_path))\n",
    "\n",
    "        end = time.time()\n",
    "        prop_time = end - start\n",
    "\n",
    "        print(f\"Mask propagation completed in {prop_time:.2f} seconds.\")\n",
    "        logger.info(f\"Mask propagation for {frames_path} took {prop_time:.2f} seconds.\")\n",
    "\n",
    "        print(\"Processing predicted masks...\")\n",
    "\n",
    "        for frame_idx, frame_result in tqdm(enumerate(video_result), desc=\"Processing video frames\"):\n",
    "            # it should have shape (1080, 1920)\n",
    "            # mask_storage_data[frame_idx] = []\n",
    "            overall_mask = np.zeros((1080, 1920), dtype=bool)\n",
    "\n",
    "            for result in frame_result:\n",
    "                if result.masks is None:\n",
    "                    # mask_storage_data[frame_idx].append({\n",
    "                    #     0: overall_mask\n",
    "                    # })\n",
    "                    continue\n",
    "\n",
    "                for mask_id, mask in enumerate(result.masks.data):\n",
    "                    mask_np = mask.cpu().numpy()\n",
    "                    reshaped_mask = cv2.resize(mask_np, (1920, 1080), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "                    # mask_storage_data[frame_idx].append({\n",
    "                    #     mask_id: reshaped_mask\n",
    "                    # })\n",
    "\n",
    "                    overall_mask = np.logical_or(overall_mask, reshaped_mask)\n",
    "\n",
    "            predicted_masks.append(overall_mask)\n",
    "            mask_storage_data[frame_idx] = overall_mask\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model name.\")\n",
    "    \n",
    "    return mask_storage_data, predicted_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Running inference for split: val\n",
      "================================================================================\n",
      "Processing 3 sub-directories and 5 domains\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sub-directories:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------\n",
      "Processing sub-directory: data/raw/SegSTRONGC_val/val/1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing domain: bg_change\n",
      "Processing left camera video...\n",
      "==================================================\n",
      "Processing video: data/raw/SegSTRONGC_val/val/1/2/bg_change/left\n",
      "Domain: bg_change, Split: val, Camera: left\n",
      "Initializing Yolo for video...\n",
      "Initialization took 0.78 seconds.\n",
      "Starting mask propagation...\n",
      "Total images in video: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/0.jpg: 384x640 1 knife, 78.8ms\n",
      "Speed: 3.2ms preprocess, 78.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/1.jpg: 384x640 (no detections), 28.9ms\n",
      "Speed: 1.9ms preprocess, 28.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/2.jpg: 384x640 (no detections), 29.8ms\n",
      "Speed: 1.7ms preprocess, 29.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/3.jpg: 384x640 (no detections), 27.2ms\n",
      "Speed: 1.9ms preprocess, 27.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/4.jpg: 384x640 1 knife, 27.4ms\n",
      "Speed: 1.8ms preprocess, 27.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/5.jpg: 384x640 1 person, 1 knife, 29.6ms\n",
      "Speed: 1.6ms preprocess, 29.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/6.jpg: 384x640 (no detections), 27.7ms\n",
      "Speed: 2.2ms preprocess, 27.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/7.jpg: 384x640 1 person, 1 knife, 27.2ms\n",
      "Speed: 2.0ms preprocess, 27.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/8.jpg: 384x640 1 knife, 41.5ms\n",
      "Speed: 1.8ms preprocess, 41.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/9.jpg: 384x640 1 person, 2 knifes, 27.2ms\n",
      "Speed: 1.6ms preprocess, 27.2ms inference, 13.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/10.jpg: 384x640 1 knife, 27.8ms\n",
      "Speed: 1.9ms preprocess, 27.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/11.jpg: 384x640 1 knife, 28.8ms\n",
      "Speed: 1.7ms preprocess, 28.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/12.jpg: 384x640 2 knifes, 26.2ms\n",
      "Speed: 2.0ms preprocess, 26.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/13.jpg: 384x640 1 knife, 28.1ms\n",
      "Speed: 2.2ms preprocess, 28.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/14.jpg: 384x640 1 knife, 1 spoon, 27.0ms\n",
      "Speed: 1.7ms preprocess, 27.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/15.jpg: 384x640 1 knife, 30.3ms\n",
      "Speed: 1.9ms preprocess, 30.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/16.jpg: 384x640 (no detections), 25.4ms\n",
      "Speed: 1.7ms preprocess, 25.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/17.jpg: 384x640 1 knife, 30.1ms\n",
      "Speed: 2.1ms preprocess, 30.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/18.jpg: 384x640 1 knife, 25.5ms\n",
      "Speed: 1.7ms preprocess, 25.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/19.jpg: 384x640 1 horse, 1 knife, 26.0ms\n",
      "Speed: 1.9ms preprocess, 26.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/20.jpg: 384x640 1 horse, 1 knife, 37.5ms\n",
      "Speed: 2.3ms preprocess, 37.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/21.jpg: 384x640 1 horse, 1 knife, 26.0ms\n",
      "Speed: 2.0ms preprocess, 26.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/22.jpg: 384x640 1 knife, 27.3ms\n",
      "Speed: 1.7ms preprocess, 27.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/23.jpg: 384x640 1 horse, 1 knife, 27.5ms\n",
      "Speed: 1.8ms preprocess, 27.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/24.jpg: 384x640 1 horse, 1 knife, 25.1ms\n",
      "Speed: 1.8ms preprocess, 25.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/25.jpg: 384x640 1 horse, 2 knifes, 27.9ms\n",
      "Speed: 1.8ms preprocess, 27.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/26.jpg: 384x640 1 knife, 35.5ms\n",
      "Speed: 2.0ms preprocess, 35.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/27.jpg: 384x640 1 knife, 27.2ms\n",
      "Speed: 2.3ms preprocess, 27.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/28.jpg: 384x640 1 horse, 1 knife, 25.6ms\n",
      "Speed: 1.8ms preprocess, 25.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/29.jpg: 384x640 1 knife, 30.6ms\n",
      "Speed: 1.7ms preprocess, 30.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/30.jpg: 384x640 1 horse, 1 knife, 27.7ms\n",
      "Speed: 1.9ms preprocess, 27.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/31.jpg: 384x640 1 horse, 1 knife, 24.6ms\n",
      "Speed: 1.9ms preprocess, 24.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/32.jpg: 384x640 1 horse, 1 knife, 30.4ms\n",
      "Speed: 1.8ms preprocess, 30.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/33.jpg: 384x640 1 knife, 26.9ms\n",
      "Speed: 2.0ms preprocess, 26.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/34.jpg: 384x640 1 horse, 1 knife, 24.1ms\n",
      "Speed: 1.9ms preprocess, 24.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/35.jpg: 384x640 1 knife, 25.4ms\n",
      "Speed: 1.8ms preprocess, 25.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/36.jpg: 384x640 1 knife, 27.8ms\n",
      "Speed: 2.1ms preprocess, 27.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/37.jpg: 384x640 2 knifes, 24.6ms\n",
      "Speed: 1.6ms preprocess, 24.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/38.jpg: 384x640 1 person, 2 knifes, 25.2ms\n",
      "Speed: 1.7ms preprocess, 25.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/39.jpg: 384x640 1 knife, 26.1ms\n",
      "Speed: 1.7ms preprocess, 26.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/40.jpg: 384x640 2 knifes, 26.7ms\n",
      "Speed: 1.7ms preprocess, 26.7ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/41.jpg: 384x640 1 knife, 26.6ms\n",
      "Speed: 1.9ms preprocess, 26.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/42.jpg: 384x640 1 horse, 1 knife, 26.9ms\n",
      "Speed: 1.8ms preprocess, 26.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/43.jpg: 384x640 1 knife, 26.9ms\n",
      "Speed: 1.7ms preprocess, 26.9ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/44.jpg: 384x640 2 knifes, 28.2ms\n",
      "Speed: 2.0ms preprocess, 28.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/45.jpg: 384x640 1 knife, 28.6ms\n",
      "Speed: 1.7ms preprocess, 28.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/46.jpg: 384x640 1 person, 27.3ms\n",
      "Speed: 1.9ms preprocess, 27.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/47.jpg: 384x640 1 person, 1 knife, 27.3ms\n",
      "Speed: 1.6ms preprocess, 27.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/48.jpg: 384x640 1 knife, 27.9ms\n",
      "Speed: 1.8ms preprocess, 27.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/49.jpg: 384x640 1 horse, 2 knifes, 35.9ms\n",
      "Speed: 2.0ms preprocess, 35.9ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/50.jpg: 384x640 1 horse, 1 knife, 30.5ms\n",
      "Speed: 2.0ms preprocess, 30.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/51.jpg: 384x640 1 horse, 33.5ms\n",
      "Speed: 1.9ms preprocess, 33.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/52.jpg: 384x640 1 horse, 29.1ms\n",
      "Speed: 2.0ms preprocess, 29.1ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/53.jpg: 384x640 1 horse, 40.6ms\n",
      "Speed: 1.9ms preprocess, 40.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/54.jpg: 384x640 1 horse, 35.1ms\n",
      "Speed: 2.3ms preprocess, 35.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/55.jpg: 384x640 1 horse, 1 knife, 29.5ms\n",
      "Speed: 1.7ms preprocess, 29.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/56.jpg: 384x640 1 horse, 30.9ms\n",
      "Speed: 2.0ms preprocess, 30.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/57.jpg: 384x640 1 horse, 1 knife, 37.9ms\n",
      "Speed: 1.9ms preprocess, 37.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/58.jpg: 384x640 1 horse, 1 knife, 30.3ms\n",
      "Speed: 1.7ms preprocess, 30.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/59.jpg: 384x640 1 horse, 30.9ms\n",
      "Speed: 1.8ms preprocess, 30.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/60.jpg: 384x640 1 knife, 31.1ms\n",
      "Speed: 1.9ms preprocess, 31.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/61.jpg: 384x640 1 horse, 31.3ms\n",
      "Speed: 1.7ms preprocess, 31.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/62.jpg: 384x640 1 horse, 1 knife, 34.7ms\n",
      "Speed: 2.1ms preprocess, 34.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/63.jpg: 384x640 1 horse, 33.8ms\n",
      "Speed: 1.9ms preprocess, 33.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/64.jpg: 384x640 1 horse, 32.3ms\n",
      "Speed: 1.9ms preprocess, 32.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/65.jpg: 384x640 1 horse, 32.1ms\n",
      "Speed: 1.7ms preprocess, 32.1ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/66.jpg: 384x640 (no detections), 33.5ms\n",
      "Speed: 1.8ms preprocess, 33.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/67.jpg: 384x640 (no detections), 33.4ms\n",
      "Speed: 1.7ms preprocess, 33.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/68.jpg: 384x640 1 horse, 33.0ms\n",
      "Speed: 1.6ms preprocess, 33.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/69.jpg: 384x640 (no detections), 33.9ms\n",
      "Speed: 1.8ms preprocess, 33.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/70.jpg: 384x640 (no detections), 33.2ms\n",
      "Speed: 1.6ms preprocess, 33.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/71.jpg: 384x640 1 knife, 33.0ms\n",
      "Speed: 1.7ms preprocess, 33.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/72.jpg: 384x640 1 knife, 32.4ms\n",
      "Speed: 1.6ms preprocess, 32.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/73.jpg: 384x640 1 knife, 38.0ms\n",
      "Speed: 1.6ms preprocess, 38.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/74.jpg: 384x640 1 knife, 36.5ms\n",
      "Speed: 1.9ms preprocess, 36.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/75.jpg: 384x640 1 knife, 29.0ms\n",
      "Speed: 1.6ms preprocess, 29.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/76.jpg: 384x640 1 knife, 1 cake, 29.4ms\n",
      "Speed: 1.7ms preprocess, 29.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/77.jpg: 384x640 1 knife, 29.3ms\n",
      "Speed: 1.7ms preprocess, 29.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/78.jpg: 384x640 1 knife, 1 cake, 31.2ms\n",
      "Speed: 1.9ms preprocess, 31.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/79.jpg: 384x640 1 knife, 29.2ms\n",
      "Speed: 1.6ms preprocess, 29.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/80.jpg: 384x640 1 knife, 29.3ms\n",
      "Speed: 1.5ms preprocess, 29.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/81.jpg: 384x640 1 knife, 29.5ms\n",
      "Speed: 1.6ms preprocess, 29.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/82.jpg: 384x640 1 knife, 29.7ms\n",
      "Speed: 2.0ms preprocess, 29.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/83.jpg: 384x640 1 knife, 28.5ms\n",
      "Speed: 1.5ms preprocess, 28.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/84.jpg: 384x640 1 knife, 1 cake, 29.1ms\n",
      "Speed: 1.7ms preprocess, 29.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/85.jpg: 384x640 1 knife, 28.8ms\n",
      "Speed: 1.8ms preprocess, 28.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/86.jpg: 384x640 1 knife, 30.1ms\n",
      "Speed: 2.1ms preprocess, 30.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/87.jpg: 384x640 1 knife, 32.0ms\n",
      "Speed: 1.5ms preprocess, 32.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/88.jpg: 384x640 1 knife, 29.0ms\n",
      "Speed: 1.7ms preprocess, 29.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/89.jpg: 384x640 1 knife, 29.3ms\n",
      "Speed: 1.8ms preprocess, 29.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/90.jpg: 384x640 1 knife, 29.5ms\n",
      "Speed: 1.7ms preprocess, 29.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/91.jpg: 384x640 1 knife, 29.0ms\n",
      "Speed: 1.6ms preprocess, 29.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/92.jpg: 384x640 1 bottle, 1 fork, 1 knife, 32.9ms\n",
      "Speed: 1.6ms preprocess, 32.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/93.jpg: 384x640 1 bottle, 1 knife, 35.1ms\n",
      "Speed: 1.8ms preprocess, 35.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/94.jpg: 384x640 1 knife, 33.2ms\n",
      "Speed: 1.7ms preprocess, 33.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/95.jpg: 384x640 1 knife, 33.2ms\n",
      "Speed: 1.5ms preprocess, 33.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/96.jpg: 384x640 1 knife, 33.2ms\n",
      "Speed: 1.5ms preprocess, 33.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/97.jpg: 384x640 2 knifes, 33.6ms\n",
      "Speed: 1.5ms preprocess, 33.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/98.jpg: 384x640 2 knifes, 37.1ms\n",
      "Speed: 1.8ms preprocess, 37.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/99.jpg: 384x640 1 knife, 33.6ms\n",
      "Speed: 1.6ms preprocess, 33.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/100.jpg: 384x640 1 knife, 33.5ms\n",
      "Speed: 1.6ms preprocess, 33.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/101.jpg: 384x640 1 knife, 34.0ms\n",
      "Speed: 1.8ms preprocess, 34.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/102.jpg: 384x640 1 knife, 34.0ms\n",
      "Speed: 1.7ms preprocess, 34.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/103.jpg: 384x640 1 knife, 37.2ms\n",
      "Speed: 1.6ms preprocess, 37.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/104.jpg: 384x640 1 knife, 34.1ms\n",
      "Speed: 1.5ms preprocess, 34.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/105.jpg: 384x640 1 knife, 34.2ms\n",
      "Speed: 1.5ms preprocess, 34.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/106.jpg: 384x640 1 knife, 34.4ms\n",
      "Speed: 1.6ms preprocess, 34.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/107.jpg: 384x640 1 knife, 34.6ms\n",
      "Speed: 1.5ms preprocess, 34.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/108.jpg: 384x640 1 bottle, 1 knife, 34.3ms\n",
      "Speed: 1.5ms preprocess, 34.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/109.jpg: 384x640 1 knife, 34.3ms\n",
      "Speed: 1.6ms preprocess, 34.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/110.jpg: 384x640 1 knife, 34.2ms\n",
      "Speed: 1.6ms preprocess, 34.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/111.jpg: 384x640 1 person, 1 knife, 38.9ms\n",
      "Speed: 1.7ms preprocess, 38.9ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/112.jpg: 384x640 (no detections), 34.9ms\n",
      "Speed: 1.7ms preprocess, 34.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/113.jpg: 384x640 1 knife, 36.0ms\n",
      "Speed: 1.5ms preprocess, 36.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/114.jpg: 384x640 1 knife, 35.1ms\n",
      "Speed: 1.7ms preprocess, 35.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/115.jpg: 384x640 1 knife, 35.4ms\n",
      "Speed: 1.5ms preprocess, 35.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/116.jpg: 384x640 1 knife, 35.5ms\n",
      "Speed: 1.7ms preprocess, 35.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/117.jpg: 384x640 1 knife, 36.1ms\n",
      "Speed: 1.7ms preprocess, 36.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/118.jpg: 384x640 1 knife, 36.0ms\n",
      "Speed: 1.6ms preprocess, 36.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/119.jpg: 384x640 1 knife, 36.3ms\n",
      "Speed: 1.7ms preprocess, 36.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/120.jpg: 384x640 1 knife, 35.9ms\n",
      "Speed: 1.5ms preprocess, 35.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/121.jpg: 384x640 1 knife, 36.3ms\n",
      "Speed: 1.5ms preprocess, 36.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/122.jpg: 384x640 2 knifes, 1 cake, 40.1ms\n",
      "Speed: 1.7ms preprocess, 40.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/123.jpg: 384x640 2 knifes, 1 cake, 40.3ms\n",
      "Speed: 1.7ms preprocess, 40.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/124.jpg: 384x640 1 knife, 36.4ms\n",
      "Speed: 1.6ms preprocess, 36.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/125.jpg: 384x640 1 knife, 1 cake, 37.3ms\n",
      "Speed: 1.9ms preprocess, 37.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/126.jpg: 384x640 1 knife, 1 cake, 41.7ms\n",
      "Speed: 1.9ms preprocess, 41.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/127.jpg: 384x640 1 knife, 41.4ms\n",
      "Speed: 1.7ms preprocess, 41.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/128.jpg: 384x640 1 horse, 1 knife, 38.8ms\n",
      "Speed: 1.7ms preprocess, 38.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/129.jpg: 384x640 1 knife, 39.7ms\n",
      "Speed: 1.7ms preprocess, 39.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/130.jpg: 384x640 1 knife, 39.0ms\n",
      "Speed: 1.8ms preprocess, 39.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/131.jpg: 384x640 1 knife, 39.2ms\n",
      "Speed: 1.7ms preprocess, 39.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/132.jpg: 384x640 1 knife, 40.9ms\n",
      "Speed: 1.7ms preprocess, 40.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/133.jpg: 384x640 1 knife, 39.2ms\n",
      "Speed: 1.8ms preprocess, 39.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/134.jpg: 384x640 1 knife, 41.0ms\n",
      "Speed: 1.6ms preprocess, 41.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/135.jpg: 384x640 1 horse, 42.0ms\n",
      "Speed: 1.9ms preprocess, 42.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/136.jpg: 384x640 (no detections), 39.2ms\n",
      "Speed: 2.0ms preprocess, 39.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/137.jpg: 384x640 1 horse, 1 knife, 39.0ms\n",
      "Speed: 2.0ms preprocess, 39.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/138.jpg: 384x640 1 horse, 1 knife, 38.9ms\n",
      "Speed: 2.1ms preprocess, 38.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/139.jpg: 384x640 1 horse, 1 knife, 39.4ms\n",
      "Speed: 2.1ms preprocess, 39.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/140.jpg: 384x640 1 horse, 39.8ms\n",
      "Speed: 2.0ms preprocess, 39.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/141.jpg: 384x640 (no detections), 39.3ms\n",
      "Speed: 1.9ms preprocess, 39.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/142.jpg: 384x640 1 toothbrush, 39.8ms\n",
      "Speed: 2.1ms preprocess, 39.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/143.jpg: 384x640 1 fork, 39.6ms\n",
      "Speed: 1.7ms preprocess, 39.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/144.jpg: 384x640 1 knife, 40.5ms\n",
      "Speed: 1.8ms preprocess, 40.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/145.jpg: 384x640 1 knife, 40.2ms\n",
      "Speed: 2.0ms preprocess, 40.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/146.jpg: 384x640 1 fork, 1 knife, 40.1ms\n",
      "Speed: 2.0ms preprocess, 40.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/147.jpg: 384x640 1 knife, 41.0ms\n",
      "Speed: 2.0ms preprocess, 41.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/148.jpg: 384x640 1 bottle, 1 knife, 40.7ms\n",
      "Speed: 2.0ms preprocess, 40.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/149.jpg: 384x640 1 knife, 40.6ms\n",
      "Speed: 1.9ms preprocess, 40.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/150.jpg: 384x640 1 knife, 40.5ms\n",
      "Speed: 2.2ms preprocess, 40.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/151.jpg: 384x640 1 knife, 44.0ms\n",
      "Speed: 2.2ms preprocess, 44.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/152.jpg: 384x640 1 knife, 40.0ms\n",
      "Speed: 2.3ms preprocess, 40.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/153.jpg: 384x640 1 knife, 65.5ms\n",
      "Speed: 4.1ms preprocess, 65.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/154.jpg: 384x640 1 knife, 65.0ms\n",
      "Speed: 2.2ms preprocess, 65.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/155.jpg: 384x640 1 knife, 61.2ms\n",
      "Speed: 2.4ms preprocess, 61.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/156.jpg: 384x640 1 knife, 32.9ms\n",
      "Speed: 1.6ms preprocess, 32.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/157.jpg: 384x640 1 knife, 33.5ms\n",
      "Speed: 1.7ms preprocess, 33.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/158.jpg: 384x640 1 horse, 1 knife, 34.8ms\n",
      "Speed: 1.7ms preprocess, 34.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/159.jpg: 384x640 1 knife, 36.4ms\n",
      "Speed: 1.8ms preprocess, 36.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/160.jpg: 384x640 1 knife, 31.6ms\n",
      "Speed: 1.9ms preprocess, 31.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/161.jpg: 384x640 1 knife, 31.5ms\n",
      "Speed: 1.6ms preprocess, 31.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/162.jpg: 384x640 1 knife, 31.4ms\n",
      "Speed: 2.1ms preprocess, 31.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/163.jpg: 384x640 1 knife, 31.4ms\n",
      "Speed: 1.8ms preprocess, 31.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/164.jpg: 384x640 1 knife, 40.3ms\n",
      "Speed: 1.6ms preprocess, 40.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/165.jpg: 384x640 1 horse, 1 toothbrush, 34.4ms\n",
      "Speed: 1.7ms preprocess, 34.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/166.jpg: 384x640 1 knife, 35.1ms\n",
      "Speed: 1.9ms preprocess, 35.1ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/167.jpg: 384x640 1 knife, 32.3ms\n",
      "Speed: 1.8ms preprocess, 32.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/168.jpg: 384x640 1 knife, 31.5ms\n",
      "Speed: 1.9ms preprocess, 31.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/169.jpg: 384x640 1 horse, 1 knife, 31.9ms\n",
      "Speed: 1.8ms preprocess, 31.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/170.jpg: 384x640 1 horse, 1 knife, 31.7ms\n",
      "Speed: 1.8ms preprocess, 31.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/171.jpg: 384x640 2 knifes, 31.3ms\n",
      "Speed: 1.8ms preprocess, 31.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/172.jpg: 384x640 2 knifes, 35.0ms\n",
      "Speed: 1.8ms preprocess, 35.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/173.jpg: 384x640 1 knife, 1 spoon, 38.5ms\n",
      "Speed: 1.7ms preprocess, 38.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/174.jpg: 384x640 1 horse, 1 knife, 35.8ms\n",
      "Speed: 1.6ms preprocess, 35.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/175.jpg: 384x640 1 horse, 1 knife, 36.1ms\n",
      "Speed: 1.7ms preprocess, 36.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/176.jpg: 384x640 1 person, 1 knife, 36.2ms\n",
      "Speed: 1.8ms preprocess, 36.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/177.jpg: 384x640 1 horse, 1 knife, 36.3ms\n",
      "Speed: 1.7ms preprocess, 36.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/178.jpg: 384x640 1 knife, 37.2ms\n",
      "Speed: 2.0ms preprocess, 37.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/179.jpg: 384x640 1 horse, 1 knife, 38.0ms\n",
      "Speed: 1.7ms preprocess, 38.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/180.jpg: 384x640 1 knife, 37.9ms\n",
      "Speed: 2.0ms preprocess, 37.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/181.jpg: 384x640 1 knife, 37.9ms\n",
      "Speed: 1.8ms preprocess, 37.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/182.jpg: 384x640 2 knifes, 1 cake, 37.5ms\n",
      "Speed: 1.7ms preprocess, 37.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/183.jpg: 384x640 1 person, 1 knife, 37.3ms\n",
      "Speed: 1.6ms preprocess, 37.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/184.jpg: 384x640 2 knifes, 38.2ms\n",
      "Speed: 1.7ms preprocess, 38.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/185.jpg: 384x640 1 knife, 46.2ms\n",
      "Speed: 1.9ms preprocess, 46.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/186.jpg: 384x640 1 knife, 37.8ms\n",
      "Speed: 1.6ms preprocess, 37.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/187.jpg: 384x640 1 knife, 38.0ms\n",
      "Speed: 2.2ms preprocess, 38.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/188.jpg: 384x640 1 knife, 39.3ms\n",
      "Speed: 2.2ms preprocess, 39.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/189.jpg: 384x640 2 knifes, 38.5ms\n",
      "Speed: 2.0ms preprocess, 38.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/190.jpg: 384x640 1 knife, 38.8ms\n",
      "Speed: 2.0ms preprocess, 38.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/191.jpg: 384x640 1 knife, 39.3ms\n",
      "Speed: 2.6ms preprocess, 39.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/192.jpg: 384x640 (no detections), 39.9ms\n",
      "Speed: 2.2ms preprocess, 39.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/193.jpg: 384x640 (no detections), 40.2ms\n",
      "Speed: 2.0ms preprocess, 40.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/194.jpg: 384x640 1 knife, 40.3ms\n",
      "Speed: 2.3ms preprocess, 40.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/195.jpg: 384x640 1 knife, 39.6ms\n",
      "Speed: 1.9ms preprocess, 39.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/196.jpg: 384x640 (no detections), 40.1ms\n",
      "Speed: 2.2ms preprocess, 40.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/197.jpg: 384x640 (no detections), 41.1ms\n",
      "Speed: 2.3ms preprocess, 41.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/198.jpg: 384x640 (no detections), 45.8ms\n",
      "Speed: 2.1ms preprocess, 45.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/199.jpg: 384x640 1 knife, 40.7ms\n",
      "Speed: 2.1ms preprocess, 40.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/200.jpg: 384x640 1 knife, 41.9ms\n",
      "Speed: 2.2ms preprocess, 41.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/201.jpg: 384x640 1 bottle, 1 knife, 40.9ms\n",
      "Speed: 2.4ms preprocess, 40.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/202.jpg: 384x640 1 knife, 45.9ms\n",
      "Speed: 2.1ms preprocess, 45.9ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/203.jpg: 384x640 1 knife, 65.2ms\n",
      "Speed: 2.8ms preprocess, 65.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/204.jpg: 384x640 1 knife, 32.2ms\n",
      "Speed: 1.6ms preprocess, 32.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/205.jpg: 384x640 1 knife, 32.3ms\n",
      "Speed: 1.6ms preprocess, 32.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/206.jpg: 384x640 1 knife, 1 cake, 32.2ms\n",
      "Speed: 1.7ms preprocess, 32.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/207.jpg: 384x640 1 knife, 41.5ms\n",
      "Speed: 1.7ms preprocess, 41.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/208.jpg: 384x640 1 knife, 39.9ms\n",
      "Speed: 1.8ms preprocess, 39.9ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/209.jpg: 384x640 1 knife, 32.6ms\n",
      "Speed: 2.0ms preprocess, 32.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/210.jpg: 384x640 1 knife, 1 cake, 32.6ms\n",
      "Speed: 2.2ms preprocess, 32.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/211.jpg: 384x640 1 knife, 33.0ms\n",
      "Speed: 1.7ms preprocess, 33.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/212.jpg: 384x640 1 knife, 32.3ms\n",
      "Speed: 1.8ms preprocess, 32.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/213.jpg: 384x640 1 knife, 32.0ms\n",
      "Speed: 1.7ms preprocess, 32.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/214.jpg: 384x640 1 knife, 40.7ms\n",
      "Speed: 1.8ms preprocess, 40.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/215.jpg: 384x640 1 knife, 1 cake, 43.0ms\n",
      "Speed: 1.8ms preprocess, 43.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/216.jpg: 384x640 1 knife, 32.3ms\n",
      "Speed: 1.7ms preprocess, 32.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/217.jpg: 384x640 1 knife, 33.1ms\n",
      "Speed: 2.2ms preprocess, 33.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/218.jpg: 384x640 1 horse, 1 knife, 32.5ms\n",
      "Speed: 1.8ms preprocess, 32.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/219.jpg: 384x640 1 horse, 1 knife, 32.9ms\n",
      "Speed: 1.8ms preprocess, 32.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/220.jpg: 384x640 1 knife, 38.0ms\n",
      "Speed: 2.0ms preprocess, 38.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/221.jpg: 384x640 1 knife, 42.3ms\n",
      "Speed: 2.0ms preprocess, 42.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/222.jpg: 384x640 1 knife, 38.0ms\n",
      "Speed: 2.1ms preprocess, 38.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/223.jpg: 384x640 1 knife, 38.7ms\n",
      "Speed: 1.8ms preprocess, 38.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/224.jpg: 384x640 1 knife, 39.1ms\n",
      "Speed: 2.1ms preprocess, 39.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/225.jpg: 384x640 2 knifes, 38.9ms\n",
      "Speed: 1.9ms preprocess, 38.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/226.jpg: 384x640 1 knife, 39.6ms\n",
      "Speed: 2.0ms preprocess, 39.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/227.jpg: 384x640 1 knife, 39.3ms\n",
      "Speed: 2.3ms preprocess, 39.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/228.jpg: 384x640 1 knife, 39.2ms\n",
      "Speed: 2.0ms preprocess, 39.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/229.jpg: 384x640 1 knife, 39.4ms\n",
      "Speed: 2.0ms preprocess, 39.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/230.jpg: 384x640 1 knife, 39.4ms\n",
      "Speed: 2.0ms preprocess, 39.4ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/231.jpg: 384x640 1 knife, 39.3ms\n",
      "Speed: 2.1ms preprocess, 39.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/232.jpg: 384x640 1 knife, 43.4ms\n",
      "Speed: 2.0ms preprocess, 43.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/233.jpg: 384x640 1 knife, 41.1ms\n",
      "Speed: 2.2ms preprocess, 41.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/234.jpg: 384x640 1 knife, 41.0ms\n",
      "Speed: 2.1ms preprocess, 41.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/235.jpg: 384x640 2 knifes, 1 cake, 40.4ms\n",
      "Speed: 2.1ms preprocess, 40.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/236.jpg: 384x640 1 knife, 1 cake, 40.8ms\n",
      "Speed: 2.1ms preprocess, 40.8ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/237.jpg: 384x640 2 knifes, 40.7ms\n",
      "Speed: 2.1ms preprocess, 40.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/238.jpg: 384x640 1 knife, 1 cake, 40.7ms\n",
      "Speed: 2.1ms preprocess, 40.7ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/239.jpg: 384x640 2 knifes, 1 cake, 65.6ms\n",
      "Speed: 2.8ms preprocess, 65.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/240.jpg: 384x640 1 knife, 65.5ms\n",
      "Speed: 2.8ms preprocess, 65.5ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/241.jpg: 384x640 1 knife, 65.0ms\n",
      "Speed: 2.8ms preprocess, 65.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/242.jpg: 384x640 1 knife, 1 cake, 30.6ms\n",
      "Speed: 2.1ms preprocess, 30.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/243.jpg: 384x640 1 knife, 29.4ms\n",
      "Speed: 1.8ms preprocess, 29.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/244.jpg: 384x640 1 knife, 29.3ms\n",
      "Speed: 2.1ms preprocess, 29.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/245.jpg: 384x640 1 knife, 30.6ms\n",
      "Speed: 1.7ms preprocess, 30.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/246.jpg: 384x640 1 knife, 29.6ms\n",
      "Speed: 2.0ms preprocess, 29.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/247.jpg: 384x640 1 knife, 29.2ms\n",
      "Speed: 1.7ms preprocess, 29.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/248.jpg: 384x640 2 knifes, 28.7ms\n",
      "Speed: 1.7ms preprocess, 28.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/249.jpg: 384x640 1 knife, 1 cake, 37.7ms\n",
      "Speed: 1.7ms preprocess, 37.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/250.jpg: 384x640 1 knife, 29.9ms\n",
      "Speed: 1.8ms preprocess, 29.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/251.jpg: 384x640 1 knife, 1 cake, 29.0ms\n",
      "Speed: 1.9ms preprocess, 29.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/252.jpg: 384x640 1 knife, 1 cake, 31.1ms\n",
      "Speed: 1.8ms preprocess, 31.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/253.jpg: 384x640 2 knifes, 28.9ms\n",
      "Speed: 1.7ms preprocess, 28.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/254.jpg: 384x640 1 knife, 31.4ms\n",
      "Speed: 1.7ms preprocess, 31.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/255.jpg: 384x640 1 knife, 29.2ms\n",
      "Speed: 1.7ms preprocess, 29.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/256.jpg: 384x640 1 knife, 30.1ms\n",
      "Speed: 1.9ms preprocess, 30.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/257.jpg: 384x640 1 spoon, 31.5ms\n",
      "Speed: 1.9ms preprocess, 31.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/258.jpg: 384x640 1 person, 2 knifes, 28.9ms\n",
      "Speed: 1.9ms preprocess, 28.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/259.jpg: 384x640 1 knife, 32.0ms\n",
      "Speed: 1.9ms preprocess, 32.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/260.jpg: 384x640 1 knife, 1 scissors, 35.1ms\n",
      "Speed: 1.9ms preprocess, 35.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/261.jpg: 384x640 1 knife, 1 scissors, 35.2ms\n",
      "Speed: 1.7ms preprocess, 35.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/262.jpg: 384x640 1 knife, 35.5ms\n",
      "Speed: 1.9ms preprocess, 35.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/263.jpg: 384x640 2 knifes, 36.3ms\n",
      "Speed: 1.8ms preprocess, 36.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/264.jpg: 384x640 2 knifes, 35.8ms\n",
      "Speed: 2.1ms preprocess, 35.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/265.jpg: 384x640 1 knife, 1 cake, 36.8ms\n",
      "Speed: 1.8ms preprocess, 36.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/266.jpg: 384x640 1 knife, 37.8ms\n",
      "Speed: 1.7ms preprocess, 37.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/267.jpg: 384x640 1 knife, 1 cake, 38.4ms\n",
      "Speed: 2.3ms preprocess, 38.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/268.jpg: 384x640 1 knife, 37.7ms\n",
      "Speed: 1.7ms preprocess, 37.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/269.jpg: 384x640 1 knife, 37.8ms\n",
      "Speed: 2.0ms preprocess, 37.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/270.jpg: 384x640 1 knife, 38.8ms\n",
      "Speed: 1.9ms preprocess, 38.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/271.jpg: 384x640 (no detections), 39.2ms\n",
      "Speed: 2.1ms preprocess, 39.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/272.jpg: 384x640 1 knife, 39.9ms\n",
      "Speed: 1.8ms preprocess, 39.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/273.jpg: 384x640 (no detections), 39.9ms\n",
      "Speed: 2.3ms preprocess, 39.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/274.jpg: 384x640 1 knife, 39.7ms\n",
      "Speed: 1.8ms preprocess, 39.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/275.jpg: 384x640 (no detections), 39.6ms\n",
      "Speed: 2.9ms preprocess, 39.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/276.jpg: 384x640 (no detections), 39.9ms\n",
      "Speed: 2.3ms preprocess, 39.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/277.jpg: 384x640 1 knife, 40.9ms\n",
      "Speed: 2.1ms preprocess, 40.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/278.jpg: 384x640 (no detections), 41.2ms\n",
      "Speed: 2.1ms preprocess, 41.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/279.jpg: 384x640 1 knife, 41.3ms\n",
      "Speed: 2.5ms preprocess, 41.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/280.jpg: 384x640 1 horse, 1 knife, 40.9ms\n",
      "Speed: 2.1ms preprocess, 40.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/281.jpg: 384x640 1 knife, 41.5ms\n",
      "Speed: 2.1ms preprocess, 41.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/282.jpg: 384x640 1 knife, 66.0ms\n",
      "Speed: 2.3ms preprocess, 66.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/283.jpg: 384x640 1 knife, 35.4ms\n",
      "Speed: 1.7ms preprocess, 35.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/284.jpg: 384x640 1 knife, 36.3ms\n",
      "Speed: 1.8ms preprocess, 36.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/285.jpg: 384x640 1 knife, 35.1ms\n",
      "Speed: 2.0ms preprocess, 35.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/286.jpg: 384x640 1 knife, 35.0ms\n",
      "Speed: 1.7ms preprocess, 35.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/287.jpg: 384x640 1 knife, 35.2ms\n",
      "Speed: 1.9ms preprocess, 35.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/288.jpg: 384x640 1 knife, 1 cake, 35.2ms\n",
      "Speed: 1.7ms preprocess, 35.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/289.jpg: 384x640 1 knife, 34.7ms\n",
      "Speed: 1.7ms preprocess, 34.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/290.jpg: 384x640 1 knife, 1 cake, 35.2ms\n",
      "Speed: 1.8ms preprocess, 35.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/291.jpg: 384x640 1 person, 1 knife, 35.6ms\n",
      "Speed: 1.7ms preprocess, 35.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/292.jpg: 384x640 1 knife, 35.0ms\n",
      "Speed: 1.8ms preprocess, 35.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/293.jpg: 384x640 1 knife, 35.3ms\n",
      "Speed: 1.8ms preprocess, 35.3ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/294.jpg: 384x640 1 bottle, 1 knife, 35.2ms\n",
      "Speed: 2.0ms preprocess, 35.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/295.jpg: 384x640 1 horse, 1 knife, 34.8ms\n",
      "Speed: 1.6ms preprocess, 34.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/296.jpg: 384x640 1 horse, 1 knife, 35.5ms\n",
      "Speed: 2.0ms preprocess, 35.5ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/297.jpg: 384x640 1 horse, 1 knife, 34.9ms\n",
      "Speed: 1.9ms preprocess, 34.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/298.jpg: 384x640 1 horse, 1 knife, 41.9ms\n",
      "Speed: 2.1ms preprocess, 41.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/left/299.jpg: 384x640 1 knife, 35.8ms\n",
      "Speed: 1.8ms preprocess, 35.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Propagating video frames: 100%|| 300/300 [00:31<00:00,  9.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask propagation completed in 31.43 seconds.\n",
      "Processing predicted masks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing video frames: 300it [00:01, 200.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 300 masks for evaluation.\n",
      "Masks saved to data/masks/yolo11x-seg/val/data-raw-SegSTRONGC_val-val-1-2-bg_change-left.pkl\n",
      "Loading ground truth masks for evaluation...\n",
      "Loaded 300 ground truth masks.\n",
      "Calculating evaluation metrics...\n",
      "Time taken for metrics calculation: 1.45 seconds.\n",
      "Mean IoU for data/raw/SegSTRONGC_val/val/1/2/bg_change/left: 0.4006\n",
      "Mean DSC for data/raw/SegSTRONGC_val/val/1/2/bg_change/left: 0.5226\n",
      "Loading existing results file: data/results/yolo11x-seg/val.json\n",
      "Results saved to data/results/yolo11x-seg/val.json\n",
      "Processing video took 39.65 seconds.\n",
      "==================================================\n",
      "Processing right camera video...\n",
      "==================================================\n",
      "Processing video: data/raw/SegSTRONGC_val/val/1/2/bg_change/right\n",
      "Domain: bg_change, Split: val, Camera: right\n",
      "Initializing Yolo for video...\n",
      "Initialization took 0.18 seconds.\n",
      "Starting mask propagation...\n",
      "Total images in video: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/0.jpg: 384x640 (no detections), 86.4ms\n",
      "Speed: 3.8ms preprocess, 86.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/1.jpg: 384x640 2 knifes, 38.8ms\n",
      "Speed: 2.0ms preprocess, 38.8ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/2.jpg: 384x640 1 knife, 27.5ms\n",
      "Speed: 2.0ms preprocess, 27.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/3.jpg: 384x640 1 fork, 1 knife, 30.8ms\n",
      "Speed: 2.1ms preprocess, 30.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/4.jpg: 384x640 1 fork, 30.8ms\n",
      "Speed: 1.9ms preprocess, 30.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/5.jpg: 384x640 (no detections), 28.3ms\n",
      "Speed: 1.9ms preprocess, 28.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/6.jpg: 384x640 1 fork, 28.4ms\n",
      "Speed: 1.7ms preprocess, 28.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/7.jpg: 384x640 1 fork, 1 toothbrush, 25.9ms\n",
      "Speed: 1.8ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/8.jpg: 384x640 1 fork, 25.8ms\n",
      "Speed: 1.5ms preprocess, 25.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/9.jpg: 384x640 1 knife, 1 spoon, 23.6ms\n",
      "Speed: 1.9ms preprocess, 23.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/10.jpg: 384x640 1 knife, 1 spoon, 26.8ms\n",
      "Speed: 1.5ms preprocess, 26.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/11.jpg: 384x640 2 knifes, 24.2ms\n",
      "Speed: 1.9ms preprocess, 24.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/12.jpg: 384x640 2 knifes, 34.1ms\n",
      "Speed: 2.1ms preprocess, 34.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/13.jpg: 384x640 2 knifes, 26.0ms\n",
      "Speed: 1.8ms preprocess, 26.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/14.jpg: 384x640 1 knife, 25.9ms\n",
      "Speed: 1.6ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/15.jpg: 384x640 1 knife, 34.2ms\n",
      "Speed: 1.5ms preprocess, 34.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/16.jpg: 384x640 1 fork, 1 knife, 35.5ms\n",
      "Speed: 2.3ms preprocess, 35.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/17.jpg: 384x640 1 knife, 28.6ms\n",
      "Speed: 1.8ms preprocess, 28.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/18.jpg: 384x640 1 fork, 1 knife, 1 cake, 34.0ms\n",
      "Speed: 1.9ms preprocess, 34.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/19.jpg: 384x640 1 knife, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/20.jpg: 384x640 1 knife, 26.8ms\n",
      "Speed: 1.9ms preprocess, 26.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/21.jpg: 384x640 1 fork, 1 knife, 28.9ms\n",
      "Speed: 1.6ms preprocess, 28.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/22.jpg: 384x640 1 knife, 26.3ms\n",
      "Speed: 1.7ms preprocess, 26.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/23.jpg: 384x640 1 knife, 23.7ms\n",
      "Speed: 1.7ms preprocess, 23.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/24.jpg: 384x640 1 knife, 25.9ms\n",
      "Speed: 1.8ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/25.jpg: 384x640 (no detections), 27.5ms\n",
      "Speed: 1.7ms preprocess, 27.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/26.jpg: 384x640 1 fork, 2 knifes, 1 sink, 27.7ms\n",
      "Speed: 1.8ms preprocess, 27.7ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/27.jpg: 384x640 1 knife, 26.6ms\n",
      "Speed: 1.9ms preprocess, 26.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/28.jpg: 384x640 (no detections), 38.1ms\n",
      "Speed: 1.9ms preprocess, 38.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/29.jpg: 384x640 1 fork, 1 knife, 27.9ms\n",
      "Speed: 1.9ms preprocess, 27.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/30.jpg: 384x640 1 fork, 1 cake, 26.9ms\n",
      "Speed: 1.9ms preprocess, 26.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/31.jpg: 384x640 1 fork, 1 cake, 25.2ms\n",
      "Speed: 1.7ms preprocess, 25.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/32.jpg: 384x640 (no detections), 22.7ms\n",
      "Speed: 1.5ms preprocess, 22.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/33.jpg: 384x640 1 fork, 1 knife, 25.0ms\n",
      "Speed: 1.5ms preprocess, 25.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/34.jpg: 384x640 1 fork, 1 knife, 27.3ms\n",
      "Speed: 1.8ms preprocess, 27.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/35.jpg: 384x640 1 fork, 1 knife, 29.2ms\n",
      "Speed: 1.5ms preprocess, 29.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/36.jpg: 384x640 1 fork, 1 knife, 25.9ms\n",
      "Speed: 1.5ms preprocess, 25.9ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/37.jpg: 384x640 1 fork, 2 knifes, 1 sink, 22.1ms\n",
      "Speed: 1.8ms preprocess, 22.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/38.jpg: 384x640 1 fork, 2 knifes, 1 sink, 26.3ms\n",
      "Speed: 1.6ms preprocess, 26.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/39.jpg: 384x640 1 knife, 36.2ms\n",
      "Speed: 1.5ms preprocess, 36.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/40.jpg: 384x640 1 knife, 31.2ms\n",
      "Speed: 2.6ms preprocess, 31.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/41.jpg: 384x640 1 knife, 1 sink, 29.5ms\n",
      "Speed: 1.7ms preprocess, 29.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/42.jpg: 384x640 1 sink, 24.6ms\n",
      "Speed: 1.4ms preprocess, 24.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/43.jpg: 384x640 1 fork, 2 knifes, 25.3ms\n",
      "Speed: 1.8ms preprocess, 25.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/44.jpg: 384x640 1 fork, 1 knife, 24.5ms\n",
      "Speed: 1.7ms preprocess, 24.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/45.jpg: 384x640 1 knife, 27.6ms\n",
      "Speed: 1.7ms preprocess, 27.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/46.jpg: 384x640 1 fork, 1 knife, 24.4ms\n",
      "Speed: 1.9ms preprocess, 24.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/47.jpg: 384x640 1 knife, 23.9ms\n",
      "Speed: 1.5ms preprocess, 23.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/48.jpg: 384x640 1 knife, 26.7ms\n",
      "Speed: 2.2ms preprocess, 26.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/49.jpg: 384x640 1 toothbrush, 23.2ms\n",
      "Speed: 1.6ms preprocess, 23.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/50.jpg: 384x640 1 knife, 26.5ms\n",
      "Speed: 1.7ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/51.jpg: 384x640 1 knife, 39.1ms\n",
      "Speed: 1.8ms preprocess, 39.1ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/52.jpg: 384x640 (no detections), 26.0ms\n",
      "Speed: 1.6ms preprocess, 26.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/53.jpg: 384x640 (no detections), 23.8ms\n",
      "Speed: 1.9ms preprocess, 23.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/54.jpg: 384x640 2 knifes, 22.9ms\n",
      "Speed: 1.7ms preprocess, 22.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/55.jpg: 384x640 (no detections), 26.2ms\n",
      "Speed: 2.0ms preprocess, 26.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/56.jpg: 384x640 (no detections), 24.0ms\n",
      "Speed: 1.9ms preprocess, 24.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/57.jpg: 384x640 1 knife, 25.1ms\n",
      "Speed: 1.8ms preprocess, 25.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/58.jpg: 384x640 1 knife, 24.6ms\n",
      "Speed: 1.5ms preprocess, 24.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/59.jpg: 384x640 1 knife, 24.9ms\n",
      "Speed: 2.0ms preprocess, 24.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/60.jpg: 384x640 (no detections), 23.7ms\n",
      "Speed: 1.6ms preprocess, 23.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/61.jpg: 384x640 (no detections), 23.7ms\n",
      "Speed: 1.7ms preprocess, 23.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/62.jpg: 384x640 (no detections), 24.1ms\n",
      "Speed: 1.7ms preprocess, 24.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/63.jpg: 384x640 (no detections), 25.8ms\n",
      "Speed: 1.8ms preprocess, 25.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/64.jpg: 384x640 (no detections), 32.7ms\n",
      "Speed: 1.7ms preprocess, 32.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/65.jpg: 384x640 (no detections), 26.6ms\n",
      "Speed: 1.5ms preprocess, 26.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/66.jpg: 384x640 (no detections), 23.9ms\n",
      "Speed: 2.3ms preprocess, 23.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/67.jpg: 384x640 (no detections), 22.7ms\n",
      "Speed: 1.8ms preprocess, 22.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/68.jpg: 384x640 (no detections), 22.7ms\n",
      "Speed: 1.6ms preprocess, 22.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/69.jpg: 384x640 1 bottle, 1 toothbrush, 31.2ms\n",
      "Speed: 1.7ms preprocess, 31.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/70.jpg: 384x640 (no detections), 27.2ms\n",
      "Speed: 1.5ms preprocess, 27.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/71.jpg: 384x640 1 knife, 1 cake, 23.2ms\n",
      "Speed: 1.8ms preprocess, 23.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/72.jpg: 384x640 1 knife, 1 cake, 33.2ms\n",
      "Speed: 1.6ms preprocess, 33.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/73.jpg: 384x640 1 knife, 23.6ms\n",
      "Speed: 1.8ms preprocess, 23.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/74.jpg: 384x640 1 knife, 1 spoon, 23.4ms\n",
      "Speed: 1.5ms preprocess, 23.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/75.jpg: 384x640 1 knife, 1 cake, 26.2ms\n",
      "Speed: 1.6ms preprocess, 26.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/76.jpg: 384x640 1 knife, 1 cake, 37.1ms\n",
      "Speed: 1.7ms preprocess, 37.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/77.jpg: 384x640 1 knife, 22.4ms\n",
      "Speed: 1.6ms preprocess, 22.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/78.jpg: 384x640 1 knife, 1 cake, 25.4ms\n",
      "Speed: 1.6ms preprocess, 25.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/79.jpg: 384x640 1 knife, 1 cake, 27.2ms\n",
      "Speed: 1.8ms preprocess, 27.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/80.jpg: 384x640 1 knife, 1 cake, 21.9ms\n",
      "Speed: 1.6ms preprocess, 21.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/81.jpg: 384x640 1 knife, 1 cake, 26.1ms\n",
      "Speed: 1.7ms preprocess, 26.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/82.jpg: 384x640 1 knife, 28.3ms\n",
      "Speed: 1.5ms preprocess, 28.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/83.jpg: 384x640 1 knife, 1 cake, 24.5ms\n",
      "Speed: 1.7ms preprocess, 24.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/84.jpg: 384x640 1 knife, 27.3ms\n",
      "Speed: 1.5ms preprocess, 27.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/85.jpg: 384x640 1 knife, 1 spoon, 25.9ms\n",
      "Speed: 1.8ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/86.jpg: 384x640 1 knife, 1 cake, 21.5ms\n",
      "Speed: 1.5ms preprocess, 21.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/87.jpg: 384x640 1 knife, 26.2ms\n",
      "Speed: 1.5ms preprocess, 26.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/88.jpg: 384x640 1 knife, 26.8ms\n",
      "Speed: 1.5ms preprocess, 26.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/89.jpg: 384x640 1 knife, 26.1ms\n",
      "Speed: 1.6ms preprocess, 26.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/90.jpg: 384x640 1 knife, 22.8ms\n",
      "Speed: 2.0ms preprocess, 22.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/91.jpg: 384x640 1 knife, 22.8ms\n",
      "Speed: 1.7ms preprocess, 22.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/92.jpg: 384x640 1 bottle, 1 knife, 24.5ms\n",
      "Speed: 1.9ms preprocess, 24.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/93.jpg: 384x640 1 knife, 22.7ms\n",
      "Speed: 2.7ms preprocess, 22.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/94.jpg: 384x640 1 bottle, 1 knife, 35.8ms\n",
      "Speed: 1.6ms preprocess, 35.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/95.jpg: 384x640 1 knife, 28.1ms\n",
      "Speed: 1.7ms preprocess, 28.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/96.jpg: 384x640 1 knife, 26.3ms\n",
      "Speed: 1.8ms preprocess, 26.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/97.jpg: 384x640 (no detections), 31.2ms\n",
      "Speed: 2.0ms preprocess, 31.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/98.jpg: 384x640 1 knife, 23.5ms\n",
      "Speed: 1.8ms preprocess, 23.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/99.jpg: 384x640 1 knife, 30.8ms\n",
      "Speed: 2.3ms preprocess, 30.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/100.jpg: 384x640 1 knife, 1 spoon, 24.3ms\n",
      "Speed: 1.8ms preprocess, 24.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/101.jpg: 384x640 1 knife, 28.9ms\n",
      "Speed: 1.9ms preprocess, 28.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/102.jpg: 384x640 1 knife, 25.1ms\n",
      "Speed: 1.5ms preprocess, 25.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/103.jpg: 384x640 1 knife, 25.8ms\n",
      "Speed: 1.8ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/104.jpg: 384x640 1 bottle, 1 knife, 33.2ms\n",
      "Speed: 1.9ms preprocess, 33.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/105.jpg: 384x640 1 knife, 28.6ms\n",
      "Speed: 1.7ms preprocess, 28.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/106.jpg: 384x640 1 bottle, 1 knife, 29.5ms\n",
      "Speed: 1.6ms preprocess, 29.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/107.jpg: 384x640 1 knife, 29.7ms\n",
      "Speed: 1.8ms preprocess, 29.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/108.jpg: 384x640 1 bottle, 1 knife, 23.2ms\n",
      "Speed: 1.7ms preprocess, 23.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/109.jpg: 384x640 1 bottle, 1 sink, 28.0ms\n",
      "Speed: 1.7ms preprocess, 28.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/110.jpg: 384x640 1 bottle, 25.1ms\n",
      "Speed: 1.6ms preprocess, 25.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/111.jpg: 384x640 1 knife, 24.4ms\n",
      "Speed: 1.9ms preprocess, 24.4ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/112.jpg: 384x640 1 knife, 40.7ms\n",
      "Speed: 1.8ms preprocess, 40.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/113.jpg: 384x640 1 bottle, 1 knife, 35.2ms\n",
      "Speed: 2.3ms preprocess, 35.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/114.jpg: 384x640 1 bottle, 23.4ms\n",
      "Speed: 1.6ms preprocess, 23.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/115.jpg: 384x640 1 bottle, 24.1ms\n",
      "Speed: 2.6ms preprocess, 24.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/116.jpg: 384x640 (no detections), 22.1ms\n",
      "Speed: 1.6ms preprocess, 22.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/117.jpg: 384x640 1 bottle, 1 knife, 25.8ms\n",
      "Speed: 1.5ms preprocess, 25.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/118.jpg: 384x640 1 knife, 25.5ms\n",
      "Speed: 2.3ms preprocess, 25.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/119.jpg: 384x640 1 knife, 25.7ms\n",
      "Speed: 1.8ms preprocess, 25.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/120.jpg: 384x640 2 knifes, 28.4ms\n",
      "Speed: 2.3ms preprocess, 28.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/121.jpg: 384x640 1 knife, 23.0ms\n",
      "Speed: 1.5ms preprocess, 23.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/122.jpg: 384x640 1 knife, 24.3ms\n",
      "Speed: 1.8ms preprocess, 24.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/123.jpg: 384x640 1 knife, 26.5ms\n",
      "Speed: 2.0ms preprocess, 26.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/124.jpg: 384x640 1 knife, 22.5ms\n",
      "Speed: 1.6ms preprocess, 22.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/125.jpg: 384x640 1 knife, 24.2ms\n",
      "Speed: 1.8ms preprocess, 24.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/126.jpg: 384x640 1 knife, 1 cake, 24.3ms\n",
      "Speed: 1.6ms preprocess, 24.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/127.jpg: 384x640 1 knife, 24.7ms\n",
      "Speed: 1.9ms preprocess, 24.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/128.jpg: 384x640 1 bottle, 1 knife, 25.6ms\n",
      "Speed: 2.0ms preprocess, 25.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/129.jpg: 384x640 1 bottle, 1 knife, 1 sink, 26.6ms\n",
      "Speed: 1.8ms preprocess, 26.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/130.jpg: 384x640 2 bottles, 28.6ms\n",
      "Speed: 1.6ms preprocess, 28.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/131.jpg: 384x640 1 bottle, 25.4ms\n",
      "Speed: 1.6ms preprocess, 25.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/132.jpg: 384x640 1 knife, 28.0ms\n",
      "Speed: 1.9ms preprocess, 28.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/133.jpg: 384x640 1 knife, 27.6ms\n",
      "Speed: 1.6ms preprocess, 27.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/134.jpg: 384x640 1 fork, 2 knifes, 25.6ms\n",
      "Speed: 1.5ms preprocess, 25.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/135.jpg: 384x640 1 bottle, 23.3ms\n",
      "Speed: 1.5ms preprocess, 23.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/136.jpg: 384x640 (no detections), 41.2ms\n",
      "Speed: 1.7ms preprocess, 41.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/137.jpg: 384x640 1 bottle, 44.8ms\n",
      "Speed: 1.6ms preprocess, 44.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/138.jpg: 384x640 1 bottle, 23.5ms\n",
      "Speed: 2.1ms preprocess, 23.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/139.jpg: 384x640 (no detections), 26.0ms\n",
      "Speed: 1.6ms preprocess, 26.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/140.jpg: 384x640 1 knife, 24.3ms\n",
      "Speed: 1.6ms preprocess, 24.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/141.jpg: 384x640 1 knife, 24.5ms\n",
      "Speed: 1.9ms preprocess, 24.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/142.jpg: 384x640 (no detections), 22.3ms\n",
      "Speed: 1.6ms preprocess, 22.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/143.jpg: 384x640 1 toothbrush, 26.2ms\n",
      "Speed: 1.5ms preprocess, 26.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/144.jpg: 384x640 (no detections), 26.9ms\n",
      "Speed: 1.6ms preprocess, 26.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/145.jpg: 384x640 1 fork, 1 knife, 25.8ms\n",
      "Speed: 1.6ms preprocess, 25.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/146.jpg: 384x640 1 fork, 1 knife, 22.9ms\n",
      "Speed: 1.8ms preprocess, 22.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/147.jpg: 384x640 1 fork, 1 knife, 43.0ms\n",
      "Speed: 1.8ms preprocess, 43.0ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/148.jpg: 384x640 1 knife, 34.5ms\n",
      "Speed: 1.7ms preprocess, 34.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/149.jpg: 384x640 1 knife, 33.7ms\n",
      "Speed: 2.0ms preprocess, 33.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/150.jpg: 384x640 1 knife, 23.0ms\n",
      "Speed: 1.5ms preprocess, 23.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/151.jpg: 384x640 1 knife, 1 cake, 28.2ms\n",
      "Speed: 2.0ms preprocess, 28.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/152.jpg: 384x640 1 knife, 26.0ms\n",
      "Speed: 1.7ms preprocess, 26.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/153.jpg: 384x640 1 knife, 22.0ms\n",
      "Speed: 1.7ms preprocess, 22.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/154.jpg: 384x640 1 knife, 1 cake, 23.6ms\n",
      "Speed: 1.7ms preprocess, 23.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/155.jpg: 384x640 1 knife, 21.6ms\n",
      "Speed: 1.8ms preprocess, 21.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/156.jpg: 384x640 1 knife, 28.1ms\n",
      "Speed: 1.8ms preprocess, 28.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/157.jpg: 384x640 1 knife, 25.9ms\n",
      "Speed: 1.9ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/158.jpg: 384x640 1 fork, 1 knife, 49.3ms\n",
      "Speed: 1.8ms preprocess, 49.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/159.jpg: 384x640 1 bottle, 29.4ms\n",
      "Speed: 1.6ms preprocess, 29.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/160.jpg: 384x640 1 bottle, 22.4ms\n",
      "Speed: 1.4ms preprocess, 22.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/161.jpg: 384x640 (no detections), 22.7ms\n",
      "Speed: 1.5ms preprocess, 22.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/162.jpg: 384x640 (no detections), 24.1ms\n",
      "Speed: 1.9ms preprocess, 24.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/163.jpg: 384x640 1 bottle, 21.6ms\n",
      "Speed: 1.5ms preprocess, 21.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/164.jpg: 384x640 1 bottle, 50.4ms\n",
      "Speed: 1.6ms preprocess, 50.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/165.jpg: 384x640 1 bottle, 1 knife, 36.0ms\n",
      "Speed: 2.2ms preprocess, 36.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/166.jpg: 384x640 1 bottle, 21.5ms\n",
      "Speed: 1.7ms preprocess, 21.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/167.jpg: 384x640 1 knife, 22.2ms\n",
      "Speed: 1.7ms preprocess, 22.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/168.jpg: 384x640 1 knife, 26.1ms\n",
      "Speed: 2.0ms preprocess, 26.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/169.jpg: 384x640 1 knife, 1 cake, 23.7ms\n",
      "Speed: 1.7ms preprocess, 23.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/170.jpg: 384x640 1 knife, 1 cake, 24.8ms\n",
      "Speed: 1.7ms preprocess, 24.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/171.jpg: 384x640 1 knife, 25.2ms\n",
      "Speed: 1.6ms preprocess, 25.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/172.jpg: 384x640 1 knife, 22.0ms\n",
      "Speed: 1.7ms preprocess, 22.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/173.jpg: 384x640 1 spoon, 26.8ms\n",
      "Speed: 2.2ms preprocess, 26.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/174.jpg: 384x640 1 knife, 23.9ms\n",
      "Speed: 1.7ms preprocess, 23.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/175.jpg: 384x640 1 knife, 26.8ms\n",
      "Speed: 1.7ms preprocess, 26.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/176.jpg: 384x640 1 knife, 28.2ms\n",
      "Speed: 1.8ms preprocess, 28.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/177.jpg: 384x640 1 knife, 1 sink, 23.9ms\n",
      "Speed: 1.5ms preprocess, 23.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/178.jpg: 384x640 1 knife, 38.4ms\n",
      "Speed: 1.9ms preprocess, 38.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/179.jpg: 384x640 1 knife, 28.4ms\n",
      "Speed: 2.2ms preprocess, 28.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/180.jpg: 384x640 1 knife, 23.7ms\n",
      "Speed: 1.6ms preprocess, 23.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/181.jpg: 384x640 1 knife, 32.2ms\n",
      "Speed: 1.7ms preprocess, 32.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/182.jpg: 384x640 1 knife, 31.4ms\n",
      "Speed: 1.8ms preprocess, 31.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/183.jpg: 384x640 1 knife, 28.0ms\n",
      "Speed: 1.5ms preprocess, 28.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/184.jpg: 384x640 1 knife, 21.8ms\n",
      "Speed: 1.7ms preprocess, 21.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/185.jpg: 384x640 1 bottle, 1 knife, 22.8ms\n",
      "Speed: 1.8ms preprocess, 22.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/186.jpg: 384x640 1 fork, 1 knife, 25.4ms\n",
      "Speed: 1.5ms preprocess, 25.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/187.jpg: 384x640 1 knife, 27.3ms\n",
      "Speed: 2.3ms preprocess, 27.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/188.jpg: 384x640 1 fork, 1 knife, 23.5ms\n",
      "Speed: 1.5ms preprocess, 23.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/189.jpg: 384x640 1 fork, 1 toothbrush, 23.3ms\n",
      "Speed: 1.6ms preprocess, 23.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/190.jpg: 384x640 1 toothbrush, 24.3ms\n",
      "Speed: 1.7ms preprocess, 24.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/191.jpg: 384x640 (no detections), 24.8ms\n",
      "Speed: 1.6ms preprocess, 24.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/192.jpg: 384x640 (no detections), 33.8ms\n",
      "Speed: 1.7ms preprocess, 33.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/193.jpg: 384x640 1 fork, 1 knife, 1 toothbrush, 24.9ms\n",
      "Speed: 1.7ms preprocess, 24.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/194.jpg: 384x640 (no detections), 22.0ms\n",
      "Speed: 1.4ms preprocess, 22.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/195.jpg: 384x640 1 toothbrush, 23.5ms\n",
      "Speed: 1.8ms preprocess, 23.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/196.jpg: 384x640 1 toothbrush, 25.4ms\n",
      "Speed: 1.6ms preprocess, 25.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/197.jpg: 384x640 (no detections), 22.4ms\n",
      "Speed: 1.6ms preprocess, 22.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/198.jpg: 384x640 1 toothbrush, 24.5ms\n",
      "Speed: 1.4ms preprocess, 24.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/199.jpg: 384x640 (no detections), 36.8ms\n",
      "Speed: 1.7ms preprocess, 36.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/200.jpg: 384x640 1 knife, 35.3ms\n",
      "Speed: 1.7ms preprocess, 35.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/201.jpg: 384x640 1 knife, 1 cake, 38.5ms\n",
      "Speed: 1.6ms preprocess, 38.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/202.jpg: 384x640 1 knife, 1 cake, 24.4ms\n",
      "Speed: 2.7ms preprocess, 24.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/203.jpg: 384x640 1 knife, 1 cake, 22.3ms\n",
      "Speed: 1.7ms preprocess, 22.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/204.jpg: 384x640 1 bottle, 1 cake, 51.2ms\n",
      "Speed: 1.6ms preprocess, 51.2ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/205.jpg: 384x640 1 knife, 1 cake, 22.7ms\n",
      "Speed: 1.7ms preprocess, 22.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/206.jpg: 384x640 1 knife, 22.8ms\n",
      "Speed: 1.4ms preprocess, 22.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/207.jpg: 384x640 1 knife, 23.0ms\n",
      "Speed: 1.7ms preprocess, 23.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/208.jpg: 384x640 1 knife, 46.0ms\n",
      "Speed: 1.8ms preprocess, 46.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/209.jpg: 384x640 1 knife, 22.0ms\n",
      "Speed: 1.5ms preprocess, 22.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/210.jpg: 384x640 1 knife, 1 cake, 32.3ms\n",
      "Speed: 1.6ms preprocess, 32.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/211.jpg: 384x640 1 knife, 1 spoon, 1 cake, 31.2ms\n",
      "Speed: 1.5ms preprocess, 31.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/212.jpg: 384x640 1 knife, 1 cake, 26.0ms\n",
      "Speed: 1.6ms preprocess, 26.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/213.jpg: 384x640 1 knife, 23.2ms\n",
      "Speed: 1.6ms preprocess, 23.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/214.jpg: 384x640 1 knife, 24.7ms\n",
      "Speed: 1.5ms preprocess, 24.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/215.jpg: 384x640 1 knife, 25.6ms\n",
      "Speed: 1.8ms preprocess, 25.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/216.jpg: 384x640 1 knife, 24.4ms\n",
      "Speed: 1.8ms preprocess, 24.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/217.jpg: 384x640 1 knife, 24.8ms\n",
      "Speed: 1.8ms preprocess, 24.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/218.jpg: 384x640 1 knife, 30.8ms\n",
      "Speed: 1.5ms preprocess, 30.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/219.jpg: 384x640 1 knife, 23.7ms\n",
      "Speed: 2.0ms preprocess, 23.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/220.jpg: 384x640 1 knife, 1 sink, 22.6ms\n",
      "Speed: 1.5ms preprocess, 22.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/221.jpg: 384x640 1 knife, 27.7ms\n",
      "Speed: 1.7ms preprocess, 27.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/222.jpg: 384x640 1 knife, 22.3ms\n",
      "Speed: 1.5ms preprocess, 22.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/223.jpg: 384x640 1 knife, 22.1ms\n",
      "Speed: 1.5ms preprocess, 22.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/224.jpg: 384x640 1 knife, 23.3ms\n",
      "Speed: 1.5ms preprocess, 23.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/225.jpg: 384x640 1 knife, 22.7ms\n",
      "Speed: 1.5ms preprocess, 22.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/226.jpg: 384x640 1 knife, 22.9ms\n",
      "Speed: 1.4ms preprocess, 22.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/227.jpg: 384x640 1 knife, 33.4ms\n",
      "Speed: 1.8ms preprocess, 33.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/228.jpg: 384x640 1 knife, 37.4ms\n",
      "Speed: 1.7ms preprocess, 37.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/229.jpg: 384x640 1 spoon, 21.9ms\n",
      "Speed: 1.4ms preprocess, 21.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/230.jpg: 384x640 1 knife, 23.5ms\n",
      "Speed: 1.5ms preprocess, 23.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/231.jpg: 384x640 1 knife, 28.4ms\n",
      "Speed: 1.5ms preprocess, 28.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/232.jpg: 384x640 1 knife, 1 spoon, 23.5ms\n",
      "Speed: 1.8ms preprocess, 23.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/233.jpg: 384x640 1 knife, 25.8ms\n",
      "Speed: 2.1ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/234.jpg: 384x640 1 knife, 32.2ms\n",
      "Speed: 1.5ms preprocess, 32.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/235.jpg: 384x640 1 knife, 21.7ms\n",
      "Speed: 1.6ms preprocess, 21.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/236.jpg: 384x640 1 knife, 1 spoon, 1 cake, 25.2ms\n",
      "Speed: 1.6ms preprocess, 25.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/237.jpg: 384x640 1 knife, 24.2ms\n",
      "Speed: 1.9ms preprocess, 24.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/238.jpg: 384x640 1 knife, 1 cake, 25.1ms\n",
      "Speed: 1.6ms preprocess, 25.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/239.jpg: 384x640 1 knife, 1 spoon, 1 cake, 22.6ms\n",
      "Speed: 1.7ms preprocess, 22.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/240.jpg: 384x640 1 knife, 1 spoon, 1 cake, 23.5ms\n",
      "Speed: 1.5ms preprocess, 23.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/241.jpg: 384x640 1 knife, 1 cake, 21.8ms\n",
      "Speed: 1.6ms preprocess, 21.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/242.jpg: 384x640 1 knife, 22.9ms\n",
      "Speed: 1.9ms preprocess, 22.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/243.jpg: 384x640 1 knife, 38.8ms\n",
      "Speed: 1.5ms preprocess, 38.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/244.jpg: 384x640 1 knife, 1 spoon, 33.2ms\n",
      "Speed: 1.8ms preprocess, 33.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/245.jpg: 384x640 1 knife, 24.7ms\n",
      "Speed: 2.2ms preprocess, 24.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/246.jpg: 384x640 1 knife, 21.8ms\n",
      "Speed: 1.4ms preprocess, 21.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/247.jpg: 384x640 1 knife, 23.4ms\n",
      "Speed: 1.7ms preprocess, 23.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/248.jpg: 384x640 1 knife, 27.9ms\n",
      "Speed: 1.6ms preprocess, 27.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/249.jpg: 384x640 1 knife, 22.1ms\n",
      "Speed: 1.5ms preprocess, 22.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/250.jpg: 384x640 1 knife, 26.1ms\n",
      "Speed: 1.5ms preprocess, 26.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/251.jpg: 384x640 1 knife, 21.2ms\n",
      "Speed: 1.5ms preprocess, 21.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/252.jpg: 384x640 1 knife, 1 sink, 34.8ms\n",
      "Speed: 1.5ms preprocess, 34.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/253.jpg: 384x640 2 knifes, 33.0ms\n",
      "Speed: 1.7ms preprocess, 33.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/254.jpg: 384x640 2 knifes, 28.9ms\n",
      "Speed: 2.0ms preprocess, 28.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/255.jpg: 384x640 2 knifes, 1 sink, 25.7ms\n",
      "Speed: 1.6ms preprocess, 25.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/256.jpg: 384x640 2 knifes, 1 cake, 39.6ms\n",
      "Speed: 1.7ms preprocess, 39.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/257.jpg: 384x640 1 spoon, 22.0ms\n",
      "Speed: 1.4ms preprocess, 22.0ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/258.jpg: 384x640 1 knife, 24.7ms\n",
      "Speed: 1.7ms preprocess, 24.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/259.jpg: 384x640 2 knifes, 23.2ms\n",
      "Speed: 1.6ms preprocess, 23.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/260.jpg: 384x640 2 knifes, 23.9ms\n",
      "Speed: 1.9ms preprocess, 23.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/261.jpg: 384x640 2 knifes, 27.4ms\n",
      "Speed: 1.6ms preprocess, 27.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/262.jpg: 384x640 2 knifes, 27.5ms\n",
      "Speed: 1.8ms preprocess, 27.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/263.jpg: 384x640 2 knifes, 21.2ms\n",
      "Speed: 1.6ms preprocess, 21.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/264.jpg: 384x640 2 knifes, 39.6ms\n",
      "Speed: 1.7ms preprocess, 39.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/265.jpg: 384x640 1 knife, 24.9ms\n",
      "Speed: 1.7ms preprocess, 24.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/266.jpg: 384x640 2 knifes, 1 cake, 21.9ms\n",
      "Speed: 1.5ms preprocess, 21.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/267.jpg: 384x640 2 knifes, 1 cake, 47.3ms\n",
      "Speed: 1.6ms preprocess, 47.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/268.jpg: 384x640 1 knife, 21.7ms\n",
      "Speed: 1.6ms preprocess, 21.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/269.jpg: 384x640 1 knife, 31.5ms\n",
      "Speed: 1.7ms preprocess, 31.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/270.jpg: 384x640 1 knife, 1 cake, 47.8ms\n",
      "Speed: 1.9ms preprocess, 47.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/271.jpg: 384x640 1 knife, 21.9ms\n",
      "Speed: 1.4ms preprocess, 21.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/272.jpg: 384x640 1 knife, 29.9ms\n",
      "Speed: 1.8ms preprocess, 29.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/273.jpg: 384x640 1 toothbrush, 26.2ms\n",
      "Speed: 1.6ms preprocess, 26.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/274.jpg: 384x640 1 fork, 1 toothbrush, 26.9ms\n",
      "Speed: 1.7ms preprocess, 26.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/275.jpg: 384x640 1 fork, 1 knife, 25.2ms\n",
      "Speed: 1.5ms preprocess, 25.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/276.jpg: 384x640 1 knife, 29.7ms\n",
      "Speed: 3.0ms preprocess, 29.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/277.jpg: 384x640 1 knife, 28.6ms\n",
      "Speed: 1.7ms preprocess, 28.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/278.jpg: 384x640 1 knife, 24.4ms\n",
      "Speed: 1.5ms preprocess, 24.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/279.jpg: 384x640 1 knife, 44.1ms\n",
      "Speed: 1.7ms preprocess, 44.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/280.jpg: 384x640 1 knife, 24.0ms\n",
      "Speed: 1.9ms preprocess, 24.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/281.jpg: 384x640 1 fork, 1 knife, 23.0ms\n",
      "Speed: 1.8ms preprocess, 23.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/282.jpg: 384x640 1 knife, 22.3ms\n",
      "Speed: 1.5ms preprocess, 22.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/283.jpg: 384x640 1 knife, 24.4ms\n",
      "Speed: 1.5ms preprocess, 24.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/284.jpg: 384x640 1 knife, 29.9ms\n",
      "Speed: 1.8ms preprocess, 29.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/285.jpg: 384x640 1 knife, 24.6ms\n",
      "Speed: 1.5ms preprocess, 24.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/286.jpg: 384x640 1 knife, 22.9ms\n",
      "Speed: 1.5ms preprocess, 22.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/287.jpg: 384x640 1 knife, 24.9ms\n",
      "Speed: 1.5ms preprocess, 24.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/288.jpg: 384x640 1 knife, 1 cake, 39.3ms\n",
      "Speed: 1.9ms preprocess, 39.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/289.jpg: 384x640 1 knife, 28.5ms\n",
      "Speed: 1.5ms preprocess, 28.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/290.jpg: 384x640 1 knife, 1 cake, 26.2ms\n",
      "Speed: 1.7ms preprocess, 26.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/291.jpg: 384x640 1 knife, 1 cake, 28.3ms\n",
      "Speed: 1.9ms preprocess, 28.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/292.jpg: 384x640 1 knife, 28.8ms\n",
      "Speed: 1.8ms preprocess, 28.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/293.jpg: 384x640 1 knife, 23.8ms\n",
      "Speed: 1.6ms preprocess, 23.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/294.jpg: 384x640 1 fork, 1 knife, 43.6ms\n",
      "Speed: 2.2ms preprocess, 43.6ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/295.jpg: 384x640 1 knife, 33.6ms\n",
      "Speed: 1.9ms preprocess, 33.6ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/296.jpg: 384x640 1 knife, 23.1ms\n",
      "Speed: 1.9ms preprocess, 23.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/297.jpg: 384x640 1 knife, 37.9ms\n",
      "Speed: 1.5ms preprocess, 37.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/298.jpg: 384x640 (no detections), 40.2ms\n",
      "Speed: 2.0ms preprocess, 40.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/bg_change/right/299.jpg: 384x640 (no detections), 29.6ms\n",
      "Speed: 1.5ms preprocess, 29.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Propagating video frames: 100%|| 300/300 [00:16<00:00, 18.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask propagation completed in 16.53 seconds.\n",
      "Processing predicted masks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing video frames: 300it [00:00, 363.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 300 masks for evaluation.\n",
      "Masks saved to data/masks/yolo11x-seg/val/data-raw-SegSTRONGC_val-val-1-2-bg_change-right.pkl\n",
      "Loading ground truth masks for evaluation...\n",
      "Loaded 300 ground truth masks.\n",
      "Calculating evaluation metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for metrics calculation: 1.56 seconds.\n",
      "Mean IoU for data/raw/SegSTRONGC_val/val/1/2/bg_change/right: 0.4379\n",
      "Mean DSC for data/raw/SegSTRONGC_val/val/1/2/bg_change/right: 0.5613\n",
      "Loading existing results file: data/results/yolo11x-seg/val.json\n",
      "Results saved to data/results/yolo11x-seg/val.json\n",
      "Processing video took 22.98 seconds.\n",
      "==================================================\n",
      "\n",
      "Results for data/raw/SegSTRONGC_val/val/1/2/bg_change:\n",
      "  Left: IoU=0.4006, DSC=0.5226\n",
      "  Right: IoU=0.4379, DSC=0.5613\n",
      "  Overall: IoU=0.4193, DSC=0.5420\n",
      "\n",
      "Processing domain: blood\n",
      "Processing left camera video...\n",
      "==================================================\n",
      "Processing video: data/raw/SegSTRONGC_val/val/1/2/blood/left\n",
      "Domain: blood, Split: val, Camera: left\n",
      "Initializing Yolo for video...\n",
      "Initialization took 0.17 seconds.\n",
      "Starting mask propagation...\n",
      "Total images in video: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/0.jpg: 384x640 1 bottle, 75.6ms\n",
      "Speed: 2.5ms preprocess, 75.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/1.jpg: 384x640 2 bottles, 3 carrots, 48.8ms\n",
      "Speed: 3.0ms preprocess, 48.8ms inference, 61.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/2.jpg: 384x640 1 baseball bat, 1 bottle, 1 carrot, 30.5ms\n",
      "Speed: 1.6ms preprocess, 30.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/3.jpg: 384x640 1 bottle, 30.1ms\n",
      "Speed: 1.6ms preprocess, 30.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/4.jpg: 384x640 1 baseball bat, 1 bottle, 1 carrot, 32.2ms\n",
      "Speed: 1.7ms preprocess, 32.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/5.jpg: 384x640 1 spoon, 1 carrot, 39.6ms\n",
      "Speed: 1.5ms preprocess, 39.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/6.jpg: 384x640 1 spoon, 1 carrot, 32.3ms\n",
      "Speed: 1.6ms preprocess, 32.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/7.jpg: 384x640 1 baseball bat, 1 bottle, 1 carrot, 28.3ms\n",
      "Speed: 1.7ms preprocess, 28.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/8.jpg: 384x640 1 bottle, 1 carrot, 28.7ms\n",
      "Speed: 1.7ms preprocess, 28.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/9.jpg: 384x640 1 carrot, 29.1ms\n",
      "Speed: 1.5ms preprocess, 29.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/10.jpg: 384x640 1 bottle, 1 carrot, 26.4ms\n",
      "Speed: 1.6ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/11.jpg: 384x640 2 bottles, 2 carrots, 26.5ms\n",
      "Speed: 2.0ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/12.jpg: 384x640 2 bottles, 1 carrot, 29.1ms\n",
      "Speed: 2.6ms preprocess, 29.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/13.jpg: 384x640 1 baseball bat, 1 carrot, 1 donut, 37.2ms\n",
      "Speed: 1.5ms preprocess, 37.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/14.jpg: 384x640 1 spoon, 1 carrot, 25.8ms\n",
      "Speed: 1.5ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/15.jpg: 384x640 1 carrot, 29.5ms\n",
      "Speed: 2.2ms preprocess, 29.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/16.jpg: 384x640 1 carrot, 1 donut, 40.0ms\n",
      "Speed: 1.7ms preprocess, 40.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/17.jpg: 384x640 3 carrots, 27.1ms\n",
      "Speed: 1.6ms preprocess, 27.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/18.jpg: 384x640 (no detections), 33.6ms\n",
      "Speed: 1.7ms preprocess, 33.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/19.jpg: 384x640 1 carrot, 31.3ms\n",
      "Speed: 2.7ms preprocess, 31.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/20.jpg: 384x640 3 carrots, 31.4ms\n",
      "Speed: 1.7ms preprocess, 31.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/21.jpg: 384x640 1 carrot, 32.2ms\n",
      "Speed: 1.7ms preprocess, 32.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/22.jpg: 384x640 2 carrots, 24.0ms\n",
      "Speed: 1.6ms preprocess, 24.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/23.jpg: 384x640 2 carrots, 1 donut, 25.9ms\n",
      "Speed: 1.7ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/24.jpg: 384x640 3 carrots, 31.6ms\n",
      "Speed: 1.7ms preprocess, 31.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/25.jpg: 384x640 1 bottle, 1 spoon, 1 carrot, 35.5ms\n",
      "Speed: 1.9ms preprocess, 35.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/26.jpg: 384x640 1 carrot, 31.7ms\n",
      "Speed: 1.6ms preprocess, 31.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/27.jpg: 384x640 1 carrot, 28.7ms\n",
      "Speed: 1.7ms preprocess, 28.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/28.jpg: 384x640 2 carrots, 1 donut, 30.6ms\n",
      "Speed: 1.6ms preprocess, 30.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/29.jpg: 384x640 1 carrot, 24.8ms\n",
      "Speed: 1.6ms preprocess, 24.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/30.jpg: 384x640 4 carrots, 1 donut, 23.9ms\n",
      "Speed: 1.6ms preprocess, 23.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/31.jpg: 384x640 3 carrots, 1 donut, 42.6ms\n",
      "Speed: 1.9ms preprocess, 42.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/32.jpg: 384x640 1 carrot, 1 donut, 31.4ms\n",
      "Speed: 1.7ms preprocess, 31.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/33.jpg: 384x640 2 carrots, 1 donut, 33.1ms\n",
      "Speed: 1.6ms preprocess, 33.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/34.jpg: 384x640 1 carrot, 1 donut, 24.4ms\n",
      "Speed: 1.7ms preprocess, 24.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/35.jpg: 384x640 2 carrots, 1 donut, 22.8ms\n",
      "Speed: 1.5ms preprocess, 22.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/36.jpg: 384x640 1 carrot, 29.0ms\n",
      "Speed: 1.7ms preprocess, 29.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/37.jpg: 384x640 2 carrots, 27.0ms\n",
      "Speed: 1.9ms preprocess, 27.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/38.jpg: 384x640 1 baseball bat, 1 bottle, 1 carrot, 1 clock, 27.4ms\n",
      "Speed: 1.5ms preprocess, 27.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/39.jpg: 384x640 1 carrot, 26.1ms\n",
      "Speed: 1.5ms preprocess, 26.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/40.jpg: 384x640 1 baseball bat, 1 carrot, 29.1ms\n",
      "Speed: 1.6ms preprocess, 29.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/41.jpg: 384x640 2 carrots, 34.0ms\n",
      "Speed: 2.2ms preprocess, 34.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/42.jpg: 384x640 1 carrot, 1 donut, 33.0ms\n",
      "Speed: 1.8ms preprocess, 33.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/43.jpg: 384x640 1 carrot, 39.4ms\n",
      "Speed: 1.9ms preprocess, 39.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/44.jpg: 384x640 1 carrot, 24.0ms\n",
      "Speed: 1.8ms preprocess, 24.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/45.jpg: 384x640 3 carrots, 25.7ms\n",
      "Speed: 1.7ms preprocess, 25.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/46.jpg: 384x640 3 carrots, 46.8ms\n",
      "Speed: 1.7ms preprocess, 46.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/47.jpg: 384x640 3 carrots, 1 donut, 23.2ms\n",
      "Speed: 1.7ms preprocess, 23.2ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/48.jpg: 384x640 2 carrots, 26.1ms\n",
      "Speed: 2.0ms preprocess, 26.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/49.jpg: 384x640 1 carrot, 1 donut, 24.7ms\n",
      "Speed: 1.8ms preprocess, 24.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/50.jpg: 384x640 1 carrot, 1 clock, 35.6ms\n",
      "Speed: 2.2ms preprocess, 35.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/51.jpg: 384x640 1 carrot, 1 clock, 23.3ms\n",
      "Speed: 1.6ms preprocess, 23.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/52.jpg: 384x640 1 baseball bat, 1 bottle, 2 carrots, 30.0ms\n",
      "Speed: 3.2ms preprocess, 30.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/53.jpg: 384x640 3 carrots, 1 clock, 22.1ms\n",
      "Speed: 1.5ms preprocess, 22.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/54.jpg: 384x640 1 bottle, 1 carrot, 22.9ms\n",
      "Speed: 1.6ms preprocess, 22.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/55.jpg: 384x640 1 baseball bat, 3 carrots, 1 clock, 22.1ms\n",
      "Speed: 1.5ms preprocess, 22.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/56.jpg: 384x640 1 baseball bat, 1 carrot, 1 clock, 23.3ms\n",
      "Speed: 1.4ms preprocess, 23.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/57.jpg: 384x640 1 carrot, 24.0ms\n",
      "Speed: 1.7ms preprocess, 24.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/58.jpg: 384x640 2 carrots, 29.2ms\n",
      "Speed: 1.4ms preprocess, 29.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/59.jpg: 384x640 2 carrots, 27.1ms\n",
      "Speed: 1.6ms preprocess, 27.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/60.jpg: 384x640 3 carrots, 25.3ms\n",
      "Speed: 1.7ms preprocess, 25.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/61.jpg: 384x640 1 carrot, 30.9ms\n",
      "Speed: 1.7ms preprocess, 30.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/62.jpg: 384x640 1 baseball bat, 1 bottle, 1 carrot, 1 clock, 41.0ms\n",
      "Speed: 1.5ms preprocess, 41.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/63.jpg: 384x640 1 baseball bat, 1 carrot, 26.0ms\n",
      "Speed: 2.9ms preprocess, 26.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/64.jpg: 384x640 1 bottle, 1 carrot, 27.1ms\n",
      "Speed: 1.5ms preprocess, 27.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/65.jpg: 384x640 1 baseball bat, 1 carrot, 1 clock, 23.5ms\n",
      "Speed: 1.6ms preprocess, 23.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/66.jpg: 384x640 1 carrot, 1 clock, 21.9ms\n",
      "Speed: 1.5ms preprocess, 21.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/67.jpg: 384x640 3 carrots, 2 donuts, 23.5ms\n",
      "Speed: 2.1ms preprocess, 23.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/68.jpg: 384x640 1 carrot, 1 clock, 22.9ms\n",
      "Speed: 1.6ms preprocess, 22.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/69.jpg: 384x640 1 donut, 1 clock, 26.3ms\n",
      "Speed: 1.6ms preprocess, 26.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/70.jpg: 384x640 3 carrots, 3 donuts, 32.8ms\n",
      "Speed: 1.6ms preprocess, 32.8ms inference, 15.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/71.jpg: 384x640 3 carrots, 2 donuts, 26.5ms\n",
      "Speed: 1.6ms preprocess, 26.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/72.jpg: 384x640 1 fork, 1 spoon, 7 carrots, 25.0ms\n",
      "Speed: 1.5ms preprocess, 25.0ms inference, 14.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/73.jpg: 384x640 5 carrots, 39.8ms\n",
      "Speed: 1.5ms preprocess, 39.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/74.jpg: 384x640 1 bottle, 1 spoon, 5 carrots, 28.7ms\n",
      "Speed: 1.6ms preprocess, 28.7ms inference, 19.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/75.jpg: 384x640 1 bottle, 4 carrots, 24.9ms\n",
      "Speed: 1.6ms preprocess, 24.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/76.jpg: 384x640 1 bottle, 7 carrots, 28.6ms\n",
      "Speed: 1.6ms preprocess, 28.6ms inference, 9.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/77.jpg: 384x640 1 bottle, 5 carrots, 25.9ms\n",
      "Speed: 1.6ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/78.jpg: 384x640 1 bottle, 5 carrots, 31.9ms\n",
      "Speed: 2.1ms preprocess, 31.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/79.jpg: 384x640 1 knife, 5 carrots, 27.9ms\n",
      "Speed: 2.0ms preprocess, 27.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/80.jpg: 384x640 1 bottle, 4 carrots, 35.5ms\n",
      "Speed: 1.7ms preprocess, 35.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/81.jpg: 384x640 1 bottle, 2 carrots, 26.4ms\n",
      "Speed: 2.0ms preprocess, 26.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/82.jpg: 384x640 1 bottle, 1 donut, 26.6ms\n",
      "Speed: 1.9ms preprocess, 26.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/83.jpg: 384x640 1 bottle, 2 carrots, 2 donuts, 28.1ms\n",
      "Speed: 1.6ms preprocess, 28.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/84.jpg: 384x640 (no detections), 28.0ms\n",
      "Speed: 1.9ms preprocess, 28.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/85.jpg: 384x640 1 spoon, 23.3ms\n",
      "Speed: 1.6ms preprocess, 23.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/86.jpg: 384x640 1 bottle, 48.7ms\n",
      "Speed: 1.5ms preprocess, 48.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/87.jpg: 384x640 1 bottle, 3 carrots, 1 donut, 23.4ms\n",
      "Speed: 1.8ms preprocess, 23.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/88.jpg: 384x640 1 bottle, 3 carrots, 22.4ms\n",
      "Speed: 1.5ms preprocess, 22.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/89.jpg: 384x640 1 bottle, 3 carrots, 23.0ms\n",
      "Speed: 2.0ms preprocess, 23.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/90.jpg: 384x640 1 bottle, 2 carrots, 32.4ms\n",
      "Speed: 1.6ms preprocess, 32.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/91.jpg: 384x640 1 bottle, 3 carrots, 30.0ms\n",
      "Speed: 1.6ms preprocess, 30.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/92.jpg: 384x640 1 bottle, 2 carrots, 25.4ms\n",
      "Speed: 1.5ms preprocess, 25.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/93.jpg: 384x640 1 bottle, 1 carrot, 26.3ms\n",
      "Speed: 1.6ms preprocess, 26.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/94.jpg: 384x640 1 bottle, 3 carrots, 28.8ms\n",
      "Speed: 2.3ms preprocess, 28.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/95.jpg: 384x640 1 carrot, 34.1ms\n",
      "Speed: 1.8ms preprocess, 34.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/96.jpg: 384x640 1 bottle, 1 carrot, 23.6ms\n",
      "Speed: 1.5ms preprocess, 23.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/97.jpg: 384x640 1 bottle, 1 carrot, 24.9ms\n",
      "Speed: 1.6ms preprocess, 24.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/98.jpg: 384x640 1 bottle, 1 carrot, 24.6ms\n",
      "Speed: 1.7ms preprocess, 24.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/99.jpg: 384x640 1 bottle, 1 carrot, 24.5ms\n",
      "Speed: 1.5ms preprocess, 24.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/100.jpg: 384x640 1 bottle, 2 carrots, 28.3ms\n",
      "Speed: 1.9ms preprocess, 28.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/101.jpg: 384x640 1 bottle, 1 carrot, 30.0ms\n",
      "Speed: 1.7ms preprocess, 30.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/102.jpg: 384x640 1 bottle, 1 carrot, 37.8ms\n",
      "Speed: 1.7ms preprocess, 37.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/103.jpg: 384x640 1 bottle, 2 carrots, 27.1ms\n",
      "Speed: 1.5ms preprocess, 27.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/104.jpg: 384x640 1 bottle, 2 carrots, 35.2ms\n",
      "Speed: 1.6ms preprocess, 35.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/105.jpg: 384x640 1 bottle, 4 carrots, 30.0ms\n",
      "Speed: 1.5ms preprocess, 30.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/106.jpg: 384x640 1 bottle, 37.5ms\n",
      "Speed: 2.0ms preprocess, 37.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/107.jpg: 384x640 1 bottle, 1 carrot, 22.9ms\n",
      "Speed: 1.5ms preprocess, 22.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/108.jpg: 384x640 1 bottle, 1 carrot, 24.3ms\n",
      "Speed: 1.9ms preprocess, 24.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/109.jpg: 384x640 1 bottle, 1 carrot, 31.5ms\n",
      "Speed: 1.6ms preprocess, 31.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/110.jpg: 384x640 1 bottle, 23.0ms\n",
      "Speed: 1.9ms preprocess, 23.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/111.jpg: 384x640 1 bottle, 3 carrots, 27.7ms\n",
      "Speed: 1.6ms preprocess, 27.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/112.jpg: 384x640 1 bottle, 1 carrot, 33.1ms\n",
      "Speed: 1.8ms preprocess, 33.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/113.jpg: 384x640 1 bottle, 1 carrot, 22.2ms\n",
      "Speed: 1.5ms preprocess, 22.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/114.jpg: 384x640 2 bottles, 2 carrots, 22.9ms\n",
      "Speed: 1.5ms preprocess, 22.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/115.jpg: 384x640 1 bottle, 1 carrot, 27.1ms\n",
      "Speed: 1.6ms preprocess, 27.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/116.jpg: 384x640 1 bottle, 2 carrots, 26.4ms\n",
      "Speed: 1.6ms preprocess, 26.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/117.jpg: 384x640 1 bottle, 1 carrot, 22.0ms\n",
      "Speed: 1.5ms preprocess, 22.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/118.jpg: 384x640 1 bottle, 1 spoon, 3 carrots, 26.8ms\n",
      "Speed: 1.6ms preprocess, 26.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/119.jpg: 384x640 1 bottle, 1 spoon, 2 carrots, 27.2ms\n",
      "Speed: 2.2ms preprocess, 27.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/120.jpg: 384x640 1 baseball bat, 1 bottle, 2 carrots, 23.1ms\n",
      "Speed: 1.7ms preprocess, 23.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/121.jpg: 384x640 1 bottle, 1 carrot, 23.7ms\n",
      "Speed: 1.6ms preprocess, 23.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/122.jpg: 384x640 1 carrot, 33.8ms\n",
      "Speed: 2.0ms preprocess, 33.8ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/123.jpg: 384x640 2 carrots, 1 donut, 22.5ms\n",
      "Speed: 1.6ms preprocess, 22.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/124.jpg: 384x640 1 bottle, 2 carrots, 24.2ms\n",
      "Speed: 1.8ms preprocess, 24.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/125.jpg: 384x640 1 bottle, 1 carrot, 23.3ms\n",
      "Speed: 1.7ms preprocess, 23.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/126.jpg: 384x640 5 carrots, 23.2ms\n",
      "Speed: 1.4ms preprocess, 23.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/127.jpg: 384x640 1 bottle, 1 carrot, 23.4ms\n",
      "Speed: 1.6ms preprocess, 23.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/128.jpg: 384x640 1 bottle, 3 carrots, 21.8ms\n",
      "Speed: 1.7ms preprocess, 21.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/129.jpg: 384x640 1 bottle, 5 carrots, 22.8ms\n",
      "Speed: 1.5ms preprocess, 22.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/130.jpg: 384x640 1 bottle, 2 carrots, 26.3ms\n",
      "Speed: 1.4ms preprocess, 26.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/131.jpg: 384x640 2 bottles, 1 carrot, 24.8ms\n",
      "Speed: 1.8ms preprocess, 24.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/132.jpg: 384x640 1 bottle, 4 carrots, 23.1ms\n",
      "Speed: 1.5ms preprocess, 23.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/133.jpg: 384x640 1 bottle, 1 carrot, 29.4ms\n",
      "Speed: 2.4ms preprocess, 29.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/134.jpg: 384x640 1 bottle, 31.1ms\n",
      "Speed: 1.6ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/135.jpg: 384x640 1 bottle, 45.5ms\n",
      "Speed: 1.9ms preprocess, 45.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/136.jpg: 384x640 1 bottle, 1 carrot, 25.3ms\n",
      "Speed: 1.6ms preprocess, 25.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/137.jpg: 384x640 1 bottle, 3 carrots, 23.4ms\n",
      "Speed: 2.1ms preprocess, 23.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/138.jpg: 384x640 1 bottle, 2 carrots, 21.3ms\n",
      "Speed: 1.8ms preprocess, 21.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/139.jpg: 384x640 3 carrots, 46.2ms\n",
      "Speed: 1.8ms preprocess, 46.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/140.jpg: 384x640 4 carrots, 1 donut, 23.3ms\n",
      "Speed: 2.3ms preprocess, 23.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/141.jpg: 384x640 3 carrots, 1 donut, 26.8ms\n",
      "Speed: 1.7ms preprocess, 26.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/142.jpg: 384x640 2 carrots, 25.6ms\n",
      "Speed: 1.8ms preprocess, 25.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/143.jpg: 384x640 1 carrot, 52.4ms\n",
      "Speed: 1.5ms preprocess, 52.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/144.jpg: 384x640 2 carrots, 26.7ms\n",
      "Speed: 1.8ms preprocess, 26.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/145.jpg: 384x640 2 carrots, 27.1ms\n",
      "Speed: 1.6ms preprocess, 27.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/146.jpg: 384x640 1 bottle, 1 spoon, 3 carrots, 1 donut, 36.0ms\n",
      "Speed: 1.7ms preprocess, 36.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/147.jpg: 384x640 1 bottle, 4 carrots, 30.0ms\n",
      "Speed: 1.8ms preprocess, 30.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/148.jpg: 384x640 3 carrots, 2 donuts, 23.6ms\n",
      "Speed: 1.5ms preprocess, 23.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/149.jpg: 384x640 1 bottle, 3 carrots, 29.6ms\n",
      "Speed: 1.6ms preprocess, 29.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/150.jpg: 384x640 1 spoon, 5 donuts, 24.0ms\n",
      "Speed: 1.9ms preprocess, 24.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/151.jpg: 384x640 1 bottle, 5 carrots, 25.7ms\n",
      "Speed: 1.7ms preprocess, 25.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/152.jpg: 384x640 1 bottle, 6 carrots, 24.0ms\n",
      "Speed: 1.5ms preprocess, 24.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/153.jpg: 384x640 1 bottle, 4 carrots, 27.2ms\n",
      "Speed: 1.7ms preprocess, 27.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/154.jpg: 384x640 1 bottle, 3 carrots, 27.0ms\n",
      "Speed: 3.0ms preprocess, 27.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/155.jpg: 384x640 1 baseball bat, 1 spoon, 3 carrots, 29.8ms\n",
      "Speed: 1.7ms preprocess, 29.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/156.jpg: 384x640 1 bottle, 25.9ms\n",
      "Speed: 1.4ms preprocess, 25.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/157.jpg: 384x640 1 bottle, 21.8ms\n",
      "Speed: 1.6ms preprocess, 21.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/158.jpg: 384x640 1 bottle, 2 carrots, 24.5ms\n",
      "Speed: 1.7ms preprocess, 24.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/159.jpg: 384x640 1 bottle, 2 carrots, 1 donut, 35.3ms\n",
      "Speed: 1.5ms preprocess, 35.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/160.jpg: 384x640 1 bottle, 3 carrots, 24.7ms\n",
      "Speed: 1.6ms preprocess, 24.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/161.jpg: 384x640 1 bottle, 4 carrots, 26.7ms\n",
      "Speed: 2.1ms preprocess, 26.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/162.jpg: 384x640 1 bottle, 5 carrots, 28.7ms\n",
      "Speed: 2.2ms preprocess, 28.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/163.jpg: 384x640 5 carrots, 27.2ms\n",
      "Speed: 1.6ms preprocess, 27.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/164.jpg: 384x640 1 bottle, 3 carrots, 1 donut, 24.0ms\n",
      "Speed: 1.7ms preprocess, 24.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/165.jpg: 384x640 3 carrots, 1 donut, 28.3ms\n",
      "Speed: 1.6ms preprocess, 28.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/166.jpg: 384x640 1 spoon, 2 carrots, 1 donut, 27.2ms\n",
      "Speed: 1.7ms preprocess, 27.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/167.jpg: 384x640 1 bottle, 2 carrots, 1 donut, 23.5ms\n",
      "Speed: 1.7ms preprocess, 23.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/168.jpg: 384x640 1 bottle, 2 carrots, 3 donuts, 27.2ms\n",
      "Speed: 1.6ms preprocess, 27.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/169.jpg: 384x640 1 knife, 1 donut, 23.0ms\n",
      "Speed: 1.5ms preprocess, 23.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/170.jpg: 384x640 1 knife, 1 spoon, 2 carrots, 22.4ms\n",
      "Speed: 1.5ms preprocess, 22.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/171.jpg: 384x640 1 knife, 1 carrot, 1 donut, 35.3ms\n",
      "Speed: 2.4ms preprocess, 35.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/172.jpg: 384x640 1 knife, 1 spoon, 1 donut, 40.9ms\n",
      "Speed: 1.8ms preprocess, 40.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/173.jpg: 384x640 1 carrot, 34.9ms\n",
      "Speed: 1.7ms preprocess, 34.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/174.jpg: 384x640 1 knife, 1 carrot, 22.2ms\n",
      "Speed: 1.8ms preprocess, 22.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/175.jpg: 384x640 1 spoon, 1 carrot, 24.9ms\n",
      "Speed: 1.9ms preprocess, 24.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/176.jpg: 384x640 1 carrot, 28.4ms\n",
      "Speed: 1.7ms preprocess, 28.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/177.jpg: 384x640 3 carrots, 36.6ms\n",
      "Speed: 2.0ms preprocess, 36.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/178.jpg: 384x640 2 carrots, 29.9ms\n",
      "Speed: 1.7ms preprocess, 29.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/179.jpg: 384x640 1 knife, 2 carrots, 33.1ms\n",
      "Speed: 1.7ms preprocess, 33.1ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/180.jpg: 384x640 1 baseball bat, 3 carrots, 23.3ms\n",
      "Speed: 1.6ms preprocess, 23.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/181.jpg: 384x640 1 carrot, 30.8ms\n",
      "Speed: 1.7ms preprocess, 30.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/182.jpg: 384x640 1 bottle, 1 carrot, 23.8ms\n",
      "Speed: 2.1ms preprocess, 23.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/183.jpg: 384x640 3 carrots, 24.9ms\n",
      "Speed: 1.7ms preprocess, 24.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/184.jpg: 384x640 2 carrots, 26.0ms\n",
      "Speed: 1.7ms preprocess, 26.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/185.jpg: 384x640 1 bottle, 1 carrot, 24.2ms\n",
      "Speed: 1.6ms preprocess, 24.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/186.jpg: 384x640 2 carrots, 1 donut, 27.5ms\n",
      "Speed: 1.7ms preprocess, 27.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/187.jpg: 384x640 1 carrot, 28.4ms\n",
      "Speed: 1.8ms preprocess, 28.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/188.jpg: 384x640 1 carrot, 1 donut, 25.4ms\n",
      "Speed: 1.8ms preprocess, 25.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/189.jpg: 384x640 1 carrot, 32.1ms\n",
      "Speed: 2.5ms preprocess, 32.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/190.jpg: 384x640 1 carrot, 22.5ms\n",
      "Speed: 1.4ms preprocess, 22.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/191.jpg: 384x640 5 carrots, 22.5ms\n",
      "Speed: 1.6ms preprocess, 22.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/192.jpg: 384x640 1 carrot, 27.1ms\n",
      "Speed: 1.7ms preprocess, 27.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/193.jpg: 384x640 2 carrots, 23.0ms\n",
      "Speed: 1.7ms preprocess, 23.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/194.jpg: 384x640 3 carrots, 33.1ms\n",
      "Speed: 1.6ms preprocess, 33.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/195.jpg: 384x640 2 carrots, 23.2ms\n",
      "Speed: 1.5ms preprocess, 23.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/196.jpg: 384x640 3 carrots, 23.8ms\n",
      "Speed: 4.1ms preprocess, 23.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/197.jpg: 384x640 3 carrots, 1 donut, 22.4ms\n",
      "Speed: 1.6ms preprocess, 22.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/198.jpg: 384x640 3 carrots, 23.2ms\n",
      "Speed: 1.8ms preprocess, 23.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/199.jpg: 384x640 3 carrots, 22.8ms\n",
      "Speed: 1.6ms preprocess, 22.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/200.jpg: 384x640 3 carrots, 1 donut, 24.9ms\n",
      "Speed: 1.7ms preprocess, 24.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/201.jpg: 384x640 3 carrots, 28.2ms\n",
      "Speed: 1.5ms preprocess, 28.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/202.jpg: 384x640 1 bottle, 1 fork, 4 carrots, 55.6ms\n",
      "Speed: 2.1ms preprocess, 55.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/203.jpg: 384x640 7 carrots, 23.2ms\n",
      "Speed: 1.5ms preprocess, 23.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/204.jpg: 384x640 4 carrots, 1 donut, 26.1ms\n",
      "Speed: 1.8ms preprocess, 26.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/205.jpg: 384x640 1 spoon, 2 carrots, 1 donut, 22.9ms\n",
      "Speed: 1.5ms preprocess, 22.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/206.jpg: 384x640 1 bottle, 1 carrot, 1 donut, 22.8ms\n",
      "Speed: 1.6ms preprocess, 22.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/207.jpg: 384x640 1 bottle, 4 carrots, 29.2ms\n",
      "Speed: 2.6ms preprocess, 29.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/208.jpg: 384x640 1 knife, 22.9ms\n",
      "Speed: 1.5ms preprocess, 22.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/209.jpg: 384x640 1 knife, 1 carrot, 24.4ms\n",
      "Speed: 1.7ms preprocess, 24.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/210.jpg: 384x640 1 carrot, 23.0ms\n",
      "Speed: 1.5ms preprocess, 23.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/211.jpg: 384x640 1 carrot, 23.7ms\n",
      "Speed: 2.1ms preprocess, 23.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/212.jpg: 384x640 1 carrot, 24.6ms\n",
      "Speed: 1.5ms preprocess, 24.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/213.jpg: 384x640 1 baseball bat, 1 bottle, 2 carrots, 1 donut, 29.6ms\n",
      "Speed: 1.7ms preprocess, 29.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/214.jpg: 384x640 1 knife, 1 carrot, 22.7ms\n",
      "Speed: 1.5ms preprocess, 22.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/215.jpg: 384x640 1 knife, 1 spoon, 4 carrots, 26.1ms\n",
      "Speed: 1.6ms preprocess, 26.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/216.jpg: 384x640 1 baseball bat, 4 carrots, 26.0ms\n",
      "Speed: 1.9ms preprocess, 26.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/217.jpg: 384x640 2 carrots, 1 donut, 34.5ms\n",
      "Speed: 2.8ms preprocess, 34.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/218.jpg: 384x640 1 carrot, 2 donuts, 21.7ms\n",
      "Speed: 1.6ms preprocess, 21.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/219.jpg: 384x640 2 carrots, 22.7ms\n",
      "Speed: 1.6ms preprocess, 22.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/220.jpg: 384x640 1 carrot, 21.7ms\n",
      "Speed: 1.9ms preprocess, 21.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/221.jpg: 384x640 3 carrots, 31.4ms\n",
      "Speed: 1.8ms preprocess, 31.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/222.jpg: 384x640 1 carrot, 1 donut, 23.2ms\n",
      "Speed: 1.5ms preprocess, 23.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/223.jpg: 384x640 1 carrot, 21.9ms\n",
      "Speed: 1.6ms preprocess, 21.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/224.jpg: 384x640 4 carrots, 27.1ms\n",
      "Speed: 1.7ms preprocess, 27.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/225.jpg: 384x640 2 carrots, 25.9ms\n",
      "Speed: 1.5ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/226.jpg: 384x640 1 bottle, 2 carrots, 29.8ms\n",
      "Speed: 1.5ms preprocess, 29.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/227.jpg: 384x640 1 spoon, 1 carrot, 23.8ms\n",
      "Speed: 1.5ms preprocess, 23.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/228.jpg: 384x640 1 carrot, 26.0ms\n",
      "Speed: 1.6ms preprocess, 26.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/229.jpg: 384x640 1 baseball bat, 1 bottle, 2 carrots, 31.6ms\n",
      "Speed: 1.7ms preprocess, 31.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/230.jpg: 384x640 1 baseball bat, 1 carrot, 24.7ms\n",
      "Speed: 1.5ms preprocess, 24.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/231.jpg: 384x640 1 baseball bat, 1 carrot, 25.1ms\n",
      "Speed: 1.9ms preprocess, 25.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/232.jpg: 384x640 1 carrot, 22.3ms\n",
      "Speed: 1.5ms preprocess, 22.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/233.jpg: 384x640 1 baseball bat, 3 carrots, 25.8ms\n",
      "Speed: 1.5ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/234.jpg: 384x640 1 baseball bat, 1 carrot, 26.4ms\n",
      "Speed: 1.5ms preprocess, 26.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/235.jpg: 384x640 1 baseball bat, 4 carrots, 23.6ms\n",
      "Speed: 2.0ms preprocess, 23.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/236.jpg: 384x640 1 spoon, 5 carrots, 24.8ms\n",
      "Speed: 1.6ms preprocess, 24.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/237.jpg: 384x640 1 spoon, 1 carrot, 21.9ms\n",
      "Speed: 1.7ms preprocess, 21.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/238.jpg: 384x640 1 spoon, 2 carrots, 34.0ms\n",
      "Speed: 1.7ms preprocess, 34.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/239.jpg: 384x640 1 spoon, 2 carrots, 23.2ms\n",
      "Speed: 2.0ms preprocess, 23.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/240.jpg: 384x640 1 spoon, 2 carrots, 23.5ms\n",
      "Speed: 1.6ms preprocess, 23.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/241.jpg: 384x640 1 baseball bat, 2 carrots, 23.0ms\n",
      "Speed: 1.6ms preprocess, 23.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/242.jpg: 384x640 1 baseball bat, 3 carrots, 26.2ms\n",
      "Speed: 1.8ms preprocess, 26.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/243.jpg: 384x640 3 carrots, 31.7ms\n",
      "Speed: 1.5ms preprocess, 31.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/244.jpg: 384x640 1 baseball bat, 3 carrots, 24.3ms\n",
      "Speed: 1.6ms preprocess, 24.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/245.jpg: 384x640 1 baseball bat, 2 carrots, 25.2ms\n",
      "Speed: 1.6ms preprocess, 25.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/246.jpg: 384x640 1 spoon, 4 carrots, 21.8ms\n",
      "Speed: 1.5ms preprocess, 21.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/247.jpg: 384x640 1 spoon, 1 carrot, 26.9ms\n",
      "Speed: 1.6ms preprocess, 26.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/248.jpg: 384x640 2 carrots, 22.3ms\n",
      "Speed: 2.5ms preprocess, 22.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/249.jpg: 384x640 1 bottle, 3 carrots, 37.7ms\n",
      "Speed: 1.6ms preprocess, 37.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/250.jpg: 384x640 1 bottle, 1 carrot, 31.0ms\n",
      "Speed: 2.3ms preprocess, 31.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/251.jpg: 384x640 1 bottle, 2 carrots, 24.2ms\n",
      "Speed: 1.5ms preprocess, 24.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/252.jpg: 384x640 4 carrots, 22.9ms\n",
      "Speed: 1.5ms preprocess, 22.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/253.jpg: 384x640 2 carrots, 24.2ms\n",
      "Speed: 1.8ms preprocess, 24.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/254.jpg: 384x640 1 baseball bat, 1 carrot, 23.1ms\n",
      "Speed: 1.5ms preprocess, 23.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/255.jpg: 384x640 1 knife, 1 carrot, 21.1ms\n",
      "Speed: 1.4ms preprocess, 21.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/256.jpg: 384x640 1 baseball bat, 1 knife, 1 carrot, 24.9ms\n",
      "Speed: 1.8ms preprocess, 24.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/257.jpg: 384x640 1 spoon, 4 carrots, 32.0ms\n",
      "Speed: 1.7ms preprocess, 32.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/258.jpg: 384x640 2 carrots, 39.6ms\n",
      "Speed: 2.0ms preprocess, 39.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/259.jpg: 384x640 2 baseball bats, 1 bottle, 2 carrots, 26.9ms\n",
      "Speed: 1.5ms preprocess, 26.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/260.jpg: 384x640 1 carrot, 22.6ms\n",
      "Speed: 1.6ms preprocess, 22.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/261.jpg: 384x640 1 bottle, 2 carrots, 24.0ms\n",
      "Speed: 2.0ms preprocess, 24.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/262.jpg: 384x640 1 carrot, 23.7ms\n",
      "Speed: 1.5ms preprocess, 23.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/263.jpg: 384x640 1 spoon, 2 carrots, 28.8ms\n",
      "Speed: 1.6ms preprocess, 28.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/264.jpg: 384x640 2 carrots, 24.3ms\n",
      "Speed: 1.9ms preprocess, 24.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/265.jpg: 384x640 4 carrots, 23.6ms\n",
      "Speed: 1.7ms preprocess, 23.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/266.jpg: 384x640 1 bottle, 5 carrots, 25.8ms\n",
      "Speed: 1.5ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/267.jpg: 384x640 1 bottle, 2 carrots, 29.2ms\n",
      "Speed: 2.9ms preprocess, 29.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/268.jpg: 384x640 2 carrots, 23.5ms\n",
      "Speed: 1.5ms preprocess, 23.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/269.jpg: 384x640 1 carrot, 26.6ms\n",
      "Speed: 1.6ms preprocess, 26.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/270.jpg: 384x640 1 carrot, 23.1ms\n",
      "Speed: 1.5ms preprocess, 23.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/271.jpg: 384x640 1 carrot, 26.2ms\n",
      "Speed: 1.7ms preprocess, 26.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/272.jpg: 384x640 4 carrots, 26.8ms\n",
      "Speed: 1.6ms preprocess, 26.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/273.jpg: 384x640 4 carrots, 3 donuts, 29.4ms\n",
      "Speed: 1.7ms preprocess, 29.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/274.jpg: 384x640 2 carrots, 30.5ms\n",
      "Speed: 1.6ms preprocess, 30.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/275.jpg: 384x640 2 carrots, 2 donuts, 38.6ms\n",
      "Speed: 5.4ms preprocess, 38.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/276.jpg: 384x640 4 carrots, 1 donut, 27.2ms\n",
      "Speed: 1.8ms preprocess, 27.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/277.jpg: 384x640 6 carrots, 25.7ms\n",
      "Speed: 1.6ms preprocess, 25.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/278.jpg: 384x640 1 spoon, 5 carrots, 33.0ms\n",
      "Speed: 1.6ms preprocess, 33.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/279.jpg: 384x640 2 carrots, 26.7ms\n",
      "Speed: 1.9ms preprocess, 26.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/280.jpg: 384x640 3 carrots, 26.6ms\n",
      "Speed: 1.5ms preprocess, 26.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/281.jpg: 384x640 3 carrots, 1 donut, 26.4ms\n",
      "Speed: 1.5ms preprocess, 26.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/282.jpg: 384x640 1 knife, 2 carrots, 25.6ms\n",
      "Speed: 1.7ms preprocess, 25.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/283.jpg: 384x640 1 baseball bat, 1 carrot, 28.5ms\n",
      "Speed: 1.8ms preprocess, 28.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/284.jpg: 384x640 1 bottle, 1 carrot, 34.7ms\n",
      "Speed: 3.5ms preprocess, 34.7ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/285.jpg: 384x640 1 bottle, 3 carrots, 35.9ms\n",
      "Speed: 2.3ms preprocess, 35.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/286.jpg: 384x640 1 baseball bat, 1 carrot, 37.0ms\n",
      "Speed: 1.8ms preprocess, 37.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/287.jpg: 384x640 1 baseball bat, 1 bottle, 5 carrots, 29.9ms\n",
      "Speed: 1.9ms preprocess, 29.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/288.jpg: 384x640 1 bottle, 3 carrots, 1 donut, 38.3ms\n",
      "Speed: 2.1ms preprocess, 38.3ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/289.jpg: 384x640 1 bottle, 6 carrots, 25.9ms\n",
      "Speed: 1.9ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/290.jpg: 384x640 1 baseball bat, 2 carrots, 37.7ms\n",
      "Speed: 1.9ms preprocess, 37.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/291.jpg: 384x640 1 carrot, 26.2ms\n",
      "Speed: 1.9ms preprocess, 26.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/292.jpg: 384x640 1 spoon, 4 carrots, 42.3ms\n",
      "Speed: 2.0ms preprocess, 42.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/293.jpg: 384x640 1 bottle, 1 carrot, 49.9ms\n",
      "Speed: 3.1ms preprocess, 49.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/294.jpg: 384x640 1 carrot, 34.1ms\n",
      "Speed: 2.6ms preprocess, 34.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/295.jpg: 384x640 1 carrot, 37.3ms\n",
      "Speed: 2.5ms preprocess, 37.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/296.jpg: 384x640 1 carrot, 29.4ms\n",
      "Speed: 2.0ms preprocess, 29.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/297.jpg: 384x640 2 carrots, 27.8ms\n",
      "Speed: 1.6ms preprocess, 27.8ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/298.jpg: 384x640 1 carrot, 43.5ms\n",
      "Speed: 2.3ms preprocess, 43.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/left/299.jpg: 384x640 1 bottle, 2 carrots, 34.4ms\n",
      "Speed: 1.9ms preprocess, 34.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Propagating video frames: 100%|| 300/300 [00:18<00:00, 16.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask propagation completed in 18.68 seconds.\n",
      "Processing predicted masks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing video frames: 300it [00:01, 155.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 300 masks for evaluation.\n",
      "Masks saved to data/masks/yolo11x-seg/val/data-raw-SegSTRONGC_val-val-1-2-blood-left.pkl\n",
      "Loading ground truth masks for evaluation...\n",
      "Loaded 300 ground truth masks.\n",
      "Calculating evaluation metrics...\n",
      "Time taken for metrics calculation: 1.55 seconds.\n",
      "Mean IoU for data/raw/SegSTRONGC_val/val/1/2/blood/left: 0.1169\n",
      "Mean DSC for data/raw/SegSTRONGC_val/val/1/2/blood/left: 0.2000\n",
      "Loading existing results file: data/results/yolo11x-seg/val.json\n",
      "Results saved to data/results/yolo11x-seg/val.json\n",
      "Processing video took 23.93 seconds.\n",
      "==================================================\n",
      "Processing right camera video...\n",
      "==================================================\n",
      "Processing video: data/raw/SegSTRONGC_val/val/1/2/blood/right\n",
      "Domain: blood, Split: val, Camera: right\n",
      "Initializing Yolo for video...\n",
      "Initialization took 0.14 seconds.\n",
      "Starting mask propagation...\n",
      "Total images in video: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/0.jpg: 384x640 1 bottle, 2 carrots, 30.3ms\n",
      "Speed: 2.4ms preprocess, 30.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/1.jpg: 384x640 1 carrot, 24.2ms\n",
      "Speed: 1.5ms preprocess, 24.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/2.jpg: 384x640 1 bottle, 1 carrot, 27.6ms\n",
      "Speed: 1.8ms preprocess, 27.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/3.jpg: 384x640 1 baseball bat, 2 bottles, 27.5ms\n",
      "Speed: 1.6ms preprocess, 27.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/4.jpg: 384x640 1 spoon, 1 carrot, 27.7ms\n",
      "Speed: 2.0ms preprocess, 27.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/5.jpg: 384x640 1 spoon, 1 carrot, 27.5ms\n",
      "Speed: 1.6ms preprocess, 27.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/6.jpg: 384x640 1 spoon, 3 carrots, 25.0ms\n",
      "Speed: 1.9ms preprocess, 25.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/7.jpg: 384x640 1 baseball bat, 2 carrots, 29.3ms\n",
      "Speed: 1.6ms preprocess, 29.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/8.jpg: 384x640 1 bottle, 1 carrot, 36.2ms\n",
      "Speed: 1.9ms preprocess, 36.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/9.jpg: 384x640 1 spoon, 1 carrot, 24.4ms\n",
      "Speed: 1.9ms preprocess, 24.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/10.jpg: 384x640 1 fork, 1 spoon, 3 carrots, 31.1ms\n",
      "Speed: 2.9ms preprocess, 31.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/11.jpg: 384x640 1 bottle, 1 carrot, 22.3ms\n",
      "Speed: 1.6ms preprocess, 22.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/12.jpg: 384x640 1 carrot, 21.8ms\n",
      "Speed: 1.5ms preprocess, 21.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/13.jpg: 384x640 1 bottle, 1 spoon, 1 carrot, 24.1ms\n",
      "Speed: 1.5ms preprocess, 24.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/14.jpg: 384x640 1 spoon, 31.4ms\n",
      "Speed: 1.9ms preprocess, 31.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/15.jpg: 384x640 1 bottle, 2 carrots, 23.7ms\n",
      "Speed: 1.6ms preprocess, 23.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/16.jpg: 384x640 1 bottle, 1 carrot, 24.4ms\n",
      "Speed: 2.1ms preprocess, 24.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/17.jpg: 384x640 3 carrots, 1 toothbrush, 22.1ms\n",
      "Speed: 1.5ms preprocess, 22.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/18.jpg: 384x640 1 fork, 2 carrots, 23.3ms\n",
      "Speed: 1.5ms preprocess, 23.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/19.jpg: 384x640 2 carrots, 26.7ms\n",
      "Speed: 1.9ms preprocess, 26.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/20.jpg: 384x640 1 fork, 4 carrots, 23.9ms\n",
      "Speed: 1.6ms preprocess, 23.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/21.jpg: 384x640 1 fork, 1 spoon, 5 carrots, 34.7ms\n",
      "Speed: 1.6ms preprocess, 34.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/22.jpg: 384x640 6 carrots, 28.4ms\n",
      "Speed: 1.7ms preprocess, 28.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/23.jpg: 384x640 1 fork, 4 carrots, 23.0ms\n",
      "Speed: 1.5ms preprocess, 23.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/24.jpg: 384x640 1 bottle, 1 fork, 1 spoon, 3 carrots, 24.3ms\n",
      "Speed: 1.6ms preprocess, 24.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/25.jpg: 384x640 1 fork, 6 carrots, 22.8ms\n",
      "Speed: 1.6ms preprocess, 22.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/26.jpg: 384x640 1 fork, 6 carrots, 25.1ms\n",
      "Speed: 1.5ms preprocess, 25.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/27.jpg: 384x640 1 bottle, 1 fork, 6 carrots, 34.0ms\n",
      "Speed: 1.6ms preprocess, 34.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/28.jpg: 384x640 1 bottle, 1 fork, 1 spoon, 3 carrots, 21.7ms\n",
      "Speed: 1.7ms preprocess, 21.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/29.jpg: 384x640 1 fork, 4 carrots, 24.4ms\n",
      "Speed: 2.0ms preprocess, 24.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/30.jpg: 384x640 1 fork, 5 carrots, 33.1ms\n",
      "Speed: 1.7ms preprocess, 33.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/31.jpg: 384x640 1 fork, 4 carrots, 22.3ms\n",
      "Speed: 1.5ms preprocess, 22.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/32.jpg: 384x640 1 fork, 1 spoon, 4 carrots, 24.9ms\n",
      "Speed: 1.6ms preprocess, 24.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/33.jpg: 384x640 1 fork, 1 spoon, 1 carrot, 22.9ms\n",
      "Speed: 1.5ms preprocess, 22.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/34.jpg: 384x640 1 fork, 1 spoon, 5 carrots, 22.5ms\n",
      "Speed: 1.8ms preprocess, 22.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/35.jpg: 384x640 1 fork, 2 spoons, 3 carrots, 21.9ms\n",
      "Speed: 1.4ms preprocess, 21.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/36.jpg: 384x640 1 fork, 1 spoon, 7 carrots, 22.8ms\n",
      "Speed: 1.5ms preprocess, 22.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/37.jpg: 384x640 1 spoon, 4 carrots, 22.9ms\n",
      "Speed: 1.7ms preprocess, 22.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/38.jpg: 384x640 1 fork, 3 carrots, 24.6ms\n",
      "Speed: 1.9ms preprocess, 24.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/39.jpg: 384x640 2 carrots, 24.6ms\n",
      "Speed: 1.4ms preprocess, 24.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/40.jpg: 384x640 1 bottle, 2 carrots, 21.6ms\n",
      "Speed: 1.6ms preprocess, 21.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/41.jpg: 384x640 1 carrot, 26.1ms\n",
      "Speed: 2.3ms preprocess, 26.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/42.jpg: 384x640 1 baseball bat, 1 spoon, 3 carrots, 21.3ms\n",
      "Speed: 1.6ms preprocess, 21.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/43.jpg: 384x640 1 spoon, 1 carrot, 22.6ms\n",
      "Speed: 1.5ms preprocess, 22.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/44.jpg: 384x640 1 baseball bat, 1 spoon, 2 carrots, 23.5ms\n",
      "Speed: 1.5ms preprocess, 23.5ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/45.jpg: 384x640 3 carrots, 22.2ms\n",
      "Speed: 1.5ms preprocess, 22.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/46.jpg: 384x640 1 spoon, 4 carrots, 21.5ms\n",
      "Speed: 1.5ms preprocess, 21.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/47.jpg: 384x640 1 bottle, 4 carrots, 28.4ms\n",
      "Speed: 1.5ms preprocess, 28.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/48.jpg: 384x640 6 carrots, 23.5ms\n",
      "Speed: 1.6ms preprocess, 23.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/49.jpg: 384x640 2 carrots, 22.1ms\n",
      "Speed: 1.5ms preprocess, 22.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/50.jpg: 384x640 1 spoon, 2 carrots, 25.5ms\n",
      "Speed: 1.7ms preprocess, 25.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/51.jpg: 384x640 2 carrots, 21.4ms\n",
      "Speed: 1.6ms preprocess, 21.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/52.jpg: 384x640 1 carrot, 28.9ms\n",
      "Speed: 1.8ms preprocess, 28.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/53.jpg: 384x640 1 carrot, 29.6ms\n",
      "Speed: 1.7ms preprocess, 29.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/54.jpg: 384x640 1 carrot, 22.6ms\n",
      "Speed: 1.5ms preprocess, 22.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/55.jpg: 384x640 1 spoon, 2 carrots, 24.2ms\n",
      "Speed: 1.6ms preprocess, 24.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/56.jpg: 384x640 1 bottle, 2 carrots, 23.7ms\n",
      "Speed: 1.6ms preprocess, 23.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/57.jpg: 384x640 1 baseball bat, 1 bottle, 3 carrots, 23.7ms\n",
      "Speed: 1.6ms preprocess, 23.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/58.jpg: 384x640 1 bottle, 4 carrots, 21.6ms\n",
      "Speed: 1.5ms preprocess, 21.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/59.jpg: 384x640 1 spoon, 3 carrots, 33.0ms\n",
      "Speed: 1.6ms preprocess, 33.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/60.jpg: 384x640 1 bottle, 5 carrots, 22.7ms\n",
      "Speed: 1.6ms preprocess, 22.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/61.jpg: 384x640 6 carrots, 22.7ms\n",
      "Speed: 1.6ms preprocess, 22.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/62.jpg: 384x640 1 carrot, 24.3ms\n",
      "Speed: 1.5ms preprocess, 24.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/63.jpg: 384x640 1 baseball bat, 1 carrot, 1 toothbrush, 23.8ms\n",
      "Speed: 1.6ms preprocess, 23.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/64.jpg: 384x640 1 bottle, 3 carrots, 21.4ms\n",
      "Speed: 1.7ms preprocess, 21.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/65.jpg: 384x640 5 carrots, 21.6ms\n",
      "Speed: 1.8ms preprocess, 21.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/66.jpg: 384x640 2 carrots, 24.0ms\n",
      "Speed: 2.1ms preprocess, 24.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/67.jpg: 384x640 2 carrots, 25.9ms\n",
      "Speed: 1.6ms preprocess, 25.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/68.jpg: 384x640 6 carrots, 25.6ms\n",
      "Speed: 1.6ms preprocess, 25.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/69.jpg: 384x640 4 carrots, 42.0ms\n",
      "Speed: 1.8ms preprocess, 42.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/70.jpg: 384x640 1 bottle, 5 carrots, 24.8ms\n",
      "Speed: 1.6ms preprocess, 24.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/71.jpg: 384x640 1 fork, 4 carrots, 29.2ms\n",
      "Speed: 1.9ms preprocess, 29.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/72.jpg: 384x640 1 fork, 1 spoon, 5 carrots, 22.2ms\n",
      "Speed: 1.6ms preprocess, 22.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/73.jpg: 384x640 1 bottle, 1 spoon, 7 carrots, 25.2ms\n",
      "Speed: 1.8ms preprocess, 25.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/74.jpg: 384x640 1 bottle, 1 spoon, 6 carrots, 23.7ms\n",
      "Speed: 1.6ms preprocess, 23.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/75.jpg: 384x640 1 bottle, 5 carrots, 27.5ms\n",
      "Speed: 1.6ms preprocess, 27.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/76.jpg: 384x640 1 bottle, 9 carrots, 23.4ms\n",
      "Speed: 1.6ms preprocess, 23.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/77.jpg: 384x640 1 bottle, 8 carrots, 40.2ms\n",
      "Speed: 1.8ms preprocess, 40.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/78.jpg: 384x640 1 spoon, 4 carrots, 24.1ms\n",
      "Speed: 1.7ms preprocess, 24.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/79.jpg: 384x640 1 bottle, 1 spoon, 5 carrots, 23.3ms\n",
      "Speed: 1.7ms preprocess, 23.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/80.jpg: 384x640 1 bottle, 4 carrots, 23.1ms\n",
      "Speed: 1.7ms preprocess, 23.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/81.jpg: 384x640 1 bottle, 4 carrots, 25.9ms\n",
      "Speed: 1.7ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/82.jpg: 384x640 1 bottle, 1 spoon, 4 carrots, 22.6ms\n",
      "Speed: 1.5ms preprocess, 22.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/83.jpg: 384x640 1 bottle, 5 carrots, 29.5ms\n",
      "Speed: 1.8ms preprocess, 29.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/84.jpg: 384x640 1 spoon, 6 carrots, 27.1ms\n",
      "Speed: 1.7ms preprocess, 27.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/85.jpg: 384x640 1 bottle, 5 carrots, 34.7ms\n",
      "Speed: 1.9ms preprocess, 34.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/86.jpg: 384x640 1 bottle, 4 carrots, 28.1ms\n",
      "Speed: 3.1ms preprocess, 28.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/87.jpg: 384x640 1 bottle, 1 spoon, 6 carrots, 26.2ms\n",
      "Speed: 1.8ms preprocess, 26.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/88.jpg: 384x640 3 carrots, 28.2ms\n",
      "Speed: 1.8ms preprocess, 28.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/89.jpg: 384x640 1 bottle, 3 carrots, 26.7ms\n",
      "Speed: 1.6ms preprocess, 26.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/90.jpg: 384x640 1 bottle, 2 carrots, 24.7ms\n",
      "Speed: 1.6ms preprocess, 24.7ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/91.jpg: 384x640 1 bottle, 3 carrots, 29.2ms\n",
      "Speed: 1.9ms preprocess, 29.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/92.jpg: 384x640 1 bottle, 4 carrots, 24.0ms\n",
      "Speed: 1.6ms preprocess, 24.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/93.jpg: 384x640 1 bottle, 1 spoon, 6 carrots, 24.9ms\n",
      "Speed: 1.5ms preprocess, 24.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/94.jpg: 384x640 1 bottle, 8 carrots, 22.9ms\n",
      "Speed: 1.6ms preprocess, 22.9ms inference, 7.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/95.jpg: 384x640 1 bottle, 5 carrots, 24.3ms\n",
      "Speed: 1.7ms preprocess, 24.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/96.jpg: 384x640 1 bottle, 6 carrots, 27.4ms\n",
      "Speed: 2.0ms preprocess, 27.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/97.jpg: 384x640 1 bottle, 4 carrots, 28.3ms\n",
      "Speed: 1.7ms preprocess, 28.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/98.jpg: 384x640 1 bottle, 1 spoon, 2 carrots, 25.7ms\n",
      "Speed: 1.6ms preprocess, 25.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/99.jpg: 384x640 1 bottle, 1 spoon, 2 carrots, 28.5ms\n",
      "Speed: 1.8ms preprocess, 28.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/100.jpg: 384x640 2 bottles, 1 carrot, 29.0ms\n",
      "Speed: 1.8ms preprocess, 29.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/101.jpg: 384x640 1 bottle, 1 carrot, 23.3ms\n",
      "Speed: 1.5ms preprocess, 23.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/102.jpg: 384x640 1 bottle, 1 spoon, 3 carrots, 25.8ms\n",
      "Speed: 1.7ms preprocess, 25.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/103.jpg: 384x640 1 bottle, 1 spoon, 4 carrots, 25.2ms\n",
      "Speed: 1.6ms preprocess, 25.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/104.jpg: 384x640 1 bottle, 1 spoon, 3 carrots, 38.0ms\n",
      "Speed: 1.5ms preprocess, 38.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/105.jpg: 384x640 1 bottle, 4 carrots, 28.1ms\n",
      "Speed: 1.6ms preprocess, 28.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/106.jpg: 384x640 1 bottle, 4 carrots, 26.5ms\n",
      "Speed: 1.7ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/107.jpg: 384x640 1 bottle, 1 spoon, 3 carrots, 34.3ms\n",
      "Speed: 2.0ms preprocess, 34.3ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/108.jpg: 384x640 1 bottle, 1 carrot, 25.1ms\n",
      "Speed: 1.7ms preprocess, 25.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/109.jpg: 384x640 1 bottle, 1 spoon, 1 carrot, 27.4ms\n",
      "Speed: 1.5ms preprocess, 27.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/110.jpg: 384x640 2 bottles, 3 carrots, 23.1ms\n",
      "Speed: 1.7ms preprocess, 23.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/111.jpg: 384x640 1 bottle, 2 carrots, 27.8ms\n",
      "Speed: 1.6ms preprocess, 27.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/112.jpg: 384x640 2 bottles, 2 carrots, 28.1ms\n",
      "Speed: 1.8ms preprocess, 28.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/113.jpg: 384x640 1 bottle, 3 carrots, 25.2ms\n",
      "Speed: 1.8ms preprocess, 25.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/114.jpg: 384x640 2 bottles, 3 carrots, 32.7ms\n",
      "Speed: 1.6ms preprocess, 32.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/115.jpg: 384x640 2 bottles, 3 carrots, 28.1ms\n",
      "Speed: 1.5ms preprocess, 28.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/116.jpg: 384x640 2 bottles, 1 spoon, 1 carrot, 52.3ms\n",
      "Speed: 1.9ms preprocess, 52.3ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/117.jpg: 384x640 1 bottle, 1 spoon, 2 carrots, 31.1ms\n",
      "Speed: 1.7ms preprocess, 31.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/118.jpg: 384x640 1 bottle, 1 spoon, 2 carrots, 23.6ms\n",
      "Speed: 1.6ms preprocess, 23.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/119.jpg: 384x640 1 bottle, 1 spoon, 2 carrots, 32.2ms\n",
      "Speed: 1.9ms preprocess, 32.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/120.jpg: 384x640 1 bottle, 1 spoon, 3 carrots, 25.5ms\n",
      "Speed: 1.5ms preprocess, 25.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/121.jpg: 384x640 1 bottle, 1 spoon, 2 carrots, 31.6ms\n",
      "Speed: 1.7ms preprocess, 31.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/122.jpg: 384x640 1 bottle, 1 spoon, 3 carrots, 26.7ms\n",
      "Speed: 1.7ms preprocess, 26.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/123.jpg: 384x640 1 bottle, 1 spoon, 7 carrots, 26.1ms\n",
      "Speed: 1.6ms preprocess, 26.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/124.jpg: 384x640 2 spoons, 7 carrots, 41.4ms\n",
      "Speed: 5.1ms preprocess, 41.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/125.jpg: 384x640 1 bottle, 1 spoon, 5 carrots, 27.9ms\n",
      "Speed: 2.4ms preprocess, 27.9ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/126.jpg: 384x640 1 bottle, 1 spoon, 5 carrots, 26.5ms\n",
      "Speed: 1.9ms preprocess, 26.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/127.jpg: 384x640 1 bottle, 6 carrots, 34.0ms\n",
      "Speed: 2.2ms preprocess, 34.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/128.jpg: 384x640 1 bottle, 5 carrots, 40.0ms\n",
      "Speed: 2.2ms preprocess, 40.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/129.jpg: 384x640 1 bottle, 4 carrots, 43.2ms\n",
      "Speed: 2.7ms preprocess, 43.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/130.jpg: 384x640 1 bottle, 1 spoon, 1 carrot, 31.1ms\n",
      "Speed: 1.8ms preprocess, 31.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/131.jpg: 384x640 1 bottle, 1 carrot, 29.9ms\n",
      "Speed: 1.6ms preprocess, 29.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/132.jpg: 384x640 2 bottles, 5 carrots, 30.0ms\n",
      "Speed: 3.0ms preprocess, 30.0ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/133.jpg: 384x640 1 spoon, 2 carrots, 27.4ms\n",
      "Speed: 1.8ms preprocess, 27.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/134.jpg: 384x640 1 bottle, 1 spoon, 3 carrots, 24.4ms\n",
      "Speed: 2.0ms preprocess, 24.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/135.jpg: 384x640 1 bottle, 1 spoon, 5 carrots, 24.6ms\n",
      "Speed: 1.7ms preprocess, 24.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/136.jpg: 384x640 1 spoon, 4 carrots, 44.2ms\n",
      "Speed: 1.5ms preprocess, 44.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/137.jpg: 384x640 1 bottle, 1 spoon, 2 carrots, 29.5ms\n",
      "Speed: 1.9ms preprocess, 29.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/138.jpg: 384x640 1 spoon, 7 carrots, 28.8ms\n",
      "Speed: 1.6ms preprocess, 28.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/139.jpg: 384x640 1 spoon, 6 carrots, 35.4ms\n",
      "Speed: 1.7ms preprocess, 35.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/140.jpg: 384x640 1 baseball bat, 4 carrots, 27.2ms\n",
      "Speed: 1.8ms preprocess, 27.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/141.jpg: 384x640 1 spoon, 6 carrots, 26.2ms\n",
      "Speed: 1.6ms preprocess, 26.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/142.jpg: 384x640 2 carrots, 23.8ms\n",
      "Speed: 1.5ms preprocess, 23.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/143.jpg: 384x640 1 spoon, 5 carrots, 23.3ms\n",
      "Speed: 2.1ms preprocess, 23.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/144.jpg: 384x640 1 carrot, 28.5ms\n",
      "Speed: 1.6ms preprocess, 28.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/145.jpg: 384x640 1 spoon, 6 carrots, 42.9ms\n",
      "Speed: 1.9ms preprocess, 42.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/146.jpg: 384x640 3 carrots, 1 toothbrush, 23.5ms\n",
      "Speed: 1.6ms preprocess, 23.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/147.jpg: 384x640 1 carrot, 1 toothbrush, 30.1ms\n",
      "Speed: 1.7ms preprocess, 30.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/148.jpg: 384x640 1 bottle, 3 carrots, 27.2ms\n",
      "Speed: 1.5ms preprocess, 27.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/149.jpg: 384x640 1 bottle, 3 carrots, 36.6ms\n",
      "Speed: 2.5ms preprocess, 36.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/150.jpg: 384x640 1 bottle, 1 spoon, 3 carrots, 29.2ms\n",
      "Speed: 2.9ms preprocess, 29.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/151.jpg: 384x640 1 bottle, 7 carrots, 24.4ms\n",
      "Speed: 1.6ms preprocess, 24.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/152.jpg: 384x640 1 bottle, 5 carrots, 39.1ms\n",
      "Speed: 1.5ms preprocess, 39.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/153.jpg: 384x640 1 bottle, 1 spoon, 5 carrots, 27.7ms\n",
      "Speed: 1.6ms preprocess, 27.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/154.jpg: 384x640 1 spoon, 4 carrots, 28.4ms\n",
      "Speed: 1.5ms preprocess, 28.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/155.jpg: 384x640 1 spoon, 4 carrots, 23.6ms\n",
      "Speed: 1.4ms preprocess, 23.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/156.jpg: 384x640 1 bottle, 2 carrots, 28.8ms\n",
      "Speed: 1.8ms preprocess, 28.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/157.jpg: 384x640 1 bottle, 3 carrots, 33.2ms\n",
      "Speed: 1.7ms preprocess, 33.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/158.jpg: 384x640 1 bottle, 4 carrots, 36.7ms\n",
      "Speed: 1.6ms preprocess, 36.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/159.jpg: 384x640 1 bottle, 4 carrots, 25.3ms\n",
      "Speed: 1.9ms preprocess, 25.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/160.jpg: 384x640 1 spoon, 3 carrots, 27.0ms\n",
      "Speed: 1.6ms preprocess, 27.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/161.jpg: 384x640 1 baseball bat, 1 bottle, 4 carrots, 22.4ms\n",
      "Speed: 1.5ms preprocess, 22.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/162.jpg: 384x640 1 bottle, 1 spoon, 4 carrots, 26.6ms\n",
      "Speed: 1.6ms preprocess, 26.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/163.jpg: 384x640 1 bottle, 1 spoon, 3 carrots, 45.2ms\n",
      "Speed: 2.1ms preprocess, 45.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/164.jpg: 384x640 2 bottles, 3 carrots, 31.9ms\n",
      "Speed: 1.8ms preprocess, 31.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/165.jpg: 384x640 1 baseball bat, 1 bottle, 1 spoon, 5 carrots, 27.5ms\n",
      "Speed: 2.0ms preprocess, 27.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/166.jpg: 384x640 1 bottle, 5 carrots, 29.1ms\n",
      "Speed: 1.6ms preprocess, 29.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/167.jpg: 384x640 1 bottle, 5 carrots, 35.2ms\n",
      "Speed: 1.7ms preprocess, 35.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/168.jpg: 384x640 1 bottle, 4 carrots, 39.5ms\n",
      "Speed: 2.0ms preprocess, 39.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/169.jpg: 384x640 1 bottle, 2 spoons, 5 carrots, 29.6ms\n",
      "Speed: 1.8ms preprocess, 29.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/170.jpg: 384x640 2 spoons, 6 carrots, 26.8ms\n",
      "Speed: 1.7ms preprocess, 26.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/171.jpg: 384x640 2 spoons, 6 carrots, 32.1ms\n",
      "Speed: 1.9ms preprocess, 32.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/172.jpg: 384x640 1 spoon, 3 carrots, 22.6ms\n",
      "Speed: 1.5ms preprocess, 22.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/173.jpg: 384x640 1 spoon, 2 carrots, 24.4ms\n",
      "Speed: 1.6ms preprocess, 24.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/174.jpg: 384x640 1 baseball bat, 1 spoon, 5 carrots, 31.9ms\n",
      "Speed: 1.8ms preprocess, 31.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/175.jpg: 384x640 1 baseball bat, 1 spoon, 3 carrots, 33.0ms\n",
      "Speed: 1.7ms preprocess, 33.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/176.jpg: 384x640 1 baseball bat, 1 spoon, 5 carrots, 32.5ms\n",
      "Speed: 1.6ms preprocess, 32.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/177.jpg: 384x640 1 baseball bat, 1 spoon, 5 carrots, 29.9ms\n",
      "Speed: 1.9ms preprocess, 29.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/178.jpg: 384x640 1 bottle, 1 spoon, 2 carrots, 32.4ms\n",
      "Speed: 2.5ms preprocess, 32.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/179.jpg: 384x640 1 baseball bat, 2 carrots, 34.1ms\n",
      "Speed: 1.7ms preprocess, 34.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/180.jpg: 384x640 3 carrots, 31.0ms\n",
      "Speed: 1.8ms preprocess, 31.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/181.jpg: 384x640 2 spoons, 3 carrots, 28.8ms\n",
      "Speed: 1.6ms preprocess, 28.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/182.jpg: 384x640 1 spoon, 6 carrots, 27.8ms\n",
      "Speed: 1.9ms preprocess, 27.8ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/183.jpg: 384x640 1 bottle, 1 spoon, 7 carrots, 32.1ms\n",
      "Speed: 4.7ms preprocess, 32.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/184.jpg: 384x640 1 bottle, 1 spoon, 6 carrots, 26.6ms\n",
      "Speed: 1.8ms preprocess, 26.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/185.jpg: 384x640 1 bottle, 1 spoon, 5 carrots, 42.5ms\n",
      "Speed: 1.8ms preprocess, 42.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/186.jpg: 384x640 1 spoon, 6 carrots, 39.1ms\n",
      "Speed: 1.8ms preprocess, 39.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/187.jpg: 384x640 1 fork, 1 spoon, 4 carrots, 23.0ms\n",
      "Speed: 1.4ms preprocess, 23.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/188.jpg: 384x640 1 fork, 1 spoon, 5 carrots, 24.3ms\n",
      "Speed: 1.7ms preprocess, 24.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/189.jpg: 384x640 1 fork, 1 spoon, 5 carrots, 47.6ms\n",
      "Speed: 1.7ms preprocess, 47.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/190.jpg: 384x640 1 spoon, 5 carrots, 27.7ms\n",
      "Speed: 1.6ms preprocess, 27.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/191.jpg: 384x640 2 spoons, 4 carrots, 28.0ms\n",
      "Speed: 1.6ms preprocess, 28.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/192.jpg: 384x640 2 spoons, 7 carrots, 24.5ms\n",
      "Speed: 1.7ms preprocess, 24.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/193.jpg: 384x640 1 fork, 2 spoons, 3 carrots, 26.1ms\n",
      "Speed: 1.5ms preprocess, 26.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/194.jpg: 384x640 1 fork, 1 spoon, 4 carrots, 22.5ms\n",
      "Speed: 1.5ms preprocess, 22.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/195.jpg: 384x640 1 spoon, 4 carrots, 28.8ms\n",
      "Speed: 2.5ms preprocess, 28.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/196.jpg: 384x640 1 spoon, 4 carrots, 27.4ms\n",
      "Speed: 1.6ms preprocess, 27.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/197.jpg: 384x640 3 carrots, 30.8ms\n",
      "Speed: 1.8ms preprocess, 30.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/198.jpg: 384x640 1 bottle, 6 carrots, 26.1ms\n",
      "Speed: 1.7ms preprocess, 26.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/199.jpg: 384x640 1 bottle, 4 carrots, 37.0ms\n",
      "Speed: 2.1ms preprocess, 37.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/200.jpg: 384x640 4 carrots, 27.5ms\n",
      "Speed: 1.5ms preprocess, 27.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/201.jpg: 384x640 1 bottle, 5 carrots, 23.4ms\n",
      "Speed: 1.5ms preprocess, 23.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/202.jpg: 384x640 1 bottle, 9 carrots, 27.7ms\n",
      "Speed: 1.7ms preprocess, 27.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/203.jpg: 384x640 1 bottle, 6 carrots, 22.6ms\n",
      "Speed: 1.6ms preprocess, 22.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/204.jpg: 384x640 1 bottle, 5 carrots, 26.7ms\n",
      "Speed: 1.5ms preprocess, 26.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/205.jpg: 384x640 2 spoons, 5 carrots, 28.4ms\n",
      "Speed: 1.7ms preprocess, 28.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/206.jpg: 384x640 1 bottle, 1 spoon, 4 carrots, 34.1ms\n",
      "Speed: 1.5ms preprocess, 34.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/207.jpg: 384x640 1 fork, 1 knife, 1 spoon, 3 carrots, 26.5ms\n",
      "Speed: 1.8ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/208.jpg: 384x640 1 fork, 1 knife, 1 carrot, 23.1ms\n",
      "Speed: 1.8ms preprocess, 23.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/209.jpg: 384x640 1 knife, 5 carrots, 27.9ms\n",
      "Speed: 1.5ms preprocess, 27.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/210.jpg: 384x640 1 bottle, 1 spoon, 5 carrots, 48.0ms\n",
      "Speed: 1.8ms preprocess, 48.0ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/211.jpg: 384x640 1 spoon, 5 carrots, 35.1ms\n",
      "Speed: 1.7ms preprocess, 35.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/212.jpg: 384x640 1 spoon, 5 carrots, 23.2ms\n",
      "Speed: 1.6ms preprocess, 23.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/213.jpg: 384x640 1 spoon, 5 carrots, 22.7ms\n",
      "Speed: 1.5ms preprocess, 22.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/214.jpg: 384x640 1 fork, 5 carrots, 35.6ms\n",
      "Speed: 1.9ms preprocess, 35.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/215.jpg: 384x640 3 carrots, 42.4ms\n",
      "Speed: 1.7ms preprocess, 42.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/216.jpg: 384x640 1 spoon, 3 carrots, 27.8ms\n",
      "Speed: 1.7ms preprocess, 27.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/217.jpg: 384x640 1 spoon, 3 carrots, 28.3ms\n",
      "Speed: 1.9ms preprocess, 28.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/218.jpg: 384x640 1 spoon, 5 carrots, 23.4ms\n",
      "Speed: 1.4ms preprocess, 23.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/219.jpg: 384x640 1 carrot, 30.7ms\n",
      "Speed: 1.6ms preprocess, 30.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/220.jpg: 384x640 2 carrots, 22.2ms\n",
      "Speed: 1.7ms preprocess, 22.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/221.jpg: 384x640 1 fork, 1 spoon, 6 carrots, 22.7ms\n",
      "Speed: 1.4ms preprocess, 22.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/222.jpg: 384x640 1 bottle, 1 spoon, 7 carrots, 29.6ms\n",
      "Speed: 1.5ms preprocess, 29.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/223.jpg: 384x640 1 bottle, 1 spoon, 7 carrots, 33.7ms\n",
      "Speed: 1.4ms preprocess, 33.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/224.jpg: 384x640 1 spoon, 7 carrots, 22.5ms\n",
      "Speed: 1.6ms preprocess, 22.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/225.jpg: 384x640 1 bottle, 1 spoon, 6 carrots, 23.8ms\n",
      "Speed: 1.6ms preprocess, 23.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/226.jpg: 384x640 1 spoon, 3 carrots, 29.0ms\n",
      "Speed: 1.6ms preprocess, 29.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/227.jpg: 384x640 2 spoons, 8 carrots, 23.5ms\n",
      "Speed: 1.7ms preprocess, 23.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/228.jpg: 384x640 1 bottle, 1 spoon, 2 carrots, 23.0ms\n",
      "Speed: 1.6ms preprocess, 23.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/229.jpg: 384x640 1 spoon, 4 carrots, 22.0ms\n",
      "Speed: 1.6ms preprocess, 22.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/230.jpg: 384x640 1 bottle, 2 spoons, 5 carrots, 25.3ms\n",
      "Speed: 1.5ms preprocess, 25.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/231.jpg: 384x640 1 bottle, 1 spoon, 5 carrots, 27.8ms\n",
      "Speed: 1.8ms preprocess, 27.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/232.jpg: 384x640 2 spoons, 1 carrot, 23.6ms\n",
      "Speed: 3.1ms preprocess, 23.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/233.jpg: 384x640 2 spoons, 4 carrots, 21.9ms\n",
      "Speed: 1.6ms preprocess, 21.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/234.jpg: 384x640 1 spoon, 5 carrots, 22.0ms\n",
      "Speed: 1.5ms preprocess, 22.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/235.jpg: 384x640 1 spoon, 2 carrots, 22.5ms\n",
      "Speed: 1.4ms preprocess, 22.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/236.jpg: 384x640 1 spoon, 2 carrots, 21.5ms\n",
      "Speed: 1.9ms preprocess, 21.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/237.jpg: 384x640 1 spoon, 3 carrots, 21.9ms\n",
      "Speed: 1.4ms preprocess, 21.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/238.jpg: 384x640 1 spoon, 1 carrot, 22.5ms\n",
      "Speed: 1.8ms preprocess, 22.5ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/239.jpg: 384x640 1 spoon, 5 carrots, 28.3ms\n",
      "Speed: 1.6ms preprocess, 28.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/240.jpg: 384x640 1 spoon, 1 carrot, 23.0ms\n",
      "Speed: 1.6ms preprocess, 23.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/241.jpg: 384x640 2 spoons, 5 carrots, 23.8ms\n",
      "Speed: 1.5ms preprocess, 23.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/242.jpg: 384x640 1 spoon, 4 carrots, 22.5ms\n",
      "Speed: 1.6ms preprocess, 22.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/243.jpg: 384x640 1 baseball bat, 1 spoon, 4 carrots, 23.6ms\n",
      "Speed: 1.7ms preprocess, 23.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/244.jpg: 384x640 3 carrots, 22.1ms\n",
      "Speed: 1.9ms preprocess, 22.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/245.jpg: 384x640 2 spoons, 2 carrots, 26.0ms\n",
      "Speed: 1.5ms preprocess, 26.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/246.jpg: 384x640 1 bottle, 1 spoon, 3 carrots, 22.1ms\n",
      "Speed: 1.7ms preprocess, 22.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/247.jpg: 384x640 1 bottle, 1 spoon, 6 carrots, 21.5ms\n",
      "Speed: 1.4ms preprocess, 21.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/248.jpg: 384x640 1 baseball bat, 1 spoon, 5 carrots, 24.0ms\n",
      "Speed: 1.6ms preprocess, 24.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/249.jpg: 384x640 1 bottle, 8 carrots, 33.6ms\n",
      "Speed: 1.4ms preprocess, 33.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/250.jpg: 384x640 2 spoons, 9 carrots, 27.6ms\n",
      "Speed: 1.9ms preprocess, 27.6ms inference, 12.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/251.jpg: 384x640 1 bottle, 1 spoon, 7 carrots, 22.3ms\n",
      "Speed: 1.8ms preprocess, 22.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/252.jpg: 384x640 5 carrots, 23.9ms\n",
      "Speed: 1.7ms preprocess, 23.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/253.jpg: 384x640 1 bottle, 6 carrots, 25.3ms\n",
      "Speed: 1.7ms preprocess, 25.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/254.jpg: 384x640 1 baseball bat, 6 carrots, 25.0ms\n",
      "Speed: 2.5ms preprocess, 25.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/255.jpg: 384x640 1 bottle, 1 spoon, 6 carrots, 21.0ms\n",
      "Speed: 1.5ms preprocess, 21.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/256.jpg: 384x640 1 baseball bat, 4 carrots, 22.5ms\n",
      "Speed: 1.9ms preprocess, 22.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/257.jpg: 384x640 1 spoon, 5 carrots, 21.5ms\n",
      "Speed: 1.6ms preprocess, 21.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/258.jpg: 384x640 2 spoons, 5 carrots, 22.3ms\n",
      "Speed: 2.3ms preprocess, 22.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/259.jpg: 384x640 1 spoon, 5 carrots, 20.7ms\n",
      "Speed: 1.4ms preprocess, 20.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/260.jpg: 384x640 2 spoons, 12 carrots, 49.1ms\n",
      "Speed: 2.0ms preprocess, 49.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/261.jpg: 384x640 1 bottle, 1 spoon, 5 carrots, 27.4ms\n",
      "Speed: 1.4ms preprocess, 27.4ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/262.jpg: 384x640 1 spoon, 7 carrots, 24.4ms\n",
      "Speed: 1.9ms preprocess, 24.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/263.jpg: 384x640 1 spoon, 6 carrots, 36.7ms\n",
      "Speed: 1.7ms preprocess, 36.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/264.jpg: 384x640 2 spoons, 9 carrots, 33.5ms\n",
      "Speed: 2.3ms preprocess, 33.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/265.jpg: 384x640 2 spoons, 4 carrots, 25.8ms\n",
      "Speed: 1.6ms preprocess, 25.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/266.jpg: 384x640 1 bottle, 5 carrots, 21.1ms\n",
      "Speed: 1.5ms preprocess, 21.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/267.jpg: 384x640 8 carrots, 22.1ms\n",
      "Speed: 1.5ms preprocess, 22.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/268.jpg: 384x640 1 bottle, 5 carrots, 22.8ms\n",
      "Speed: 1.8ms preprocess, 22.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/269.jpg: 384x640 1 spoon, 8 carrots, 30.4ms\n",
      "Speed: 2.1ms preprocess, 30.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/270.jpg: 384x640 1 spoon, 5 carrots, 21.8ms\n",
      "Speed: 1.6ms preprocess, 21.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/271.jpg: 384x640 4 carrots, 1 toothbrush, 21.4ms\n",
      "Speed: 1.4ms preprocess, 21.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/272.jpg: 384x640 1 spoon, 1 carrot, 37.4ms\n",
      "Speed: 1.8ms preprocess, 37.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/273.jpg: 384x640 7 carrots, 1 toothbrush, 22.0ms\n",
      "Speed: 1.4ms preprocess, 22.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/274.jpg: 384x640 8 carrots, 1 toothbrush, 22.7ms\n",
      "Speed: 1.6ms preprocess, 22.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/275.jpg: 384x640 6 carrots, 1 toothbrush, 28.2ms\n",
      "Speed: 1.7ms preprocess, 28.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/276.jpg: 384x640 1 fork, 1 spoon, 7 carrots, 21.6ms\n",
      "Speed: 1.5ms preprocess, 21.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/277.jpg: 384x640 1 fork, 1 spoon, 4 carrots, 22.3ms\n",
      "Speed: 1.7ms preprocess, 22.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/278.jpg: 384x640 1 spoon, 6 carrots, 33.5ms\n",
      "Speed: 1.5ms preprocess, 33.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/279.jpg: 384x640 1 fork, 1 spoon, 3 carrots, 1 toothbrush, 23.8ms\n",
      "Speed: 1.6ms preprocess, 23.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/280.jpg: 384x640 1 fork, 1 spoon, 6 carrots, 22.0ms\n",
      "Speed: 1.4ms preprocess, 22.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/281.jpg: 384x640 2 spoons, 3 carrots, 26.7ms\n",
      "Speed: 2.0ms preprocess, 26.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/282.jpg: 384x640 1 bottle, 6 carrots, 27.9ms\n",
      "Speed: 1.9ms preprocess, 27.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/283.jpg: 384x640 3 carrots, 24.8ms\n",
      "Speed: 1.7ms preprocess, 24.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/284.jpg: 384x640 1 spoon, 3 carrots, 32.4ms\n",
      "Speed: 1.7ms preprocess, 32.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/285.jpg: 384x640 1 knife, 1 spoon, 2 carrots, 21.7ms\n",
      "Speed: 1.5ms preprocess, 21.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/286.jpg: 384x640 1 knife, 2 carrots, 43.1ms\n",
      "Speed: 2.1ms preprocess, 43.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/287.jpg: 384x640 1 baseball bat, 1 spoon, 3 carrots, 24.3ms\n",
      "Speed: 1.5ms preprocess, 24.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/288.jpg: 384x640 1 spoon, 6 carrots, 27.1ms\n",
      "Speed: 1.9ms preprocess, 27.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/289.jpg: 384x640 1 spoon, 3 carrots, 33.9ms\n",
      "Speed: 1.5ms preprocess, 33.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/290.jpg: 384x640 1 spoon, 7 carrots, 33.2ms\n",
      "Speed: 1.6ms preprocess, 33.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/291.jpg: 384x640 2 carrots, 28.3ms\n",
      "Speed: 2.1ms preprocess, 28.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/292.jpg: 384x640 7 carrots, 25.5ms\n",
      "Speed: 1.8ms preprocess, 25.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/293.jpg: 384x640 1 bottle, 1 spoon, 4 carrots, 24.4ms\n",
      "Speed: 1.8ms preprocess, 24.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/294.jpg: 384x640 1 fork, 6 carrots, 29.8ms\n",
      "Speed: 1.6ms preprocess, 29.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/295.jpg: 384x640 1 fork, 5 carrots, 22.0ms\n",
      "Speed: 1.8ms preprocess, 22.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/296.jpg: 384x640 4 carrots, 24.2ms\n",
      "Speed: 1.7ms preprocess, 24.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/297.jpg: 384x640 5 carrots, 49.5ms\n",
      "Speed: 1.5ms preprocess, 49.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/298.jpg: 384x640 1 fork, 6 carrots, 33.2ms\n",
      "Speed: 2.0ms preprocess, 33.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/blood/right/299.jpg: 384x640 7 carrots, 23.2ms\n",
      "Speed: 1.5ms preprocess, 23.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Propagating video frames: 100%|| 300/300 [00:16<00:00, 17.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask propagation completed in 16.73 seconds.\n",
      "Processing predicted masks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing video frames: 300it [00:02, 100.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 300 masks for evaluation.\n",
      "Masks saved to data/masks/yolo11x-seg/val/data-raw-SegSTRONGC_val-val-1-2-blood-right.pkl\n",
      "Loading ground truth masks for evaluation...\n",
      "Loaded 300 ground truth masks.\n",
      "Calculating evaluation metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for metrics calculation: 1.55 seconds.\n",
      "Mean IoU for data/raw/SegSTRONGC_val/val/1/2/blood/right: 0.1161\n",
      "Mean DSC for data/raw/SegSTRONGC_val/val/1/2/blood/right: 0.2001\n",
      "Loading existing results file: data/results/yolo11x-seg/val.json\n",
      "Results saved to data/results/yolo11x-seg/val.json\n",
      "Processing video took 22.61 seconds.\n",
      "==================================================\n",
      "\n",
      "Results for data/raw/SegSTRONGC_val/val/1/2/blood:\n",
      "  Left: IoU=0.1169, DSC=0.2000\n",
      "  Right: IoU=0.1161, DSC=0.2001\n",
      "  Overall: IoU=0.1165, DSC=0.2000\n",
      "\n",
      "Processing domain: low_brightness\n",
      "Processing left camera video...\n",
      "==================================================\n",
      "Processing video: data/raw/SegSTRONGC_val/val/1/2/low_brightness/left\n",
      "Domain: low_brightness, Split: val, Camera: left\n",
      "Initializing Yolo for video...\n",
      "Initialization took 0.14 seconds.\n",
      "Starting mask propagation...\n",
      "Total images in video: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/0.jpg: 384x640 (no detections), 36.6ms\n",
      "Speed: 1.9ms preprocess, 36.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/1.jpg: 384x640 (no detections), 25.9ms\n",
      "Speed: 1.7ms preprocess, 25.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/2.jpg: 384x640 (no detections), 34.5ms\n",
      "Speed: 2.0ms preprocess, 34.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/3.jpg: 384x640 (no detections), 24.8ms\n",
      "Speed: 1.7ms preprocess, 24.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/4.jpg: 384x640 (no detections), 27.0ms\n",
      "Speed: 1.8ms preprocess, 27.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/5.jpg: 384x640 (no detections), 24.7ms\n",
      "Speed: 1.7ms preprocess, 24.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/6.jpg: 384x640 (no detections), 30.4ms\n",
      "Speed: 1.5ms preprocess, 30.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/7.jpg: 384x640 (no detections), 25.5ms\n",
      "Speed: 1.5ms preprocess, 25.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/8.jpg: 384x640 (no detections), 26.5ms\n",
      "Speed: 1.7ms preprocess, 26.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/9.jpg: 384x640 (no detections), 22.4ms\n",
      "Speed: 1.6ms preprocess, 22.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/10.jpg: 384x640 (no detections), 23.5ms\n",
      "Speed: 1.7ms preprocess, 23.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/11.jpg: 384x640 (no detections), 26.3ms\n",
      "Speed: 1.7ms preprocess, 26.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/12.jpg: 384x640 (no detections), 26.6ms\n",
      "Speed: 1.7ms preprocess, 26.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/13.jpg: 384x640 1 motorcycle, 38.8ms\n",
      "Speed: 2.1ms preprocess, 38.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/14.jpg: 384x640 1 spoon, 24.9ms\n",
      "Speed: 2.0ms preprocess, 24.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/15.jpg: 384x640 1 spoon, 26.7ms\n",
      "Speed: 1.6ms preprocess, 26.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/16.jpg: 384x640 (no detections), 21.7ms\n",
      "Speed: 1.6ms preprocess, 21.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/17.jpg: 384x640 (no detections), 41.7ms\n",
      "Speed: 1.4ms preprocess, 41.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/18.jpg: 384x640 (no detections), 23.2ms\n",
      "Speed: 2.1ms preprocess, 23.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/19.jpg: 384x640 (no detections), 22.3ms\n",
      "Speed: 1.4ms preprocess, 22.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/20.jpg: 384x640 1 toothbrush, 22.1ms\n",
      "Speed: 1.7ms preprocess, 22.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/21.jpg: 384x640 (no detections), 23.4ms\n",
      "Speed: 1.9ms preprocess, 23.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/22.jpg: 384x640 (no detections), 22.0ms\n",
      "Speed: 1.3ms preprocess, 22.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/23.jpg: 384x640 (no detections), 40.4ms\n",
      "Speed: 1.9ms preprocess, 40.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/24.jpg: 384x640 (no detections), 22.8ms\n",
      "Speed: 1.8ms preprocess, 22.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/25.jpg: 384x640 (no detections), 24.7ms\n",
      "Speed: 1.8ms preprocess, 24.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/26.jpg: 384x640 (no detections), 22.0ms\n",
      "Speed: 1.5ms preprocess, 22.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/27.jpg: 384x640 (no detections), 22.7ms\n",
      "Speed: 1.5ms preprocess, 22.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/28.jpg: 384x640 (no detections), 23.9ms\n",
      "Speed: 2.4ms preprocess, 23.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/29.jpg: 384x640 (no detections), 23.3ms\n",
      "Speed: 1.5ms preprocess, 23.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/30.jpg: 384x640 (no detections), 36.3ms\n",
      "Speed: 2.3ms preprocess, 36.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/31.jpg: 384x640 (no detections), 28.1ms\n",
      "Speed: 2.0ms preprocess, 28.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/32.jpg: 384x640 (no detections), 23.9ms\n",
      "Speed: 1.6ms preprocess, 23.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/33.jpg: 384x640 (no detections), 21.2ms\n",
      "Speed: 1.4ms preprocess, 21.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/34.jpg: 384x640 (no detections), 24.7ms\n",
      "Speed: 1.8ms preprocess, 24.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/35.jpg: 384x640 (no detections), 22.0ms\n",
      "Speed: 1.6ms preprocess, 22.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/36.jpg: 384x640 (no detections), 34.3ms\n",
      "Speed: 1.7ms preprocess, 34.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/37.jpg: 384x640 (no detections), 23.5ms\n",
      "Speed: 1.7ms preprocess, 23.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/38.jpg: 384x640 (no detections), 24.2ms\n",
      "Speed: 1.6ms preprocess, 24.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/39.jpg: 384x640 1 toothbrush, 21.8ms\n",
      "Speed: 1.7ms preprocess, 21.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/40.jpg: 384x640 (no detections), 22.5ms\n",
      "Speed: 1.4ms preprocess, 22.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/41.jpg: 384x640 (no detections), 21.8ms\n",
      "Speed: 2.0ms preprocess, 21.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/42.jpg: 384x640 (no detections), 34.2ms\n",
      "Speed: 1.5ms preprocess, 34.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/43.jpg: 384x640 (no detections), 22.7ms\n",
      "Speed: 1.5ms preprocess, 22.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/44.jpg: 384x640 (no detections), 30.7ms\n",
      "Speed: 2.2ms preprocess, 30.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/45.jpg: 384x640 (no detections), 23.3ms\n",
      "Speed: 1.7ms preprocess, 23.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/46.jpg: 384x640 (no detections), 26.3ms\n",
      "Speed: 1.5ms preprocess, 26.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/47.jpg: 384x640 (no detections), 23.2ms\n",
      "Speed: 1.6ms preprocess, 23.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/48.jpg: 384x640 (no detections), 23.3ms\n",
      "Speed: 1.7ms preprocess, 23.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/49.jpg: 384x640 (no detections), 21.2ms\n",
      "Speed: 1.6ms preprocess, 21.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/50.jpg: 384x640 (no detections), 25.9ms\n",
      "Speed: 1.7ms preprocess, 25.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/51.jpg: 384x640 (no detections), 23.6ms\n",
      "Speed: 1.5ms preprocess, 23.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/52.jpg: 384x640 1 motorcycle, 21.9ms\n",
      "Speed: 1.9ms preprocess, 21.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/53.jpg: 384x640 (no detections), 22.8ms\n",
      "Speed: 1.7ms preprocess, 22.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/54.jpg: 384x640 (no detections), 23.6ms\n",
      "Speed: 1.7ms preprocess, 23.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/55.jpg: 384x640 (no detections), 22.3ms\n",
      "Speed: 1.5ms preprocess, 22.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/56.jpg: 384x640 (no detections), 23.1ms\n",
      "Speed: 1.6ms preprocess, 23.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/57.jpg: 384x640 (no detections), 28.8ms\n",
      "Speed: 1.5ms preprocess, 28.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/58.jpg: 384x640 (no detections), 25.0ms\n",
      "Speed: 1.6ms preprocess, 25.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/59.jpg: 384x640 (no detections), 26.9ms\n",
      "Speed: 1.6ms preprocess, 26.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/60.jpg: 384x640 (no detections), 23.8ms\n",
      "Speed: 1.6ms preprocess, 23.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/61.jpg: 384x640 (no detections), 37.8ms\n",
      "Speed: 1.7ms preprocess, 37.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/62.jpg: 384x640 (no detections), 28.0ms\n",
      "Speed: 1.9ms preprocess, 28.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/63.jpg: 384x640 (no detections), 25.2ms\n",
      "Speed: 1.8ms preprocess, 25.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/64.jpg: 384x640 (no detections), 22.9ms\n",
      "Speed: 1.7ms preprocess, 22.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/65.jpg: 384x640 (no detections), 25.5ms\n",
      "Speed: 1.6ms preprocess, 25.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/66.jpg: 384x640 (no detections), 31.3ms\n",
      "Speed: 1.8ms preprocess, 31.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/67.jpg: 384x640 (no detections), 33.5ms\n",
      "Speed: 2.4ms preprocess, 33.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/68.jpg: 384x640 (no detections), 24.2ms\n",
      "Speed: 1.5ms preprocess, 24.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/69.jpg: 384x640 (no detections), 31.8ms\n",
      "Speed: 2.3ms preprocess, 31.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/70.jpg: 384x640 (no detections), 25.3ms\n",
      "Speed: 2.7ms preprocess, 25.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/71.jpg: 384x640 (no detections), 26.6ms\n",
      "Speed: 1.7ms preprocess, 26.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/72.jpg: 384x640 (no detections), 23.3ms\n",
      "Speed: 1.7ms preprocess, 23.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/73.jpg: 384x640 (no detections), 25.1ms\n",
      "Speed: 1.5ms preprocess, 25.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/74.jpg: 384x640 (no detections), 25.2ms\n",
      "Speed: 1.6ms preprocess, 25.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/75.jpg: 384x640 (no detections), 25.6ms\n",
      "Speed: 1.9ms preprocess, 25.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/76.jpg: 384x640 (no detections), 24.4ms\n",
      "Speed: 1.7ms preprocess, 24.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/77.jpg: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.4ms preprocess, 25.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/78.jpg: 384x640 (no detections), 24.9ms\n",
      "Speed: 1.7ms preprocess, 24.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/79.jpg: 384x640 (no detections), 24.1ms\n",
      "Speed: 1.6ms preprocess, 24.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/80.jpg: 384x640 (no detections), 24.4ms\n",
      "Speed: 1.7ms preprocess, 24.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/81.jpg: 384x640 (no detections), 27.2ms\n",
      "Speed: 1.7ms preprocess, 27.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/82.jpg: 384x640 (no detections), 28.8ms\n",
      "Speed: 1.6ms preprocess, 28.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/83.jpg: 384x640 (no detections), 22.3ms\n",
      "Speed: 1.7ms preprocess, 22.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/84.jpg: 384x640 (no detections), 26.3ms\n",
      "Speed: 1.9ms preprocess, 26.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/85.jpg: 384x640 (no detections), 26.2ms\n",
      "Speed: 2.6ms preprocess, 26.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/86.jpg: 384x640 (no detections), 24.3ms\n",
      "Speed: 1.5ms preprocess, 24.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/87.jpg: 384x640 (no detections), 22.3ms\n",
      "Speed: 1.9ms preprocess, 22.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/88.jpg: 384x640 (no detections), 26.2ms\n",
      "Speed: 1.8ms preprocess, 26.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/89.jpg: 384x640 (no detections), 23.7ms\n",
      "Speed: 1.4ms preprocess, 23.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/90.jpg: 384x640 (no detections), 29.8ms\n",
      "Speed: 1.9ms preprocess, 29.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/91.jpg: 384x640 (no detections), 32.2ms\n",
      "Speed: 2.8ms preprocess, 32.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/92.jpg: 384x640 (no detections), 24.4ms\n",
      "Speed: 1.7ms preprocess, 24.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/93.jpg: 384x640 (no detections), 24.0ms\n",
      "Speed: 1.6ms preprocess, 24.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/94.jpg: 384x640 (no detections), 24.9ms\n",
      "Speed: 1.8ms preprocess, 24.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/95.jpg: 384x640 1 motorcycle, 35.0ms\n",
      "Speed: 1.6ms preprocess, 35.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/96.jpg: 384x640 (no detections), 31.7ms\n",
      "Speed: 1.5ms preprocess, 31.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/97.jpg: 384x640 1 airplane, 28.0ms\n",
      "Speed: 3.1ms preprocess, 28.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/98.jpg: 384x640 (no detections), 35.5ms\n",
      "Speed: 1.9ms preprocess, 35.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/99.jpg: 384x640 1 airplane, 44.5ms\n",
      "Speed: 1.8ms preprocess, 44.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/100.jpg: 384x640 (no detections), 37.1ms\n",
      "Speed: 2.0ms preprocess, 37.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/101.jpg: 384x640 1 motorcycle, 22.6ms\n",
      "Speed: 1.5ms preprocess, 22.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/102.jpg: 384x640 (no detections), 23.7ms\n",
      "Speed: 1.6ms preprocess, 23.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/103.jpg: 384x640 (no detections), 28.5ms\n",
      "Speed: 1.5ms preprocess, 28.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/104.jpg: 384x640 (no detections), 27.6ms\n",
      "Speed: 1.7ms preprocess, 27.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/105.jpg: 384x640 (no detections), 21.9ms\n",
      "Speed: 1.6ms preprocess, 21.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/106.jpg: 384x640 (no detections), 23.4ms\n",
      "Speed: 1.8ms preprocess, 23.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/107.jpg: 384x640 (no detections), 23.3ms\n",
      "Speed: 1.5ms preprocess, 23.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/108.jpg: 384x640 (no detections), 24.9ms\n",
      "Speed: 1.7ms preprocess, 24.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/109.jpg: 384x640 1 motorcycle, 32.0ms\n",
      "Speed: 1.5ms preprocess, 32.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/110.jpg: 384x640 (no detections), 22.3ms\n",
      "Speed: 2.3ms preprocess, 22.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/111.jpg: 384x640 (no detections), 28.3ms\n",
      "Speed: 2.1ms preprocess, 28.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/112.jpg: 384x640 (no detections), 22.4ms\n",
      "Speed: 1.7ms preprocess, 22.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/113.jpg: 384x640 1 motorcycle, 25.0ms\n",
      "Speed: 1.5ms preprocess, 25.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/114.jpg: 384x640 (no detections), 25.8ms\n",
      "Speed: 1.5ms preprocess, 25.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/115.jpg: 384x640 (no detections), 23.6ms\n",
      "Speed: 1.8ms preprocess, 23.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/116.jpg: 384x640 (no detections), 23.5ms\n",
      "Speed: 1.6ms preprocess, 23.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/117.jpg: 384x640 (no detections), 24.7ms\n",
      "Speed: 1.8ms preprocess, 24.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/118.jpg: 384x640 (no detections), 26.1ms\n",
      "Speed: 1.7ms preprocess, 26.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/119.jpg: 384x640 (no detections), 21.8ms\n",
      "Speed: 1.5ms preprocess, 21.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/120.jpg: 384x640 1 motorcycle, 23.3ms\n",
      "Speed: 1.9ms preprocess, 23.3ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/121.jpg: 384x640 1 motorcycle, 25.4ms\n",
      "Speed: 1.7ms preprocess, 25.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/122.jpg: 384x640 (no detections), 23.6ms\n",
      "Speed: 1.9ms preprocess, 23.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/123.jpg: 384x640 (no detections), 39.4ms\n",
      "Speed: 1.5ms preprocess, 39.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/124.jpg: 384x640 (no detections), 30.8ms\n",
      "Speed: 2.0ms preprocess, 30.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/125.jpg: 384x640 (no detections), 23.4ms\n",
      "Speed: 1.7ms preprocess, 23.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/126.jpg: 384x640 1 motorcycle, 23.3ms\n",
      "Speed: 1.9ms preprocess, 23.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/127.jpg: 384x640 (no detections), 22.4ms\n",
      "Speed: 1.5ms preprocess, 22.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/128.jpg: 384x640 (no detections), 26.1ms\n",
      "Speed: 1.4ms preprocess, 26.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/129.jpg: 384x640 (no detections), 23.7ms\n",
      "Speed: 1.6ms preprocess, 23.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/130.jpg: 384x640 1 motorcycle, 40.5ms\n",
      "Speed: 1.4ms preprocess, 40.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/131.jpg: 384x640 1 motorcycle, 23.5ms\n",
      "Speed: 2.1ms preprocess, 23.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/132.jpg: 384x640 1 motorcycle, 22.6ms\n",
      "Speed: 1.5ms preprocess, 22.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/133.jpg: 384x640 1 motorcycle, 24.0ms\n",
      "Speed: 1.7ms preprocess, 24.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/134.jpg: 384x640 (no detections), 24.5ms\n",
      "Speed: 1.5ms preprocess, 24.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/135.jpg: 384x640 (no detections), 22.8ms\n",
      "Speed: 1.5ms preprocess, 22.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/136.jpg: 384x640 1 motorcycle, 22.6ms\n",
      "Speed: 1.6ms preprocess, 22.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/137.jpg: 384x640 1 motorcycle, 24.0ms\n",
      "Speed: 1.8ms preprocess, 24.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/138.jpg: 384x640 1 motorcycle, 21.6ms\n",
      "Speed: 1.7ms preprocess, 21.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/139.jpg: 384x640 1 motorcycle, 25.1ms\n",
      "Speed: 1.7ms preprocess, 25.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/140.jpg: 384x640 (no detections), 27.3ms\n",
      "Speed: 1.7ms preprocess, 27.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/141.jpg: 384x640 1 motorcycle, 27.4ms\n",
      "Speed: 1.7ms preprocess, 27.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/142.jpg: 384x640 (no detections), 26.4ms\n",
      "Speed: 2.0ms preprocess, 26.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/143.jpg: 384x640 (no detections), 36.5ms\n",
      "Speed: 1.8ms preprocess, 36.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/144.jpg: 384x640 1 motorcycle, 35.0ms\n",
      "Speed: 1.7ms preprocess, 35.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/145.jpg: 384x640 (no detections), 37.5ms\n",
      "Speed: 1.6ms preprocess, 37.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/146.jpg: 384x640 (no detections), 24.9ms\n",
      "Speed: 1.9ms preprocess, 24.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/147.jpg: 384x640 (no detections), 33.4ms\n",
      "Speed: 1.9ms preprocess, 33.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/148.jpg: 384x640 (no detections), 24.0ms\n",
      "Speed: 1.8ms preprocess, 24.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/149.jpg: 384x640 1 motorcycle, 30.3ms\n",
      "Speed: 1.7ms preprocess, 30.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/150.jpg: 384x640 (no detections), 36.7ms\n",
      "Speed: 1.6ms preprocess, 36.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/151.jpg: 384x640 1 airplane, 25.7ms\n",
      "Speed: 1.6ms preprocess, 25.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/152.jpg: 384x640 (no detections), 23.9ms\n",
      "Speed: 1.7ms preprocess, 23.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/153.jpg: 384x640 1 airplane, 30.6ms\n",
      "Speed: 2.0ms preprocess, 30.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/154.jpg: 384x640 1 airplane, 30.1ms\n",
      "Speed: 1.8ms preprocess, 30.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/155.jpg: 384x640 1 motorcycle, 31.1ms\n",
      "Speed: 1.9ms preprocess, 31.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/156.jpg: 384x640 (no detections), 22.5ms\n",
      "Speed: 1.4ms preprocess, 22.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/157.jpg: 384x640 (no detections), 22.8ms\n",
      "Speed: 1.8ms preprocess, 22.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/158.jpg: 384x640 (no detections), 26.9ms\n",
      "Speed: 1.7ms preprocess, 26.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/159.jpg: 384x640 (no detections), 45.6ms\n",
      "Speed: 1.6ms preprocess, 45.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/160.jpg: 384x640 (no detections), 32.8ms\n",
      "Speed: 2.0ms preprocess, 32.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/161.jpg: 384x640 1 motorcycle, 25.1ms\n",
      "Speed: 1.6ms preprocess, 25.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/162.jpg: 384x640 1 motorcycle, 22.7ms\n",
      "Speed: 1.7ms preprocess, 22.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/163.jpg: 384x640 (no detections), 24.8ms\n",
      "Speed: 1.8ms preprocess, 24.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/164.jpg: 384x640 1 motorcycle, 25.1ms\n",
      "Speed: 1.8ms preprocess, 25.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/165.jpg: 384x640 1 motorcycle, 21.6ms\n",
      "Speed: 1.5ms preprocess, 21.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/166.jpg: 384x640 1 motorcycle, 33.6ms\n",
      "Speed: 1.7ms preprocess, 33.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/167.jpg: 384x640 1 motorcycle, 36.3ms\n",
      "Speed: 1.6ms preprocess, 36.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/168.jpg: 384x640 (no detections), 25.1ms\n",
      "Speed: 2.2ms preprocess, 25.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/169.jpg: 384x640 (no detections), 29.8ms\n",
      "Speed: 2.1ms preprocess, 29.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/170.jpg: 384x640 (no detections), 24.7ms\n",
      "Speed: 1.6ms preprocess, 24.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/171.jpg: 384x640 (no detections), 23.0ms\n",
      "Speed: 1.7ms preprocess, 23.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/172.jpg: 384x640 1 motorcycle, 25.9ms\n",
      "Speed: 1.6ms preprocess, 25.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/173.jpg: 384x640 (no detections), 22.7ms\n",
      "Speed: 1.7ms preprocess, 22.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/174.jpg: 384x640 (no detections), 29.2ms\n",
      "Speed: 2.0ms preprocess, 29.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/175.jpg: 384x640 (no detections), 38.3ms\n",
      "Speed: 3.0ms preprocess, 38.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/176.jpg: 384x640 (no detections), 30.2ms\n",
      "Speed: 2.1ms preprocess, 30.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/177.jpg: 384x640 1 boat, 31.0ms\n",
      "Speed: 1.8ms preprocess, 31.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/178.jpg: 384x640 (no detections), 36.3ms\n",
      "Speed: 1.8ms preprocess, 36.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/179.jpg: 384x640 (no detections), 30.8ms\n",
      "Speed: 1.7ms preprocess, 30.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/180.jpg: 384x640 (no detections), 37.5ms\n",
      "Speed: 1.6ms preprocess, 37.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/181.jpg: 384x640 (no detections), 29.3ms\n",
      "Speed: 1.8ms preprocess, 29.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/182.jpg: 384x640 (no detections), 29.5ms\n",
      "Speed: 1.6ms preprocess, 29.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/183.jpg: 384x640 (no detections), 24.4ms\n",
      "Speed: 1.6ms preprocess, 24.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/184.jpg: 384x640 (no detections), 27.7ms\n",
      "Speed: 1.9ms preprocess, 27.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/185.jpg: 384x640 1 motorcycle, 42.4ms\n",
      "Speed: 1.9ms preprocess, 42.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/186.jpg: 384x640 (no detections), 27.8ms\n",
      "Speed: 2.0ms preprocess, 27.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/187.jpg: 384x640 (no detections), 30.6ms\n",
      "Speed: 1.6ms preprocess, 30.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/188.jpg: 384x640 (no detections), 37.0ms\n",
      "Speed: 1.4ms preprocess, 37.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/189.jpg: 384x640 (no detections), 34.3ms\n",
      "Speed: 1.7ms preprocess, 34.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/190.jpg: 384x640 (no detections), 23.5ms\n",
      "Speed: 1.6ms preprocess, 23.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/191.jpg: 384x640 (no detections), 24.8ms\n",
      "Speed: 1.7ms preprocess, 24.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/192.jpg: 384x640 (no detections), 31.5ms\n",
      "Speed: 1.6ms preprocess, 31.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/193.jpg: 384x640 (no detections), 22.5ms\n",
      "Speed: 1.6ms preprocess, 22.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/194.jpg: 384x640 (no detections), 24.6ms\n",
      "Speed: 1.5ms preprocess, 24.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/195.jpg: 384x640 1 motorcycle, 32.3ms\n",
      "Speed: 1.7ms preprocess, 32.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/196.jpg: 384x640 (no detections), 31.9ms\n",
      "Speed: 2.1ms preprocess, 31.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/197.jpg: 384x640 (no detections), 23.3ms\n",
      "Speed: 1.5ms preprocess, 23.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/198.jpg: 384x640 (no detections), 24.5ms\n",
      "Speed: 2.0ms preprocess, 24.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/199.jpg: 384x640 (no detections), 28.7ms\n",
      "Speed: 1.5ms preprocess, 28.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/200.jpg: 384x640 (no detections), 35.6ms\n",
      "Speed: 1.5ms preprocess, 35.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/201.jpg: 384x640 (no detections), 26.9ms\n",
      "Speed: 2.1ms preprocess, 26.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/202.jpg: 384x640 1 motorcycle, 23.2ms\n",
      "Speed: 2.0ms preprocess, 23.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/203.jpg: 384x640 (no detections), 28.1ms\n",
      "Speed: 1.7ms preprocess, 28.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/204.jpg: 384x640 (no detections), 24.2ms\n",
      "Speed: 1.6ms preprocess, 24.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/205.jpg: 384x640 (no detections), 26.9ms\n",
      "Speed: 1.6ms preprocess, 26.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/206.jpg: 384x640 (no detections), 28.3ms\n",
      "Speed: 1.7ms preprocess, 28.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/207.jpg: 384x640 (no detections), 30.3ms\n",
      "Speed: 1.9ms preprocess, 30.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/208.jpg: 384x640 (no detections), 24.9ms\n",
      "Speed: 1.8ms preprocess, 24.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/209.jpg: 384x640 (no detections), 24.3ms\n",
      "Speed: 1.5ms preprocess, 24.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/210.jpg: 384x640 (no detections), 40.3ms\n",
      "Speed: 1.6ms preprocess, 40.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/211.jpg: 384x640 (no detections), 24.3ms\n",
      "Speed: 1.5ms preprocess, 24.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/212.jpg: 384x640 1 motorcycle, 32.0ms\n",
      "Speed: 1.6ms preprocess, 32.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/213.jpg: 384x640 (no detections), 23.6ms\n",
      "Speed: 1.6ms preprocess, 23.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/214.jpg: 384x640 1 motorcycle, 26.7ms\n",
      "Speed: 1.8ms preprocess, 26.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/215.jpg: 384x640 (no detections), 25.7ms\n",
      "Speed: 2.4ms preprocess, 25.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/216.jpg: 384x640 (no detections), 46.6ms\n",
      "Speed: 4.0ms preprocess, 46.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/217.jpg: 384x640 (no detections), 27.7ms\n",
      "Speed: 1.7ms preprocess, 27.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/218.jpg: 384x640 (no detections), 36.4ms\n",
      "Speed: 2.4ms preprocess, 36.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/219.jpg: 384x640 (no detections), 26.3ms\n",
      "Speed: 1.8ms preprocess, 26.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/220.jpg: 384x640 (no detections), 26.7ms\n",
      "Speed: 2.4ms preprocess, 26.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/221.jpg: 384x640 (no detections), 23.3ms\n",
      "Speed: 1.6ms preprocess, 23.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/222.jpg: 384x640 (no detections), 38.0ms\n",
      "Speed: 1.8ms preprocess, 38.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/223.jpg: 384x640 1 motorcycle, 29.2ms\n",
      "Speed: 2.4ms preprocess, 29.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/224.jpg: 384x640 (no detections), 28.0ms\n",
      "Speed: 1.9ms preprocess, 28.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/225.jpg: 384x640 (no detections), 55.2ms\n",
      "Speed: 2.1ms preprocess, 55.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/226.jpg: 384x640 (no detections), 30.8ms\n",
      "Speed: 1.6ms preprocess, 30.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/227.jpg: 384x640 (no detections), 27.2ms\n",
      "Speed: 1.6ms preprocess, 27.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/228.jpg: 384x640 (no detections), 43.0ms\n",
      "Speed: 1.9ms preprocess, 43.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/229.jpg: 384x640 (no detections), 32.4ms\n",
      "Speed: 3.2ms preprocess, 32.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/230.jpg: 384x640 (no detections), 30.4ms\n",
      "Speed: 2.0ms preprocess, 30.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/231.jpg: 384x640 (no detections), 27.2ms\n",
      "Speed: 1.9ms preprocess, 27.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/232.jpg: 384x640 (no detections), 55.6ms\n",
      "Speed: 1.9ms preprocess, 55.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/233.jpg: 384x640 (no detections), 51.3ms\n",
      "Speed: 2.0ms preprocess, 51.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/234.jpg: 384x640 (no detections), 43.2ms\n",
      "Speed: 3.3ms preprocess, 43.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/235.jpg: 384x640 (no detections), 27.8ms\n",
      "Speed: 2.0ms preprocess, 27.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/236.jpg: 384x640 (no detections), 37.1ms\n",
      "Speed: 2.3ms preprocess, 37.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/237.jpg: 384x640 (no detections), 27.4ms\n",
      "Speed: 1.9ms preprocess, 27.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/238.jpg: 384x640 (no detections), 41.5ms\n",
      "Speed: 2.8ms preprocess, 41.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/239.jpg: 384x640 (no detections), 53.3ms\n",
      "Speed: 2.3ms preprocess, 53.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/240.jpg: 384x640 (no detections), 58.7ms\n",
      "Speed: 2.5ms preprocess, 58.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/241.jpg: 384x640 (no detections), 40.7ms\n",
      "Speed: 2.0ms preprocess, 40.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/242.jpg: 384x640 (no detections), 44.5ms\n",
      "Speed: 2.0ms preprocess, 44.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/243.jpg: 384x640 (no detections), 53.1ms\n",
      "Speed: 1.7ms preprocess, 53.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/244.jpg: 384x640 (no detections), 33.9ms\n",
      "Speed: 2.8ms preprocess, 33.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/245.jpg: 384x640 (no detections), 29.9ms\n",
      "Speed: 2.0ms preprocess, 29.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/246.jpg: 384x640 (no detections), 43.9ms\n",
      "Speed: 2.0ms preprocess, 43.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/247.jpg: 384x640 (no detections), 28.2ms\n",
      "Speed: 3.2ms preprocess, 28.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/248.jpg: 384x640 (no detections), 65.4ms\n",
      "Speed: 2.3ms preprocess, 65.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/249.jpg: 384x640 (no detections), 32.2ms\n",
      "Speed: 2.1ms preprocess, 32.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/250.jpg: 384x640 (no detections), 35.4ms\n",
      "Speed: 1.9ms preprocess, 35.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/251.jpg: 384x640 (no detections), 30.8ms\n",
      "Speed: 2.8ms preprocess, 30.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/252.jpg: 384x640 (no detections), 34.0ms\n",
      "Speed: 2.0ms preprocess, 34.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/253.jpg: 384x640 (no detections), 51.0ms\n",
      "Speed: 2.8ms preprocess, 51.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/254.jpg: 384x640 (no detections), 46.7ms\n",
      "Speed: 2.2ms preprocess, 46.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/255.jpg: 384x640 (no detections), 32.1ms\n",
      "Speed: 1.9ms preprocess, 32.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/256.jpg: 384x640 (no detections), 41.4ms\n",
      "Speed: 2.2ms preprocess, 41.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/257.jpg: 384x640 (no detections), 42.3ms\n",
      "Speed: 2.3ms preprocess, 42.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/258.jpg: 384x640 (no detections), 60.0ms\n",
      "Speed: 3.1ms preprocess, 60.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/259.jpg: 384x640 (no detections), 29.1ms\n",
      "Speed: 1.9ms preprocess, 29.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/260.jpg: 384x640 (no detections), 59.6ms\n",
      "Speed: 2.2ms preprocess, 59.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/261.jpg: 384x640 (no detections), 34.6ms\n",
      "Speed: 2.0ms preprocess, 34.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/262.jpg: 384x640 (no detections), 40.1ms\n",
      "Speed: 2.8ms preprocess, 40.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/263.jpg: 384x640 (no detections), 30.2ms\n",
      "Speed: 1.8ms preprocess, 30.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/264.jpg: 384x640 (no detections), 34.5ms\n",
      "Speed: 1.9ms preprocess, 34.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/265.jpg: 384x640 (no detections), 32.9ms\n",
      "Speed: 2.9ms preprocess, 32.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/266.jpg: 384x640 (no detections), 42.4ms\n",
      "Speed: 2.1ms preprocess, 42.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/267.jpg: 384x640 (no detections), 39.4ms\n",
      "Speed: 1.9ms preprocess, 39.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/268.jpg: 384x640 (no detections), 32.0ms\n",
      "Speed: 1.8ms preprocess, 32.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/269.jpg: 384x640 (no detections), 33.9ms\n",
      "Speed: 1.9ms preprocess, 33.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/270.jpg: 384x640 (no detections), 32.4ms\n",
      "Speed: 1.8ms preprocess, 32.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/271.jpg: 384x640 (no detections), 37.1ms\n",
      "Speed: 2.6ms preprocess, 37.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/272.jpg: 384x640 1 motorcycle, 39.0ms\n",
      "Speed: 1.8ms preprocess, 39.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/273.jpg: 384x640 (no detections), 37.4ms\n",
      "Speed: 1.7ms preprocess, 37.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/274.jpg: 384x640 (no detections), 37.1ms\n",
      "Speed: 1.9ms preprocess, 37.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/275.jpg: 384x640 (no detections), 28.6ms\n",
      "Speed: 1.9ms preprocess, 28.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/276.jpg: 384x640 (no detections), 34.5ms\n",
      "Speed: 2.3ms preprocess, 34.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/277.jpg: 384x640 (no detections), 36.8ms\n",
      "Speed: 2.0ms preprocess, 36.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/278.jpg: 384x640 (no detections), 38.5ms\n",
      "Speed: 2.1ms preprocess, 38.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/279.jpg: 384x640 (no detections), 29.6ms\n",
      "Speed: 1.7ms preprocess, 29.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/280.jpg: 384x640 (no detections), 37.6ms\n",
      "Speed: 2.1ms preprocess, 37.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/281.jpg: 384x640 (no detections), 30.2ms\n",
      "Speed: 1.7ms preprocess, 30.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/282.jpg: 384x640 (no detections), 34.6ms\n",
      "Speed: 2.7ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/283.jpg: 384x640 (no detections), 40.6ms\n",
      "Speed: 1.8ms preprocess, 40.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/284.jpg: 384x640 (no detections), 36.3ms\n",
      "Speed: 2.0ms preprocess, 36.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/285.jpg: 384x640 (no detections), 29.0ms\n",
      "Speed: 1.8ms preprocess, 29.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/286.jpg: 384x640 (no detections), 28.0ms\n",
      "Speed: 2.7ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/287.jpg: 384x640 (no detections), 34.9ms\n",
      "Speed: 2.2ms preprocess, 34.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/288.jpg: 384x640 (no detections), 37.8ms\n",
      "Speed: 1.9ms preprocess, 37.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/289.jpg: 384x640 (no detections), 36.1ms\n",
      "Speed: 1.7ms preprocess, 36.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/290.jpg: 384x640 (no detections), 29.3ms\n",
      "Speed: 1.7ms preprocess, 29.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/291.jpg: 384x640 (no detections), 29.5ms\n",
      "Speed: 1.7ms preprocess, 29.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/292.jpg: 384x640 (no detections), 31.4ms\n",
      "Speed: 1.9ms preprocess, 31.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/293.jpg: 384x640 (no detections), 48.3ms\n",
      "Speed: 1.6ms preprocess, 48.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/294.jpg: 384x640 (no detections), 29.7ms\n",
      "Speed: 1.7ms preprocess, 29.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/295.jpg: 384x640 (no detections), 35.7ms\n",
      "Speed: 2.0ms preprocess, 35.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/296.jpg: 384x640 (no detections), 31.1ms\n",
      "Speed: 1.8ms preprocess, 31.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/297.jpg: 384x640 (no detections), 33.2ms\n",
      "Speed: 2.1ms preprocess, 33.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/298.jpg: 384x640 (no detections), 32.6ms\n",
      "Speed: 1.9ms preprocess, 32.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/left/299.jpg: 384x640 (no detections), 28.3ms\n",
      "Speed: 1.7ms preprocess, 28.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Propagating video frames: 100%|| 300/300 [00:18<00:00, 16.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask propagation completed in 18.05 seconds.\n",
      "Processing predicted masks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing video frames: 300it [00:00, 1298.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 300 masks for evaluation.\n",
      "Masks saved to data/masks/yolo11x-seg/val/data-raw-SegSTRONGC_val-val-1-2-low_brightness-left.pkl\n",
      "Loading ground truth masks for evaluation...\n",
      "Loaded 300 ground truth masks.\n",
      "Calculating evaluation metrics...\n",
      "Time taken for metrics calculation: 1.93 seconds.\n",
      "Mean IoU for data/raw/SegSTRONGC_val/val/1/2/low_brightness/left: 0.0285\n",
      "Mean DSC for data/raw/SegSTRONGC_val/val/1/2/low_brightness/left: 0.0462\n",
      "Loading existing results file: data/results/yolo11x-seg/val.json\n",
      "Results saved to data/results/yolo11x-seg/val.json\n",
      "Processing video took 23.02 seconds.\n",
      "==================================================\n",
      "Processing right camera video...\n",
      "==================================================\n",
      "Processing video: data/raw/SegSTRONGC_val/val/1/2/low_brightness/right\n",
      "Domain: low_brightness, Split: val, Camera: right\n",
      "Initializing Yolo for video...\n",
      "Initialization took 1.96 seconds.\n",
      "Starting mask propagation...\n",
      "Total images in video: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/0.jpg: 384x640 (no detections), 78.9ms\n",
      "Speed: 2.0ms preprocess, 78.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/1.jpg: 384x640 1 sink, 26.0ms\n",
      "Speed: 2.3ms preprocess, 26.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/2.jpg: 384x640 (no detections), 26.0ms\n",
      "Speed: 1.9ms preprocess, 26.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/3.jpg: 384x640 (no detections), 28.5ms\n",
      "Speed: 2.0ms preprocess, 28.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/4.jpg: 384x640 (no detections), 26.4ms\n",
      "Speed: 2.1ms preprocess, 26.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/5.jpg: 384x640 1 toothbrush, 26.5ms\n",
      "Speed: 2.7ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/6.jpg: 384x640 1 toothbrush, 40.8ms\n",
      "Speed: 1.8ms preprocess, 40.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/7.jpg: 384x640 1 toothbrush, 28.6ms\n",
      "Speed: 1.9ms preprocess, 28.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/8.jpg: 384x640 1 toothbrush, 35.5ms\n",
      "Speed: 2.2ms preprocess, 35.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/9.jpg: 384x640 (no detections), 27.0ms\n",
      "Speed: 2.0ms preprocess, 27.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/10.jpg: 384x640 (no detections), 34.1ms\n",
      "Speed: 2.1ms preprocess, 34.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/11.jpg: 384x640 (no detections), 39.7ms\n",
      "Speed: 2.1ms preprocess, 39.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/12.jpg: 384x640 1 toothbrush, 31.4ms\n",
      "Speed: 1.9ms preprocess, 31.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/13.jpg: 384x640 (no detections), 26.8ms\n",
      "Speed: 1.9ms preprocess, 26.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/14.jpg: 384x640 (no detections), 31.8ms\n",
      "Speed: 2.2ms preprocess, 31.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/15.jpg: 384x640 (no detections), 38.9ms\n",
      "Speed: 1.8ms preprocess, 38.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/16.jpg: 384x640 (no detections), 42.0ms\n",
      "Speed: 2.6ms preprocess, 42.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/17.jpg: 384x640 1 toothbrush, 42.8ms\n",
      "Speed: 2.0ms preprocess, 42.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/18.jpg: 384x640 (no detections), 31.1ms\n",
      "Speed: 2.1ms preprocess, 31.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/19.jpg: 384x640 (no detections), 29.2ms\n",
      "Speed: 2.0ms preprocess, 29.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/20.jpg: 384x640 1 sink, 1 toothbrush, 31.9ms\n",
      "Speed: 2.8ms preprocess, 31.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/21.jpg: 384x640 (no detections), 36.1ms\n",
      "Speed: 2.9ms preprocess, 36.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/22.jpg: 384x640 (no detections), 38.4ms\n",
      "Speed: 2.5ms preprocess, 38.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/23.jpg: 384x640 1 sink, 1 toothbrush, 53.1ms\n",
      "Speed: 2.7ms preprocess, 53.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/24.jpg: 384x640 1 toothbrush, 46.4ms\n",
      "Speed: 2.9ms preprocess, 46.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/25.jpg: 384x640 1 sink, 1 toothbrush, 34.8ms\n",
      "Speed: 1.8ms preprocess, 34.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/26.jpg: 384x640 (no detections), 36.4ms\n",
      "Speed: 1.8ms preprocess, 36.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/27.jpg: 384x640 (no detections), 34.6ms\n",
      "Speed: 2.8ms preprocess, 34.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/28.jpg: 384x640 (no detections), 30.8ms\n",
      "Speed: 2.1ms preprocess, 30.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/29.jpg: 384x640 1 toothbrush, 53.8ms\n",
      "Speed: 1.9ms preprocess, 53.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/30.jpg: 384x640 (no detections), 32.5ms\n",
      "Speed: 1.9ms preprocess, 32.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/31.jpg: 384x640 1 toothbrush, 31.4ms\n",
      "Speed: 2.2ms preprocess, 31.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/32.jpg: 384x640 (no detections), 30.5ms\n",
      "Speed: 2.7ms preprocess, 30.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/33.jpg: 384x640 (no detections), 27.6ms\n",
      "Speed: 1.9ms preprocess, 27.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/34.jpg: 384x640 (no detections), 35.8ms\n",
      "Speed: 1.9ms preprocess, 35.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/35.jpg: 384x640 1 toothbrush, 39.5ms\n",
      "Speed: 2.7ms preprocess, 39.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/36.jpg: 384x640 1 sink, 1 toothbrush, 54.9ms\n",
      "Speed: 2.1ms preprocess, 54.9ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/37.jpg: 384x640 1 sink, 1 toothbrush, 30.7ms\n",
      "Speed: 1.7ms preprocess, 30.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/38.jpg: 384x640 1 sink, 1 toothbrush, 29.2ms\n",
      "Speed: 2.9ms preprocess, 29.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/39.jpg: 384x640 (no detections), 28.1ms\n",
      "Speed: 1.7ms preprocess, 28.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/40.jpg: 384x640 (no detections), 38.3ms\n",
      "Speed: 1.8ms preprocess, 38.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/41.jpg: 384x640 (no detections), 37.9ms\n",
      "Speed: 2.0ms preprocess, 37.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/42.jpg: 384x640 (no detections), 38.1ms\n",
      "Speed: 2.8ms preprocess, 38.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/43.jpg: 384x640 (no detections), 29.9ms\n",
      "Speed: 1.8ms preprocess, 29.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/44.jpg: 384x640 (no detections), 31.3ms\n",
      "Speed: 1.8ms preprocess, 31.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/45.jpg: 384x640 (no detections), 28.2ms\n",
      "Speed: 1.8ms preprocess, 28.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/46.jpg: 384x640 (no detections), 32.2ms\n",
      "Speed: 1.9ms preprocess, 32.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/47.jpg: 384x640 (no detections), 49.5ms\n",
      "Speed: 2.1ms preprocess, 49.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/48.jpg: 384x640 (no detections), 31.9ms\n",
      "Speed: 2.0ms preprocess, 31.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/49.jpg: 384x640 (no detections), 28.4ms\n",
      "Speed: 3.4ms preprocess, 28.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/50.jpg: 384x640 (no detections), 29.5ms\n",
      "Speed: 1.8ms preprocess, 29.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/51.jpg: 384x640 (no detections), 32.6ms\n",
      "Speed: 2.2ms preprocess, 32.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/52.jpg: 384x640 (no detections), 40.3ms\n",
      "Speed: 1.8ms preprocess, 40.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/53.jpg: 384x640 (no detections), 39.0ms\n",
      "Speed: 2.1ms preprocess, 39.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/54.jpg: 384x640 (no detections), 41.9ms\n",
      "Speed: 2.3ms preprocess, 41.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/55.jpg: 384x640 (no detections), 29.8ms\n",
      "Speed: 2.2ms preprocess, 29.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/56.jpg: 384x640 (no detections), 43.0ms\n",
      "Speed: 1.7ms preprocess, 43.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/57.jpg: 384x640 (no detections), 39.7ms\n",
      "Speed: 2.5ms preprocess, 39.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/58.jpg: 384x640 (no detections), 42.5ms\n",
      "Speed: 2.9ms preprocess, 42.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/59.jpg: 384x640 (no detections), 29.9ms\n",
      "Speed: 1.8ms preprocess, 29.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/60.jpg: 384x640 (no detections), 38.0ms\n",
      "Speed: 2.3ms preprocess, 38.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/61.jpg: 384x640 1 sink, 40.7ms\n",
      "Speed: 3.5ms preprocess, 40.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/62.jpg: 384x640 (no detections), 43.1ms\n",
      "Speed: 3.1ms preprocess, 43.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/63.jpg: 384x640 (no detections), 101.4ms\n",
      "Speed: 1.7ms preprocess, 101.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/64.jpg: 384x640 (no detections), 32.4ms\n",
      "Speed: 1.8ms preprocess, 32.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/65.jpg: 384x640 (no detections), 29.7ms\n",
      "Speed: 1.9ms preprocess, 29.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/66.jpg: 384x640 (no detections), 54.9ms\n",
      "Speed: 1.9ms preprocess, 54.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/67.jpg: 384x640 (no detections), 53.4ms\n",
      "Speed: 2.4ms preprocess, 53.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/68.jpg: 384x640 1 toothbrush, 33.9ms\n",
      "Speed: 2.0ms preprocess, 33.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/69.jpg: 384x640 (no detections), 38.0ms\n",
      "Speed: 1.9ms preprocess, 38.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/70.jpg: 384x640 (no detections), 34.8ms\n",
      "Speed: 2.0ms preprocess, 34.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/71.jpg: 384x640 1 sink, 40.9ms\n",
      "Speed: 2.2ms preprocess, 40.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/72.jpg: 384x640 1 sink, 1 toothbrush, 62.9ms\n",
      "Speed: 3.1ms preprocess, 62.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/73.jpg: 384x640 1 toothbrush, 42.5ms\n",
      "Speed: 3.3ms preprocess, 42.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/74.jpg: 384x640 (no detections), 47.8ms\n",
      "Speed: 2.2ms preprocess, 47.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/75.jpg: 384x640 1 toothbrush, 31.7ms\n",
      "Speed: 3.6ms preprocess, 31.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/76.jpg: 384x640 1 toothbrush, 54.0ms\n",
      "Speed: 3.8ms preprocess, 54.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/77.jpg: 384x640 (no detections), 45.3ms\n",
      "Speed: 2.4ms preprocess, 45.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/78.jpg: 384x640 1 toothbrush, 45.3ms\n",
      "Speed: 2.4ms preprocess, 45.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/79.jpg: 384x640 (no detections), 35.9ms\n",
      "Speed: 2.1ms preprocess, 35.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/80.jpg: 384x640 1 toothbrush, 45.2ms\n",
      "Speed: 2.1ms preprocess, 45.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/81.jpg: 384x640 1 toothbrush, 32.8ms\n",
      "Speed: 1.8ms preprocess, 32.8ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/82.jpg: 384x640 1 toothbrush, 32.5ms\n",
      "Speed: 2.7ms preprocess, 32.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/83.jpg: 384x640 1 sink, 2 toothbrushs, 54.0ms\n",
      "Speed: 3.2ms preprocess, 54.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/84.jpg: 384x640 2 toothbrushs, 36.5ms\n",
      "Speed: 1.9ms preprocess, 36.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/85.jpg: 384x640 (no detections), 33.9ms\n",
      "Speed: 1.8ms preprocess, 33.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/86.jpg: 384x640 (no detections), 44.3ms\n",
      "Speed: 2.4ms preprocess, 44.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/87.jpg: 384x640 (no detections), 37.2ms\n",
      "Speed: 3.0ms preprocess, 37.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/88.jpg: 384x640 1 toothbrush, 38.5ms\n",
      "Speed: 2.2ms preprocess, 38.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/89.jpg: 384x640 (no detections), 44.6ms\n",
      "Speed: 4.4ms preprocess, 44.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/90.jpg: 384x640 (no detections), 40.8ms\n",
      "Speed: 2.3ms preprocess, 40.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/91.jpg: 384x640 (no detections), 32.7ms\n",
      "Speed: 2.4ms preprocess, 32.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/92.jpg: 384x640 (no detections), 38.6ms\n",
      "Speed: 3.1ms preprocess, 38.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/93.jpg: 384x640 (no detections), 44.9ms\n",
      "Speed: 2.0ms preprocess, 44.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/94.jpg: 384x640 (no detections), 35.8ms\n",
      "Speed: 2.2ms preprocess, 35.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/95.jpg: 384x640 1 motorcycle, 34.0ms\n",
      "Speed: 2.1ms preprocess, 34.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/96.jpg: 384x640 (no detections), 39.8ms\n",
      "Speed: 3.5ms preprocess, 39.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/97.jpg: 384x640 (no detections), 42.7ms\n",
      "Speed: 2.0ms preprocess, 42.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/98.jpg: 384x640 (no detections), 45.8ms\n",
      "Speed: 2.2ms preprocess, 45.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/99.jpg: 384x640 (no detections), 48.0ms\n",
      "Speed: 2.6ms preprocess, 48.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/100.jpg: 384x640 (no detections), 35.7ms\n",
      "Speed: 3.2ms preprocess, 35.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/101.jpg: 384x640 (no detections), 38.7ms\n",
      "Speed: 2.5ms preprocess, 38.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/102.jpg: 384x640 (no detections), 43.8ms\n",
      "Speed: 3.8ms preprocess, 43.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/103.jpg: 384x640 (no detections), 39.2ms\n",
      "Speed: 2.1ms preprocess, 39.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/104.jpg: 384x640 (no detections), 34.0ms\n",
      "Speed: 2.2ms preprocess, 34.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/105.jpg: 384x640 (no detections), 49.3ms\n",
      "Speed: 2.6ms preprocess, 49.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/106.jpg: 384x640 (no detections), 32.6ms\n",
      "Speed: 2.9ms preprocess, 32.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/107.jpg: 384x640 1 toothbrush, 41.1ms\n",
      "Speed: 1.9ms preprocess, 41.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/108.jpg: 384x640 (no detections), 42.6ms\n",
      "Speed: 2.2ms preprocess, 42.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/109.jpg: 384x640 (no detections), 30.6ms\n",
      "Speed: 2.4ms preprocess, 30.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/110.jpg: 384x640 (no detections), 40.7ms\n",
      "Speed: 3.0ms preprocess, 40.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/111.jpg: 384x640 (no detections), 31.2ms\n",
      "Speed: 1.9ms preprocess, 31.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/112.jpg: 384x640 (no detections), 34.6ms\n",
      "Speed: 2.0ms preprocess, 34.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/113.jpg: 384x640 (no detections), 31.3ms\n",
      "Speed: 2.0ms preprocess, 31.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/114.jpg: 384x640 1 sink, 1 toothbrush, 32.3ms\n",
      "Speed: 2.2ms preprocess, 32.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/115.jpg: 384x640 (no detections), 28.6ms\n",
      "Speed: 1.7ms preprocess, 28.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/116.jpg: 384x640 (no detections), 36.8ms\n",
      "Speed: 2.7ms preprocess, 36.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/117.jpg: 384x640 (no detections), 34.8ms\n",
      "Speed: 1.7ms preprocess, 34.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/118.jpg: 384x640 1 bottle, 44.7ms\n",
      "Speed: 2.3ms preprocess, 44.7ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/119.jpg: 384x640 1 motorcycle, 36.0ms\n",
      "Speed: 2.9ms preprocess, 36.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/120.jpg: 384x640 (no detections), 55.0ms\n",
      "Speed: 3.5ms preprocess, 55.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/121.jpg: 384x640 1 motorcycle, 34.1ms\n",
      "Speed: 2.5ms preprocess, 34.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/122.jpg: 384x640 (no detections), 41.9ms\n",
      "Speed: 2.1ms preprocess, 41.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/123.jpg: 384x640 (no detections), 28.9ms\n",
      "Speed: 2.6ms preprocess, 28.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/124.jpg: 384x640 (no detections), 28.4ms\n",
      "Speed: 2.2ms preprocess, 28.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/125.jpg: 384x640 (no detections), 40.9ms\n",
      "Speed: 2.1ms preprocess, 40.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/126.jpg: 384x640 (no detections), 43.4ms\n",
      "Speed: 2.5ms preprocess, 43.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/127.jpg: 384x640 1 motorcycle, 31.8ms\n",
      "Speed: 2.0ms preprocess, 31.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/128.jpg: 384x640 (no detections), 33.7ms\n",
      "Speed: 2.6ms preprocess, 33.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/129.jpg: 384x640 (no detections), 27.8ms\n",
      "Speed: 1.9ms preprocess, 27.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/130.jpg: 384x640 (no detections), 33.4ms\n",
      "Speed: 2.1ms preprocess, 33.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/131.jpg: 384x640 1 bottle, 26.5ms\n",
      "Speed: 1.9ms preprocess, 26.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/132.jpg: 384x640 1 toothbrush, 40.5ms\n",
      "Speed: 2.1ms preprocess, 40.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/133.jpg: 384x640 1 bottle, 31.1ms\n",
      "Speed: 3.0ms preprocess, 31.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/134.jpg: 384x640 1 toothbrush, 31.6ms\n",
      "Speed: 2.2ms preprocess, 31.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/135.jpg: 384x640 (no detections), 50.5ms\n",
      "Speed: 2.0ms preprocess, 50.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/136.jpg: 384x640 (no detections), 35.5ms\n",
      "Speed: 2.1ms preprocess, 35.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/137.jpg: 384x640 (no detections), 34.4ms\n",
      "Speed: 2.0ms preprocess, 34.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/138.jpg: 384x640 (no detections), 27.2ms\n",
      "Speed: 1.8ms preprocess, 27.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/139.jpg: 384x640 (no detections), 47.4ms\n",
      "Speed: 1.9ms preprocess, 47.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/140.jpg: 384x640 (no detections), 34.4ms\n",
      "Speed: 2.0ms preprocess, 34.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/141.jpg: 384x640 (no detections), 26.9ms\n",
      "Speed: 1.9ms preprocess, 26.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/142.jpg: 384x640 (no detections), 29.6ms\n",
      "Speed: 2.0ms preprocess, 29.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/143.jpg: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.0ms preprocess, 25.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/144.jpg: 384x640 (no detections), 31.8ms\n",
      "Speed: 1.9ms preprocess, 31.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/145.jpg: 384x640 (no detections), 25.7ms\n",
      "Speed: 1.8ms preprocess, 25.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/146.jpg: 384x640 (no detections), 37.2ms\n",
      "Speed: 1.8ms preprocess, 37.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/147.jpg: 384x640 1 toothbrush, 49.7ms\n",
      "Speed: 2.8ms preprocess, 49.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/148.jpg: 384x640 (no detections), 32.4ms\n",
      "Speed: 2.7ms preprocess, 32.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/149.jpg: 384x640 (no detections), 48.2ms\n",
      "Speed: 1.8ms preprocess, 48.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/150.jpg: 384x640 1 toothbrush, 29.7ms\n",
      "Speed: 1.9ms preprocess, 29.7ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/151.jpg: 384x640 1 toothbrush, 41.3ms\n",
      "Speed: 2.4ms preprocess, 41.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/152.jpg: 384x640 (no detections), 31.9ms\n",
      "Speed: 2.2ms preprocess, 31.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/153.jpg: 384x640 (no detections), 36.4ms\n",
      "Speed: 3.2ms preprocess, 36.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/154.jpg: 384x640 (no detections), 42.9ms\n",
      "Speed: 1.9ms preprocess, 42.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/155.jpg: 384x640 (no detections), 27.8ms\n",
      "Speed: 3.3ms preprocess, 27.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/156.jpg: 384x640 (no detections), 32.5ms\n",
      "Speed: 1.9ms preprocess, 32.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/157.jpg: 384x640 (no detections), 33.8ms\n",
      "Speed: 2.0ms preprocess, 33.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/158.jpg: 384x640 (no detections), 31.5ms\n",
      "Speed: 1.8ms preprocess, 31.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/159.jpg: 384x640 (no detections), 38.5ms\n",
      "Speed: 2.0ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/160.jpg: 384x640 (no detections), 40.7ms\n",
      "Speed: 2.1ms preprocess, 40.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/161.jpg: 384x640 (no detections), 34.3ms\n",
      "Speed: 2.8ms preprocess, 34.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/162.jpg: 384x640 (no detections), 36.5ms\n",
      "Speed: 2.1ms preprocess, 36.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/163.jpg: 384x640 (no detections), 31.1ms\n",
      "Speed: 2.0ms preprocess, 31.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/164.jpg: 384x640 (no detections), 26.3ms\n",
      "Speed: 1.9ms preprocess, 26.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/165.jpg: 384x640 (no detections), 31.3ms\n",
      "Speed: 1.9ms preprocess, 31.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/166.jpg: 384x640 (no detections), 26.2ms\n",
      "Speed: 1.9ms preprocess, 26.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/167.jpg: 384x640 1 toothbrush, 29.5ms\n",
      "Speed: 1.8ms preprocess, 29.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/168.jpg: 384x640 (no detections), 41.1ms\n",
      "Speed: 2.0ms preprocess, 41.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/169.jpg: 384x640 1 toothbrush, 28.1ms\n",
      "Speed: 1.9ms preprocess, 28.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/170.jpg: 384x640 1 sink, 1 toothbrush, 30.8ms\n",
      "Speed: 2.1ms preprocess, 30.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/171.jpg: 384x640 1 toothbrush, 26.8ms\n",
      "Speed: 1.7ms preprocess, 26.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/172.jpg: 384x640 (no detections), 27.8ms\n",
      "Speed: 3.3ms preprocess, 27.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/173.jpg: 384x640 (no detections), 37.4ms\n",
      "Speed: 1.7ms preprocess, 37.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/174.jpg: 384x640 (no detections), 33.2ms\n",
      "Speed: 2.0ms preprocess, 33.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/175.jpg: 384x640 (no detections), 26.2ms\n",
      "Speed: 1.9ms preprocess, 26.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/176.jpg: 384x640 (no detections), 25.4ms\n",
      "Speed: 1.8ms preprocess, 25.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/177.jpg: 384x640 1 toothbrush, 33.7ms\n",
      "Speed: 1.8ms preprocess, 33.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/178.jpg: 384x640 (no detections), 27.7ms\n",
      "Speed: 2.6ms preprocess, 27.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/179.jpg: 384x640 1 toothbrush, 27.7ms\n",
      "Speed: 1.8ms preprocess, 27.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/180.jpg: 384x640 (no detections), 29.8ms\n",
      "Speed: 2.3ms preprocess, 29.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/181.jpg: 384x640 1 spoon, 36.3ms\n",
      "Speed: 1.9ms preprocess, 36.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/182.jpg: 384x640 1 spoon, 26.8ms\n",
      "Speed: 2.2ms preprocess, 26.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/183.jpg: 384x640 1 spoon, 27.9ms\n",
      "Speed: 2.1ms preprocess, 27.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/184.jpg: 384x640 (no detections), 34.8ms\n",
      "Speed: 2.2ms preprocess, 34.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/185.jpg: 384x640 (no detections), 33.2ms\n",
      "Speed: 2.8ms preprocess, 33.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/186.jpg: 384x640 (no detections), 29.9ms\n",
      "Speed: 1.9ms preprocess, 29.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/187.jpg: 384x640 (no detections), 40.7ms\n",
      "Speed: 1.8ms preprocess, 40.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/188.jpg: 384x640 (no detections), 28.6ms\n",
      "Speed: 2.1ms preprocess, 28.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/189.jpg: 384x640 1 toothbrush, 35.5ms\n",
      "Speed: 1.8ms preprocess, 35.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/190.jpg: 384x640 (no detections), 29.7ms\n",
      "Speed: 2.3ms preprocess, 29.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/191.jpg: 384x640 1 sink, 26.4ms\n",
      "Speed: 1.8ms preprocess, 26.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/192.jpg: 384x640 (no detections), 40.6ms\n",
      "Speed: 2.1ms preprocess, 40.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/193.jpg: 384x640 (no detections), 28.1ms\n",
      "Speed: 1.7ms preprocess, 28.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/194.jpg: 384x640 (no detections), 38.6ms\n",
      "Speed: 2.1ms preprocess, 38.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/195.jpg: 384x640 (no detections), 33.4ms\n",
      "Speed: 1.8ms preprocess, 33.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/196.jpg: 384x640 (no detections), 27.4ms\n",
      "Speed: 2.3ms preprocess, 27.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/197.jpg: 384x640 (no detections), 28.0ms\n",
      "Speed: 2.1ms preprocess, 28.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/198.jpg: 384x640 (no detections), 29.3ms\n",
      "Speed: 1.9ms preprocess, 29.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/199.jpg: 384x640 (no detections), 27.9ms\n",
      "Speed: 2.0ms preprocess, 27.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/200.jpg: 384x640 (no detections), 27.0ms\n",
      "Speed: 2.1ms preprocess, 27.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/201.jpg: 384x640 (no detections), 32.1ms\n",
      "Speed: 1.9ms preprocess, 32.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/202.jpg: 384x640 (no detections), 36.9ms\n",
      "Speed: 1.8ms preprocess, 36.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/203.jpg: 384x640 (no detections), 25.1ms\n",
      "Speed: 1.8ms preprocess, 25.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/204.jpg: 384x640 (no detections), 26.4ms\n",
      "Speed: 1.8ms preprocess, 26.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/205.jpg: 384x640 (no detections), 31.8ms\n",
      "Speed: 1.9ms preprocess, 31.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/206.jpg: 384x640 1 toothbrush, 35.2ms\n",
      "Speed: 2.0ms preprocess, 35.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/207.jpg: 384x640 (no detections), 26.2ms\n",
      "Speed: 1.9ms preprocess, 26.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/208.jpg: 384x640 1 sink, 1 toothbrush, 26.0ms\n",
      "Speed: 1.8ms preprocess, 26.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/209.jpg: 384x640 1 toothbrush, 24.3ms\n",
      "Speed: 2.0ms preprocess, 24.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/210.jpg: 384x640 1 toothbrush, 25.0ms\n",
      "Speed: 1.7ms preprocess, 25.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/211.jpg: 384x640 1 sink, 1 toothbrush, 27.2ms\n",
      "Speed: 1.6ms preprocess, 27.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/212.jpg: 384x640 (no detections), 34.9ms\n",
      "Speed: 2.0ms preprocess, 34.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/213.jpg: 384x640 1 toothbrush, 37.7ms\n",
      "Speed: 1.8ms preprocess, 37.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/214.jpg: 384x640 1 toothbrush, 43.6ms\n",
      "Speed: 1.9ms preprocess, 43.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/215.jpg: 384x640 1 toothbrush, 25.7ms\n",
      "Speed: 2.0ms preprocess, 25.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/216.jpg: 384x640 1 sink, 1 toothbrush, 27.1ms\n",
      "Speed: 1.7ms preprocess, 27.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/217.jpg: 384x640 (no detections), 26.3ms\n",
      "Speed: 1.8ms preprocess, 26.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/218.jpg: 384x640 1 toothbrush, 26.9ms\n",
      "Speed: 3.0ms preprocess, 26.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/219.jpg: 384x640 1 sink, 1 toothbrush, 27.5ms\n",
      "Speed: 1.6ms preprocess, 27.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/220.jpg: 384x640 1 sink, 26.5ms\n",
      "Speed: 1.7ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/221.jpg: 384x640 (no detections), 45.4ms\n",
      "Speed: 1.9ms preprocess, 45.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/222.jpg: 384x640 (no detections), 35.0ms\n",
      "Speed: 3.3ms preprocess, 35.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/223.jpg: 384x640 (no detections), 28.3ms\n",
      "Speed: 1.7ms preprocess, 28.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/224.jpg: 384x640 (no detections), 25.8ms\n",
      "Speed: 1.7ms preprocess, 25.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/225.jpg: 384x640 (no detections), 33.3ms\n",
      "Speed: 1.6ms preprocess, 33.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/226.jpg: 384x640 (no detections), 28.1ms\n",
      "Speed: 2.2ms preprocess, 28.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/227.jpg: 384x640 (no detections), 54.8ms\n",
      "Speed: 2.2ms preprocess, 54.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/228.jpg: 384x640 (no detections), 36.1ms\n",
      "Speed: 2.4ms preprocess, 36.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/229.jpg: 384x640 (no detections), 27.7ms\n",
      "Speed: 2.0ms preprocess, 27.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/230.jpg: 384x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/231.jpg: 384x640 (no detections), 37.7ms\n",
      "Speed: 2.7ms preprocess, 37.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/232.jpg: 384x640 (no detections), 34.2ms\n",
      "Speed: 1.9ms preprocess, 34.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/233.jpg: 384x640 (no detections), 38.3ms\n",
      "Speed: 1.7ms preprocess, 38.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/234.jpg: 384x640 (no detections), 54.5ms\n",
      "Speed: 2.2ms preprocess, 54.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/235.jpg: 384x640 (no detections), 38.4ms\n",
      "Speed: 2.0ms preprocess, 38.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/236.jpg: 384x640 (no detections), 42.9ms\n",
      "Speed: 1.7ms preprocess, 42.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/237.jpg: 384x640 (no detections), 31.0ms\n",
      "Speed: 1.8ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/238.jpg: 384x640 (no detections), 46.9ms\n",
      "Speed: 2.5ms preprocess, 46.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/239.jpg: 384x640 (no detections), 29.3ms\n",
      "Speed: 1.8ms preprocess, 29.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/240.jpg: 384x640 (no detections), 27.3ms\n",
      "Speed: 1.8ms preprocess, 27.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/241.jpg: 384x640 (no detections), 32.3ms\n",
      "Speed: 1.7ms preprocess, 32.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/242.jpg: 384x640 (no detections), 30.8ms\n",
      "Speed: 1.8ms preprocess, 30.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/243.jpg: 384x640 (no detections), 28.0ms\n",
      "Speed: 2.0ms preprocess, 28.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/244.jpg: 384x640 (no detections), 28.8ms\n",
      "Speed: 1.8ms preprocess, 28.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/245.jpg: 384x640 (no detections), 28.4ms\n",
      "Speed: 1.8ms preprocess, 28.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/246.jpg: 384x640 (no detections), 37.5ms\n",
      "Speed: 2.5ms preprocess, 37.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/247.jpg: 384x640 (no detections), 25.8ms\n",
      "Speed: 1.9ms preprocess, 25.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/248.jpg: 384x640 (no detections), 29.7ms\n",
      "Speed: 1.9ms preprocess, 29.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/249.jpg: 384x640 (no detections), 31.7ms\n",
      "Speed: 1.7ms preprocess, 31.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/250.jpg: 384x640 (no detections), 35.6ms\n",
      "Speed: 1.9ms preprocess, 35.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/251.jpg: 384x640 (no detections), 31.1ms\n",
      "Speed: 2.5ms preprocess, 31.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/252.jpg: 384x640 (no detections), 26.9ms\n",
      "Speed: 1.9ms preprocess, 26.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/253.jpg: 384x640 (no detections), 30.0ms\n",
      "Speed: 2.9ms preprocess, 30.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/254.jpg: 384x640 (no detections), 28.5ms\n",
      "Speed: 1.8ms preprocess, 28.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/255.jpg: 384x640 (no detections), 38.9ms\n",
      "Speed: 3.1ms preprocess, 38.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/256.jpg: 384x640 (no detections), 30.5ms\n",
      "Speed: 1.8ms preprocess, 30.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/257.jpg: 384x640 1 spoon, 30.0ms\n",
      "Speed: 1.9ms preprocess, 30.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/258.jpg: 384x640 (no detections), 28.3ms\n",
      "Speed: 2.2ms preprocess, 28.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/259.jpg: 384x640 (no detections), 32.1ms\n",
      "Speed: 1.8ms preprocess, 32.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/260.jpg: 384x640 (no detections), 30.9ms\n",
      "Speed: 2.0ms preprocess, 30.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/261.jpg: 384x640 (no detections), 26.0ms\n",
      "Speed: 1.7ms preprocess, 26.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/262.jpg: 384x640 (no detections), 28.4ms\n",
      "Speed: 2.2ms preprocess, 28.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/263.jpg: 384x640 (no detections), 28.4ms\n",
      "Speed: 1.9ms preprocess, 28.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/264.jpg: 384x640 (no detections), 36.1ms\n",
      "Speed: 1.9ms preprocess, 36.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/265.jpg: 384x640 (no detections), 35.1ms\n",
      "Speed: 1.9ms preprocess, 35.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/266.jpg: 384x640 (no detections), 37.6ms\n",
      "Speed: 1.9ms preprocess, 37.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/267.jpg: 384x640 (no detections), 34.8ms\n",
      "Speed: 2.0ms preprocess, 34.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/268.jpg: 384x640 (no detections), 39.9ms\n",
      "Speed: 2.9ms preprocess, 39.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/269.jpg: 384x640 (no detections), 38.8ms\n",
      "Speed: 3.5ms preprocess, 38.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/270.jpg: 384x640 (no detections), 45.3ms\n",
      "Speed: 2.2ms preprocess, 45.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/271.jpg: 384x640 (no detections), 46.9ms\n",
      "Speed: 2.0ms preprocess, 46.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/272.jpg: 384x640 (no detections), 56.2ms\n",
      "Speed: 2.3ms preprocess, 56.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/273.jpg: 384x640 (no detections), 36.8ms\n",
      "Speed: 2.1ms preprocess, 36.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/274.jpg: 384x640 (no detections), 28.1ms\n",
      "Speed: 2.3ms preprocess, 28.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/275.jpg: 384x640 (no detections), 28.2ms\n",
      "Speed: 1.9ms preprocess, 28.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/276.jpg: 384x640 (no detections), 46.9ms\n",
      "Speed: 2.1ms preprocess, 46.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/277.jpg: 384x640 (no detections), 39.1ms\n",
      "Speed: 2.6ms preprocess, 39.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/278.jpg: 384x640 (no detections), 36.3ms\n",
      "Speed: 2.0ms preprocess, 36.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/279.jpg: 384x640 (no detections), 30.9ms\n",
      "Speed: 1.8ms preprocess, 30.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/280.jpg: 384x640 (no detections), 32.1ms\n",
      "Speed: 1.8ms preprocess, 32.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/281.jpg: 384x640 (no detections), 54.3ms\n",
      "Speed: 3.0ms preprocess, 54.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/282.jpg: 384x640 (no detections), 28.1ms\n",
      "Speed: 1.8ms preprocess, 28.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/283.jpg: 384x640 1 toothbrush, 29.7ms\n",
      "Speed: 2.4ms preprocess, 29.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/284.jpg: 384x640 (no detections), 58.0ms\n",
      "Speed: 2.2ms preprocess, 58.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/285.jpg: 384x640 (no detections), 39.1ms\n",
      "Speed: 1.6ms preprocess, 39.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/286.jpg: 384x640 (no detections), 26.3ms\n",
      "Speed: 2.3ms preprocess, 26.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/287.jpg: 384x640 1 toothbrush, 27.8ms\n",
      "Speed: 1.7ms preprocess, 27.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/288.jpg: 384x640 1 toothbrush, 32.4ms\n",
      "Speed: 1.8ms preprocess, 32.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/289.jpg: 384x640 1 toothbrush, 32.7ms\n",
      "Speed: 2.0ms preprocess, 32.7ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/290.jpg: 384x640 (no detections), 47.9ms\n",
      "Speed: 2.1ms preprocess, 47.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/291.jpg: 384x640 (no detections), 26.0ms\n",
      "Speed: 1.7ms preprocess, 26.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/292.jpg: 384x640 (no detections), 27.0ms\n",
      "Speed: 1.8ms preprocess, 27.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/293.jpg: 384x640 (no detections), 26.6ms\n",
      "Speed: 2.5ms preprocess, 26.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/294.jpg: 384x640 (no detections), 32.2ms\n",
      "Speed: 1.9ms preprocess, 32.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/295.jpg: 384x640 (no detections), 28.2ms\n",
      "Speed: 1.9ms preprocess, 28.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/296.jpg: 384x640 (no detections), 25.6ms\n",
      "Speed: 1.7ms preprocess, 25.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/297.jpg: 384x640 (no detections), 28.0ms\n",
      "Speed: 1.6ms preprocess, 28.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/298.jpg: 384x640 (no detections), 30.0ms\n",
      "Speed: 1.9ms preprocess, 30.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/low_brightness/right/299.jpg: 384x640 (no detections), 34.7ms\n",
      "Speed: 1.9ms preprocess, 34.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Propagating video frames: 100%|| 300/300 [00:20<00:00, 14.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask propagation completed in 20.95 seconds.\n",
      "Processing predicted masks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing video frames: 300it [00:00, 966.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 300 masks for evaluation.\n",
      "Masks saved to data/masks/yolo11x-seg/val/data-raw-SegSTRONGC_val-val-1-2-low_brightness-right.pkl\n",
      "Loading ground truth masks for evaluation...\n",
      "Loaded 300 ground truth masks.\n",
      "Calculating evaluation metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for metrics calculation: 1.55 seconds.\n",
      "Mean IoU for data/raw/SegSTRONGC_val/val/1/2/low_brightness/right: 0.0623\n",
      "Mean DSC for data/raw/SegSTRONGC_val/val/1/2/low_brightness/right: 0.0967\n",
      "Loading existing results file: data/results/yolo11x-seg/val.json\n",
      "Results saved to data/results/yolo11x-seg/val.json\n",
      "Processing video took 25.91 seconds.\n",
      "==================================================\n",
      "\n",
      "Results for data/raw/SegSTRONGC_val/val/1/2/low_brightness:\n",
      "  Left: IoU=0.0285, DSC=0.0462\n",
      "  Right: IoU=0.0623, DSC=0.0967\n",
      "  Overall: IoU=0.0454, DSC=0.0715\n",
      "\n",
      "Processing domain: regular\n",
      "Processing left camera video...\n",
      "==================================================\n",
      "Processing video: data/raw/SegSTRONGC_val/val/1/2/regular/left\n",
      "Domain: regular, Split: val, Camera: left\n",
      "Initializing Yolo for video...\n",
      "Initialization took 0.17 seconds.\n",
      "Starting mask propagation...\n",
      "Total images in video: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/0.jpg: 384x640 1 baseball bat, 1 bottle, 2 carrots, 47.7ms\n",
      "Speed: 2.7ms preprocess, 47.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/1.jpg: 384x640 1 baseball bat, 2 bottles, 1 carrot, 45.3ms\n",
      "Speed: 2.1ms preprocess, 45.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/2.jpg: 384x640 1 baseball bat, 2 bottles, 1 carrot, 28.4ms\n",
      "Speed: 1.9ms preprocess, 28.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/3.jpg: 384x640 1 baseball bat, 1 bottle, 1 carrot, 28.1ms\n",
      "Speed: 2.3ms preprocess, 28.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/4.jpg: 384x640 1 bottle, 1 carrot, 39.7ms\n",
      "Speed: 3.3ms preprocess, 39.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/5.jpg: 384x640 1 baseball bat, 1 spoon, 1 carrot, 51.8ms\n",
      "Speed: 2.7ms preprocess, 51.8ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/6.jpg: 384x640 1 spoon, 1 carrot, 39.5ms\n",
      "Speed: 2.7ms preprocess, 39.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/7.jpg: 384x640 1 bottle, 1 carrot, 1 donut, 71.2ms\n",
      "Speed: 2.0ms preprocess, 71.2ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/8.jpg: 384x640 1 baseball bat, 1 bottle, 1 carrot, 56.3ms\n",
      "Speed: 3.3ms preprocess, 56.3ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/9.jpg: 384x640 1 bottle, 1 carrot, 51.4ms\n",
      "Speed: 2.3ms preprocess, 51.4ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/10.jpg: 384x640 1 bottle, 1 carrot, 31.5ms\n",
      "Speed: 2.3ms preprocess, 31.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/11.jpg: 384x640 1 bottle, 1 carrot, 37.5ms\n",
      "Speed: 2.1ms preprocess, 37.5ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/12.jpg: 384x640 1 baseball bat, 2 bottles, 1 carrot, 43.1ms\n",
      "Speed: 3.0ms preprocess, 43.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/13.jpg: 384x640 1 bottle, 1 carrot, 34.5ms\n",
      "Speed: 3.2ms preprocess, 34.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/14.jpg: 384x640 1 spoon, 1 carrot, 1 donut, 30.0ms\n",
      "Speed: 1.9ms preprocess, 30.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/15.jpg: 384x640 1 bottle, 31.2ms\n",
      "Speed: 2.4ms preprocess, 31.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/16.jpg: 384x640 1 bottle, 1 carrot, 51.8ms\n",
      "Speed: 2.1ms preprocess, 51.8ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/17.jpg: 384x640 4 carrots, 59.7ms\n",
      "Speed: 2.0ms preprocess, 59.7ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/18.jpg: 384x640 3 carrots, 41.1ms\n",
      "Speed: 2.9ms preprocess, 41.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/19.jpg: 384x640 3 carrots, 53.7ms\n",
      "Speed: 2.5ms preprocess, 53.7ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/20.jpg: 384x640 1 carrot, 35.5ms\n",
      "Speed: 2.8ms preprocess, 35.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/21.jpg: 384x640 1 carrot, 32.6ms\n",
      "Speed: 2.0ms preprocess, 32.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/22.jpg: 384x640 1 carrot, 38.9ms\n",
      "Speed: 2.3ms preprocess, 38.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/23.jpg: 384x640 3 carrots, 28.6ms\n",
      "Speed: 1.9ms preprocess, 28.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/24.jpg: 384x640 5 carrots, 34.7ms\n",
      "Speed: 3.0ms preprocess, 34.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/25.jpg: 384x640 1 carrot, 36.9ms\n",
      "Speed: 2.0ms preprocess, 36.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/26.jpg: 384x640 1 carrot, 54.3ms\n",
      "Speed: 2.0ms preprocess, 54.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/27.jpg: 384x640 3 carrots, 1 donut, 33.8ms\n",
      "Speed: 2.2ms preprocess, 33.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/28.jpg: 384x640 2 carrots, 38.6ms\n",
      "Speed: 1.7ms preprocess, 38.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/29.jpg: 384x640 2 carrots, 41.2ms\n",
      "Speed: 1.9ms preprocess, 41.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/30.jpg: 384x640 3 carrots, 1 donut, 39.3ms\n",
      "Speed: 1.8ms preprocess, 39.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/31.jpg: 384x640 4 carrots, 1 donut, 29.5ms\n",
      "Speed: 2.1ms preprocess, 29.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/32.jpg: 384x640 2 carrots, 29.9ms\n",
      "Speed: 1.9ms preprocess, 29.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/33.jpg: 384x640 2 carrots, 1 donut, 33.4ms\n",
      "Speed: 2.9ms preprocess, 33.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/34.jpg: 384x640 1 carrot, 1 donut, 46.6ms\n",
      "Speed: 3.2ms preprocess, 46.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/35.jpg: 384x640 3 carrots, 40.7ms\n",
      "Speed: 1.9ms preprocess, 40.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/36.jpg: 384x640 1 baseball bat, 2 carrots, 42.2ms\n",
      "Speed: 2.5ms preprocess, 42.2ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/37.jpg: 384x640 1 carrot, 37.1ms\n",
      "Speed: 2.2ms preprocess, 37.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/38.jpg: 384x640 1 bottle, 2 carrots, 1 donut, 44.4ms\n",
      "Speed: 1.9ms preprocess, 44.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/39.jpg: 384x640 1 carrot, 1 donut, 28.4ms\n",
      "Speed: 2.1ms preprocess, 28.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/40.jpg: 384x640 3 carrots, 1 donut, 37.1ms\n",
      "Speed: 2.1ms preprocess, 37.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/41.jpg: 384x640 2 carrots, 28.1ms\n",
      "Speed: 2.2ms preprocess, 28.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/42.jpg: 384x640 1 baseball bat, 1 bottle, 3 carrots, 1 donut, 1 toothbrush, 43.5ms\n",
      "Speed: 3.3ms preprocess, 43.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/43.jpg: 384x640 2 carrots, 1 donut, 30.2ms\n",
      "Speed: 1.8ms preprocess, 30.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/44.jpg: 384x640 3 carrots, 1 donut, 45.7ms\n",
      "Speed: 1.6ms preprocess, 45.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/45.jpg: 384x640 2 carrots, 1 donut, 32.9ms\n",
      "Speed: 2.3ms preprocess, 32.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/46.jpg: 384x640 4 carrots, 36.3ms\n",
      "Speed: 3.0ms preprocess, 36.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/47.jpg: 384x640 3 carrots, 1 donut, 35.5ms\n",
      "Speed: 2.1ms preprocess, 35.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/48.jpg: 384x640 3 carrots, 28.6ms\n",
      "Speed: 1.7ms preprocess, 28.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/49.jpg: 384x640 3 carrots, 1 donut, 39.1ms\n",
      "Speed: 1.9ms preprocess, 39.1ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/50.jpg: 384x640 1 carrot, 28.1ms\n",
      "Speed: 1.8ms preprocess, 28.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/51.jpg: 384x640 1 baseball bat, 2 carrots, 45.5ms\n",
      "Speed: 3.0ms preprocess, 45.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/52.jpg: 384x640 1 carrot, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/53.jpg: 384x640 1 carrot, 32.2ms\n",
      "Speed: 1.9ms preprocess, 32.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/54.jpg: 384x640 1 baseball bat, 1 carrot, 49.6ms\n",
      "Speed: 3.1ms preprocess, 49.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/55.jpg: 384x640 1 baseball bat, 1 carrot, 31.7ms\n",
      "Speed: 2.3ms preprocess, 31.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/56.jpg: 384x640 1 bottle, 2 carrots, 32.1ms\n",
      "Speed: 1.9ms preprocess, 32.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/57.jpg: 384x640 4 carrots, 36.7ms\n",
      "Speed: 2.0ms preprocess, 36.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/58.jpg: 384x640 1 baseball bat, 1 bottle, 3 carrots, 28.5ms\n",
      "Speed: 2.1ms preprocess, 28.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/59.jpg: 384x640 1 carrot, 47.2ms\n",
      "Speed: 2.1ms preprocess, 47.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/60.jpg: 384x640 5 carrots, 1 donut, 28.7ms\n",
      "Speed: 1.8ms preprocess, 28.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/61.jpg: 384x640 5 carrots, 35.3ms\n",
      "Speed: 3.4ms preprocess, 35.3ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/62.jpg: 384x640 1 baseball bat, 3 carrots, 1 donut, 29.3ms\n",
      "Speed: 1.8ms preprocess, 29.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/63.jpg: 384x640 3 carrots, 40.5ms\n",
      "Speed: 1.7ms preprocess, 40.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/64.jpg: 384x640 1 baseball bat, 1 bottle, 1 carrot, 28.4ms\n",
      "Speed: 1.6ms preprocess, 28.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/65.jpg: 384x640 2 carrots, 40.4ms\n",
      "Speed: 1.9ms preprocess, 40.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/66.jpg: 384x640 1 baseball bat, 3 carrots, 32.0ms\n",
      "Speed: 2.4ms preprocess, 32.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/67.jpg: 384x640 4 carrots, 1 donut, 29.8ms\n",
      "Speed: 1.7ms preprocess, 29.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/68.jpg: 384x640 3 carrots, 1 donut, 31.0ms\n",
      "Speed: 1.7ms preprocess, 31.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/69.jpg: 384x640 2 carrots, 1 donut, 44.4ms\n",
      "Speed: 1.8ms preprocess, 44.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/70.jpg: 384x640 2 carrots, 2 donuts, 29.7ms\n",
      "Speed: 1.9ms preprocess, 29.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/71.jpg: 384x640 4 carrots, 1 donut, 37.2ms\n",
      "Speed: 1.7ms preprocess, 37.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/72.jpg: 384x640 1 fork, 7 carrots, 1 donut, 30.7ms\n",
      "Speed: 1.6ms preprocess, 30.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/73.jpg: 384x640 10 carrots, 40.7ms\n",
      "Speed: 1.7ms preprocess, 40.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/74.jpg: 384x640 4 carrots, 2 donuts, 36.2ms\n",
      "Speed: 3.2ms preprocess, 36.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/75.jpg: 384x640 1 knife, 6 carrots, 28.1ms\n",
      "Speed: 2.0ms preprocess, 28.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/76.jpg: 384x640 5 carrots, 34.3ms\n",
      "Speed: 1.9ms preprocess, 34.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/77.jpg: 384x640 1 bottle, 6 carrots, 27.8ms\n",
      "Speed: 2.6ms preprocess, 27.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/78.jpg: 384x640 1 baseball bat, 1 bottle, 5 carrots, 53.1ms\n",
      "Speed: 2.3ms preprocess, 53.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/79.jpg: 384x640 1 knife, 5 carrots, 43.0ms\n",
      "Speed: 1.8ms preprocess, 43.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/80.jpg: 384x640 1 baseball bat, 1 bottle, 6 carrots, 32.5ms\n",
      "Speed: 1.9ms preprocess, 32.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/81.jpg: 384x640 1 spoon, 3 carrots, 1 donut, 44.5ms\n",
      "Speed: 1.8ms preprocess, 44.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/82.jpg: 384x640 1 bottle, 5 carrots, 35.0ms\n",
      "Speed: 3.3ms preprocess, 35.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/83.jpg: 384x640 1 bottle, 1 spoon, 2 carrots, 1 donut, 29.3ms\n",
      "Speed: 1.8ms preprocess, 29.3ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/84.jpg: 384x640 1 spoon, 3 carrots, 48.0ms\n",
      "Speed: 2.1ms preprocess, 48.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/85.jpg: 384x640 1 bottle, 1 carrot, 2 donuts, 60.0ms\n",
      "Speed: 2.0ms preprocess, 60.0ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/86.jpg: 384x640 1 bottle, 3 carrots, 39.4ms\n",
      "Speed: 2.2ms preprocess, 39.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/87.jpg: 384x640 1 knife, 4 carrots, 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/88.jpg: 384x640 4 carrots, 48.5ms\n",
      "Speed: 2.6ms preprocess, 48.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/89.jpg: 384x640 1 bottle, 2 carrots, 44.0ms\n",
      "Speed: 1.9ms preprocess, 44.0ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/90.jpg: 384x640 1 bottle, 4 carrots, 50.2ms\n",
      "Speed: 3.6ms preprocess, 50.2ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/91.jpg: 384x640 1 bottle, 6 carrots, 42.5ms\n",
      "Speed: 2.0ms preprocess, 42.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/92.jpg: 384x640 1 bottle, 2 carrots, 39.0ms\n",
      "Speed: 2.0ms preprocess, 39.0ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/93.jpg: 384x640 1 bottle, 2 carrots, 37.9ms\n",
      "Speed: 2.6ms preprocess, 37.9ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/94.jpg: 384x640 1 bottle, 3 carrots, 34.0ms\n",
      "Speed: 2.2ms preprocess, 34.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/95.jpg: 384x640 1 bottle, 4 carrots, 29.6ms\n",
      "Speed: 2.3ms preprocess, 29.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/96.jpg: 384x640 1 bottle, 1 spoon, 2 carrots, 46.1ms\n",
      "Speed: 2.4ms preprocess, 46.1ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/97.jpg: 384x640 1 bottle, 1 carrot, 42.8ms\n",
      "Speed: 2.1ms preprocess, 42.8ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/98.jpg: 384x640 1 bottle, 1 carrot, 35.2ms\n",
      "Speed: 1.9ms preprocess, 35.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/99.jpg: 384x640 1 baseball bat, 1 bottle, 2 carrots, 37.8ms\n",
      "Speed: 2.0ms preprocess, 37.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/100.jpg: 384x640 1 baseball bat, 1 bottle, 1 carrot, 46.1ms\n",
      "Speed: 2.1ms preprocess, 46.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/101.jpg: 384x640 1 baseball bat, 1 bottle, 4 carrots, 40.8ms\n",
      "Speed: 2.1ms preprocess, 40.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/102.jpg: 384x640 1 baseball bat, 1 bottle, 3 carrots, 34.2ms\n",
      "Speed: 1.8ms preprocess, 34.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/103.jpg: 384x640 1 bottle, 5 carrots, 28.8ms\n",
      "Speed: 2.1ms preprocess, 28.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/104.jpg: 384x640 1 bottle, 1 carrot, 34.4ms\n",
      "Speed: 2.9ms preprocess, 34.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/105.jpg: 384x640 1 bottle, 4 carrots, 43.2ms\n",
      "Speed: 2.0ms preprocess, 43.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/106.jpg: 384x640 1 bottle, 1 carrot, 31.5ms\n",
      "Speed: 2.4ms preprocess, 31.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/107.jpg: 384x640 1 bottle, 1 carrot, 53.3ms\n",
      "Speed: 1.9ms preprocess, 53.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/108.jpg: 384x640 1 bottle, 1 carrot, 27.6ms\n",
      "Speed: 1.6ms preprocess, 27.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/109.jpg: 384x640 1 bottle, 1 carrot, 1 donut, 37.4ms\n",
      "Speed: 1.8ms preprocess, 37.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/110.jpg: 384x640 1 bottle, 2 carrots, 26.5ms\n",
      "Speed: 1.6ms preprocess, 26.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/111.jpg: 384x640 1 bottle, 2 carrots, 28.7ms\n",
      "Speed: 1.6ms preprocess, 28.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/112.jpg: 384x640 1 bottle, 3 carrots, 36.6ms\n",
      "Speed: 2.0ms preprocess, 36.6ms inference, 12.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/113.jpg: 384x640 1 bottle, 2 carrots, 1 donut, 35.1ms\n",
      "Speed: 2.6ms preprocess, 35.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/114.jpg: 384x640 1 bottle, 1 carrot, 26.5ms\n",
      "Speed: 1.7ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/115.jpg: 384x640 1 bottle, 1 carrot, 26.8ms\n",
      "Speed: 1.9ms preprocess, 26.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/116.jpg: 384x640 1 bottle, 1 carrot, 46.2ms\n",
      "Speed: 2.1ms preprocess, 46.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/117.jpg: 384x640 1 bottle, 1 carrot, 30.1ms\n",
      "Speed: 2.0ms preprocess, 30.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/118.jpg: 384x640 1 baseball bat, 1 bottle, 7 carrots, 30.9ms\n",
      "Speed: 1.9ms preprocess, 30.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/119.jpg: 384x640 1 baseball bat, 2 bottles, 2 carrots, 28.6ms\n",
      "Speed: 2.1ms preprocess, 28.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/120.jpg: 384x640 1 bottle, 2 carrots, 28.1ms\n",
      "Speed: 1.7ms preprocess, 28.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/121.jpg: 384x640 1 spoon, 1 carrot, 27.5ms\n",
      "Speed: 2.5ms preprocess, 27.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/122.jpg: 384x640 1 bottle, 9 carrots, 26.6ms\n",
      "Speed: 1.7ms preprocess, 26.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/123.jpg: 384x640 1 bottle, 8 carrots, 28.6ms\n",
      "Speed: 1.8ms preprocess, 28.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/124.jpg: 384x640 1 bottle, 7 carrots, 29.0ms\n",
      "Speed: 1.7ms preprocess, 29.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/125.jpg: 384x640 1 bottle, 5 carrots, 31.4ms\n",
      "Speed: 2.0ms preprocess, 31.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/126.jpg: 384x640 1 bottle, 8 carrots, 28.0ms\n",
      "Speed: 2.4ms preprocess, 28.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/127.jpg: 384x640 1 bottle, 1 carrot, 32.1ms\n",
      "Speed: 1.9ms preprocess, 32.1ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/128.jpg: 384x640 2 bottles, 2 carrots, 26.8ms\n",
      "Speed: 1.9ms preprocess, 26.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/129.jpg: 384x640 1 bottle, 3 carrots, 34.8ms\n",
      "Speed: 5.7ms preprocess, 34.8ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/130.jpg: 384x640 1 bottle, 1 carrot, 25.2ms\n",
      "Speed: 1.8ms preprocess, 25.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/131.jpg: 384x640 1 bottle, 1 carrot, 26.4ms\n",
      "Speed: 1.9ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/132.jpg: 384x640 1 carrot, 39.5ms\n",
      "Speed: 1.6ms preprocess, 39.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/133.jpg: 384x640 1 bottle, 5 carrots, 49.4ms\n",
      "Speed: 2.6ms preprocess, 49.4ms inference, 9.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/134.jpg: 384x640 1 bottle, 2 carrots, 37.7ms\n",
      "Speed: 3.2ms preprocess, 37.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/135.jpg: 384x640 2 carrots, 1 donut, 54.1ms\n",
      "Speed: 1.9ms preprocess, 54.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/136.jpg: 384x640 1 bottle, 1 carrot, 26.3ms\n",
      "Speed: 1.7ms preprocess, 26.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/137.jpg: 384x640 1 carrot, 38.4ms\n",
      "Speed: 1.7ms preprocess, 38.4ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/138.jpg: 384x640 4 carrots, 28.4ms\n",
      "Speed: 2.9ms preprocess, 28.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/139.jpg: 384x640 7 carrots, 30.6ms\n",
      "Speed: 2.2ms preprocess, 30.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/140.jpg: 384x640 9 carrots, 1 donut, 39.2ms\n",
      "Speed: 1.9ms preprocess, 39.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/141.jpg: 384x640 7 carrots, 1 donut, 65.9ms\n",
      "Speed: 3.3ms preprocess, 65.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/142.jpg: 384x640 4 carrots, 43.3ms\n",
      "Speed: 2.4ms preprocess, 43.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/143.jpg: 384x640 4 carrots, 43.4ms\n",
      "Speed: 2.4ms preprocess, 43.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/144.jpg: 384x640 1 bottle, 4 carrots, 48.4ms\n",
      "Speed: 2.4ms preprocess, 48.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/145.jpg: 384x640 1 bottle, 7 carrots, 1 donut, 48.3ms\n",
      "Speed: 3.4ms preprocess, 48.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/146.jpg: 384x640 1 bottle, 4 carrots, 41.8ms\n",
      "Speed: 2.9ms preprocess, 41.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/147.jpg: 384x640 5 carrots, 39.2ms\n",
      "Speed: 2.0ms preprocess, 39.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/148.jpg: 384x640 2 carrots, 30.2ms\n",
      "Speed: 2.3ms preprocess, 30.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/149.jpg: 384x640 4 carrots, 30.9ms\n",
      "Speed: 1.8ms preprocess, 30.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/150.jpg: 384x640 1 bottle, 3 carrots, 1 donut, 27.8ms\n",
      "Speed: 2.0ms preprocess, 27.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/151.jpg: 384x640 1 bottle, 3 carrots, 34.2ms\n",
      "Speed: 1.9ms preprocess, 34.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/152.jpg: 384x640 1 baseball bat, 1 bottle, 1 spoon, 2 carrots, 28.1ms\n",
      "Speed: 1.8ms preprocess, 28.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/153.jpg: 384x640 1 bottle, 1 spoon, 4 carrots, 36.5ms\n",
      "Speed: 1.8ms preprocess, 36.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/154.jpg: 384x640 4 carrots, 1 donut, 27.1ms\n",
      "Speed: 1.8ms preprocess, 27.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/155.jpg: 384x640 1 bottle, 4 carrots, 37.8ms\n",
      "Speed: 1.7ms preprocess, 37.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/156.jpg: 384x640 3 carrots, 25.8ms\n",
      "Speed: 1.9ms preprocess, 25.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/157.jpg: 384x640 4 carrots, 27.4ms\n",
      "Speed: 2.0ms preprocess, 27.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/158.jpg: 384x640 2 carrots, 1 toothbrush, 41.3ms\n",
      "Speed: 2.9ms preprocess, 41.3ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/159.jpg: 384x640 3 carrots, 1 donut, 26.2ms\n",
      "Speed: 1.8ms preprocess, 26.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/160.jpg: 384x640 1 bottle, 3 carrots, 1 donut, 26.6ms\n",
      "Speed: 1.7ms preprocess, 26.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/161.jpg: 384x640 1 bottle, 4 carrots, 29.0ms\n",
      "Speed: 1.9ms preprocess, 29.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/162.jpg: 384x640 5 carrots, 26.3ms\n",
      "Speed: 1.8ms preprocess, 26.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/163.jpg: 384x640 1 carrot, 30.3ms\n",
      "Speed: 1.7ms preprocess, 30.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/164.jpg: 384x640 1 bottle, 2 carrots, 25.9ms\n",
      "Speed: 1.9ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/165.jpg: 384x640 1 bottle, 3 carrots, 1 donut, 25.8ms\n",
      "Speed: 1.9ms preprocess, 25.8ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/166.jpg: 384x640 1 bottle, 5 carrots, 25.6ms\n",
      "Speed: 1.8ms preprocess, 25.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/167.jpg: 384x640 1 bottle, 4 carrots, 38.2ms\n",
      "Speed: 1.9ms preprocess, 38.2ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/168.jpg: 384x640 1 bottle, 3 carrots, 1 donut, 26.2ms\n",
      "Speed: 1.6ms preprocess, 26.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/169.jpg: 384x640 1 spoon, 3 carrots, 26.5ms\n",
      "Speed: 1.8ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/170.jpg: 384x640 1 knife, 4 carrots, 31.5ms\n",
      "Speed: 1.5ms preprocess, 31.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/171.jpg: 384x640 1 spoon, 2 carrots, 30.9ms\n",
      "Speed: 1.7ms preprocess, 30.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/172.jpg: 384x640 2 carrots, 28.2ms\n",
      "Speed: 2.6ms preprocess, 28.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/173.jpg: 384x640 1 spoon, 4 carrots, 26.4ms\n",
      "Speed: 1.7ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/174.jpg: 384x640 1 knife, 3 carrots, 1 donut, 26.3ms\n",
      "Speed: 1.6ms preprocess, 26.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/175.jpg: 384x640 1 knife, 1 carrot, 37.4ms\n",
      "Speed: 2.5ms preprocess, 37.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/176.jpg: 384x640 1 carrot, 27.4ms\n",
      "Speed: 1.9ms preprocess, 27.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/177.jpg: 384x640 2 carrots, 32.3ms\n",
      "Speed: 2.9ms preprocess, 32.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/178.jpg: 384x640 3 carrots, 32.8ms\n",
      "Speed: 2.6ms preprocess, 32.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/179.jpg: 384x640 1 knife, 4 carrots, 37.1ms\n",
      "Speed: 1.7ms preprocess, 37.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/180.jpg: 384x640 1 bottle, 4 carrots, 26.6ms\n",
      "Speed: 1.6ms preprocess, 26.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/181.jpg: 384x640 1 baseball bat, 2 carrots, 26.8ms\n",
      "Speed: 1.6ms preprocess, 26.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/182.jpg: 384x640 1 bottle, 3 carrots, 29.9ms\n",
      "Speed: 1.5ms preprocess, 29.9ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/183.jpg: 384x640 1 carrot, 35.9ms\n",
      "Speed: 2.3ms preprocess, 35.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/184.jpg: 384x640 2 carrots, 32.2ms\n",
      "Speed: 2.6ms preprocess, 32.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/185.jpg: 384x640 1 bottle, 3 carrots, 36.7ms\n",
      "Speed: 1.8ms preprocess, 36.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/186.jpg: 384x640 1 spoon, 1 carrot, 2 donuts, 27.6ms\n",
      "Speed: 1.8ms preprocess, 27.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/187.jpg: 384x640 1 carrot, 1 donut, 29.5ms\n",
      "Speed: 1.8ms preprocess, 29.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/188.jpg: 384x640 2 carrots, 1 donut, 45.5ms\n",
      "Speed: 3.4ms preprocess, 45.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/189.jpg: 384x640 4 carrots, 1 donut, 33.6ms\n",
      "Speed: 2.3ms preprocess, 33.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/190.jpg: 384x640 2 carrots, 1 donut, 48.2ms\n",
      "Speed: 1.7ms preprocess, 48.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/191.jpg: 384x640 4 carrots, 37.8ms\n",
      "Speed: 2.1ms preprocess, 37.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/192.jpg: 384x640 4 carrots, 1 donut, 33.3ms\n",
      "Speed: 2.7ms preprocess, 33.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/193.jpg: 384x640 1 spoon, 4 carrots, 42.8ms\n",
      "Speed: 2.9ms preprocess, 42.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/194.jpg: 384x640 1 carrot, 32.3ms\n",
      "Speed: 2.1ms preprocess, 32.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/195.jpg: 384x640 3 carrots, 43.3ms\n",
      "Speed: 2.7ms preprocess, 43.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/196.jpg: 384x640 5 carrots, 36.8ms\n",
      "Speed: 1.9ms preprocess, 36.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/197.jpg: 384x640 4 carrots, 43.4ms\n",
      "Speed: 1.8ms preprocess, 43.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/198.jpg: 384x640 2 carrots, 43.1ms\n",
      "Speed: 2.8ms preprocess, 43.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/199.jpg: 384x640 4 carrots, 40.4ms\n",
      "Speed: 1.8ms preprocess, 40.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/200.jpg: 384x640 5 carrots, 1 donut, 31.8ms\n",
      "Speed: 2.0ms preprocess, 31.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/201.jpg: 384x640 1 fork, 3 carrots, 26.9ms\n",
      "Speed: 1.9ms preprocess, 26.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/202.jpg: 384x640 1 bottle, 8 carrots, 32.7ms\n",
      "Speed: 2.1ms preprocess, 32.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/203.jpg: 384x640 1 bottle, 5 carrots, 34.0ms\n",
      "Speed: 1.9ms preprocess, 34.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/204.jpg: 384x640 1 bottle, 4 carrots, 1 donut, 30.8ms\n",
      "Speed: 1.7ms preprocess, 30.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/205.jpg: 384x640 1 spoon, 4 carrots, 36.1ms\n",
      "Speed: 1.7ms preprocess, 36.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/206.jpg: 384x640 1 spoon, 1 carrot, 1 donut, 26.0ms\n",
      "Speed: 1.9ms preprocess, 26.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/207.jpg: 384x640 1 spoon, 1 carrot, 1 donut, 27.5ms\n",
      "Speed: 1.9ms preprocess, 27.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/208.jpg: 384x640 1 knife, 3 carrots, 30.8ms\n",
      "Speed: 1.6ms preprocess, 30.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/209.jpg: 384x640 1 knife, 1 spoon, 3 carrots, 29.6ms\n",
      "Speed: 1.6ms preprocess, 29.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/210.jpg: 384x640 1 baseball bat, 4 carrots, 46.1ms\n",
      "Speed: 3.5ms preprocess, 46.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/211.jpg: 384x640 1 baseball bat, 1 bottle, 5 carrots, 33.4ms\n",
      "Speed: 1.7ms preprocess, 33.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/212.jpg: 384x640 1 baseball bat, 3 carrots, 27.4ms\n",
      "Speed: 1.7ms preprocess, 27.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/213.jpg: 384x640 1 baseball bat, 1 carrot, 38.0ms\n",
      "Speed: 2.0ms preprocess, 38.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/214.jpg: 384x640 1 knife, 1 carrot, 26.4ms\n",
      "Speed: 1.9ms preprocess, 26.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/215.jpg: 384x640 1 knife, 1 carrot, 1 donut, 39.3ms\n",
      "Speed: 2.0ms preprocess, 39.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/216.jpg: 384x640 3 carrots, 25.9ms\n",
      "Speed: 1.6ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/217.jpg: 384x640 2 carrots, 2 donuts, 34.7ms\n",
      "Speed: 1.5ms preprocess, 34.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/218.jpg: 384x640 3 carrots, 2 donuts, 41.9ms\n",
      "Speed: 1.7ms preprocess, 41.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/219.jpg: 384x640 1 bottle, 1 carrot, 1 donut, 26.0ms\n",
      "Speed: 2.0ms preprocess, 26.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/220.jpg: 384x640 2 carrots, 27.6ms\n",
      "Speed: 1.6ms preprocess, 27.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/221.jpg: 384x640 6 carrots, 1 donut, 28.3ms\n",
      "Speed: 2.1ms preprocess, 28.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/222.jpg: 384x640 2 carrots, 26.3ms\n",
      "Speed: 1.9ms preprocess, 26.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/223.jpg: 384x640 5 carrots, 26.1ms\n",
      "Speed: 1.6ms preprocess, 26.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/224.jpg: 384x640 6 carrots, 27.8ms\n",
      "Speed: 1.7ms preprocess, 27.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/225.jpg: 384x640 1 spoon, 2 carrots, 38.0ms\n",
      "Speed: 1.8ms preprocess, 38.0ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/226.jpg: 384x640 1 spoon, 3 carrots, 29.7ms\n",
      "Speed: 2.9ms preprocess, 29.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/227.jpg: 384x640 1 baseball bat, 2 carrots, 28.6ms\n",
      "Speed: 1.7ms preprocess, 28.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/228.jpg: 384x640 1 baseball bat, 1 carrot, 26.1ms\n",
      "Speed: 1.7ms preprocess, 26.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/229.jpg: 384x640 1 baseball bat, 4 carrots, 34.8ms\n",
      "Speed: 1.8ms preprocess, 34.8ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/230.jpg: 384x640 1 baseball bat, 4 carrots, 27.6ms\n",
      "Speed: 2.1ms preprocess, 27.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/231.jpg: 384x640 1 baseball bat, 1 bottle, 7 carrots, 29.8ms\n",
      "Speed: 1.9ms preprocess, 29.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/232.jpg: 384x640 1 baseball bat, 5 carrots, 26.1ms\n",
      "Speed: 1.9ms preprocess, 26.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/233.jpg: 384x640 1 baseball bat, 1 spoon, 7 carrots, 33.0ms\n",
      "Speed: 2.1ms preprocess, 33.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/234.jpg: 384x640 1 spoon, 9 carrots, 36.4ms\n",
      "Speed: 2.7ms preprocess, 36.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/235.jpg: 384x640 1 baseball bat, 6 carrots, 29.0ms\n",
      "Speed: 1.7ms preprocess, 29.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/236.jpg: 384x640 1 baseball bat, 1 spoon, 3 carrots, 35.6ms\n",
      "Speed: 1.9ms preprocess, 35.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/237.jpg: 384x640 1 spoon, 3 carrots, 37.7ms\n",
      "Speed: 2.1ms preprocess, 37.7ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/238.jpg: 384x640 1 spoon, 7 carrots, 26.5ms\n",
      "Speed: 1.8ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/239.jpg: 384x640 1 spoon, 7 carrots, 30.4ms\n",
      "Speed: 1.8ms preprocess, 30.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/240.jpg: 384x640 1 baseball bat, 1 spoon, 6 carrots, 31.8ms\n",
      "Speed: 1.7ms preprocess, 31.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/241.jpg: 384x640 1 spoon, 5 carrots, 30.8ms\n",
      "Speed: 1.6ms preprocess, 30.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/242.jpg: 384x640 1 baseball bat, 8 carrots, 38.0ms\n",
      "Speed: 3.0ms preprocess, 38.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/243.jpg: 384x640 1 spoon, 6 carrots, 28.1ms\n",
      "Speed: 1.7ms preprocess, 28.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/244.jpg: 384x640 1 baseball bat, 1 carrot, 33.1ms\n",
      "Speed: 1.7ms preprocess, 33.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/245.jpg: 384x640 1 baseball bat, 3 carrots, 29.3ms\n",
      "Speed: 1.7ms preprocess, 29.3ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/246.jpg: 384x640 1 spoon, 3 carrots, 30.0ms\n",
      "Speed: 1.7ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/247.jpg: 384x640 1 spoon, 2 carrots, 31.0ms\n",
      "Speed: 2.0ms preprocess, 31.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/248.jpg: 384x640 1 bottle, 4 carrots, 27.0ms\n",
      "Speed: 3.1ms preprocess, 27.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/249.jpg: 384x640 1 bottle, 4 carrots, 34.8ms\n",
      "Speed: 1.9ms preprocess, 34.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/250.jpg: 384x640 4 carrots, 53.6ms\n",
      "Speed: 3.1ms preprocess, 53.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/251.jpg: 384x640 1 bottle, 3 carrots, 32.8ms\n",
      "Speed: 1.7ms preprocess, 32.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/252.jpg: 384x640 1 baseball bat, 4 carrots, 30.5ms\n",
      "Speed: 1.8ms preprocess, 30.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/253.jpg: 384x640 3 carrots, 27.5ms\n",
      "Speed: 2.6ms preprocess, 27.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/254.jpg: 384x640 4 carrots, 42.8ms\n",
      "Speed: 3.6ms preprocess, 42.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/255.jpg: 384x640 2 carrots, 40.6ms\n",
      "Speed: 2.1ms preprocess, 40.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/256.jpg: 384x640 2 carrots, 52.6ms\n",
      "Speed: 1.9ms preprocess, 52.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/257.jpg: 384x640 1 spoon, 3 carrots, 39.7ms\n",
      "Speed: 1.8ms preprocess, 39.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/258.jpg: 384x640 4 carrots, 38.7ms\n",
      "Speed: 3.0ms preprocess, 38.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/259.jpg: 384x640 5 carrots, 34.6ms\n",
      "Speed: 2.1ms preprocess, 34.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/260.jpg: 384x640 6 carrots, 27.4ms\n",
      "Speed: 1.8ms preprocess, 27.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/261.jpg: 384x640 1 bottle, 4 carrots, 30.4ms\n",
      "Speed: 2.0ms preprocess, 30.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/262.jpg: 384x640 1 spoon, 1 carrot, 25.8ms\n",
      "Speed: 1.8ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/263.jpg: 384x640 1 spoon, 3 carrots, 32.7ms\n",
      "Speed: 1.8ms preprocess, 32.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/264.jpg: 384x640 3 carrots, 32.8ms\n",
      "Speed: 1.8ms preprocess, 32.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/265.jpg: 384x640 5 carrots, 37.7ms\n",
      "Speed: 2.3ms preprocess, 37.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/266.jpg: 384x640 4 carrots, 29.6ms\n",
      "Speed: 1.9ms preprocess, 29.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/267.jpg: 384x640 2 bottles, 3 carrots, 46.4ms\n",
      "Speed: 2.0ms preprocess, 46.4ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/268.jpg: 384x640 1 bottle, 8 carrots, 33.9ms\n",
      "Speed: 2.7ms preprocess, 33.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/269.jpg: 384x640 1 baseball bat, 2 carrots, 30.1ms\n",
      "Speed: 1.9ms preprocess, 30.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/270.jpg: 384x640 1 bottle, 5 carrots, 32.8ms\n",
      "Speed: 2.8ms preprocess, 32.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/271.jpg: 384x640 6 carrots, 54.2ms\n",
      "Speed: 2.1ms preprocess, 54.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/272.jpg: 384x640 1 fork, 1 spoon, 5 carrots, 28.2ms\n",
      "Speed: 1.8ms preprocess, 28.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/273.jpg: 384x640 1 spoon, 5 carrots, 36.8ms\n",
      "Speed: 1.8ms preprocess, 36.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/274.jpg: 384x640 1 fork, 1 carrot, 28.1ms\n",
      "Speed: 1.7ms preprocess, 28.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/275.jpg: 384x640 4 carrots, 29.1ms\n",
      "Speed: 1.8ms preprocess, 29.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/276.jpg: 384x640 5 carrots, 1 donut, 36.4ms\n",
      "Speed: 3.0ms preprocess, 36.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/277.jpg: 384x640 4 carrots, 39.3ms\n",
      "Speed: 1.9ms preprocess, 39.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/278.jpg: 384x640 1 bottle, 5 carrots, 47.5ms\n",
      "Speed: 2.1ms preprocess, 47.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/279.jpg: 384x640 5 carrots, 40.0ms\n",
      "Speed: 2.0ms preprocess, 40.0ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/280.jpg: 384x640 2 carrots, 47.3ms\n",
      "Speed: 2.3ms preprocess, 47.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/281.jpg: 384x640 1 spoon, 2 carrots, 1 donut, 34.3ms\n",
      "Speed: 1.7ms preprocess, 34.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/282.jpg: 384x640 1 knife, 7 carrots, 34.2ms\n",
      "Speed: 2.1ms preprocess, 34.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/283.jpg: 384x640 1 carrot, 35.7ms\n",
      "Speed: 2.0ms preprocess, 35.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/284.jpg: 384x640 1 carrot, 31.6ms\n",
      "Speed: 1.9ms preprocess, 31.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/285.jpg: 384x640 1 baseball bat, 1 bottle, 3 carrots, 40.1ms\n",
      "Speed: 1.8ms preprocess, 40.1ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/286.jpg: 384x640 3 carrots, 30.3ms\n",
      "Speed: 1.8ms preprocess, 30.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/287.jpg: 384x640 5 carrots, 42.0ms\n",
      "Speed: 1.7ms preprocess, 42.0ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/288.jpg: 384x640 4 carrots, 36.8ms\n",
      "Speed: 2.7ms preprocess, 36.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/289.jpg: 384x640 1 bottle, 6 carrots, 35.7ms\n",
      "Speed: 2.0ms preprocess, 35.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/290.jpg: 384x640 5 carrots, 31.2ms\n",
      "Speed: 1.5ms preprocess, 31.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/291.jpg: 384x640 1 knife, 1 carrot, 29.6ms\n",
      "Speed: 1.9ms preprocess, 29.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/292.jpg: 384x640 1 carrot, 27.4ms\n",
      "Speed: 1.8ms preprocess, 27.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/293.jpg: 384x640 6 carrots, 44.2ms\n",
      "Speed: 2.7ms preprocess, 44.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/294.jpg: 384x640 2 carrots, 28.0ms\n",
      "Speed: 1.7ms preprocess, 28.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/295.jpg: 384x640 2 carrots, 1 remote, 30.9ms\n",
      "Speed: 1.9ms preprocess, 30.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/296.jpg: 384x640 2 carrots, 2 donuts, 44.6ms\n",
      "Speed: 2.0ms preprocess, 44.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/297.jpg: 384x640 1 carrot, 2 donuts, 40.3ms\n",
      "Speed: 2.1ms preprocess, 40.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/298.jpg: 384x640 4 carrots, 37.3ms\n",
      "Speed: 2.1ms preprocess, 37.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/left/299.jpg: 384x640 5 carrots, 33.3ms\n",
      "Speed: 2.8ms preprocess, 33.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Propagating video frames: 100%|| 300/300 [00:22<00:00, 13.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask propagation completed in 22.11 seconds.\n",
      "Processing predicted masks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing video frames: 300it [00:02, 105.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 300 masks for evaluation.\n",
      "Masks saved to data/masks/yolo11x-seg/val/data-raw-SegSTRONGC_val-val-1-2-regular-left.pkl\n",
      "Loading ground truth masks for evaluation...\n",
      "Loaded 300 ground truth masks.\n",
      "Calculating evaluation metrics...\n",
      "Time taken for metrics calculation: 1.54 seconds.\n",
      "Mean IoU for data/raw/SegSTRONGC_val/val/1/2/regular/left: 0.0945\n",
      "Mean DSC for data/raw/SegSTRONGC_val/val/1/2/regular/left: 0.1675\n",
      "Loading existing results file: data/results/yolo11x-seg/val.json\n",
      "Results saved to data/results/yolo11x-seg/val.json\n",
      "Processing video took 30.14 seconds.\n",
      "==================================================\n",
      "Processing right camera video...\n",
      "==================================================\n",
      "Processing video: data/raw/SegSTRONGC_val/val/1/2/regular/right\n",
      "Domain: regular, Split: val, Camera: right\n",
      "Initializing Yolo for video...\n",
      "Initialization took 0.17 seconds.\n",
      "Starting mask propagation...\n",
      "Total images in video: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/0.jpg: 384x640 1 baseball bat, 2 bottles, 2 carrots, 71.7ms\n",
      "Speed: 3.1ms preprocess, 71.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/1.jpg: 384x640 2 bottles, 2 carrots, 27.1ms\n",
      "Speed: 2.0ms preprocess, 27.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/2.jpg: 384x640 1 bottle, 2 carrots, 25.2ms\n",
      "Speed: 2.5ms preprocess, 25.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/3.jpg: 384x640 1 bottle, 1 carrot, 42.0ms\n",
      "Speed: 2.2ms preprocess, 42.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/4.jpg: 384x640 1 spoon, 33.0ms\n",
      "Speed: 1.7ms preprocess, 33.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/5.jpg: 384x640 1 spoon, 3 carrots, 25.7ms\n",
      "Speed: 1.7ms preprocess, 25.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/6.jpg: 384x640 1 spoon, 2 carrots, 26.7ms\n",
      "Speed: 1.8ms preprocess, 26.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/7.jpg: 384x640 1 bottle, 2 carrots, 30.5ms\n",
      "Speed: 2.2ms preprocess, 30.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/8.jpg: 384x640 1 bottle, 1 carrot, 23.7ms\n",
      "Speed: 1.5ms preprocess, 23.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/9.jpg: 384x640 1 bottle, 1 fork, 2 carrots, 26.7ms\n",
      "Speed: 1.5ms preprocess, 26.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/10.jpg: 384x640 1 bottle, 1 fork, 2 carrots, 22.2ms\n",
      "Speed: 1.4ms preprocess, 22.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/11.jpg: 384x640 2 bottles, 3 carrots, 27.5ms\n",
      "Speed: 1.5ms preprocess, 27.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/12.jpg: 384x640 2 bottles, 1 spoon, 2 carrots, 21.9ms\n",
      "Speed: 1.6ms preprocess, 21.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/13.jpg: 384x640 1 spoon, 3 carrots, 24.2ms\n",
      "Speed: 2.2ms preprocess, 24.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/14.jpg: 384x640 1 spoon, 1 carrot, 24.1ms\n",
      "Speed: 1.5ms preprocess, 24.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/15.jpg: 384x640 2 bottles, 4 carrots, 24.7ms\n",
      "Speed: 1.5ms preprocess, 24.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/16.jpg: 384x640 1 bottle, 3 carrots, 27.2ms\n",
      "Speed: 1.5ms preprocess, 27.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/17.jpg: 384x640 4 carrots, 23.6ms\n",
      "Speed: 1.9ms preprocess, 23.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/18.jpg: 384x640 1 fork, 5 carrots, 27.2ms\n",
      "Speed: 1.6ms preprocess, 27.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/19.jpg: 384x640 1 bottle, 1 fork, 4 carrots, 31.9ms\n",
      "Speed: 1.6ms preprocess, 31.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/20.jpg: 384x640 1 bottle, 1 fork, 2 carrots, 24.9ms\n",
      "Speed: 1.6ms preprocess, 24.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/21.jpg: 384x640 1 bottle, 1 fork, 1 spoon, 6 carrots, 26.2ms\n",
      "Speed: 1.5ms preprocess, 26.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/22.jpg: 384x640 1 bottle, 6 carrots, 28.8ms\n",
      "Speed: 1.8ms preprocess, 28.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/23.jpg: 384x640 1 bottle, 6 carrots, 32.1ms\n",
      "Speed: 1.9ms preprocess, 32.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/24.jpg: 384x640 5 carrots, 23.9ms\n",
      "Speed: 1.6ms preprocess, 23.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/25.jpg: 384x640 1 bottle, 6 carrots, 30.4ms\n",
      "Speed: 1.6ms preprocess, 30.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/26.jpg: 384x640 4 carrots, 29.5ms\n",
      "Speed: 1.6ms preprocess, 29.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/27.jpg: 384x640 1 bottle, 1 spoon, 6 carrots, 25.2ms\n",
      "Speed: 1.8ms preprocess, 25.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/28.jpg: 384x640 1 bottle, 5 carrots, 27.7ms\n",
      "Speed: 1.7ms preprocess, 27.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/29.jpg: 384x640 1 fork, 1 spoon, 4 carrots, 22.7ms\n",
      "Speed: 1.5ms preprocess, 22.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/30.jpg: 384x640 1 fork, 5 carrots, 24.4ms\n",
      "Speed: 1.6ms preprocess, 24.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/31.jpg: 384x640 1 fork, 4 carrots, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/32.jpg: 384x640 1 fork, 2 spoons, 5 carrots, 24.2ms\n",
      "Speed: 1.5ms preprocess, 24.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/33.jpg: 384x640 1 fork, 4 carrots, 26.5ms\n",
      "Speed: 1.5ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/34.jpg: 384x640 1 fork, 7 carrots, 23.6ms\n",
      "Speed: 1.5ms preprocess, 23.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/35.jpg: 384x640 1 bottle, 7 carrots, 27.2ms\n",
      "Speed: 1.6ms preprocess, 27.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/36.jpg: 384x640 1 fork, 3 carrots, 22.1ms\n",
      "Speed: 1.5ms preprocess, 22.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/37.jpg: 384x640 1 bottle, 4 carrots, 27.8ms\n",
      "Speed: 2.6ms preprocess, 27.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/38.jpg: 384x640 4 carrots, 32.7ms\n",
      "Speed: 1.5ms preprocess, 32.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/39.jpg: 384x640 1 bottle, 4 carrots, 21.9ms\n",
      "Speed: 1.5ms preprocess, 21.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/40.jpg: 384x640 1 bottle, 6 carrots, 25.5ms\n",
      "Speed: 2.0ms preprocess, 25.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/41.jpg: 384x640 1 bottle, 1 fork, 4 carrots, 32.3ms\n",
      "Speed: 1.8ms preprocess, 32.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/42.jpg: 384x640 2 bottles, 3 carrots, 24.6ms\n",
      "Speed: 1.5ms preprocess, 24.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/43.jpg: 384x640 6 carrots, 26.0ms\n",
      "Speed: 1.6ms preprocess, 26.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/44.jpg: 384x640 1 baseball bat, 1 spoon, 2 carrots, 23.5ms\n",
      "Speed: 1.5ms preprocess, 23.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/45.jpg: 384x640 1 bottle, 4 carrots, 26.1ms\n",
      "Speed: 2.1ms preprocess, 26.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/46.jpg: 384x640 3 carrots, 36.7ms\n",
      "Speed: 1.5ms preprocess, 36.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/47.jpg: 384x640 1 bottle, 3 carrots, 26.5ms\n",
      "Speed: 1.6ms preprocess, 26.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/48.jpg: 384x640 1 spoon, 3 carrots, 23.0ms\n",
      "Speed: 1.5ms preprocess, 23.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/49.jpg: 384x640 4 carrots, 25.5ms\n",
      "Speed: 1.6ms preprocess, 25.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/50.jpg: 384x640 1 baseball bat, 1 bottle, 2 carrots, 26.4ms\n",
      "Speed: 1.7ms preprocess, 26.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/51.jpg: 384x640 1 bottle, 2 carrots, 23.4ms\n",
      "Speed: 1.5ms preprocess, 23.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/52.jpg: 384x640 2 bottles, 3 carrots, 23.0ms\n",
      "Speed: 1.5ms preprocess, 23.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/53.jpg: 384x640 1 bottle, 1 carrot, 24.0ms\n",
      "Speed: 1.4ms preprocess, 24.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/54.jpg: 384x640 1 bottle, 2 carrots, 38.8ms\n",
      "Speed: 1.6ms preprocess, 38.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/55.jpg: 384x640 1 bottle, 1 carrot, 24.8ms\n",
      "Speed: 1.8ms preprocess, 24.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/56.jpg: 384x640 1 bottle, 1 carrot, 26.7ms\n",
      "Speed: 1.6ms preprocess, 26.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/57.jpg: 384x640 1 baseball bat, 5 carrots, 32.4ms\n",
      "Speed: 1.5ms preprocess, 32.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/58.jpg: 384x640 1 bottle, 6 carrots, 21.9ms\n",
      "Speed: 1.7ms preprocess, 21.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/59.jpg: 384x640 4 carrots, 31.1ms\n",
      "Speed: 1.6ms preprocess, 31.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/60.jpg: 384x640 4 carrots, 24.7ms\n",
      "Speed: 1.5ms preprocess, 24.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/61.jpg: 384x640 7 carrots, 36.2ms\n",
      "Speed: 1.5ms preprocess, 36.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/62.jpg: 384x640 4 carrots, 21.5ms\n",
      "Speed: 1.9ms preprocess, 21.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/63.jpg: 384x640 5 carrots, 28.1ms\n",
      "Speed: 1.6ms preprocess, 28.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/64.jpg: 384x640 2 carrots, 31.4ms\n",
      "Speed: 1.6ms preprocess, 31.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/65.jpg: 384x640 6 carrots, 34.6ms\n",
      "Speed: 1.8ms preprocess, 34.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/66.jpg: 384x640 1 baseball bat, 1 carrot, 25.3ms\n",
      "Speed: 1.5ms preprocess, 25.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/67.jpg: 384x640 4 carrots, 26.7ms\n",
      "Speed: 1.8ms preprocess, 26.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/68.jpg: 384x640 3 carrots, 25.2ms\n",
      "Speed: 1.4ms preprocess, 25.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/69.jpg: 384x640 5 carrots, 24.8ms\n",
      "Speed: 1.5ms preprocess, 24.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/70.jpg: 384x640 6 carrots, 29.2ms\n",
      "Speed: 1.8ms preprocess, 29.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/71.jpg: 384x640 4 carrots, 24.0ms\n",
      "Speed: 1.8ms preprocess, 24.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/72.jpg: 384x640 1 fork, 6 carrots, 39.7ms\n",
      "Speed: 1.9ms preprocess, 39.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/73.jpg: 384x640 1 spoon, 6 carrots, 26.4ms\n",
      "Speed: 1.4ms preprocess, 26.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/74.jpg: 384x640 1 bottle, 5 carrots, 37.2ms\n",
      "Speed: 1.9ms preprocess, 37.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/75.jpg: 384x640 1 bottle, 1 spoon, 7 carrots, 22.6ms\n",
      "Speed: 1.6ms preprocess, 22.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/76.jpg: 384x640 1 spoon, 7 carrots, 25.0ms\n",
      "Speed: 1.8ms preprocess, 25.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/77.jpg: 384x640 1 spoon, 7 carrots, 22.9ms\n",
      "Speed: 1.6ms preprocess, 22.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/78.jpg: 384x640 1 spoon, 7 carrots, 35.4ms\n",
      "Speed: 1.5ms preprocess, 35.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/79.jpg: 384x640 1 bottle, 1 spoon, 5 carrots, 33.3ms\n",
      "Speed: 3.1ms preprocess, 33.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/80.jpg: 384x640 1 bottle, 1 spoon, 4 carrots, 30.9ms\n",
      "Speed: 1.7ms preprocess, 30.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/81.jpg: 384x640 1 spoon, 4 carrots, 23.4ms\n",
      "Speed: 1.4ms preprocess, 23.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/82.jpg: 384x640 1 spoon, 4 carrots, 23.8ms\n",
      "Speed: 1.6ms preprocess, 23.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/83.jpg: 384x640 1 bottle, 1 spoon, 4 carrots, 40.1ms\n",
      "Speed: 1.6ms preprocess, 40.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/84.jpg: 384x640 1 bottle, 5 carrots, 24.7ms\n",
      "Speed: 1.6ms preprocess, 24.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/85.jpg: 384x640 1 bottle, 1 spoon, 4 carrots, 22.6ms\n",
      "Speed: 1.5ms preprocess, 22.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/86.jpg: 384x640 1 bottle, 6 carrots, 27.3ms\n",
      "Speed: 1.8ms preprocess, 27.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/87.jpg: 384x640 1 bottle, 5 carrots, 36.4ms\n",
      "Speed: 1.6ms preprocess, 36.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/88.jpg: 384x640 1 bottle, 6 carrots, 23.3ms\n",
      "Speed: 1.5ms preprocess, 23.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/89.jpg: 384x640 1 bottle, 5 carrots, 23.0ms\n",
      "Speed: 1.7ms preprocess, 23.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/90.jpg: 384x640 1 bottle, 2 carrots, 28.3ms\n",
      "Speed: 1.6ms preprocess, 28.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/91.jpg: 384x640 1 bottle, 6 carrots, 22.0ms\n",
      "Speed: 1.6ms preprocess, 22.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/92.jpg: 384x640 1 bottle, 4 carrots, 26.6ms\n",
      "Speed: 1.7ms preprocess, 26.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/93.jpg: 384x640 1 bottle, 7 carrots, 24.0ms\n",
      "Speed: 1.6ms preprocess, 24.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/94.jpg: 384x640 1 bottle, 7 carrots, 22.9ms\n",
      "Speed: 1.5ms preprocess, 22.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/95.jpg: 384x640 1 bottle, 1 spoon, 7 carrots, 29.8ms\n",
      "Speed: 1.9ms preprocess, 29.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/96.jpg: 384x640 1 bottle, 7 carrots, 23.6ms\n",
      "Speed: 1.5ms preprocess, 23.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/97.jpg: 384x640 1 bottle, 1 spoon, 4 carrots, 22.9ms\n",
      "Speed: 1.4ms preprocess, 22.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/98.jpg: 384x640 1 bottle, 1 spoon, 4 carrots, 33.2ms\n",
      "Speed: 1.7ms preprocess, 33.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/99.jpg: 384x640 1 bottle, 2 carrots, 23.5ms\n",
      "Speed: 2.8ms preprocess, 23.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/100.jpg: 384x640 1 baseball bat, 1 bottle, 2 carrots, 30.6ms\n",
      "Speed: 1.8ms preprocess, 30.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/101.jpg: 384x640 1 bottle, 3 carrots, 28.4ms\n",
      "Speed: 1.5ms preprocess, 28.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/102.jpg: 384x640 2 bottles, 4 carrots, 30.7ms\n",
      "Speed: 2.5ms preprocess, 30.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/103.jpg: 384x640 2 bottles, 2 carrots, 30.3ms\n",
      "Speed: 2.2ms preprocess, 30.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/104.jpg: 384x640 1 bottle, 3 carrots, 27.3ms\n",
      "Speed: 1.6ms preprocess, 27.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/105.jpg: 384x640 1 bottle, 5 carrots, 27.8ms\n",
      "Speed: 1.6ms preprocess, 27.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/106.jpg: 384x640 1 bottle, 5 carrots, 24.4ms\n",
      "Speed: 1.9ms preprocess, 24.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/107.jpg: 384x640 1 bottle, 1 spoon, 4 carrots, 38.0ms\n",
      "Speed: 1.6ms preprocess, 38.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/108.jpg: 384x640 2 bottles, 6 carrots, 24.8ms\n",
      "Speed: 1.8ms preprocess, 24.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/109.jpg: 384x640 2 bottles, 4 carrots, 23.9ms\n",
      "Speed: 1.5ms preprocess, 23.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/110.jpg: 384x640 2 bottles, 3 carrots, 31.7ms\n",
      "Speed: 1.7ms preprocess, 31.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/111.jpg: 384x640 1 baseball bat, 2 bottles, 3 carrots, 23.3ms\n",
      "Speed: 1.5ms preprocess, 23.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/112.jpg: 384x640 2 bottles, 4 carrots, 23.0ms\n",
      "Speed: 1.6ms preprocess, 23.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/113.jpg: 384x640 2 bottles, 3 carrots, 25.1ms\n",
      "Speed: 1.5ms preprocess, 25.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/114.jpg: 384x640 2 bottles, 4 carrots, 22.1ms\n",
      "Speed: 1.4ms preprocess, 22.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/115.jpg: 384x640 2 bottles, 4 carrots, 25.8ms\n",
      "Speed: 1.4ms preprocess, 25.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/116.jpg: 384x640 2 bottles, 3 carrots, 25.2ms\n",
      "Speed: 1.5ms preprocess, 25.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/117.jpg: 384x640 1 bottle, 1 carrot, 34.3ms\n",
      "Speed: 2.3ms preprocess, 34.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/118.jpg: 384x640 1 baseball bat, 2 bottles, 7 carrots, 36.7ms\n",
      "Speed: 1.8ms preprocess, 36.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/119.jpg: 384x640 2 bottles, 6 carrots, 24.0ms\n",
      "Speed: 1.9ms preprocess, 24.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/120.jpg: 384x640 1 bottle, 1 spoon, 4 carrots, 32.3ms\n",
      "Speed: 2.0ms preprocess, 32.3ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/121.jpg: 384x640 2 bottles, 1 spoon, 3 carrots, 39.7ms\n",
      "Speed: 1.7ms preprocess, 39.7ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/122.jpg: 384x640 2 bottles, 1 spoon, 5 carrots, 36.3ms\n",
      "Speed: 3.1ms preprocess, 36.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/123.jpg: 384x640 2 bottles, 6 carrots, 26.8ms\n",
      "Speed: 1.6ms preprocess, 26.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/124.jpg: 384x640 2 bottles, 6 carrots, 27.5ms\n",
      "Speed: 1.7ms preprocess, 27.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/125.jpg: 384x640 1 bottle, 8 carrots, 24.1ms\n",
      "Speed: 1.6ms preprocess, 24.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/126.jpg: 384x640 1 bottle, 9 carrots, 32.3ms\n",
      "Speed: 1.6ms preprocess, 32.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/127.jpg: 384x640 2 bottles, 6 carrots, 23.0ms\n",
      "Speed: 1.6ms preprocess, 23.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/128.jpg: 384x640 1 bottle, 5 carrots, 31.5ms\n",
      "Speed: 2.1ms preprocess, 31.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/129.jpg: 384x640 1 baseball bat, 1 bottle, 4 carrots, 39.0ms\n",
      "Speed: 1.7ms preprocess, 39.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/130.jpg: 384x640 2 bottles, 5 carrots, 38.3ms\n",
      "Speed: 1.7ms preprocess, 38.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/131.jpg: 384x640 1 baseball bat, 2 bottles, 3 carrots, 30.9ms\n",
      "Speed: 1.9ms preprocess, 30.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/132.jpg: 384x640 1 bottle, 5 carrots, 27.9ms\n",
      "Speed: 1.5ms preprocess, 27.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/133.jpg: 384x640 1 bottle, 4 carrots, 26.4ms\n",
      "Speed: 1.8ms preprocess, 26.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/134.jpg: 384x640 1 bottle, 5 carrots, 41.6ms\n",
      "Speed: 1.9ms preprocess, 41.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/135.jpg: 384x640 1 bottle, 1 spoon, 4 carrots, 35.3ms\n",
      "Speed: 2.5ms preprocess, 35.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/136.jpg: 384x640 1 bottle, 5 carrots, 44.1ms\n",
      "Speed: 1.8ms preprocess, 44.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/137.jpg: 384x640 1 baseball bat, 3 carrots, 44.5ms\n",
      "Speed: 2.0ms preprocess, 44.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/138.jpg: 384x640 7 carrots, 33.3ms\n",
      "Speed: 2.1ms preprocess, 33.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/139.jpg: 384x640 1 bottle, 4 carrots, 29.9ms\n",
      "Speed: 2.1ms preprocess, 29.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/140.jpg: 384x640 1 bottle, 4 carrots, 24.0ms\n",
      "Speed: 1.7ms preprocess, 24.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/141.jpg: 384x640 6 carrots, 25.0ms\n",
      "Speed: 3.0ms preprocess, 25.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/142.jpg: 384x640 4 carrots, 29.5ms\n",
      "Speed: 2.0ms preprocess, 29.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/143.jpg: 384x640 2 carrots, 42.2ms\n",
      "Speed: 1.9ms preprocess, 42.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/144.jpg: 384x640 4 carrots, 26.0ms\n",
      "Speed: 1.7ms preprocess, 26.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/145.jpg: 384x640 5 carrots, 29.0ms\n",
      "Speed: 1.7ms preprocess, 29.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/146.jpg: 384x640 5 carrots, 24.9ms\n",
      "Speed: 1.8ms preprocess, 24.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/147.jpg: 384x640 2 carrots, 25.5ms\n",
      "Speed: 1.7ms preprocess, 25.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/148.jpg: 384x640 1 bottle, 4 carrots, 25.3ms\n",
      "Speed: 1.7ms preprocess, 25.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/149.jpg: 384x640 1 bottle, 4 carrots, 25.8ms\n",
      "Speed: 1.7ms preprocess, 25.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/150.jpg: 384x640 1 bottle, 1 spoon, 5 carrots, 25.0ms\n",
      "Speed: 1.5ms preprocess, 25.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/151.jpg: 384x640 1 spoon, 7 carrots, 35.6ms\n",
      "Speed: 1.9ms preprocess, 35.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/152.jpg: 384x640 1 bottle, 1 spoon, 6 carrots, 30.6ms\n",
      "Speed: 2.0ms preprocess, 30.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/153.jpg: 384x640 1 spoon, 5 carrots, 36.9ms\n",
      "Speed: 2.1ms preprocess, 36.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/154.jpg: 384x640 1 bottle, 3 carrots, 30.7ms\n",
      "Speed: 1.7ms preprocess, 30.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/155.jpg: 384x640 1 bottle, 4 carrots, 46.0ms\n",
      "Speed: 1.9ms preprocess, 46.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/156.jpg: 384x640 1 bottle, 3 carrots, 38.5ms\n",
      "Speed: 2.0ms preprocess, 38.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/157.jpg: 384x640 1 bottle, 4 carrots, 30.6ms\n",
      "Speed: 2.0ms preprocess, 30.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/158.jpg: 384x640 1 bottle, 4 carrots, 28.3ms\n",
      "Speed: 1.7ms preprocess, 28.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/159.jpg: 384x640 1 bottle, 4 carrots, 29.3ms\n",
      "Speed: 1.8ms preprocess, 29.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/160.jpg: 384x640 1 bottle, 3 carrots, 30.5ms\n",
      "Speed: 2.5ms preprocess, 30.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/161.jpg: 384x640 1 bottle, 3 carrots, 37.8ms\n",
      "Speed: 1.8ms preprocess, 37.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/162.jpg: 384x640 1 bottle, 5 carrots, 43.9ms\n",
      "Speed: 1.8ms preprocess, 43.9ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/163.jpg: 384x640 1 bottle, 3 carrots, 30.3ms\n",
      "Speed: 1.7ms preprocess, 30.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/164.jpg: 384x640 1 bottle, 3 carrots, 26.2ms\n",
      "Speed: 1.7ms preprocess, 26.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/165.jpg: 384x640 1 bottle, 4 carrots, 30.4ms\n",
      "Speed: 1.9ms preprocess, 30.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/166.jpg: 384x640 1 bottle, 6 carrots, 32.9ms\n",
      "Speed: 1.9ms preprocess, 32.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/167.jpg: 384x640 1 bottle, 6 carrots, 31.4ms\n",
      "Speed: 2.2ms preprocess, 31.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/168.jpg: 384x640 1 bottle, 4 carrots, 25.3ms\n",
      "Speed: 1.8ms preprocess, 25.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/169.jpg: 384x640 1 spoon, 5 carrots, 31.3ms\n",
      "Speed: 1.9ms preprocess, 31.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/170.jpg: 384x640 2 spoons, 5 carrots, 36.5ms\n",
      "Speed: 1.9ms preprocess, 36.5ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/171.jpg: 384x640 1 spoon, 5 carrots, 35.2ms\n",
      "Speed: 1.7ms preprocess, 35.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/172.jpg: 384x640 1 spoon, 1 carrot, 38.2ms\n",
      "Speed: 1.9ms preprocess, 38.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/173.jpg: 384x640 1 spoon, 3 carrots, 26.9ms\n",
      "Speed: 1.6ms preprocess, 26.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/174.jpg: 384x640 5 carrots, 37.4ms\n",
      "Speed: 2.0ms preprocess, 37.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/175.jpg: 384x640 3 carrots, 31.9ms\n",
      "Speed: 2.3ms preprocess, 31.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/176.jpg: 384x640 2 carrots, 31.9ms\n",
      "Speed: 1.7ms preprocess, 31.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/177.jpg: 384x640 4 carrots, 31.1ms\n",
      "Speed: 1.6ms preprocess, 31.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/178.jpg: 384x640 1 baseball bat, 1 bottle, 1 carrot, 37.4ms\n",
      "Speed: 1.6ms preprocess, 37.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/179.jpg: 384x640 1 spoon, 1 carrot, 22.9ms\n",
      "Speed: 1.8ms preprocess, 22.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/180.jpg: 384x640 4 carrots, 33.3ms\n",
      "Speed: 1.8ms preprocess, 33.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/181.jpg: 384x640 1 spoon, 2 carrots, 27.9ms\n",
      "Speed: 1.7ms preprocess, 27.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/182.jpg: 384x640 1 spoon, 4 carrots, 34.1ms\n",
      "Speed: 1.8ms preprocess, 34.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/183.jpg: 384x640 1 bottle, 5 carrots, 33.2ms\n",
      "Speed: 2.5ms preprocess, 33.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/184.jpg: 384x640 2 bottles, 5 carrots, 34.2ms\n",
      "Speed: 2.0ms preprocess, 34.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/185.jpg: 384x640 1 bottle, 8 carrots, 25.5ms\n",
      "Speed: 1.7ms preprocess, 25.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/186.jpg: 384x640 2 bottles, 3 carrots, 28.5ms\n",
      "Speed: 1.7ms preprocess, 28.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/187.jpg: 384x640 1 bottle, 1 fork, 4 carrots, 24.0ms\n",
      "Speed: 1.5ms preprocess, 24.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/188.jpg: 384x640 1 fork, 4 carrots, 38.7ms\n",
      "Speed: 2.4ms preprocess, 38.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/189.jpg: 384x640 1 bottle, 4 carrots, 28.3ms\n",
      "Speed: 1.6ms preprocess, 28.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/190.jpg: 384x640 1 bottle, 3 carrots, 29.7ms\n",
      "Speed: 1.5ms preprocess, 29.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/191.jpg: 384x640 1 bottle, 3 carrots, 30.4ms\n",
      "Speed: 1.9ms preprocess, 30.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/192.jpg: 384x640 1 bottle, 2 spoons, 2 carrots, 27.2ms\n",
      "Speed: 1.6ms preprocess, 27.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/193.jpg: 384x640 2 spoons, 3 carrots, 30.8ms\n",
      "Speed: 1.7ms preprocess, 30.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/194.jpg: 384x640 1 bottle, 3 carrots, 26.9ms\n",
      "Speed: 1.8ms preprocess, 26.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/195.jpg: 384x640 4 carrots, 33.8ms\n",
      "Speed: 2.0ms preprocess, 33.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/196.jpg: 384x640 1 spoon, 5 carrots, 40.8ms\n",
      "Speed: 3.6ms preprocess, 40.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/197.jpg: 384x640 1 carrot, 26.2ms\n",
      "Speed: 1.7ms preprocess, 26.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/198.jpg: 384x640 1 bottle, 3 carrots, 32.6ms\n",
      "Speed: 2.3ms preprocess, 32.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/199.jpg: 384x640 1 bottle, 4 carrots, 29.5ms\n",
      "Speed: 1.7ms preprocess, 29.5ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/200.jpg: 384x640 7 carrots, 26.5ms\n",
      "Speed: 3.4ms preprocess, 26.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/201.jpg: 384x640 1 bottle, 6 carrots, 25.1ms\n",
      "Speed: 1.6ms preprocess, 25.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/202.jpg: 384x640 1 bottle, 5 carrots, 29.7ms\n",
      "Speed: 1.8ms preprocess, 29.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/203.jpg: 384x640 1 bottle, 6 carrots, 43.5ms\n",
      "Speed: 2.0ms preprocess, 43.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/204.jpg: 384x640 1 bottle, 5 carrots, 33.9ms\n",
      "Speed: 2.6ms preprocess, 33.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/205.jpg: 384x640 1 bottle, 3 carrots, 25.5ms\n",
      "Speed: 1.7ms preprocess, 25.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/206.jpg: 384x640 1 spoon, 3 carrots, 25.7ms\n",
      "Speed: 1.8ms preprocess, 25.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/207.jpg: 384x640 1 spoon, 5 carrots, 50.4ms\n",
      "Speed: 1.6ms preprocess, 50.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/208.jpg: 384x640 1 spoon, 4 carrots, 24.5ms\n",
      "Speed: 1.6ms preprocess, 24.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/209.jpg: 384x640 1 spoon, 3 carrots, 25.9ms\n",
      "Speed: 2.1ms preprocess, 25.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/210.jpg: 384x640 1 bottle, 2 spoons, 6 carrots, 24.9ms\n",
      "Speed: 1.7ms preprocess, 24.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/211.jpg: 384x640 1 bottle, 6 carrots, 46.8ms\n",
      "Speed: 1.7ms preprocess, 46.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/212.jpg: 384x640 1 spoon, 5 carrots, 26.1ms\n",
      "Speed: 3.0ms preprocess, 26.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/213.jpg: 384x640 1 spoon, 7 carrots, 28.5ms\n",
      "Speed: 1.9ms preprocess, 28.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/214.jpg: 384x640 1 fork, 3 carrots, 26.9ms\n",
      "Speed: 1.5ms preprocess, 26.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/215.jpg: 384x640 5 carrots, 39.8ms\n",
      "Speed: 1.8ms preprocess, 39.8ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/216.jpg: 384x640 4 carrots, 25.7ms\n",
      "Speed: 2.9ms preprocess, 25.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/217.jpg: 384x640 1 spoon, 5 carrots, 43.1ms\n",
      "Speed: 1.8ms preprocess, 43.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/218.jpg: 384x640 1 bottle, 1 spoon, 5 carrots, 23.9ms\n",
      "Speed: 1.6ms preprocess, 23.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/219.jpg: 384x640 1 spoon, 5 carrots, 27.4ms\n",
      "Speed: 1.6ms preprocess, 27.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/220.jpg: 384x640 1 bottle, 5 carrots, 28.0ms\n",
      "Speed: 1.6ms preprocess, 28.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/221.jpg: 384x640 1 baseball bat, 4 carrots, 27.1ms\n",
      "Speed: 1.8ms preprocess, 27.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/222.jpg: 384x640 9 carrots, 29.6ms\n",
      "Speed: 1.7ms preprocess, 29.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/223.jpg: 384x640 2 bottles, 6 carrots, 28.9ms\n",
      "Speed: 1.9ms preprocess, 28.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/224.jpg: 384x640 1 bottle, 1 spoon, 9 carrots, 32.0ms\n",
      "Speed: 1.8ms preprocess, 32.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/225.jpg: 384x640 1 bottle, 1 spoon, 5 carrots, 29.1ms\n",
      "Speed: 1.6ms preprocess, 29.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/226.jpg: 384x640 2 bottles, 1 spoon, 3 carrots, 25.1ms\n",
      "Speed: 1.8ms preprocess, 25.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/227.jpg: 384x640 1 baseball bat, 2 bottles, 7 carrots, 30.1ms\n",
      "Speed: 1.6ms preprocess, 30.1ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/228.jpg: 384x640 1 bottle, 1 spoon, 5 carrots, 24.7ms\n",
      "Speed: 1.6ms preprocess, 24.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/229.jpg: 384x640 1 baseball bat, 2 bottles, 5 carrots, 28.7ms\n",
      "Speed: 1.7ms preprocess, 28.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/230.jpg: 384x640 1 baseball bat, 1 bottle, 2 spoons, 6 carrots, 25.7ms\n",
      "Speed: 1.6ms preprocess, 25.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/231.jpg: 384x640 1 baseball bat, 2 spoons, 6 carrots, 40.6ms\n",
      "Speed: 1.8ms preprocess, 40.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/232.jpg: 384x640 1 baseball bat, 2 spoons, 6 carrots, 45.2ms\n",
      "Speed: 1.7ms preprocess, 45.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/233.jpg: 384x640 1 baseball bat, 2 spoons, 9 carrots, 27.9ms\n",
      "Speed: 1.8ms preprocess, 27.9ms inference, 18.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/234.jpg: 384x640 2 spoons, 8 carrots, 23.8ms\n",
      "Speed: 1.8ms preprocess, 23.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/235.jpg: 384x640 1 spoon, 7 carrots, 31.9ms\n",
      "Speed: 1.8ms preprocess, 31.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/236.jpg: 384x640 1 spoon, 7 carrots, 25.7ms\n",
      "Speed: 1.8ms preprocess, 25.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/237.jpg: 384x640 1 spoon, 8 carrots, 25.6ms\n",
      "Speed: 1.5ms preprocess, 25.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/238.jpg: 384x640 1 spoon, 7 carrots, 29.6ms\n",
      "Speed: 1.8ms preprocess, 29.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/239.jpg: 384x640 1 spoon, 7 carrots, 23.3ms\n",
      "Speed: 1.6ms preprocess, 23.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/240.jpg: 384x640 1 spoon, 7 carrots, 27.3ms\n",
      "Speed: 1.8ms preprocess, 27.3ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/241.jpg: 384x640 1 spoon, 9 carrots, 41.1ms\n",
      "Speed: 5.8ms preprocess, 41.1ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/242.jpg: 384x640 1 spoon, 9 carrots, 29.4ms\n",
      "Speed: 1.7ms preprocess, 29.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/243.jpg: 384x640 1 spoon, 11 carrots, 31.7ms\n",
      "Speed: 1.8ms preprocess, 31.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/244.jpg: 384x640 2 spoons, 9 carrots, 33.9ms\n",
      "Speed: 1.5ms preprocess, 33.9ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/245.jpg: 384x640 1 baseball bat, 1 spoon, 4 carrots, 34.3ms\n",
      "Speed: 2.4ms preprocess, 34.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/246.jpg: 384x640 1 bottle, 2 spoons, 3 carrots, 31.5ms\n",
      "Speed: 1.9ms preprocess, 31.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/247.jpg: 384x640 1 baseball bat, 2 bottles, 6 carrots, 25.6ms\n",
      "Speed: 2.0ms preprocess, 25.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/248.jpg: 384x640 2 bottles, 1 spoon, 10 carrots, 34.3ms\n",
      "Speed: 1.8ms preprocess, 34.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/249.jpg: 384x640 1 bottle, 1 spoon, 7 carrots, 23.8ms\n",
      "Speed: 2.2ms preprocess, 23.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/250.jpg: 384x640 2 bottles, 1 spoon, 9 carrots, 30.5ms\n",
      "Speed: 1.7ms preprocess, 30.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/251.jpg: 384x640 2 bottles, 8 carrots, 35.1ms\n",
      "Speed: 2.0ms preprocess, 35.1ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/252.jpg: 384x640 1 bottle, 8 carrots, 31.9ms\n",
      "Speed: 1.8ms preprocess, 31.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/253.jpg: 384x640 1 bottle, 6 carrots, 23.2ms\n",
      "Speed: 1.6ms preprocess, 23.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/254.jpg: 384x640 7 carrots, 28.7ms\n",
      "Speed: 2.0ms preprocess, 28.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/255.jpg: 384x640 1 bottle, 1 spoon, 7 carrots, 23.6ms\n",
      "Speed: 1.5ms preprocess, 23.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/256.jpg: 384x640 1 baseball bat, 1 bottle, 6 carrots, 44.1ms\n",
      "Speed: 2.2ms preprocess, 44.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/257.jpg: 384x640 1 spoon, 3 carrots, 39.4ms\n",
      "Speed: 1.9ms preprocess, 39.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/258.jpg: 384x640 3 spoons, 4 carrots, 35.8ms\n",
      "Speed: 1.5ms preprocess, 35.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/259.jpg: 384x640 2 spoons, 4 carrots, 33.7ms\n",
      "Speed: 1.6ms preprocess, 33.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/260.jpg: 384x640 2 spoons, 4 carrots, 26.6ms\n",
      "Speed: 1.7ms preprocess, 26.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/261.jpg: 384x640 1 bottle, 1 spoon, 5 carrots, 28.7ms\n",
      "Speed: 2.3ms preprocess, 28.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/262.jpg: 384x640 1 spoon, 5 carrots, 24.8ms\n",
      "Speed: 1.7ms preprocess, 24.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/263.jpg: 384x640 1 spoon, 7 carrots, 41.5ms\n",
      "Speed: 2.0ms preprocess, 41.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/264.jpg: 384x640 1 bottle, 8 carrots, 26.0ms\n",
      "Speed: 1.5ms preprocess, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/265.jpg: 384x640 1 bottle, 6 carrots, 36.5ms\n",
      "Speed: 3.0ms preprocess, 36.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/266.jpg: 384x640 7 carrots, 23.8ms\n",
      "Speed: 1.6ms preprocess, 23.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/267.jpg: 384x640 2 bottles, 9 carrots, 28.7ms\n",
      "Speed: 1.9ms preprocess, 28.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/268.jpg: 384x640 1 bottle, 7 carrots, 32.0ms\n",
      "Speed: 1.6ms preprocess, 32.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/269.jpg: 384x640 2 bottles, 6 carrots, 29.3ms\n",
      "Speed: 1.6ms preprocess, 29.3ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/270.jpg: 384x640 1 bottle, 7 carrots, 31.8ms\n",
      "Speed: 3.1ms preprocess, 31.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/271.jpg: 384x640 1 bottle, 8 carrots, 29.9ms\n",
      "Speed: 1.5ms preprocess, 29.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/272.jpg: 384x640 1 fork, 8 carrots, 28.2ms\n",
      "Speed: 1.7ms preprocess, 28.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/273.jpg: 384x640 7 carrots, 27.0ms\n",
      "Speed: 1.8ms preprocess, 27.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/274.jpg: 384x640 6 carrots, 29.2ms\n",
      "Speed: 1.6ms preprocess, 29.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/275.jpg: 384x640 7 carrots, 26.9ms\n",
      "Speed: 1.9ms preprocess, 26.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/276.jpg: 384x640 1 spoon, 6 carrots, 32.8ms\n",
      "Speed: 1.6ms preprocess, 32.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/277.jpg: 384x640 1 fork, 6 carrots, 24.7ms\n",
      "Speed: 1.7ms preprocess, 24.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/278.jpg: 384x640 6 carrots, 28.9ms\n",
      "Speed: 1.9ms preprocess, 28.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/279.jpg: 384x640 1 spoon, 5 carrots, 23.3ms\n",
      "Speed: 1.6ms preprocess, 23.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/280.jpg: 384x640 5 carrots, 24.3ms\n",
      "Speed: 1.9ms preprocess, 24.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/281.jpg: 384x640 1 spoon, 7 carrots, 37.7ms\n",
      "Speed: 2.3ms preprocess, 37.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/282.jpg: 384x640 1 bottle, 1 spoon, 9 carrots, 29.4ms\n",
      "Speed: 1.6ms preprocess, 29.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/283.jpg: 384x640 1 spoon, 5 carrots, 26.3ms\n",
      "Speed: 1.7ms preprocess, 26.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/284.jpg: 384x640 5 carrots, 22.7ms\n",
      "Speed: 1.7ms preprocess, 22.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/285.jpg: 384x640 1 spoon, 6 carrots, 27.4ms\n",
      "Speed: 1.7ms preprocess, 27.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/286.jpg: 384x640 1 spoon, 3 carrots, 37.0ms\n",
      "Speed: 1.8ms preprocess, 37.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/287.jpg: 384x640 1 spoon, 6 carrots, 28.1ms\n",
      "Speed: 1.6ms preprocess, 28.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/288.jpg: 384x640 1 spoon, 7 carrots, 23.5ms\n",
      "Speed: 1.9ms preprocess, 23.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/289.jpg: 384x640 4 carrots, 28.2ms\n",
      "Speed: 1.8ms preprocess, 28.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/290.jpg: 384x640 1 spoon, 9 carrots, 37.2ms\n",
      "Speed: 1.8ms preprocess, 37.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/291.jpg: 384x640 1 spoon, 6 carrots, 39.9ms\n",
      "Speed: 2.6ms preprocess, 39.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/292.jpg: 384x640 1 bottle, 4 carrots, 24.6ms\n",
      "Speed: 2.1ms preprocess, 24.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/293.jpg: 384x640 1 bottle, 8 carrots, 27.5ms\n",
      "Speed: 1.6ms preprocess, 27.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/294.jpg: 384x640 1 bottle, 5 carrots, 27.6ms\n",
      "Speed: 1.7ms preprocess, 27.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/295.jpg: 384x640 1 bottle, 1 fork, 6 carrots, 29.8ms\n",
      "Speed: 1.6ms preprocess, 29.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/296.jpg: 384x640 1 bottle, 4 carrots, 30.2ms\n",
      "Speed: 1.5ms preprocess, 30.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/297.jpg: 384x640 4 carrots, 41.6ms\n",
      "Speed: 1.7ms preprocess, 41.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/298.jpg: 384x640 1 bottle, 6 carrots, 30.7ms\n",
      "Speed: 2.0ms preprocess, 30.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/regular/right/299.jpg: 384x640 3 carrots, 25.5ms\n",
      "Speed: 1.6ms preprocess, 25.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Propagating video frames: 100%|| 300/300 [00:17<00:00, 16.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask propagation completed in 17.85 seconds.\n",
      "Processing predicted masks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing video frames: 300it [00:03, 84.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 300 masks for evaluation.\n",
      "Masks saved to data/masks/yolo11x-seg/val/data-raw-SegSTRONGC_val-val-1-2-regular-right.pkl\n",
      "Loading ground truth masks for evaluation...\n",
      "Loaded 300 ground truth masks.\n",
      "Calculating evaluation metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for metrics calculation: 1.50 seconds.\n",
      "Mean IoU for data/raw/SegSTRONGC_val/val/1/2/regular/right: 0.1162\n",
      "Mean DSC for data/raw/SegSTRONGC_val/val/1/2/regular/right: 0.1986\n",
      "Loading existing results file: data/results/yolo11x-seg/val.json\n",
      "Results saved to data/results/yolo11x-seg/val.json\n",
      "Processing video took 24.87 seconds.\n",
      "==================================================\n",
      "\n",
      "Results for data/raw/SegSTRONGC_val/val/1/2/regular:\n",
      "  Left: IoU=0.0945, DSC=0.1675\n",
      "  Right: IoU=0.1162, DSC=0.1986\n",
      "  Overall: IoU=0.1054, DSC=0.1831\n",
      "\n",
      "Processing domain: smoke\n",
      "Processing left camera video...\n",
      "==================================================\n",
      "Processing video: data/raw/SegSTRONGC_val/val/1/2/smoke/left\n",
      "Domain: smoke, Split: val, Camera: left\n",
      "Initializing Yolo for video...\n",
      "Initialization took 0.23 seconds.\n",
      "Starting mask propagation...\n",
      "Total images in video: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/0.jpg: 384x640 1 airplane, 73.0ms\n",
      "Speed: 3.0ms preprocess, 73.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/1.jpg: 384x640 2 airplanes, 41.0ms\n",
      "Speed: 2.1ms preprocess, 41.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/2.jpg: 384x640 (no detections), 35.7ms\n",
      "Speed: 1.7ms preprocess, 35.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/3.jpg: 384x640 1 airplane, 1 boat, 24.5ms\n",
      "Speed: 1.9ms preprocess, 24.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/4.jpg: 384x640 1 airplane, 30.6ms\n",
      "Speed: 1.9ms preprocess, 30.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/5.jpg: 384x640 (no detections), 31.8ms\n",
      "Speed: 1.7ms preprocess, 31.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/6.jpg: 384x640 1 spoon, 27.8ms\n",
      "Speed: 1.7ms preprocess, 27.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/7.jpg: 384x640 1 boat, 23.3ms\n",
      "Speed: 1.8ms preprocess, 23.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/8.jpg: 384x640 1 airplane, 1 boat, 29.2ms\n",
      "Speed: 1.8ms preprocess, 29.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/9.jpg: 384x640 1 person, 1 boat, 33.3ms\n",
      "Speed: 1.9ms preprocess, 33.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/10.jpg: 384x640 (no detections), 29.1ms\n",
      "Speed: 1.6ms preprocess, 29.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/11.jpg: 384x640 2 airplanes, 1 boat, 25.2ms\n",
      "Speed: 1.5ms preprocess, 25.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/12.jpg: 384x640 1 airplane, 29.4ms\n",
      "Speed: 1.7ms preprocess, 29.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/13.jpg: 384x640 1 airplane, 31.7ms\n",
      "Speed: 1.5ms preprocess, 31.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/14.jpg: 384x640 1 airplane, 22.4ms\n",
      "Speed: 1.5ms preprocess, 22.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/15.jpg: 384x640 (no detections), 23.2ms\n",
      "Speed: 1.5ms preprocess, 23.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/16.jpg: 384x640 (no detections), 35.1ms\n",
      "Speed: 1.6ms preprocess, 35.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/17.jpg: 384x640 (no detections), 29.1ms\n",
      "Speed: 1.5ms preprocess, 29.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/18.jpg: 384x640 (no detections), 29.7ms\n",
      "Speed: 1.9ms preprocess, 29.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/19.jpg: 384x640 1 person, 1 boat, 22.4ms\n",
      "Speed: 1.6ms preprocess, 22.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/20.jpg: 384x640 (no detections), 25.2ms\n",
      "Speed: 1.5ms preprocess, 25.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/21.jpg: 384x640 1 airplane, 27.7ms\n",
      "Speed: 1.6ms preprocess, 27.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/22.jpg: 384x640 (no detections), 27.2ms\n",
      "Speed: 1.6ms preprocess, 27.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/23.jpg: 384x640 1 donut, 24.6ms\n",
      "Speed: 1.7ms preprocess, 24.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/24.jpg: 384x640 (no detections), 28.5ms\n",
      "Speed: 1.6ms preprocess, 28.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/25.jpg: 384x640 1 airplane, 26.9ms\n",
      "Speed: 1.5ms preprocess, 26.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/26.jpg: 384x640 1 airplane, 26.1ms\n",
      "Speed: 1.5ms preprocess, 26.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/27.jpg: 384x640 (no detections), 25.1ms\n",
      "Speed: 1.6ms preprocess, 25.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/28.jpg: 384x640 1 airplane, 26.5ms\n",
      "Speed: 1.7ms preprocess, 26.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/29.jpg: 384x640 1 airplane, 1 boat, 24.6ms\n",
      "Speed: 1.7ms preprocess, 24.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/30.jpg: 384x640 1 clock, 22.0ms\n",
      "Speed: 1.6ms preprocess, 22.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/31.jpg: 384x640 (no detections), 44.1ms\n",
      "Speed: 2.0ms preprocess, 44.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/32.jpg: 384x640 (no detections), 28.9ms\n",
      "Speed: 1.6ms preprocess, 28.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/33.jpg: 384x640 1 boat, 23.1ms\n",
      "Speed: 1.5ms preprocess, 23.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/34.jpg: 384x640 (no detections), 28.2ms\n",
      "Speed: 1.7ms preprocess, 28.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/35.jpg: 384x640 1 airplane, 1 boat, 22.4ms\n",
      "Speed: 1.6ms preprocess, 22.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/36.jpg: 384x640 1 boat, 32.8ms\n",
      "Speed: 1.5ms preprocess, 32.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/37.jpg: 384x640 1 boat, 24.1ms\n",
      "Speed: 1.5ms preprocess, 24.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/38.jpg: 384x640 1 boat, 23.8ms\n",
      "Speed: 1.7ms preprocess, 23.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/39.jpg: 384x640 1 boat, 29.8ms\n",
      "Speed: 1.6ms preprocess, 29.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/40.jpg: 384x640 (no detections), 28.3ms\n",
      "Speed: 2.0ms preprocess, 28.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/41.jpg: 384x640 (no detections), 21.8ms\n",
      "Speed: 1.5ms preprocess, 21.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/42.jpg: 384x640 1 clock, 26.1ms\n",
      "Speed: 2.0ms preprocess, 26.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/43.jpg: 384x640 (no detections), 22.8ms\n",
      "Speed: 1.6ms preprocess, 22.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/44.jpg: 384x640 (no detections), 24.5ms\n",
      "Speed: 2.1ms preprocess, 24.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/45.jpg: 384x640 (no detections), 25.0ms\n",
      "Speed: 1.7ms preprocess, 25.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/46.jpg: 384x640 (no detections), 21.7ms\n",
      "Speed: 1.9ms preprocess, 21.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/47.jpg: 384x640 (no detections), 44.2ms\n",
      "Speed: 1.7ms preprocess, 44.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/48.jpg: 384x640 (no detections), 27.3ms\n",
      "Speed: 1.8ms preprocess, 27.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/49.jpg: 384x640 (no detections), 30.1ms\n",
      "Speed: 1.5ms preprocess, 30.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/50.jpg: 384x640 1 boat, 23.1ms\n",
      "Speed: 1.6ms preprocess, 23.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/51.jpg: 384x640 (no detections), 28.2ms\n",
      "Speed: 1.9ms preprocess, 28.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/52.jpg: 384x640 1 airplane, 36.6ms\n",
      "Speed: 1.8ms preprocess, 36.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/53.jpg: 384x640 1 airplane, 25.9ms\n",
      "Speed: 1.7ms preprocess, 25.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/54.jpg: 384x640 (no detections), 28.7ms\n",
      "Speed: 1.6ms preprocess, 28.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/55.jpg: 384x640 1 boat, 26.7ms\n",
      "Speed: 1.7ms preprocess, 26.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/56.jpg: 384x640 (no detections), 22.4ms\n",
      "Speed: 1.7ms preprocess, 22.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/57.jpg: 384x640 (no detections), 29.1ms\n",
      "Speed: 1.7ms preprocess, 29.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/58.jpg: 384x640 1 airplane, 25.9ms\n",
      "Speed: 1.7ms preprocess, 25.9ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/59.jpg: 384x640 1 person, 1 boat, 28.1ms\n",
      "Speed: 1.5ms preprocess, 28.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/60.jpg: 384x640 (no detections), 34.7ms\n",
      "Speed: 1.5ms preprocess, 34.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/61.jpg: 384x640 (no detections), 29.8ms\n",
      "Speed: 1.9ms preprocess, 29.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/62.jpg: 384x640 (no detections), 37.8ms\n",
      "Speed: 1.6ms preprocess, 37.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/63.jpg: 384x640 (no detections), 31.3ms\n",
      "Speed: 1.8ms preprocess, 31.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/64.jpg: 384x640 1 boat, 27.6ms\n",
      "Speed: 1.7ms preprocess, 27.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/65.jpg: 384x640 (no detections), 28.0ms\n",
      "Speed: 1.9ms preprocess, 28.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/66.jpg: 384x640 1 airplane, 32.1ms\n",
      "Speed: 3.1ms preprocess, 32.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/67.jpg: 384x640 2 airplanes, 33.2ms\n",
      "Speed: 2.1ms preprocess, 33.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/68.jpg: 384x640 (no detections), 27.3ms\n",
      "Speed: 2.4ms preprocess, 27.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/69.jpg: 384x640 1 clock, 25.2ms\n",
      "Speed: 1.8ms preprocess, 25.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/70.jpg: 384x640 (no detections), 36.7ms\n",
      "Speed: 2.0ms preprocess, 36.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/71.jpg: 384x640 (no detections), 23.6ms\n",
      "Speed: 1.7ms preprocess, 23.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/72.jpg: 384x640 (no detections), 20.8ms\n",
      "Speed: 1.6ms preprocess, 20.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/73.jpg: 384x640 1 airplane, 30.1ms\n",
      "Speed: 1.8ms preprocess, 30.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/74.jpg: 384x640 (no detections), 39.0ms\n",
      "Speed: 1.6ms preprocess, 39.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/75.jpg: 384x640 1 person, 1 boat, 25.4ms\n",
      "Speed: 1.6ms preprocess, 25.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/76.jpg: 384x640 (no detections), 30.4ms\n",
      "Speed: 1.9ms preprocess, 30.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/77.jpg: 384x640 (no detections), 26.3ms\n",
      "Speed: 1.6ms preprocess, 26.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/78.jpg: 384x640 2 airplanes, 34.2ms\n",
      "Speed: 1.8ms preprocess, 34.2ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/79.jpg: 384x640 1 knife, 32.3ms\n",
      "Speed: 1.8ms preprocess, 32.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/80.jpg: 384x640 1 bottle, 26.2ms\n",
      "Speed: 1.6ms preprocess, 26.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/81.jpg: 384x640 1 person, 23.4ms\n",
      "Speed: 1.7ms preprocess, 23.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/82.jpg: 384x640 1 spoon, 1 donut, 25.2ms\n",
      "Speed: 1.7ms preprocess, 25.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/83.jpg: 384x640 (no detections), 26.1ms\n",
      "Speed: 1.7ms preprocess, 26.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/84.jpg: 384x640 1 person, 1 airplane, 26.9ms\n",
      "Speed: 1.6ms preprocess, 26.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/85.jpg: 384x640 2 persons, 1 airplane, 32.3ms\n",
      "Speed: 2.3ms preprocess, 32.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/86.jpg: 384x640 (no detections), 30.5ms\n",
      "Speed: 1.8ms preprocess, 30.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/87.jpg: 384x640 1 airplane, 27.9ms\n",
      "Speed: 2.2ms preprocess, 27.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/88.jpg: 384x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/89.jpg: 384x640 (no detections), 24.7ms\n",
      "Speed: 1.5ms preprocess, 24.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/90.jpg: 384x640 1 airplane, 23.4ms\n",
      "Speed: 1.9ms preprocess, 23.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/91.jpg: 384x640 1 airplane, 35.6ms\n",
      "Speed: 1.6ms preprocess, 35.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/92.jpg: 384x640 1 airplane, 22.9ms\n",
      "Speed: 1.5ms preprocess, 22.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/93.jpg: 384x640 2 airplanes, 41.9ms\n",
      "Speed: 1.8ms preprocess, 41.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/94.jpg: 384x640 1 person, 25.0ms\n",
      "Speed: 1.7ms preprocess, 25.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/95.jpg: 384x640 1 airplane, 43.0ms\n",
      "Speed: 1.6ms preprocess, 43.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/96.jpg: 384x640 2 airplanes, 24.1ms\n",
      "Speed: 1.4ms preprocess, 24.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/97.jpg: 384x640 (no detections), 27.4ms\n",
      "Speed: 1.8ms preprocess, 27.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/98.jpg: 384x640 1 person, 26.8ms\n",
      "Speed: 1.9ms preprocess, 26.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/99.jpg: 384x640 (no detections), 25.5ms\n",
      "Speed: 1.6ms preprocess, 25.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/100.jpg: 384x640 1 bottle, 27.5ms\n",
      "Speed: 1.7ms preprocess, 27.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/101.jpg: 384x640 1 person, 1 airplane, 24.6ms\n",
      "Speed: 1.5ms preprocess, 24.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/102.jpg: 384x640 1 person, 1 airplane, 24.2ms\n",
      "Speed: 1.4ms preprocess, 24.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/103.jpg: 384x640 (no detections), 23.7ms\n",
      "Speed: 1.7ms preprocess, 23.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/104.jpg: 384x640 (no detections), 22.6ms\n",
      "Speed: 1.8ms preprocess, 22.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/105.jpg: 384x640 (no detections), 55.2ms\n",
      "Speed: 1.4ms preprocess, 55.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/106.jpg: 384x640 (no detections), 31.8ms\n",
      "Speed: 2.0ms preprocess, 31.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/107.jpg: 384x640 1 airplane, 26.9ms\n",
      "Speed: 1.8ms preprocess, 26.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/108.jpg: 384x640 1 bottle, 1 carrot, 23.1ms\n",
      "Speed: 1.7ms preprocess, 23.1ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/109.jpg: 384x640 1 bottle, 1 carrot, 1 donut, 41.0ms\n",
      "Speed: 2.0ms preprocess, 41.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/110.jpg: 384x640 1 airplane, 25.4ms\n",
      "Speed: 1.8ms preprocess, 25.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/111.jpg: 384x640 (no detections), 24.0ms\n",
      "Speed: 1.5ms preprocess, 24.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/112.jpg: 384x640 1 person, 34.6ms\n",
      "Speed: 1.9ms preprocess, 34.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/113.jpg: 384x640 1 airplane, 39.1ms\n",
      "Speed: 1.8ms preprocess, 39.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/114.jpg: 384x640 4 airplanes, 23.2ms\n",
      "Speed: 1.6ms preprocess, 23.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/115.jpg: 384x640 1 airplane, 28.1ms\n",
      "Speed: 2.0ms preprocess, 28.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/116.jpg: 384x640 1 airplane, 24.0ms\n",
      "Speed: 1.7ms preprocess, 24.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/117.jpg: 384x640 1 airplane, 23.5ms\n",
      "Speed: 1.7ms preprocess, 23.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/118.jpg: 384x640 1 airplane, 25.7ms\n",
      "Speed: 1.6ms preprocess, 25.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/119.jpg: 384x640 (no detections), 22.5ms\n",
      "Speed: 1.8ms preprocess, 22.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/120.jpg: 384x640 (no detections), 26.9ms\n",
      "Speed: 1.8ms preprocess, 26.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/121.jpg: 384x640 (no detections), 26.5ms\n",
      "Speed: 1.9ms preprocess, 26.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/122.jpg: 384x640 (no detections), 21.6ms\n",
      "Speed: 1.5ms preprocess, 21.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/123.jpg: 384x640 2 birds, 26.8ms\n",
      "Speed: 1.7ms preprocess, 26.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/124.jpg: 384x640 (no detections), 35.9ms\n",
      "Speed: 1.7ms preprocess, 35.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/125.jpg: 384x640 (no detections), 28.8ms\n",
      "Speed: 1.9ms preprocess, 28.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/126.jpg: 384x640 1 airplane, 29.1ms\n",
      "Speed: 2.1ms preprocess, 29.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/127.jpg: 384x640 1 airplane, 40.3ms\n",
      "Speed: 1.8ms preprocess, 40.3ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/128.jpg: 384x640 1 bottle, 29.3ms\n",
      "Speed: 2.3ms preprocess, 29.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/129.jpg: 384x640 2 airplanes, 22.3ms\n",
      "Speed: 1.5ms preprocess, 22.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/130.jpg: 384x640 (no detections), 40.9ms\n",
      "Speed: 1.9ms preprocess, 40.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/131.jpg: 384x640 2 airplanes, 27.6ms\n",
      "Speed: 1.7ms preprocess, 27.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/132.jpg: 384x640 1 airplane, 42.1ms\n",
      "Speed: 1.5ms preprocess, 42.1ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/133.jpg: 384x640 (no detections), 24.3ms\n",
      "Speed: 2.3ms preprocess, 24.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/134.jpg: 384x640 1 airplane, 28.6ms\n",
      "Speed: 1.8ms preprocess, 28.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/135.jpg: 384x640 (no detections), 29.5ms\n",
      "Speed: 1.7ms preprocess, 29.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/136.jpg: 384x640 1 person, 1 airplane, 26.4ms\n",
      "Speed: 1.5ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/137.jpg: 384x640 1 airplane, 27.4ms\n",
      "Speed: 1.5ms preprocess, 27.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/138.jpg: 384x640 1 airplane, 30.3ms\n",
      "Speed: 1.8ms preprocess, 30.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/139.jpg: 384x640 1 airplane, 26.5ms\n",
      "Speed: 1.6ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/140.jpg: 384x640 (no detections), 42.5ms\n",
      "Speed: 1.8ms preprocess, 42.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/141.jpg: 384x640 2 airplanes, 25.4ms\n",
      "Speed: 1.5ms preprocess, 25.4ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/142.jpg: 384x640 1 airplane, 20.6ms\n",
      "Speed: 1.5ms preprocess, 20.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/143.jpg: 384x640 1 motorcycle, 1 fork, 1 carrot, 21.8ms\n",
      "Speed: 1.5ms preprocess, 21.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/144.jpg: 384x640 1 carrot, 31.7ms\n",
      "Speed: 1.9ms preprocess, 31.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/145.jpg: 384x640 2 airplanes, 22.2ms\n",
      "Speed: 1.6ms preprocess, 22.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/146.jpg: 384x640 1 airplane, 32.1ms\n",
      "Speed: 2.4ms preprocess, 32.1ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/147.jpg: 384x640 1 airplane, 22.2ms\n",
      "Speed: 1.5ms preprocess, 22.2ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/148.jpg: 384x640 1 airplane, 22.4ms\n",
      "Speed: 1.5ms preprocess, 22.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/149.jpg: 384x640 (no detections), 20.2ms\n",
      "Speed: 1.5ms preprocess, 20.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/150.jpg: 384x640 1 boat, 25.7ms\n",
      "Speed: 1.7ms preprocess, 25.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/151.jpg: 384x640 (no detections), 31.7ms\n",
      "Speed: 2.2ms preprocess, 31.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/152.jpg: 384x640 (no detections), 29.7ms\n",
      "Speed: 1.5ms preprocess, 29.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/153.jpg: 384x640 (no detections), 25.9ms\n",
      "Speed: 1.5ms preprocess, 25.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/154.jpg: 384x640 (no detections), 23.4ms\n",
      "Speed: 1.5ms preprocess, 23.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/155.jpg: 384x640 1 person, 2 airplanes, 21.0ms\n",
      "Speed: 1.7ms preprocess, 21.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/156.jpg: 384x640 (no detections), 26.5ms\n",
      "Speed: 1.5ms preprocess, 26.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/157.jpg: 384x640 (no detections), 23.9ms\n",
      "Speed: 1.4ms preprocess, 23.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/158.jpg: 384x640 1 airplane, 23.2ms\n",
      "Speed: 1.5ms preprocess, 23.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/159.jpg: 384x640 1 airplane, 28.1ms\n",
      "Speed: 1.5ms preprocess, 28.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/160.jpg: 384x640 1 airplane, 1 boat, 23.2ms\n",
      "Speed: 1.8ms preprocess, 23.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/161.jpg: 384x640 1 airplane, 21.1ms\n",
      "Speed: 1.4ms preprocess, 21.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/162.jpg: 384x640 1 airplane, 23.5ms\n",
      "Speed: 1.6ms preprocess, 23.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/163.jpg: 384x640 (no detections), 22.0ms\n",
      "Speed: 1.4ms preprocess, 22.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/164.jpg: 384x640 2 persons, 1 boat, 30.7ms\n",
      "Speed: 1.7ms preprocess, 30.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/165.jpg: 384x640 1 airplane, 35.4ms\n",
      "Speed: 1.9ms preprocess, 35.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/166.jpg: 384x640 1 carrot, 1 toothbrush, 26.7ms\n",
      "Speed: 1.9ms preprocess, 26.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/167.jpg: 384x640 2 airplanes, 46.1ms\n",
      "Speed: 1.9ms preprocess, 46.1ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/168.jpg: 384x640 (no detections), 24.9ms\n",
      "Speed: 1.5ms preprocess, 24.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/169.jpg: 384x640 1 airplane, 25.1ms\n",
      "Speed: 1.6ms preprocess, 25.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/170.jpg: 384x640 (no detections), 29.7ms\n",
      "Speed: 1.5ms preprocess, 29.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/171.jpg: 384x640 (no detections), 28.7ms\n",
      "Speed: 1.5ms preprocess, 28.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/172.jpg: 384x640 (no detections), 38.5ms\n",
      "Speed: 1.5ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/173.jpg: 384x640 (no detections), 22.0ms\n",
      "Speed: 1.6ms preprocess, 22.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/174.jpg: 384x640 (no detections), 33.7ms\n",
      "Speed: 1.8ms preprocess, 33.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/175.jpg: 384x640 1 person, 50.2ms\n",
      "Speed: 1.7ms preprocess, 50.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/176.jpg: 384x640 (no detections), 21.0ms\n",
      "Speed: 1.4ms preprocess, 21.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/177.jpg: 384x640 (no detections), 27.3ms\n",
      "Speed: 1.9ms preprocess, 27.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/178.jpg: 384x640 1 person, 2 boats, 35.0ms\n",
      "Speed: 2.0ms preprocess, 35.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/179.jpg: 384x640 (no detections), 32.4ms\n",
      "Speed: 1.8ms preprocess, 32.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/180.jpg: 384x640 1 airplane, 21.2ms\n",
      "Speed: 1.5ms preprocess, 21.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/181.jpg: 384x640 1 airplane, 51.4ms\n",
      "Speed: 1.8ms preprocess, 51.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/182.jpg: 384x640 1 bottle, 2 carrots, 22.1ms\n",
      "Speed: 1.5ms preprocess, 22.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/183.jpg: 384x640 (no detections), 34.0ms\n",
      "Speed: 1.8ms preprocess, 34.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/184.jpg: 384x640 (no detections), 28.5ms\n",
      "Speed: 1.6ms preprocess, 28.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/185.jpg: 384x640 1 airplane, 38.9ms\n",
      "Speed: 1.9ms preprocess, 38.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/186.jpg: 384x640 (no detections), 23.2ms\n",
      "Speed: 1.5ms preprocess, 23.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/187.jpg: 384x640 (no detections), 41.5ms\n",
      "Speed: 1.8ms preprocess, 41.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/188.jpg: 384x640 (no detections), 27.2ms\n",
      "Speed: 1.6ms preprocess, 27.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/189.jpg: 384x640 (no detections), 22.0ms\n",
      "Speed: 1.5ms preprocess, 22.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/190.jpg: 384x640 (no detections), 33.8ms\n",
      "Speed: 1.7ms preprocess, 33.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/191.jpg: 384x640 1 airplane, 22.2ms\n",
      "Speed: 1.8ms preprocess, 22.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/192.jpg: 384x640 (no detections), 34.2ms\n",
      "Speed: 1.7ms preprocess, 34.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/193.jpg: 384x640 1 airplane, 30.0ms\n",
      "Speed: 1.8ms preprocess, 30.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/194.jpg: 384x640 1 airplane, 35.1ms\n",
      "Speed: 1.8ms preprocess, 35.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/195.jpg: 384x640 (no detections), 32.2ms\n",
      "Speed: 1.4ms preprocess, 32.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/196.jpg: 384x640 1 airplane, 23.4ms\n",
      "Speed: 1.6ms preprocess, 23.4ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/197.jpg: 384x640 1 airplane, 30.9ms\n",
      "Speed: 3.0ms preprocess, 30.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/198.jpg: 384x640 (no detections), 26.3ms\n",
      "Speed: 1.5ms preprocess, 26.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/199.jpg: 384x640 (no detections), 24.7ms\n",
      "Speed: 1.4ms preprocess, 24.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/200.jpg: 384x640 (no detections), 43.1ms\n",
      "Speed: 2.1ms preprocess, 43.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/201.jpg: 384x640 (no detections), 23.6ms\n",
      "Speed: 1.9ms preprocess, 23.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/202.jpg: 384x640 (no detections), 31.5ms\n",
      "Speed: 3.5ms preprocess, 31.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/203.jpg: 384x640 (no detections), 21.7ms\n",
      "Speed: 1.5ms preprocess, 21.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/204.jpg: 384x640 (no detections), 22.6ms\n",
      "Speed: 1.5ms preprocess, 22.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/205.jpg: 384x640 1 airplane, 27.1ms\n",
      "Speed: 2.6ms preprocess, 27.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/206.jpg: 384x640 (no detections), 34.1ms\n",
      "Speed: 1.5ms preprocess, 34.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/207.jpg: 384x640 (no detections), 40.4ms\n",
      "Speed: 1.5ms preprocess, 40.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/208.jpg: 384x640 (no detections), 24.9ms\n",
      "Speed: 2.3ms preprocess, 24.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/209.jpg: 384x640 (no detections), 20.8ms\n",
      "Speed: 1.5ms preprocess, 20.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/210.jpg: 384x640 (no detections), 24.8ms\n",
      "Speed: 1.6ms preprocess, 24.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/211.jpg: 384x640 (no detections), 36.9ms\n",
      "Speed: 1.5ms preprocess, 36.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/212.jpg: 384x640 (no detections), 27.3ms\n",
      "Speed: 1.9ms preprocess, 27.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/213.jpg: 384x640 1 airplane, 38.9ms\n",
      "Speed: 2.4ms preprocess, 38.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/214.jpg: 384x640 (no detections), 28.1ms\n",
      "Speed: 2.3ms preprocess, 28.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/215.jpg: 384x640 1 person, 21.6ms\n",
      "Speed: 1.4ms preprocess, 21.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/216.jpg: 384x640 1 airplane, 22.2ms\n",
      "Speed: 1.6ms preprocess, 22.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/217.jpg: 384x640 (no detections), 30.3ms\n",
      "Speed: 1.8ms preprocess, 30.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/218.jpg: 384x640 2 airplanes, 22.2ms\n",
      "Speed: 1.5ms preprocess, 22.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/219.jpg: 384x640 2 airplanes, 23.9ms\n",
      "Speed: 1.7ms preprocess, 23.9ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/220.jpg: 384x640 (no detections), 30.7ms\n",
      "Speed: 2.1ms preprocess, 30.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/221.jpg: 384x640 (no detections), 21.6ms\n",
      "Speed: 1.4ms preprocess, 21.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/222.jpg: 384x640 (no detections), 34.1ms\n",
      "Speed: 1.6ms preprocess, 34.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/223.jpg: 384x640 (no detections), 25.1ms\n",
      "Speed: 1.4ms preprocess, 25.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/224.jpg: 384x640 (no detections), 21.7ms\n",
      "Speed: 1.4ms preprocess, 21.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/225.jpg: 384x640 (no detections), 23.3ms\n",
      "Speed: 1.5ms preprocess, 23.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/226.jpg: 384x640 (no detections), 27.6ms\n",
      "Speed: 2.2ms preprocess, 27.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/227.jpg: 384x640 (no detections), 35.3ms\n",
      "Speed: 1.5ms preprocess, 35.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/228.jpg: 384x640 2 airplanes, 25.3ms\n",
      "Speed: 1.6ms preprocess, 25.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/229.jpg: 384x640 (no detections), 22.4ms\n",
      "Speed: 1.5ms preprocess, 22.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/230.jpg: 384x640 (no detections), 32.6ms\n",
      "Speed: 1.6ms preprocess, 32.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/231.jpg: 384x640 (no detections), 23.3ms\n",
      "Speed: 1.5ms preprocess, 23.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/232.jpg: 384x640 (no detections), 27.4ms\n",
      "Speed: 2.8ms preprocess, 27.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/233.jpg: 384x640 1 spoon, 2 carrots, 21.0ms\n",
      "Speed: 1.5ms preprocess, 21.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/234.jpg: 384x640 (no detections), 36.0ms\n",
      "Speed: 1.8ms preprocess, 36.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/235.jpg: 384x640 (no detections), 25.3ms\n",
      "Speed: 1.7ms preprocess, 25.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/236.jpg: 384x640 (no detections), 42.9ms\n",
      "Speed: 1.5ms preprocess, 42.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/237.jpg: 384x640 (no detections), 26.5ms\n",
      "Speed: 3.8ms preprocess, 26.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/238.jpg: 384x640 1 spoon, 5 carrots, 35.3ms\n",
      "Speed: 2.0ms preprocess, 35.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/239.jpg: 384x640 (no detections), 21.5ms\n",
      "Speed: 1.5ms preprocess, 21.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/240.jpg: 384x640 1 knife, 22.3ms\n",
      "Speed: 1.6ms preprocess, 22.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/241.jpg: 384x640 1 person, 49.3ms\n",
      "Speed: 1.6ms preprocess, 49.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/242.jpg: 384x640 (no detections), 27.0ms\n",
      "Speed: 1.9ms preprocess, 27.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/243.jpg: 384x640 1 spoon, 4 carrots, 26.2ms\n",
      "Speed: 1.5ms preprocess, 26.2ms inference, 10.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/244.jpg: 384x640 1 baseball bat, 22.9ms\n",
      "Speed: 1.8ms preprocess, 22.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/245.jpg: 384x640 (no detections), 37.6ms\n",
      "Speed: 1.6ms preprocess, 37.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/246.jpg: 384x640 (no detections), 26.3ms\n",
      "Speed: 1.5ms preprocess, 26.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/247.jpg: 384x640 (no detections), 23.2ms\n",
      "Speed: 1.8ms preprocess, 23.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/248.jpg: 384x640 (no detections), 29.1ms\n",
      "Speed: 3.1ms preprocess, 29.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/249.jpg: 384x640 (no detections), 23.0ms\n",
      "Speed: 1.5ms preprocess, 23.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/250.jpg: 384x640 (no detections), 27.2ms\n",
      "Speed: 1.9ms preprocess, 27.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/251.jpg: 384x640 (no detections), 22.8ms\n",
      "Speed: 1.4ms preprocess, 22.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/252.jpg: 384x640 3 airplanes, 34.0ms\n",
      "Speed: 1.5ms preprocess, 34.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/253.jpg: 384x640 (no detections), 24.5ms\n",
      "Speed: 2.0ms preprocess, 24.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/254.jpg: 384x640 2 airplanes, 30.3ms\n",
      "Speed: 2.3ms preprocess, 30.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/255.jpg: 384x640 (no detections), 20.8ms\n",
      "Speed: 1.4ms preprocess, 20.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/256.jpg: 384x640 1 airplane, 22.0ms\n",
      "Speed: 1.5ms preprocess, 22.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/257.jpg: 384x640 (no detections), 21.5ms\n",
      "Speed: 1.5ms preprocess, 21.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/258.jpg: 384x640 (no detections), 23.1ms\n",
      "Speed: 1.5ms preprocess, 23.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/259.jpg: 384x640 (no detections), 25.6ms\n",
      "Speed: 1.5ms preprocess, 25.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/260.jpg: 384x640 (no detections), 37.0ms\n",
      "Speed: 1.9ms preprocess, 37.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/261.jpg: 384x640 (no detections), 35.3ms\n",
      "Speed: 1.6ms preprocess, 35.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/262.jpg: 384x640 1 spoon, 31.5ms\n",
      "Speed: 1.8ms preprocess, 31.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/263.jpg: 384x640 1 spoon, 1 carrot, 38.9ms\n",
      "Speed: 2.2ms preprocess, 38.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/264.jpg: 384x640 (no detections), 24.3ms\n",
      "Speed: 1.7ms preprocess, 24.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/265.jpg: 384x640 (no detections), 27.8ms\n",
      "Speed: 1.6ms preprocess, 27.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/266.jpg: 384x640 (no detections), 23.2ms\n",
      "Speed: 1.8ms preprocess, 23.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/267.jpg: 384x640 (no detections), 22.7ms\n",
      "Speed: 1.5ms preprocess, 22.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/268.jpg: 384x640 (no detections), 26.5ms\n",
      "Speed: 1.9ms preprocess, 26.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/269.jpg: 384x640 (no detections), 22.6ms\n",
      "Speed: 1.6ms preprocess, 22.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/270.jpg: 384x640 (no detections), 25.1ms\n",
      "Speed: 1.5ms preprocess, 25.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/271.jpg: 384x640 (no detections), 27.1ms\n",
      "Speed: 1.6ms preprocess, 27.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/272.jpg: 384x640 1 toothbrush, 30.6ms\n",
      "Speed: 2.0ms preprocess, 30.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/273.jpg: 384x640 1 airplane, 22.6ms\n",
      "Speed: 1.5ms preprocess, 22.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/274.jpg: 384x640 (no detections), 34.7ms\n",
      "Speed: 1.6ms preprocess, 34.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/275.jpg: 384x640 2 airplanes, 24.0ms\n",
      "Speed: 1.6ms preprocess, 24.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/276.jpg: 384x640 (no detections), 23.5ms\n",
      "Speed: 1.6ms preprocess, 23.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/277.jpg: 384x640 (no detections), 37.8ms\n",
      "Speed: 1.6ms preprocess, 37.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/278.jpg: 384x640 (no detections), 34.9ms\n",
      "Speed: 2.7ms preprocess, 34.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/279.jpg: 384x640 (no detections), 26.7ms\n",
      "Speed: 1.6ms preprocess, 26.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/280.jpg: 384x640 1 airplane, 23.1ms\n",
      "Speed: 1.5ms preprocess, 23.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/281.jpg: 384x640 (no detections), 41.1ms\n",
      "Speed: 1.7ms preprocess, 41.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/282.jpg: 384x640 (no detections), 25.0ms\n",
      "Speed: 1.7ms preprocess, 25.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/283.jpg: 384x640 (no detections), 42.8ms\n",
      "Speed: 2.5ms preprocess, 42.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/284.jpg: 384x640 1 airplane, 25.4ms\n",
      "Speed: 1.6ms preprocess, 25.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/285.jpg: 384x640 (no detections), 21.5ms\n",
      "Speed: 1.6ms preprocess, 21.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/286.jpg: 384x640 (no detections), 23.0ms\n",
      "Speed: 1.6ms preprocess, 23.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/287.jpg: 384x640 (no detections), 23.4ms\n",
      "Speed: 1.5ms preprocess, 23.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/288.jpg: 384x640 (no detections), 21.4ms\n",
      "Speed: 1.5ms preprocess, 21.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/289.jpg: 384x640 (no detections), 24.4ms\n",
      "Speed: 1.5ms preprocess, 24.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/290.jpg: 384x640 (no detections), 43.2ms\n",
      "Speed: 2.2ms preprocess, 43.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/291.jpg: 384x640 (no detections), 45.0ms\n",
      "Speed: 3.1ms preprocess, 45.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/292.jpg: 384x640 1 airplane, 21.3ms\n",
      "Speed: 1.5ms preprocess, 21.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/293.jpg: 384x640 (no detections), 25.4ms\n",
      "Speed: 1.4ms preprocess, 25.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/294.jpg: 384x640 (no detections), 24.5ms\n",
      "Speed: 1.5ms preprocess, 24.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/295.jpg: 384x640 (no detections), 26.1ms\n",
      "Speed: 1.7ms preprocess, 26.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/296.jpg: 384x640 (no detections), 33.4ms\n",
      "Speed: 2.3ms preprocess, 33.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/297.jpg: 384x640 1 boat, 25.9ms\n",
      "Speed: 1.5ms preprocess, 25.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/298.jpg: 384x640 (no detections), 37.1ms\n",
      "Speed: 1.6ms preprocess, 37.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/left/299.jpg: 384x640 (no detections), 25.9ms\n",
      "Speed: 1.6ms preprocess, 25.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Propagating video frames: 100%|| 300/300 [00:16<00:00, 18.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask propagation completed in 16.10 seconds.\n",
      "Processing predicted masks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing video frames: 300it [00:00, 656.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 300 masks for evaluation.\n",
      "Masks saved to data/masks/yolo11x-seg/val/data-raw-SegSTRONGC_val-val-1-2-smoke-left.pkl\n",
      "Loading ground truth masks for evaluation...\n",
      "Loaded 300 ground truth masks.\n",
      "Calculating evaluation metrics...\n",
      "Time taken for metrics calculation: 1.75 seconds.\n",
      "Mean IoU for data/raw/SegSTRONGC_val/val/1/2/smoke/left: 0.0829\n",
      "Mean DSC for data/raw/SegSTRONGC_val/val/1/2/smoke/left: 0.1301\n",
      "Loading existing results file: data/results/yolo11x-seg/val.json\n",
      "Results saved to data/results/yolo11x-seg/val.json\n",
      "Processing video took 22.15 seconds.\n",
      "==================================================\n",
      "Processing right camera video...\n",
      "==================================================\n",
      "Processing video: data/raw/SegSTRONGC_val/val/1/2/smoke/right\n",
      "Domain: smoke, Split: val, Camera: right\n",
      "Initializing Yolo for video...\n",
      "Initialization took 0.16 seconds.\n",
      "Starting mask propagation...\n",
      "Total images in video: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/0.jpg: 384x640 1 airplane, 52.4ms\n",
      "Speed: 2.4ms preprocess, 52.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/1.jpg: 384x640 (no detections), 25.0ms\n",
      "Speed: 2.0ms preprocess, 25.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/2.jpg: 384x640 (no detections), 35.0ms\n",
      "Speed: 1.5ms preprocess, 35.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/3.jpg: 384x640 (no detections), 27.6ms\n",
      "Speed: 1.8ms preprocess, 27.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/4.jpg: 384x640 (no detections), 26.7ms\n",
      "Speed: 1.6ms preprocess, 26.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/5.jpg: 384x640 1 spoon, 30.2ms\n",
      "Speed: 1.5ms preprocess, 30.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/6.jpg: 384x640 1 spoon, 31.1ms\n",
      "Speed: 2.1ms preprocess, 31.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/7.jpg: 384x640 (no detections), 27.6ms\n",
      "Speed: 2.0ms preprocess, 27.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/8.jpg: 384x640 1 motorcycle, 30.8ms\n",
      "Speed: 1.5ms preprocess, 30.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/9.jpg: 384x640 2 motorcycles, 23.9ms\n",
      "Speed: 1.3ms preprocess, 23.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/10.jpg: 384x640 (no detections), 22.5ms\n",
      "Speed: 1.5ms preprocess, 22.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/11.jpg: 384x640 (no detections), 28.9ms\n",
      "Speed: 1.6ms preprocess, 28.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/12.jpg: 384x640 1 airplane, 24.5ms\n",
      "Speed: 1.8ms preprocess, 24.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/13.jpg: 384x640 1 airplane, 22.5ms\n",
      "Speed: 1.5ms preprocess, 22.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/14.jpg: 384x640 (no detections), 21.9ms\n",
      "Speed: 1.5ms preprocess, 21.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/15.jpg: 384x640 1 toothbrush, 22.2ms\n",
      "Speed: 1.5ms preprocess, 22.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/16.jpg: 384x640 2 bottles, 1 toothbrush, 25.8ms\n",
      "Speed: 1.9ms preprocess, 25.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/17.jpg: 384x640 1 toothbrush, 28.9ms\n",
      "Speed: 2.1ms preprocess, 28.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/18.jpg: 384x640 (no detections), 42.0ms\n",
      "Speed: 1.6ms preprocess, 42.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/19.jpg: 384x640 (no detections), 34.8ms\n",
      "Speed: 1.6ms preprocess, 34.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/20.jpg: 384x640 (no detections), 24.1ms\n",
      "Speed: 1.7ms preprocess, 24.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/21.jpg: 384x640 (no detections), 37.1ms\n",
      "Speed: 2.0ms preprocess, 37.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/22.jpg: 384x640 (no detections), 31.1ms\n",
      "Speed: 1.6ms preprocess, 31.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/23.jpg: 384x640 1 fork, 4 carrots, 23.1ms\n",
      "Speed: 1.7ms preprocess, 23.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/24.jpg: 384x640 (no detections), 33.2ms\n",
      "Speed: 1.8ms preprocess, 33.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/25.jpg: 384x640 (no detections), 25.3ms\n",
      "Speed: 1.7ms preprocess, 25.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/26.jpg: 384x640 (no detections), 22.5ms\n",
      "Speed: 1.5ms preprocess, 22.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/27.jpg: 384x640 (no detections), 21.7ms\n",
      "Speed: 1.5ms preprocess, 21.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/28.jpg: 384x640 1 airplane, 23.9ms\n",
      "Speed: 1.7ms preprocess, 23.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/29.jpg: 384x640 1 sink, 32.3ms\n",
      "Speed: 2.3ms preprocess, 32.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/30.jpg: 384x640 1 sink, 23.4ms\n",
      "Speed: 1.6ms preprocess, 23.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/31.jpg: 384x640 (no detections), 36.5ms\n",
      "Speed: 1.6ms preprocess, 36.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/32.jpg: 384x640 (no detections), 22.4ms\n",
      "Speed: 1.6ms preprocess, 22.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/33.jpg: 384x640 1 boat, 30.8ms\n",
      "Speed: 1.6ms preprocess, 30.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/34.jpg: 384x640 (no detections), 23.7ms\n",
      "Speed: 1.5ms preprocess, 23.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/35.jpg: 384x640 (no detections), 21.1ms\n",
      "Speed: 1.4ms preprocess, 21.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/36.jpg: 384x640 (no detections), 22.3ms\n",
      "Speed: 1.6ms preprocess, 22.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/37.jpg: 384x640 (no detections), 23.0ms\n",
      "Speed: 1.4ms preprocess, 23.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/38.jpg: 384x640 (no detections), 31.0ms\n",
      "Speed: 1.7ms preprocess, 31.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/39.jpg: 384x640 (no detections), 24.6ms\n",
      "Speed: 1.7ms preprocess, 24.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/40.jpg: 384x640 1 bottle, 1 sink, 1 toothbrush, 22.3ms\n",
      "Speed: 1.6ms preprocess, 22.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/41.jpg: 384x640 1 bottle, 2 carrots, 26.1ms\n",
      "Speed: 1.6ms preprocess, 26.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/42.jpg: 384x640 1 bottle, 1 toothbrush, 24.0ms\n",
      "Speed: 1.6ms preprocess, 24.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/43.jpg: 384x640 (no detections), 24.7ms\n",
      "Speed: 1.8ms preprocess, 24.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/44.jpg: 384x640 (no detections), 23.2ms\n",
      "Speed: 1.8ms preprocess, 23.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/45.jpg: 384x640 (no detections), 27.4ms\n",
      "Speed: 2.0ms preprocess, 27.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/46.jpg: 384x640 (no detections), 25.5ms\n",
      "Speed: 1.9ms preprocess, 25.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/47.jpg: 384x640 (no detections), 31.2ms\n",
      "Speed: 2.6ms preprocess, 31.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/48.jpg: 384x640 (no detections), 23.5ms\n",
      "Speed: 1.6ms preprocess, 23.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/49.jpg: 384x640 1 spoon, 1 orange, 1 toothbrush, 24.4ms\n",
      "Speed: 1.8ms preprocess, 24.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/50.jpg: 384x640 (no detections), 27.3ms\n",
      "Speed: 1.9ms preprocess, 27.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/51.jpg: 384x640 (no detections), 27.5ms\n",
      "Speed: 2.9ms preprocess, 27.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/52.jpg: 384x640 1 boat, 23.3ms\n",
      "Speed: 1.7ms preprocess, 23.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/53.jpg: 384x640 (no detections), 22.8ms\n",
      "Speed: 1.5ms preprocess, 22.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/54.jpg: 384x640 (no detections), 22.5ms\n",
      "Speed: 1.5ms preprocess, 22.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/55.jpg: 384x640 (no detections), 38.2ms\n",
      "Speed: 1.6ms preprocess, 38.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/56.jpg: 384x640 1 bottle, 24.1ms\n",
      "Speed: 2.9ms preprocess, 24.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/57.jpg: 384x640 (no detections), 23.0ms\n",
      "Speed: 1.6ms preprocess, 23.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/58.jpg: 384x640 (no detections), 23.7ms\n",
      "Speed: 1.6ms preprocess, 23.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/59.jpg: 384x640 (no detections), 21.6ms\n",
      "Speed: 2.0ms preprocess, 21.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/60.jpg: 384x640 (no detections), 37.7ms\n",
      "Speed: 1.7ms preprocess, 37.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/61.jpg: 384x640 (no detections), 24.0ms\n",
      "Speed: 1.7ms preprocess, 24.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/62.jpg: 384x640 1 toothbrush, 22.8ms\n",
      "Speed: 1.6ms preprocess, 22.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/63.jpg: 384x640 (no detections), 26.7ms\n",
      "Speed: 2.6ms preprocess, 26.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/64.jpg: 384x640 (no detections), 37.1ms\n",
      "Speed: 1.6ms preprocess, 37.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/65.jpg: 384x640 (no detections), 24.6ms\n",
      "Speed: 1.7ms preprocess, 24.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/66.jpg: 384x640 (no detections), 23.3ms\n",
      "Speed: 1.8ms preprocess, 23.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/67.jpg: 384x640 (no detections), 24.1ms\n",
      "Speed: 1.7ms preprocess, 24.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/68.jpg: 384x640 1 toothbrush, 21.4ms\n",
      "Speed: 1.6ms preprocess, 21.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/69.jpg: 384x640 1 toothbrush, 24.1ms\n",
      "Speed: 1.9ms preprocess, 24.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/70.jpg: 384x640 1 bottle, 23.7ms\n",
      "Speed: 1.6ms preprocess, 23.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/71.jpg: 384x640 1 airplane, 22.4ms\n",
      "Speed: 1.5ms preprocess, 22.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/72.jpg: 384x640 (no detections), 23.2ms\n",
      "Speed: 1.6ms preprocess, 23.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/73.jpg: 384x640 (no detections), 32.8ms\n",
      "Speed: 1.7ms preprocess, 32.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/74.jpg: 384x640 (no detections), 39.6ms\n",
      "Speed: 2.0ms preprocess, 39.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/75.jpg: 384x640 (no detections), 24.9ms\n",
      "Speed: 1.7ms preprocess, 24.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/76.jpg: 384x640 (no detections), 23.7ms\n",
      "Speed: 1.7ms preprocess, 23.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/77.jpg: 384x640 1 sink, 1 toothbrush, 28.8ms\n",
      "Speed: 1.8ms preprocess, 28.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/78.jpg: 384x640 (no detections), 30.8ms\n",
      "Speed: 2.4ms preprocess, 30.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/79.jpg: 384x640 1 bottle, 1 spoon, 4 carrots, 23.3ms\n",
      "Speed: 1.6ms preprocess, 23.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/80.jpg: 384x640 1 bottle, 1 spoon, 6 carrots, 23.8ms\n",
      "Speed: 1.8ms preprocess, 23.8ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/81.jpg: 384x640 (no detections), 27.7ms\n",
      "Speed: 1.9ms preprocess, 27.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/82.jpg: 384x640 1 bottle, 1 spoon, 5 carrots, 26.8ms\n",
      "Speed: 2.8ms preprocess, 26.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/83.jpg: 384x640 1 bottle, 5 carrots, 23.3ms\n",
      "Speed: 1.5ms preprocess, 23.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/84.jpg: 384x640 1 airplane, 25.0ms\n",
      "Speed: 1.6ms preprocess, 25.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/85.jpg: 384x640 1 airplane, 28.8ms\n",
      "Speed: 1.5ms preprocess, 28.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/86.jpg: 384x640 1 airplane, 24.3ms\n",
      "Speed: 1.6ms preprocess, 24.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/87.jpg: 384x640 1 airplane, 25.1ms\n",
      "Speed: 1.6ms preprocess, 25.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/88.jpg: 384x640 (no detections), 23.8ms\n",
      "Speed: 1.5ms preprocess, 23.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/89.jpg: 384x640 1 bottle, 1 toothbrush, 27.0ms\n",
      "Speed: 1.6ms preprocess, 27.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/90.jpg: 384x640 2 oranges, 1 toothbrush, 27.3ms\n",
      "Speed: 2.6ms preprocess, 27.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/91.jpg: 384x640 1 airplane, 22.4ms\n",
      "Speed: 1.6ms preprocess, 22.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/92.jpg: 384x640 1 airplane, 32.9ms\n",
      "Speed: 1.6ms preprocess, 32.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/93.jpg: 384x640 (no detections), 24.7ms\n",
      "Speed: 1.7ms preprocess, 24.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/94.jpg: 384x640 1 airplane, 42.4ms\n",
      "Speed: 2.0ms preprocess, 42.4ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/95.jpg: 384x640 1 airplane, 25.1ms\n",
      "Speed: 1.6ms preprocess, 25.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/96.jpg: 384x640 (no detections), 38.2ms\n",
      "Speed: 1.6ms preprocess, 38.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/97.jpg: 384x640 (no detections), 25.8ms\n",
      "Speed: 1.8ms preprocess, 25.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/98.jpg: 384x640 (no detections), 22.9ms\n",
      "Speed: 1.8ms preprocess, 22.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/99.jpg: 384x640 (no detections), 44.4ms\n",
      "Speed: 2.0ms preprocess, 44.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/100.jpg: 384x640 1 baseball bat, 2 bottles, 25.4ms\n",
      "Speed: 1.9ms preprocess, 25.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/101.jpg: 384x640 (no detections), 26.7ms\n",
      "Speed: 2.2ms preprocess, 26.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/102.jpg: 384x640 (no detections), 24.6ms\n",
      "Speed: 1.5ms preprocess, 24.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/103.jpg: 384x640 1 airplane, 26.8ms\n",
      "Speed: 1.6ms preprocess, 26.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/104.jpg: 384x640 (no detections), 24.9ms\n",
      "Speed: 1.8ms preprocess, 24.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/105.jpg: 384x640 1 airplane, 22.0ms\n",
      "Speed: 1.7ms preprocess, 22.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/106.jpg: 384x640 1 person, 27.1ms\n",
      "Speed: 1.8ms preprocess, 27.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/107.jpg: 384x640 1 orange, 1 sink, 1 toothbrush, 41.1ms\n",
      "Speed: 2.1ms preprocess, 41.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/108.jpg: 384x640 2 bottles, 36.4ms\n",
      "Speed: 1.7ms preprocess, 36.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/109.jpg: 384x640 1 baseball bat, 2 bottles, 2 carrots, 24.0ms\n",
      "Speed: 1.7ms preprocess, 24.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/110.jpg: 384x640 2 bottles, 29.0ms\n",
      "Speed: 1.6ms preprocess, 29.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/111.jpg: 384x640 1 airplane, 25.4ms\n",
      "Speed: 1.6ms preprocess, 25.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/112.jpg: 384x640 (no detections), 26.3ms\n",
      "Speed: 1.6ms preprocess, 26.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/113.jpg: 384x640 (no detections), 23.6ms\n",
      "Speed: 1.6ms preprocess, 23.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/114.jpg: 384x640 (no detections), 29.9ms\n",
      "Speed: 2.8ms preprocess, 29.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/115.jpg: 384x640 2 airplanes, 36.4ms\n",
      "Speed: 2.0ms preprocess, 36.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/116.jpg: 384x640 (no detections), 21.9ms\n",
      "Speed: 1.6ms preprocess, 21.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/117.jpg: 384x640 1 airplane, 24.8ms\n",
      "Speed: 1.7ms preprocess, 24.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/118.jpg: 384x640 1 airplane, 24.1ms\n",
      "Speed: 1.6ms preprocess, 24.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/119.jpg: 384x640 (no detections), 24.3ms\n",
      "Speed: 1.7ms preprocess, 24.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/120.jpg: 384x640 2 spoons, 1 toothbrush, 31.7ms\n",
      "Speed: 1.6ms preprocess, 31.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/121.jpg: 384x640 (no detections), 25.9ms\n",
      "Speed: 1.6ms preprocess, 25.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/122.jpg: 384x640 (no detections), 23.1ms\n",
      "Speed: 1.8ms preprocess, 23.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/123.jpg: 384x640 3 oranges, 24.0ms\n",
      "Speed: 1.6ms preprocess, 24.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/124.jpg: 384x640 (no detections), 23.0ms\n",
      "Speed: 1.6ms preprocess, 23.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/125.jpg: 384x640 (no detections), 20.8ms\n",
      "Speed: 1.5ms preprocess, 20.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/126.jpg: 384x640 (no detections), 27.7ms\n",
      "Speed: 1.5ms preprocess, 27.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/127.jpg: 384x640 (no detections), 23.4ms\n",
      "Speed: 1.6ms preprocess, 23.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/128.jpg: 384x640 2 bottles, 21.8ms\n",
      "Speed: 1.4ms preprocess, 21.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/129.jpg: 384x640 1 airplane, 24.3ms\n",
      "Speed: 1.7ms preprocess, 24.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/130.jpg: 384x640 (no detections), 23.1ms\n",
      "Speed: 1.6ms preprocess, 23.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/131.jpg: 384x640 (no detections), 22.2ms\n",
      "Speed: 1.5ms preprocess, 22.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/132.jpg: 384x640 1 airplane, 23.4ms\n",
      "Speed: 1.6ms preprocess, 23.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/133.jpg: 384x640 1 bottle, 1 carrot, 22.9ms\n",
      "Speed: 1.7ms preprocess, 22.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/134.jpg: 384x640 1 orange, 1 toothbrush, 21.9ms\n",
      "Speed: 1.6ms preprocess, 21.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/135.jpg: 384x640 1 airplane, 22.3ms\n",
      "Speed: 1.6ms preprocess, 22.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/136.jpg: 384x640 1 airplane, 21.9ms\n",
      "Speed: 1.5ms preprocess, 21.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/137.jpg: 384x640 1 airplane, 23.0ms\n",
      "Speed: 1.4ms preprocess, 23.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/138.jpg: 384x640 1 airplane, 26.4ms\n",
      "Speed: 1.7ms preprocess, 26.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/139.jpg: 384x640 (no detections), 22.5ms\n",
      "Speed: 1.5ms preprocess, 22.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/140.jpg: 384x640 (no detections), 24.9ms\n",
      "Speed: 1.6ms preprocess, 24.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/141.jpg: 384x640 1 airplane, 26.4ms\n",
      "Speed: 2.2ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/142.jpg: 384x640 (no detections), 23.9ms\n",
      "Speed: 1.6ms preprocess, 23.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/143.jpg: 384x640 1 carrot, 25.4ms\n",
      "Speed: 1.5ms preprocess, 25.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/144.jpg: 384x640 1 carrot, 1 toothbrush, 22.5ms\n",
      "Speed: 1.6ms preprocess, 22.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/145.jpg: 384x640 (no detections), 25.0ms\n",
      "Speed: 1.6ms preprocess, 25.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/146.jpg: 384x640 (no detections), 33.5ms\n",
      "Speed: 3.3ms preprocess, 33.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/147.jpg: 384x640 1 airplane, 26.6ms\n",
      "Speed: 1.8ms preprocess, 26.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/148.jpg: 384x640 1 orange, 32.0ms\n",
      "Speed: 1.7ms preprocess, 32.0ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/149.jpg: 384x640 1 toothbrush, 23.1ms\n",
      "Speed: 1.6ms preprocess, 23.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/150.jpg: 384x640 1 bottle, 6 carrots, 24.6ms\n",
      "Speed: 1.8ms preprocess, 24.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/151.jpg: 384x640 (no detections), 24.5ms\n",
      "Speed: 1.8ms preprocess, 24.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/152.jpg: 384x640 1 sink, 1 toothbrush, 41.7ms\n",
      "Speed: 1.6ms preprocess, 41.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/153.jpg: 384x640 1 airplane, 27.3ms\n",
      "Speed: 1.7ms preprocess, 27.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/154.jpg: 384x640 (no detections), 23.0ms\n",
      "Speed: 1.6ms preprocess, 23.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/155.jpg: 384x640 (no detections), 24.0ms\n",
      "Speed: 1.6ms preprocess, 24.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/156.jpg: 384x640 (no detections), 26.4ms\n",
      "Speed: 1.8ms preprocess, 26.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/157.jpg: 384x640 1 sink, 1 toothbrush, 25.5ms\n",
      "Speed: 1.7ms preprocess, 25.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/158.jpg: 384x640 1 airplane, 25.0ms\n",
      "Speed: 1.7ms preprocess, 25.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/159.jpg: 384x640 1 airplane, 35.1ms\n",
      "Speed: 1.6ms preprocess, 35.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/160.jpg: 384x640 1 airplane, 1 bottle, 28.7ms\n",
      "Speed: 1.8ms preprocess, 28.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/161.jpg: 384x640 1 bottle, 30.4ms\n",
      "Speed: 2.0ms preprocess, 30.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/162.jpg: 384x640 1 bottle, 24.2ms\n",
      "Speed: 1.6ms preprocess, 24.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/163.jpg: 384x640 (no detections), 23.6ms\n",
      "Speed: 1.6ms preprocess, 23.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/164.jpg: 384x640 1 airplane, 33.9ms\n",
      "Speed: 2.6ms preprocess, 33.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/165.jpg: 384x640 1 airplane, 22.2ms\n",
      "Speed: 1.8ms preprocess, 22.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/166.jpg: 384x640 1 bottle, 5 carrots, 25.9ms\n",
      "Speed: 1.8ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/167.jpg: 384x640 1 toothbrush, 22.1ms\n",
      "Speed: 1.6ms preprocess, 22.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/168.jpg: 384x640 (no detections), 26.1ms\n",
      "Speed: 1.6ms preprocess, 26.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/169.jpg: 384x640 (no detections), 21.7ms\n",
      "Speed: 1.6ms preprocess, 21.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/170.jpg: 384x640 (no detections), 22.1ms\n",
      "Speed: 1.5ms preprocess, 22.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/171.jpg: 384x640 (no detections), 24.7ms\n",
      "Speed: 1.8ms preprocess, 24.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/172.jpg: 384x640 (no detections), 22.3ms\n",
      "Speed: 1.5ms preprocess, 22.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/173.jpg: 384x640 (no detections), 23.5ms\n",
      "Speed: 1.7ms preprocess, 23.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/174.jpg: 384x640 1 person, 24.3ms\n",
      "Speed: 1.6ms preprocess, 24.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/175.jpg: 384x640 (no detections), 22.5ms\n",
      "Speed: 1.6ms preprocess, 22.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/176.jpg: 384x640 (no detections), 29.9ms\n",
      "Speed: 1.6ms preprocess, 29.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/177.jpg: 384x640 (no detections), 23.3ms\n",
      "Speed: 1.5ms preprocess, 23.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/178.jpg: 384x640 2 toothbrushs, 22.8ms\n",
      "Speed: 1.5ms preprocess, 22.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/179.jpg: 384x640 (no detections), 38.1ms\n",
      "Speed: 1.5ms preprocess, 38.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/180.jpg: 384x640 (no detections), 29.0ms\n",
      "Speed: 1.6ms preprocess, 29.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/181.jpg: 384x640 (no detections), 23.5ms\n",
      "Speed: 1.4ms preprocess, 23.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/182.jpg: 384x640 1 spoon, 2 carrots, 22.9ms\n",
      "Speed: 1.7ms preprocess, 22.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/183.jpg: 384x640 (no detections), 24.1ms\n",
      "Speed: 1.5ms preprocess, 24.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/184.jpg: 384x640 (no detections), 22.5ms\n",
      "Speed: 1.9ms preprocess, 22.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/185.jpg: 384x640 (no detections), 24.6ms\n",
      "Speed: 1.8ms preprocess, 24.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/186.jpg: 384x640 1 orange, 1 sink, 2 toothbrushs, 31.2ms\n",
      "Speed: 1.6ms preprocess, 31.2ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/187.jpg: 384x640 (no detections), 25.1ms\n",
      "Speed: 1.8ms preprocess, 25.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/188.jpg: 384x640 1 airplane, 27.3ms\n",
      "Speed: 1.6ms preprocess, 27.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/189.jpg: 384x640 (no detections), 26.0ms\n",
      "Speed: 1.6ms preprocess, 26.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/190.jpg: 384x640 1 toothbrush, 28.9ms\n",
      "Speed: 2.0ms preprocess, 28.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/191.jpg: 384x640 (no detections), 31.0ms\n",
      "Speed: 2.9ms preprocess, 31.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/192.jpg: 384x640 1 spoon, 1 toothbrush, 23.8ms\n",
      "Speed: 1.7ms preprocess, 23.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/193.jpg: 384x640 2 toothbrushs, 22.3ms\n",
      "Speed: 1.5ms preprocess, 22.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/194.jpg: 384x640 (no detections), 25.4ms\n",
      "Speed: 1.7ms preprocess, 25.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/195.jpg: 384x640 (no detections), 28.7ms\n",
      "Speed: 2.1ms preprocess, 28.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/196.jpg: 384x640 (no detections), 27.9ms\n",
      "Speed: 1.7ms preprocess, 27.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/197.jpg: 384x640 (no detections), 36.2ms\n",
      "Speed: 1.7ms preprocess, 36.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/198.jpg: 384x640 (no detections), 24.6ms\n",
      "Speed: 1.7ms preprocess, 24.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/199.jpg: 384x640 (no detections), 33.2ms\n",
      "Speed: 2.8ms preprocess, 33.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/200.jpg: 384x640 (no detections), 24.7ms\n",
      "Speed: 2.1ms preprocess, 24.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/201.jpg: 384x640 (no detections), 24.2ms\n",
      "Speed: 1.9ms preprocess, 24.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/202.jpg: 384x640 (no detections), 25.3ms\n",
      "Speed: 1.9ms preprocess, 25.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/203.jpg: 384x640 (no detections), 29.2ms\n",
      "Speed: 2.1ms preprocess, 29.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/204.jpg: 384x640 (no detections), 24.0ms\n",
      "Speed: 1.8ms preprocess, 24.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/205.jpg: 384x640 1 spoon, 23.2ms\n",
      "Speed: 1.8ms preprocess, 23.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/206.jpg: 384x640 (no detections), 23.7ms\n",
      "Speed: 1.5ms preprocess, 23.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/207.jpg: 384x640 1 spoon, 1 apple, 1 toothbrush, 33.3ms\n",
      "Speed: 1.6ms preprocess, 33.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/208.jpg: 384x640 (no detections), 23.3ms\n",
      "Speed: 1.7ms preprocess, 23.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/209.jpg: 384x640 (no detections), 23.9ms\n",
      "Speed: 1.6ms preprocess, 23.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/210.jpg: 384x640 (no detections), 23.0ms\n",
      "Speed: 1.5ms preprocess, 23.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/211.jpg: 384x640 (no detections), 23.7ms\n",
      "Speed: 1.5ms preprocess, 23.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/212.jpg: 384x640 (no detections), 23.6ms\n",
      "Speed: 1.7ms preprocess, 23.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/213.jpg: 384x640 (no detections), 35.2ms\n",
      "Speed: 1.5ms preprocess, 35.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/214.jpg: 384x640 (no detections), 23.9ms\n",
      "Speed: 1.8ms preprocess, 23.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/215.jpg: 384x640 1 airplane, 27.7ms\n",
      "Speed: 1.7ms preprocess, 27.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/216.jpg: 384x640 (no detections), 26.1ms\n",
      "Speed: 2.0ms preprocess, 26.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/217.jpg: 384x640 (no detections), 33.0ms\n",
      "Speed: 2.2ms preprocess, 33.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/218.jpg: 384x640 (no detections), 26.7ms\n",
      "Speed: 1.9ms preprocess, 26.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/219.jpg: 384x640 (no detections), 51.5ms\n",
      "Speed: 2.2ms preprocess, 51.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/220.jpg: 384x640 (no detections), 26.3ms\n",
      "Speed: 1.7ms preprocess, 26.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/221.jpg: 384x640 (no detections), 48.1ms\n",
      "Speed: 1.9ms preprocess, 48.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/222.jpg: 384x640 (no detections), 26.2ms\n",
      "Speed: 2.3ms preprocess, 26.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/223.jpg: 384x640 1 airplane, 30.3ms\n",
      "Speed: 2.2ms preprocess, 30.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/224.jpg: 384x640 (no detections), 45.1ms\n",
      "Speed: 1.9ms preprocess, 45.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/225.jpg: 384x640 (no detections), 24.3ms\n",
      "Speed: 1.7ms preprocess, 24.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/226.jpg: 384x640 (no detections), 22.4ms\n",
      "Speed: 1.5ms preprocess, 22.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/227.jpg: 384x640 (no detections), 21.9ms\n",
      "Speed: 1.5ms preprocess, 21.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/228.jpg: 384x640 (no detections), 22.9ms\n",
      "Speed: 1.5ms preprocess, 22.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/229.jpg: 384x640 (no detections), 23.7ms\n",
      "Speed: 1.5ms preprocess, 23.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/230.jpg: 384x640 (no detections), 22.9ms\n",
      "Speed: 1.6ms preprocess, 22.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/231.jpg: 384x640 (no detections), 22.3ms\n",
      "Speed: 1.5ms preprocess, 22.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/232.jpg: 384x640 1 bottle, 1 spoon, 4 carrots, 23.1ms\n",
      "Speed: 1.6ms preprocess, 23.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/233.jpg: 384x640 1 baseball bat, 2 spoons, 5 carrots, 24.9ms\n",
      "Speed: 1.6ms preprocess, 24.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/234.jpg: 384x640 1 orange, 28.3ms\n",
      "Speed: 1.8ms preprocess, 28.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/235.jpg: 384x640 (no detections), 23.4ms\n",
      "Speed: 1.3ms preprocess, 23.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/236.jpg: 384x640 (no detections), 25.7ms\n",
      "Speed: 1.6ms preprocess, 25.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/237.jpg: 384x640 (no detections), 23.6ms\n",
      "Speed: 1.7ms preprocess, 23.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/238.jpg: 384x640 1 spoon, 6 carrots, 27.8ms\n",
      "Speed: 1.6ms preprocess, 27.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/239.jpg: 384x640 (no detections), 24.4ms\n",
      "Speed: 1.6ms preprocess, 24.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/240.jpg: 384x640 1 spoon, 1 sink, 32.5ms\n",
      "Speed: 1.7ms preprocess, 32.5ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/241.jpg: 384x640 2 spoons, 1 carrot, 29.1ms\n",
      "Speed: 1.9ms preprocess, 29.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/242.jpg: 384x640 1 motorcycle, 33.8ms\n",
      "Speed: 1.6ms preprocess, 33.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/243.jpg: 384x640 1 spoon, 7 carrots, 25.4ms\n",
      "Speed: 1.5ms preprocess, 25.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/244.jpg: 384x640 2 bottles, 2 spoons, 1 carrot, 23.4ms\n",
      "Speed: 1.6ms preprocess, 23.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/245.jpg: 384x640 1 spoon, 1 sink, 1 toothbrush, 31.6ms\n",
      "Speed: 2.8ms preprocess, 31.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/246.jpg: 384x640 (no detections), 23.4ms\n",
      "Speed: 1.6ms preprocess, 23.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/247.jpg: 384x640 (no detections), 25.1ms\n",
      "Speed: 1.5ms preprocess, 25.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/248.jpg: 384x640 (no detections), 39.4ms\n",
      "Speed: 1.7ms preprocess, 39.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/249.jpg: 384x640 (no detections), 24.5ms\n",
      "Speed: 1.7ms preprocess, 24.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/250.jpg: 384x640 (no detections), 26.3ms\n",
      "Speed: 1.6ms preprocess, 26.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/251.jpg: 384x640 (no detections), 29.7ms\n",
      "Speed: 1.6ms preprocess, 29.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/252.jpg: 384x640 (no detections), 23.7ms\n",
      "Speed: 1.5ms preprocess, 23.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/253.jpg: 384x640 (no detections), 38.1ms\n",
      "Speed: 1.6ms preprocess, 38.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/254.jpg: 384x640 1 orange, 32.5ms\n",
      "Speed: 1.9ms preprocess, 32.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/255.jpg: 384x640 (no detections), 22.6ms\n",
      "Speed: 1.6ms preprocess, 22.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/256.jpg: 384x640 (no detections), 28.5ms\n",
      "Speed: 1.8ms preprocess, 28.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/257.jpg: 384x640 1 spoon, 27.4ms\n",
      "Speed: 1.6ms preprocess, 27.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/258.jpg: 384x640 (no detections), 24.4ms\n",
      "Speed: 1.5ms preprocess, 24.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/259.jpg: 384x640 (no detections), 24.9ms\n",
      "Speed: 1.4ms preprocess, 24.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/260.jpg: 384x640 (no detections), 37.4ms\n",
      "Speed: 2.0ms preprocess, 37.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/261.jpg: 384x640 (no detections), 39.1ms\n",
      "Speed: 1.7ms preprocess, 39.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/262.jpg: 384x640 1 spoon, 1 carrot, 24.4ms\n",
      "Speed: 1.6ms preprocess, 24.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/263.jpg: 384x640 1 spoon, 3 carrots, 25.9ms\n",
      "Speed: 1.6ms preprocess, 25.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/264.jpg: 384x640 (no detections), 27.0ms\n",
      "Speed: 2.3ms preprocess, 27.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/265.jpg: 384x640 (no detections), 23.3ms\n",
      "Speed: 1.5ms preprocess, 23.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/266.jpg: 384x640 (no detections), 30.7ms\n",
      "Speed: 1.8ms preprocess, 30.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/267.jpg: 384x640 (no detections), 25.4ms\n",
      "Speed: 1.9ms preprocess, 25.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/268.jpg: 384x640 (no detections), 23.7ms\n",
      "Speed: 1.5ms preprocess, 23.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/269.jpg: 384x640 (no detections), 33.5ms\n",
      "Speed: 2.5ms preprocess, 33.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/270.jpg: 384x640 (no detections), 22.5ms\n",
      "Speed: 1.5ms preprocess, 22.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/271.jpg: 384x640 (no detections), 26.6ms\n",
      "Speed: 1.5ms preprocess, 26.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/272.jpg: 384x640 6 carrots, 1 toothbrush, 22.5ms\n",
      "Speed: 1.6ms preprocess, 22.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/273.jpg: 384x640 (no detections), 22.5ms\n",
      "Speed: 1.5ms preprocess, 22.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/274.jpg: 384x640 1 orange, 1 sink, 1 toothbrush, 24.0ms\n",
      "Speed: 1.5ms preprocess, 24.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/275.jpg: 384x640 (no detections), 27.0ms\n",
      "Speed: 3.1ms preprocess, 27.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/276.jpg: 384x640 1 spoon, 1 toothbrush, 27.1ms\n",
      "Speed: 2.2ms preprocess, 27.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/277.jpg: 384x640 (no detections), 23.6ms\n",
      "Speed: 1.6ms preprocess, 23.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/278.jpg: 384x640 1 boat, 25.8ms\n",
      "Speed: 1.9ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/279.jpg: 384x640 (no detections), 21.8ms\n",
      "Speed: 1.5ms preprocess, 21.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/280.jpg: 384x640 (no detections), 27.7ms\n",
      "Speed: 1.6ms preprocess, 27.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/281.jpg: 384x640 (no detections), 21.9ms\n",
      "Speed: 1.5ms preprocess, 21.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/282.jpg: 384x640 (no detections), 21.6ms\n",
      "Speed: 1.5ms preprocess, 21.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/283.jpg: 384x640 (no detections), 25.5ms\n",
      "Speed: 1.6ms preprocess, 25.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/284.jpg: 384x640 (no detections), 42.8ms\n",
      "Speed: 2.3ms preprocess, 42.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/285.jpg: 384x640 (no detections), 22.4ms\n",
      "Speed: 1.6ms preprocess, 22.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/286.jpg: 384x640 (no detections), 23.3ms\n",
      "Speed: 1.5ms preprocess, 23.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/287.jpg: 384x640 (no detections), 34.1ms\n",
      "Speed: 2.6ms preprocess, 34.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/288.jpg: 384x640 (no detections), 23.0ms\n",
      "Speed: 1.6ms preprocess, 23.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/289.jpg: 384x640 (no detections), 36.3ms\n",
      "Speed: 2.0ms preprocess, 36.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/290.jpg: 384x640 (no detections), 33.7ms\n",
      "Speed: 1.5ms preprocess, 33.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/291.jpg: 384x640 (no detections), 30.4ms\n",
      "Speed: 2.2ms preprocess, 30.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/292.jpg: 384x640 (no detections), 31.9ms\n",
      "Speed: 2.3ms preprocess, 31.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/293.jpg: 384x640 (no detections), 38.8ms\n",
      "Speed: 1.9ms preprocess, 38.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/294.jpg: 384x640 (no detections), 37.2ms\n",
      "Speed: 2.5ms preprocess, 37.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/295.jpg: 384x640 (no detections), 29.5ms\n",
      "Speed: 2.0ms preprocess, 29.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/296.jpg: 384x640 1 sink, 1 toothbrush, 37.1ms\n",
      "Speed: 1.9ms preprocess, 37.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/297.jpg: 384x640 (no detections), 28.2ms\n",
      "Speed: 1.6ms preprocess, 28.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/298.jpg: 384x640 (no detections), 49.8ms\n",
      "Speed: 2.0ms preprocess, 49.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/2/smoke/right/299.jpg: 384x640 (no detections), 43.9ms\n",
      "Speed: 1.8ms preprocess, 43.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Propagating video frames: 100%|| 300/300 [00:17<00:00, 17.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask propagation completed in 17.08 seconds.\n",
      "Processing predicted masks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing video frames: 300it [00:00, 472.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 300 masks for evaluation.\n",
      "Masks saved to data/masks/yolo11x-seg/val/data-raw-SegSTRONGC_val-val-1-2-smoke-right.pkl\n",
      "Loading ground truth masks for evaluation...\n",
      "Loaded 300 ground truth masks.\n",
      "Calculating evaluation metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing domains: 100%|| 5/5 [04:16<00:00, 51.31s/it]\n",
      "Processing sub-directories:  33%|      | 1/3 [04:16<08:33, 256.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for metrics calculation: 1.48 seconds.\n",
      "Mean IoU for data/raw/SegSTRONGC_val/val/1/2/smoke/right: 0.1007\n",
      "Mean DSC for data/raw/SegSTRONGC_val/val/1/2/smoke/right: 0.1465\n",
      "Loading existing results file: data/results/yolo11x-seg/val.json\n",
      "Results saved to data/results/yolo11x-seg/val.json\n",
      "Processing video took 21.27 seconds.\n",
      "==================================================\n",
      "\n",
      "Results for data/raw/SegSTRONGC_val/val/1/2/smoke:\n",
      "  Left: IoU=0.0829, DSC=0.1301\n",
      "  Right: IoU=0.1007, DSC=0.1465\n",
      "  Overall: IoU=0.0918, DSC=0.1383\n",
      "\n",
      "------------------------------------------------------------\n",
      "Processing sub-directory: data/raw/SegSTRONGC_val/val/1/0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing domain: bg_change\n",
      "Processing left camera video...\n",
      "==================================================\n",
      "Processing video: data/raw/SegSTRONGC_val/val/1/0/bg_change/left\n",
      "Domain: bg_change, Split: val, Camera: left\n",
      "Initializing Yolo for video...\n",
      "Initialization took 0.16 seconds.\n",
      "Starting mask propagation...\n",
      "Total images in video: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/0.jpg: 384x640 2 knifes, 1 cake, 31.5ms\n",
      "Speed: 1.8ms preprocess, 31.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/1.jpg: 384x640 2 knifes, 1 cake, 33.0ms\n",
      "Speed: 2.2ms preprocess, 33.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/2.jpg: 384x640 2 knifes, 1 cake, 27.5ms\n",
      "Speed: 1.5ms preprocess, 27.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/3.jpg: 384x640 2 knifes, 1 cake, 25.4ms\n",
      "Speed: 1.8ms preprocess, 25.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/4.jpg: 384x640 2 knifes, 1 cake, 23.2ms\n",
      "Speed: 1.5ms preprocess, 23.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/5.jpg: 384x640 2 knifes, 1 hot dog, 1 cake, 25.8ms\n",
      "Speed: 1.6ms preprocess, 25.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/6.jpg: 384x640 2 knifes, 1 cake, 23.5ms\n",
      "Speed: 1.6ms preprocess, 23.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/7.jpg: 384x640 2 knifes, 1 cake, 25.4ms\n",
      "Speed: 1.5ms preprocess, 25.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/8.jpg: 384x640 2 knifes, 1 cake, 28.5ms\n",
      "Speed: 2.9ms preprocess, 28.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/9.jpg: 384x640 2 knifes, 1 cake, 36.3ms\n",
      "Speed: 1.7ms preprocess, 36.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/10.jpg: 384x640 2 knifes, 1 cake, 26.5ms\n",
      "Speed: 3.0ms preprocess, 26.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/11.jpg: 384x640 2 knifes, 1 cake, 30.2ms\n",
      "Speed: 1.7ms preprocess, 30.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/12.jpg: 384x640 2 knifes, 30.3ms\n",
      "Speed: 2.8ms preprocess, 30.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/13.jpg: 384x640 2 knifes, 1 cake, 42.5ms\n",
      "Speed: 1.8ms preprocess, 42.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/14.jpg: 384x640 2 knifes, 1 cake, 26.6ms\n",
      "Speed: 1.6ms preprocess, 26.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/15.jpg: 384x640 2 knifes, 1 cake, 27.7ms\n",
      "Speed: 1.6ms preprocess, 27.7ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/16.jpg: 384x640 2 knifes, 1 cake, 31.6ms\n",
      "Speed: 1.9ms preprocess, 31.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/17.jpg: 384x640 2 knifes, 1 cake, 30.4ms\n",
      "Speed: 1.7ms preprocess, 30.4ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/18.jpg: 384x640 2 knifes, 24.2ms\n",
      "Speed: 1.7ms preprocess, 24.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/19.jpg: 384x640 2 knifes, 1 cake, 31.5ms\n",
      "Speed: 1.6ms preprocess, 31.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/20.jpg: 384x640 2 knifes, 1 cake, 48.8ms\n",
      "Speed: 5.8ms preprocess, 48.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/21.jpg: 384x640 1 knife, 1 cake, 49.5ms\n",
      "Speed: 2.3ms preprocess, 49.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/22.jpg: 384x640 2 knifes, 41.9ms\n",
      "Speed: 1.6ms preprocess, 41.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/23.jpg: 384x640 2 knifes, 1 hot dog, 1 cake, 42.0ms\n",
      "Speed: 1.9ms preprocess, 42.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/24.jpg: 384x640 1 knife, 1 hot dog, 1 cake, 36.5ms\n",
      "Speed: 2.2ms preprocess, 36.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/25.jpg: 384x640 2 knifes, 1 cake, 53.2ms\n",
      "Speed: 1.9ms preprocess, 53.2ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/26.jpg: 384x640 2 knifes, 1 hot dog, 1 cake, 35.7ms\n",
      "Speed: 2.2ms preprocess, 35.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/27.jpg: 384x640 2 knifes, 1 cake, 46.3ms\n",
      "Speed: 2.0ms preprocess, 46.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/28.jpg: 384x640 2 knifes, 44.8ms\n",
      "Speed: 2.4ms preprocess, 44.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/29.jpg: 384x640 2 knifes, 1 cake, 49.8ms\n",
      "Speed: 2.2ms preprocess, 49.8ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/30.jpg: 384x640 2 knifes, 1 cake, 41.0ms\n",
      "Speed: 2.2ms preprocess, 41.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/31.jpg: 384x640 2 knifes, 1 cake, 29.2ms\n",
      "Speed: 1.9ms preprocess, 29.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/32.jpg: 384x640 2 knifes, 1 cake, 42.7ms\n",
      "Speed: 2.7ms preprocess, 42.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/33.jpg: 384x640 2 knifes, 1 cake, 44.6ms\n",
      "Speed: 2.0ms preprocess, 44.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/34.jpg: 384x640 2 knifes, 28.3ms\n",
      "Speed: 1.7ms preprocess, 28.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/35.jpg: 384x640 2 knifes, 1 cake, 28.3ms\n",
      "Speed: 1.9ms preprocess, 28.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/36.jpg: 384x640 2 knifes, 1 cake, 32.6ms\n",
      "Speed: 2.8ms preprocess, 32.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/37.jpg: 384x640 2 knifes, 1 cake, 29.4ms\n",
      "Speed: 2.0ms preprocess, 29.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/38.jpg: 384x640 2 knifes, 1 cake, 48.4ms\n",
      "Speed: 2.2ms preprocess, 48.4ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/39.jpg: 384x640 2 knifes, 1 cake, 30.6ms\n",
      "Speed: 2.0ms preprocess, 30.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/40.jpg: 384x640 1 knife, 36.8ms\n",
      "Speed: 4.0ms preprocess, 36.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/41.jpg: 384x640 1 knife, 1 cake, 38.3ms\n",
      "Speed: 3.0ms preprocess, 38.3ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/42.jpg: 384x640 1 knife, 1 cake, 31.1ms\n",
      "Speed: 2.0ms preprocess, 31.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/43.jpg: 384x640 2 knifes, 1 cake, 54.3ms\n",
      "Speed: 2.1ms preprocess, 54.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/44.jpg: 384x640 2 knifes, 1 cake, 30.9ms\n",
      "Speed: 2.0ms preprocess, 30.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/45.jpg: 384x640 1 knife, 36.6ms\n",
      "Speed: 1.9ms preprocess, 36.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/46.jpg: 384x640 1 knife, 1 hot dog, 1 cake, 46.3ms\n",
      "Speed: 1.9ms preprocess, 46.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/47.jpg: 384x640 1 knife, 1 cake, 46.2ms\n",
      "Speed: 1.8ms preprocess, 46.2ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/48.jpg: 384x640 2 knifes, 35.4ms\n",
      "Speed: 3.3ms preprocess, 35.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/49.jpg: 384x640 2 knifes, 1 cake, 54.4ms\n",
      "Speed: 2.2ms preprocess, 54.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/50.jpg: 384x640 2 knifes, 1 cake, 27.6ms\n",
      "Speed: 1.9ms preprocess, 27.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/51.jpg: 384x640 2 knifes, 1 cake, 36.5ms\n",
      "Speed: 2.6ms preprocess, 36.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/52.jpg: 384x640 2 knifes, 1 cake, 32.2ms\n",
      "Speed: 1.9ms preprocess, 32.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/53.jpg: 384x640 2 knifes, 1 cake, 37.5ms\n",
      "Speed: 1.8ms preprocess, 37.5ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/54.jpg: 384x640 2 knifes, 1 cake, 33.2ms\n",
      "Speed: 2.3ms preprocess, 33.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/55.jpg: 384x640 2 knifes, 1 cake, 30.8ms\n",
      "Speed: 1.8ms preprocess, 30.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/56.jpg: 384x640 2 knifes, 1 cake, 31.7ms\n",
      "Speed: 1.7ms preprocess, 31.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/57.jpg: 384x640 2 knifes, 1 cake, 32.2ms\n",
      "Speed: 1.8ms preprocess, 32.2ms inference, 9.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/58.jpg: 384x640 2 knifes, 1 hot dog, 29.6ms\n",
      "Speed: 1.8ms preprocess, 29.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/59.jpg: 384x640 1 knife, 1 hot dog, 1 cake, 33.4ms\n",
      "Speed: 2.1ms preprocess, 33.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/60.jpg: 384x640 2 knifes, 1 apple, 1 hot dog, 1 cake, 42.7ms\n",
      "Speed: 2.5ms preprocess, 42.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/61.jpg: 384x640 2 knifes, 1 cake, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/62.jpg: 384x640 1 knife, 1 cake, 36.2ms\n",
      "Speed: 2.1ms preprocess, 36.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/63.jpg: 384x640 2 knifes, 1 cake, 36.7ms\n",
      "Speed: 2.1ms preprocess, 36.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/64.jpg: 384x640 2 knifes, 1 hot dog, 1 cake, 45.0ms\n",
      "Speed: 2.0ms preprocess, 45.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/65.jpg: 384x640 1 knife, 1 cake, 41.1ms\n",
      "Speed: 2.1ms preprocess, 41.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/66.jpg: 384x640 2 knifes, 1 cake, 36.7ms\n",
      "Speed: 2.2ms preprocess, 36.7ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/67.jpg: 384x640 2 knifes, 1 cake, 66.5ms\n",
      "Speed: 2.0ms preprocess, 66.5ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/68.jpg: 384x640 2 knifes, 1 hot dog, 1 cake, 30.9ms\n",
      "Speed: 1.8ms preprocess, 30.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/69.jpg: 384x640 2 knifes, 1 hot dog, 1 cake, 44.0ms\n",
      "Speed: 2.1ms preprocess, 44.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/70.jpg: 384x640 2 knifes, 1 cake, 46.3ms\n",
      "Speed: 1.9ms preprocess, 46.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/71.jpg: 384x640 2 knifes, 1 hot dog, 1 cake, 84.5ms\n",
      "Speed: 2.1ms preprocess, 84.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/72.jpg: 384x640 2 knifes, 1 cake, 53.9ms\n",
      "Speed: 2.0ms preprocess, 53.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/73.jpg: 384x640 2 knifes, 1 cake, 62.9ms\n",
      "Speed: 2.2ms preprocess, 62.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/74.jpg: 384x640 2 knifes, 1 cake, 37.0ms\n",
      "Speed: 1.9ms preprocess, 37.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/75.jpg: 384x640 1 bottle, 1 knife, 1 cake, 49.6ms\n",
      "Speed: 2.5ms preprocess, 49.6ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/76.jpg: 384x640 2 knifes, 1 cake, 74.0ms\n",
      "Speed: 2.1ms preprocess, 74.0ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/77.jpg: 384x640 2 knifes, 1 hot dog, 1 cake, 71.1ms\n",
      "Speed: 2.3ms preprocess, 71.1ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/78.jpg: 384x640 2 knifes, 1 cake, 40.8ms\n",
      "Speed: 2.4ms preprocess, 40.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/79.jpg: 384x640 2 knifes, 1 cake, 46.3ms\n",
      "Speed: 2.1ms preprocess, 46.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/80.jpg: 384x640 1 knife, 1 cake, 36.2ms\n",
      "Speed: 2.0ms preprocess, 36.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/81.jpg: 384x640 2 knifes, 1 cake, 43.4ms\n",
      "Speed: 2.7ms preprocess, 43.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/82.jpg: 384x640 2 knifes, 1 cake, 34.7ms\n",
      "Speed: 1.9ms preprocess, 34.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/83.jpg: 384x640 2 knifes, 1 cake, 56.3ms\n",
      "Speed: 2.1ms preprocess, 56.3ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/84.jpg: 384x640 1 knife, 1 cake, 39.8ms\n",
      "Speed: 2.1ms preprocess, 39.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/85.jpg: 384x640 1 knife, 1 hot dog, 1 cake, 33.6ms\n",
      "Speed: 2.4ms preprocess, 33.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/86.jpg: 384x640 1 knife, 1 cake, 28.6ms\n",
      "Speed: 1.8ms preprocess, 28.6ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/87.jpg: 384x640 2 knifes, 1 cake, 33.1ms\n",
      "Speed: 1.9ms preprocess, 33.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/88.jpg: 384x640 1 knife, 1 cake, 28.9ms\n",
      "Speed: 2.0ms preprocess, 28.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/89.jpg: 384x640 1 knife, 32.3ms\n",
      "Speed: 1.8ms preprocess, 32.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/90.jpg: 384x640 1 knife, 1 cake, 41.4ms\n",
      "Speed: 1.6ms preprocess, 41.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/91.jpg: 384x640 2 knifes, 1 cake, 38.2ms\n",
      "Speed: 2.0ms preprocess, 38.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/92.jpg: 384x640 1 knife, 34.6ms\n",
      "Speed: 1.7ms preprocess, 34.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/93.jpg: 384x640 2 knifes, 1 cake, 30.9ms\n",
      "Speed: 1.7ms preprocess, 30.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/94.jpg: 384x640 1 knife, 1 hot dog, 35.6ms\n",
      "Speed: 2.7ms preprocess, 35.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/95.jpg: 384x640 2 knifes, 1 cake, 29.0ms\n",
      "Speed: 1.7ms preprocess, 29.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/96.jpg: 384x640 1 knife, 1 cake, 29.8ms\n",
      "Speed: 1.7ms preprocess, 29.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/97.jpg: 384x640 1 knife, 1 cake, 36.6ms\n",
      "Speed: 1.8ms preprocess, 36.6ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/98.jpg: 384x640 1 fork, 1 knife, 1 cake, 40.3ms\n",
      "Speed: 1.9ms preprocess, 40.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/99.jpg: 384x640 1 fork, 1 knife, 1 cake, 40.6ms\n",
      "Speed: 1.8ms preprocess, 40.6ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/100.jpg: 384x640 1 fork, 1 knife, 1 cake, 34.9ms\n",
      "Speed: 1.9ms preprocess, 34.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/101.jpg: 384x640 1 knife, 30.7ms\n",
      "Speed: 1.8ms preprocess, 30.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/102.jpg: 384x640 1 knife, 1 cake, 42.7ms\n",
      "Speed: 1.8ms preprocess, 42.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/103.jpg: 384x640 1 knife, 1 cake, 28.8ms\n",
      "Speed: 2.0ms preprocess, 28.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/104.jpg: 384x640 1 knife, 1 cake, 35.4ms\n",
      "Speed: 2.0ms preprocess, 35.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/105.jpg: 384x640 1 knife, 1 cake, 40.0ms\n",
      "Speed: 1.8ms preprocess, 40.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/106.jpg: 384x640 2 knifes, 1 cake, 34.0ms\n",
      "Speed: 2.0ms preprocess, 34.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/107.jpg: 384x640 2 knifes, 1 cake, 35.3ms\n",
      "Speed: 2.1ms preprocess, 35.3ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/108.jpg: 384x640 1 knife, 1 cake, 36.2ms\n",
      "Speed: 1.7ms preprocess, 36.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/109.jpg: 384x640 2 knifes, 1 cake, 44.1ms\n",
      "Speed: 1.9ms preprocess, 44.1ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/110.jpg: 384x640 1 knife, 27.4ms\n",
      "Speed: 1.8ms preprocess, 27.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/111.jpg: 384x640 1 knife, 1 cake, 37.5ms\n",
      "Speed: 1.8ms preprocess, 37.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/112.jpg: 384x640 1 knife, 1 cake, 37.5ms\n",
      "Speed: 1.6ms preprocess, 37.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/113.jpg: 384x640 1 knife, 1 cake, 39.7ms\n",
      "Speed: 2.9ms preprocess, 39.7ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/114.jpg: 384x640 1 bottle, 1 knife, 35.1ms\n",
      "Speed: 2.3ms preprocess, 35.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/115.jpg: 384x640 1 knife, 53.2ms\n",
      "Speed: 2.0ms preprocess, 53.2ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/116.jpg: 384x640 1 knife, 1 hot dog, 33.3ms\n",
      "Speed: 2.8ms preprocess, 33.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/117.jpg: 384x640 1 knife, 36.3ms\n",
      "Speed: 1.8ms preprocess, 36.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/118.jpg: 384x640 2 knifes, 1 cake, 40.9ms\n",
      "Speed: 1.9ms preprocess, 40.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/119.jpg: 384x640 2 knifes, 1 hot dog, 38.1ms\n",
      "Speed: 1.8ms preprocess, 38.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/120.jpg: 384x640 2 knifes, 1 cake, 34.7ms\n",
      "Speed: 2.2ms preprocess, 34.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/121.jpg: 384x640 2 knifes, 1 cake, 50.7ms\n",
      "Speed: 2.1ms preprocess, 50.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/122.jpg: 384x640 2 knifes, 1 hot dog, 39.8ms\n",
      "Speed: 2.0ms preprocess, 39.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/123.jpg: 384x640 1 bottle, 1 knife, 1 cake, 48.7ms\n",
      "Speed: 1.9ms preprocess, 48.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/124.jpg: 384x640 2 knifes, 45.4ms\n",
      "Speed: 1.8ms preprocess, 45.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/125.jpg: 384x640 1 knife, 1 cake, 41.8ms\n",
      "Speed: 1.8ms preprocess, 41.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/126.jpg: 384x640 1 knife, 1 cake, 28.9ms\n",
      "Speed: 1.9ms preprocess, 28.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/127.jpg: 384x640 1 bottle, 1 knife, 1 cake, 32.3ms\n",
      "Speed: 1.9ms preprocess, 32.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/128.jpg: 384x640 1 knife, 1 cake, 30.3ms\n",
      "Speed: 1.8ms preprocess, 30.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/129.jpg: 384x640 1 bottle, 1 cake, 29.0ms\n",
      "Speed: 1.7ms preprocess, 29.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/130.jpg: 384x640 1 bottle, 1 cake, 39.9ms\n",
      "Speed: 1.9ms preprocess, 39.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/131.jpg: 384x640 1 knife, 1 cake, 28.9ms\n",
      "Speed: 1.7ms preprocess, 28.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/132.jpg: 384x640 1 bottle, 1 knife, 1 hot dog, 1 cake, 34.1ms\n",
      "Speed: 2.3ms preprocess, 34.1ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/133.jpg: 384x640 1 bottle, 1 knife, 1 cake, 32.4ms\n",
      "Speed: 2.2ms preprocess, 32.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/134.jpg: 384x640 1 bottle, 1 knife, 32.7ms\n",
      "Speed: 2.0ms preprocess, 32.7ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/135.jpg: 384x640 2 knifes, 39.7ms\n",
      "Speed: 1.8ms preprocess, 39.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/136.jpg: 384x640 1 bottle, 1 knife, 37.3ms\n",
      "Speed: 3.0ms preprocess, 37.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/137.jpg: 384x640 1 bottle, 1 knife, 40.6ms\n",
      "Speed: 1.8ms preprocess, 40.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/138.jpg: 384x640 1 knife, 30.8ms\n",
      "Speed: 1.6ms preprocess, 30.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/139.jpg: 384x640 1 bottle, 1 knife, 37.8ms\n",
      "Speed: 2.0ms preprocess, 37.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/140.jpg: 384x640 2 knifes, 34.0ms\n",
      "Speed: 2.0ms preprocess, 34.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/141.jpg: 384x640 1 bottle, 1 knife, 39.3ms\n",
      "Speed: 1.8ms preprocess, 39.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/142.jpg: 384x640 1 knife, 42.3ms\n",
      "Speed: 1.6ms preprocess, 42.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/143.jpg: 384x640 1 bottle, 1 knife, 42.5ms\n",
      "Speed: 1.9ms preprocess, 42.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/144.jpg: 384x640 1 bottle, 1 knife, 40.0ms\n",
      "Speed: 1.9ms preprocess, 40.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/145.jpg: 384x640 1 knife, 1 cake, 39.4ms\n",
      "Speed: 1.7ms preprocess, 39.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/146.jpg: 384x640 1 knife, 1 cake, 38.9ms\n",
      "Speed: 1.8ms preprocess, 38.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/147.jpg: 384x640 1 knife, 1 spoon, 1 cake, 41.6ms\n",
      "Speed: 2.4ms preprocess, 41.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/148.jpg: 384x640 1 knife, 1 cake, 27.8ms\n",
      "Speed: 1.7ms preprocess, 27.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/149.jpg: 384x640 1 bottle, 1 knife, 1 cake, 30.0ms\n",
      "Speed: 2.1ms preprocess, 30.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/150.jpg: 384x640 2 knifes, 32.3ms\n",
      "Speed: 1.7ms preprocess, 32.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/151.jpg: 384x640 2 knifes, 46.1ms\n",
      "Speed: 1.8ms preprocess, 46.1ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/152.jpg: 384x640 2 knifes, 1 cake, 30.2ms\n",
      "Speed: 1.8ms preprocess, 30.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/153.jpg: 384x640 2 knifes, 1 cake, 45.0ms\n",
      "Speed: 2.4ms preprocess, 45.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/154.jpg: 384x640 2 knifes, 1 cake, 28.9ms\n",
      "Speed: 1.6ms preprocess, 28.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/155.jpg: 384x640 2 knifes, 46.2ms\n",
      "Speed: 2.3ms preprocess, 46.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/156.jpg: 384x640 2 knifes, 1 cake, 27.3ms\n",
      "Speed: 2.2ms preprocess, 27.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/157.jpg: 384x640 1 knife, 1 cake, 37.5ms\n",
      "Speed: 1.8ms preprocess, 37.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/158.jpg: 384x640 2 knifes, 1 cake, 26.5ms\n",
      "Speed: 1.7ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/159.jpg: 384x640 2 knifes, 1 cake, 33.5ms\n",
      "Speed: 1.7ms preprocess, 33.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/160.jpg: 384x640 2 knifes, 1 cake, 41.3ms\n",
      "Speed: 2.0ms preprocess, 41.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/161.jpg: 384x640 1 knife, 27.8ms\n",
      "Speed: 1.7ms preprocess, 27.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/162.jpg: 384x640 2 knifes, 29.1ms\n",
      "Speed: 1.9ms preprocess, 29.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/163.jpg: 384x640 1 fork, 1 knife, 1 spoon, 42.0ms\n",
      "Speed: 3.0ms preprocess, 42.0ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/164.jpg: 384x640 1 fork, 1 knife, 1 hot dog, 1 cake, 40.8ms\n",
      "Speed: 2.2ms preprocess, 40.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/165.jpg: 384x640 1 fork, 1 knife, 1 cake, 40.0ms\n",
      "Speed: 2.3ms preprocess, 40.0ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/166.jpg: 384x640 1 knife, 1 spoon, 1 cake, 30.8ms\n",
      "Speed: 1.9ms preprocess, 30.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/167.jpg: 384x640 2 knifes, 1 cake, 31.1ms\n",
      "Speed: 2.0ms preprocess, 31.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/168.jpg: 384x640 1 knife, 1 cake, 35.6ms\n",
      "Speed: 2.5ms preprocess, 35.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/169.jpg: 384x640 1 knife, 1 cake, 32.8ms\n",
      "Speed: 1.8ms preprocess, 32.8ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/170.jpg: 384x640 1 knife, 1 cake, 31.9ms\n",
      "Speed: 1.8ms preprocess, 31.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/171.jpg: 384x640 1 fork, 1 knife, 1 cake, 47.2ms\n",
      "Speed: 1.8ms preprocess, 47.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/172.jpg: 384x640 2 knifes, 1 cake, 28.3ms\n",
      "Speed: 1.8ms preprocess, 28.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/173.jpg: 384x640 1 knife, 31.1ms\n",
      "Speed: 1.8ms preprocess, 31.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/174.jpg: 384x640 1 knife, 27.9ms\n",
      "Speed: 1.7ms preprocess, 27.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/175.jpg: 384x640 2 knifes, 31.2ms\n",
      "Speed: 2.1ms preprocess, 31.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/176.jpg: 384x640 2 knifes, 1 cake, 31.8ms\n",
      "Speed: 2.5ms preprocess, 31.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/177.jpg: 384x640 1 knife, 29.5ms\n",
      "Speed: 1.9ms preprocess, 29.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/178.jpg: 384x640 2 knifes, 1 cake, 39.0ms\n",
      "Speed: 3.0ms preprocess, 39.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/179.jpg: 384x640 2 knifes, 1 cake, 33.7ms\n",
      "Speed: 2.0ms preprocess, 33.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/180.jpg: 384x640 2 knifes, 47.9ms\n",
      "Speed: 2.0ms preprocess, 47.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/181.jpg: 384x640 2 knifes, 32.1ms\n",
      "Speed: 1.8ms preprocess, 32.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/182.jpg: 384x640 2 knifes, 1 pizza, 33.5ms\n",
      "Speed: 1.7ms preprocess, 33.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/183.jpg: 384x640 2 knifes, 34.8ms\n",
      "Speed: 1.8ms preprocess, 34.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/184.jpg: 384x640 2 knifes, 28.6ms\n",
      "Speed: 2.4ms preprocess, 28.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/185.jpg: 384x640 2 knifes, 1 cake, 30.3ms\n",
      "Speed: 1.8ms preprocess, 30.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/186.jpg: 384x640 2 knifes, 28.7ms\n",
      "Speed: 1.6ms preprocess, 28.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/187.jpg: 384x640 2 knifes, 32.2ms\n",
      "Speed: 2.0ms preprocess, 32.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/188.jpg: 384x640 2 knifes, 28.4ms\n",
      "Speed: 2.6ms preprocess, 28.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/189.jpg: 384x640 2 knifes, 1 cake, 38.6ms\n",
      "Speed: 2.0ms preprocess, 38.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/190.jpg: 384x640 2 knifes, 28.5ms\n",
      "Speed: 1.8ms preprocess, 28.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/191.jpg: 384x640 2 knifes, 1 hot dog, 35.3ms\n",
      "Speed: 1.7ms preprocess, 35.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/192.jpg: 384x640 1 knife, 1 hot dog, 1 cake, 42.7ms\n",
      "Speed: 2.5ms preprocess, 42.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/193.jpg: 384x640 1 knife, 1 cake, 30.5ms\n",
      "Speed: 1.7ms preprocess, 30.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/194.jpg: 384x640 1 knife, 40.5ms\n",
      "Speed: 2.1ms preprocess, 40.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/195.jpg: 384x640 2 knifes, 27.7ms\n",
      "Speed: 1.7ms preprocess, 27.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/196.jpg: 384x640 2 knifes, 34.1ms\n",
      "Speed: 2.7ms preprocess, 34.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/197.jpg: 384x640 2 knifes, 1 hot dog, 28.7ms\n",
      "Speed: 2.0ms preprocess, 28.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/198.jpg: 384x640 2 knifes, 32.9ms\n",
      "Speed: 1.8ms preprocess, 32.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/199.jpg: 384x640 2 knifes, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/200.jpg: 384x640 1 knife, 1 carrot, 30.3ms\n",
      "Speed: 1.7ms preprocess, 30.3ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/201.jpg: 384x640 1 knife, 1 carrot, 31.2ms\n",
      "Speed: 1.7ms preprocess, 31.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/202.jpg: 384x640 1 knife, 27.3ms\n",
      "Speed: 2.4ms preprocess, 27.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/203.jpg: 384x640 2 knifes, 1 cake, 46.5ms\n",
      "Speed: 2.0ms preprocess, 46.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/204.jpg: 384x640 2 knifes, 35.8ms\n",
      "Speed: 2.5ms preprocess, 35.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/205.jpg: 384x640 2 knifes, 27.9ms\n",
      "Speed: 1.7ms preprocess, 27.9ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/206.jpg: 384x640 2 knifes, 1 carrot, 1 cake, 29.2ms\n",
      "Speed: 1.6ms preprocess, 29.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/207.jpg: 384x640 2 knifes, 1 carrot, 1 hot dog, 34.6ms\n",
      "Speed: 2.2ms preprocess, 34.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/208.jpg: 384x640 1 knife, 1 carrot, 1 hot dog, 48.7ms\n",
      "Speed: 1.7ms preprocess, 48.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/209.jpg: 384x640 2 knifes, 30.8ms\n",
      "Speed: 2.0ms preprocess, 30.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/210.jpg: 384x640 1 knife, 2 carrots, 1 hot dog, 30.7ms\n",
      "Speed: 1.8ms preprocess, 30.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/211.jpg: 384x640 1 knife, 1 carrot, 1 hot dog, 41.2ms\n",
      "Speed: 1.7ms preprocess, 41.2ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/212.jpg: 384x640 1 knife, 1 carrot, 1 hot dog, 32.4ms\n",
      "Speed: 2.2ms preprocess, 32.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/213.jpg: 384x640 1 knife, 1 carrot, 1 hot dog, 38.4ms\n",
      "Speed: 1.6ms preprocess, 38.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/214.jpg: 384x640 2 knifes, 1 carrot, 27.8ms\n",
      "Speed: 1.6ms preprocess, 27.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/215.jpg: 384x640 1 carrot, 1 hot dog, 37.0ms\n",
      "Speed: 1.8ms preprocess, 37.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/216.jpg: 384x640 1 knife, 2 carrots, 1 hot dog, 27.4ms\n",
      "Speed: 1.7ms preprocess, 27.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/217.jpg: 384x640 1 knife, 2 carrots, 1 hot dog, 37.1ms\n",
      "Speed: 1.8ms preprocess, 37.1ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/218.jpg: 384x640 2 knifes, 1 carrot, 1 hot dog, 49.9ms\n",
      "Speed: 2.2ms preprocess, 49.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/219.jpg: 384x640 2 knifes, 31.5ms\n",
      "Speed: 2.0ms preprocess, 31.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/220.jpg: 384x640 1 knife, 28.6ms\n",
      "Speed: 1.7ms preprocess, 28.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/221.jpg: 384x640 2 knifes, 33.9ms\n",
      "Speed: 2.4ms preprocess, 33.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/222.jpg: 384x640 2 knifes, 27.9ms\n",
      "Speed: 1.8ms preprocess, 27.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/223.jpg: 384x640 2 knifes, 1 cake, 29.1ms\n",
      "Speed: 1.8ms preprocess, 29.1ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/224.jpg: 384x640 2 knifes, 28.1ms\n",
      "Speed: 1.9ms preprocess, 28.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/225.jpg: 384x640 2 knifes, 1 cake, 37.1ms\n",
      "Speed: 1.9ms preprocess, 37.1ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/226.jpg: 384x640 2 knifes, 1 cake, 28.7ms\n",
      "Speed: 2.7ms preprocess, 28.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/227.jpg: 384x640 2 knifes, 1 cake, 36.7ms\n",
      "Speed: 1.7ms preprocess, 36.7ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/228.jpg: 384x640 2 knifes, 1 cake, 32.2ms\n",
      "Speed: 1.9ms preprocess, 32.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/229.jpg: 384x640 2 knifes, 1 cake, 46.4ms\n",
      "Speed: 2.0ms preprocess, 46.4ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/230.jpg: 384x640 1 knife, 1 cake, 34.2ms\n",
      "Speed: 2.0ms preprocess, 34.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/231.jpg: 384x640 2 knifes, 1 cake, 40.7ms\n",
      "Speed: 2.2ms preprocess, 40.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/232.jpg: 384x640 2 knifes, 27.7ms\n",
      "Speed: 1.9ms preprocess, 27.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/233.jpg: 384x640 1 knife, 1 cake, 33.7ms\n",
      "Speed: 1.8ms preprocess, 33.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/234.jpg: 384x640 1 knife, 1 cake, 30.5ms\n",
      "Speed: 2.1ms preprocess, 30.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/235.jpg: 384x640 2 knifes, 1 cake, 35.4ms\n",
      "Speed: 1.8ms preprocess, 35.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/236.jpg: 384x640 2 knifes, 1 cake, 27.7ms\n",
      "Speed: 1.5ms preprocess, 27.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/237.jpg: 384x640 1 knife, 1 hot dog, 1 cake, 31.3ms\n",
      "Speed: 1.8ms preprocess, 31.3ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/238.jpg: 384x640 2 knifes, 1 cake, 37.2ms\n",
      "Speed: 2.0ms preprocess, 37.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/239.jpg: 384x640 2 knifes, 1 cake, 28.4ms\n",
      "Speed: 1.6ms preprocess, 28.4ms inference, 8.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/240.jpg: 384x640 2 knifes, 1 hot dog, 1 cake, 28.9ms\n",
      "Speed: 1.9ms preprocess, 28.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/241.jpg: 384x640 2 knifes, 1 cake, 50.4ms\n",
      "Speed: 2.0ms preprocess, 50.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/242.jpg: 384x640 2 knifes, 1 cake, 28.3ms\n",
      "Speed: 1.8ms preprocess, 28.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/243.jpg: 384x640 2 knifes, 1 cake, 35.0ms\n",
      "Speed: 1.9ms preprocess, 35.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/244.jpg: 384x640 2 knifes, 1 cake, 27.7ms\n",
      "Speed: 1.8ms preprocess, 27.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/245.jpg: 384x640 2 knifes, 1 cake, 47.0ms\n",
      "Speed: 1.8ms preprocess, 47.0ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/246.jpg: 384x640 2 knifes, 1 cake, 36.7ms\n",
      "Speed: 2.0ms preprocess, 36.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/247.jpg: 384x640 2 knifes, 1 cake, 29.3ms\n",
      "Speed: 2.0ms preprocess, 29.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/248.jpg: 384x640 2 knifes, 27.9ms\n",
      "Speed: 3.3ms preprocess, 27.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/249.jpg: 384x640 2 knifes, 1 cake, 35.7ms\n",
      "Speed: 1.7ms preprocess, 35.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/250.jpg: 384x640 2 knifes, 33.6ms\n",
      "Speed: 2.9ms preprocess, 33.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/251.jpg: 384x640 2 knifes, 37.1ms\n",
      "Speed: 2.9ms preprocess, 37.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/252.jpg: 384x640 2 knifes, 1 cake, 44.5ms\n",
      "Speed: 1.9ms preprocess, 44.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/253.jpg: 384x640 2 knifes, 1 cake, 35.5ms\n",
      "Speed: 1.7ms preprocess, 35.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/254.jpg: 384x640 2 knifes, 27.7ms\n",
      "Speed: 1.9ms preprocess, 27.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/255.jpg: 384x640 2 knifes, 1 cake, 45.1ms\n",
      "Speed: 2.1ms preprocess, 45.1ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/256.jpg: 384x640 2 knifes, 1 cake, 29.6ms\n",
      "Speed: 1.8ms preprocess, 29.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/257.jpg: 384x640 2 knifes, 1 cake, 35.8ms\n",
      "Speed: 1.9ms preprocess, 35.8ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/258.jpg: 384x640 2 knifes, 27.1ms\n",
      "Speed: 1.7ms preprocess, 27.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/259.jpg: 384x640 2 knifes, 1 cake, 55.3ms\n",
      "Speed: 1.8ms preprocess, 55.3ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/260.jpg: 384x640 2 knifes, 1 cake, 34.8ms\n",
      "Speed: 1.8ms preprocess, 34.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/261.jpg: 384x640 2 knifes, 1 cake, 32.6ms\n",
      "Speed: 2.7ms preprocess, 32.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/262.jpg: 384x640 2 knifes, 1 cake, 28.3ms\n",
      "Speed: 2.1ms preprocess, 28.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/263.jpg: 384x640 2 knifes, 1 cake, 37.7ms\n",
      "Speed: 1.6ms preprocess, 37.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/264.jpg: 384x640 2 knifes, 1 cake, 45.1ms\n",
      "Speed: 1.6ms preprocess, 45.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/265.jpg: 384x640 2 knifes, 30.2ms\n",
      "Speed: 1.9ms preprocess, 30.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/266.jpg: 384x640 2 knifes, 30.1ms\n",
      "Speed: 2.0ms preprocess, 30.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/267.jpg: 384x640 2 knifes, 47.0ms\n",
      "Speed: 2.0ms preprocess, 47.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/268.jpg: 384x640 2 knifes, 1 cake, 33.7ms\n",
      "Speed: 1.8ms preprocess, 33.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/269.jpg: 384x640 2 knifes, 1 cake, 40.8ms\n",
      "Speed: 2.6ms preprocess, 40.8ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/270.jpg: 384x640 2 knifes, 1 cake, 28.7ms\n",
      "Speed: 1.7ms preprocess, 28.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/271.jpg: 384x640 2 knifes, 1 cake, 43.9ms\n",
      "Speed: 1.7ms preprocess, 43.9ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/272.jpg: 384x640 2 knifes, 1 hot dog, 1 cake, 31.3ms\n",
      "Speed: 1.4ms preprocess, 31.3ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/273.jpg: 384x640 2 knifes, 1 cake, 34.1ms\n",
      "Speed: 1.8ms preprocess, 34.1ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/274.jpg: 384x640 2 knifes, 1 hot dog, 1 cake, 27.8ms\n",
      "Speed: 1.8ms preprocess, 27.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/275.jpg: 384x640 2 knifes, 1 cake, 38.9ms\n",
      "Speed: 2.0ms preprocess, 38.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/276.jpg: 384x640 2 knifes, 42.5ms\n",
      "Speed: 1.8ms preprocess, 42.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/277.jpg: 384x640 2 knifes, 27.8ms\n",
      "Speed: 1.7ms preprocess, 27.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/278.jpg: 384x640 2 knifes, 1 cake, 28.2ms\n",
      "Speed: 1.6ms preprocess, 28.2ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/279.jpg: 384x640 2 knifes, 1 cake, 42.4ms\n",
      "Speed: 1.7ms preprocess, 42.4ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/280.jpg: 384x640 1 knife, 39.6ms\n",
      "Speed: 2.0ms preprocess, 39.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/281.jpg: 384x640 2 knifes, 39.5ms\n",
      "Speed: 2.2ms preprocess, 39.5ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/282.jpg: 384x640 2 knifes, 1 carrot, 29.4ms\n",
      "Speed: 2.5ms preprocess, 29.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/283.jpg: 384x640 2 knifes, 46.6ms\n",
      "Speed: 1.7ms preprocess, 46.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/284.jpg: 384x640 2 knifes, 1 cake, 31.2ms\n",
      "Speed: 1.7ms preprocess, 31.2ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/285.jpg: 384x640 2 knifes, 1 cake, 37.8ms\n",
      "Speed: 1.7ms preprocess, 37.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/286.jpg: 384x640 2 knifes, 1 cake, 28.2ms\n",
      "Speed: 2.1ms preprocess, 28.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/287.jpg: 384x640 2 knifes, 1 cake, 45.5ms\n",
      "Speed: 1.7ms preprocess, 45.5ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/288.jpg: 384x640 2 knifes, 1 cake, 27.8ms\n",
      "Speed: 1.8ms preprocess, 27.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/289.jpg: 384x640 1 knife, 1 cake, 47.9ms\n",
      "Speed: 1.8ms preprocess, 47.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/290.jpg: 384x640 2 knifes, 1 cake, 33.4ms\n",
      "Speed: 1.8ms preprocess, 33.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/291.jpg: 384x640 1 knife, 1 cake, 49.4ms\n",
      "Speed: 2.0ms preprocess, 49.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/292.jpg: 384x640 2 knifes, 1 cake, 27.9ms\n",
      "Speed: 1.6ms preprocess, 27.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/293.jpg: 384x640 2 knifes, 1 cake, 30.9ms\n",
      "Speed: 1.8ms preprocess, 30.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/294.jpg: 384x640 2 knifes, 27.4ms\n",
      "Speed: 1.6ms preprocess, 27.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/295.jpg: 384x640 2 knifes, 46.9ms\n",
      "Speed: 2.0ms preprocess, 46.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/296.jpg: 384x640 2 knifes, 37.4ms\n",
      "Speed: 1.6ms preprocess, 37.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/297.jpg: 384x640 2 knifes, 30.3ms\n",
      "Speed: 1.6ms preprocess, 30.3ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/298.jpg: 384x640 2 knifes, 31.0ms\n",
      "Speed: 2.1ms preprocess, 31.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/left/299.jpg: 384x640 2 knifes, 29.3ms\n",
      "Speed: 1.7ms preprocess, 29.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Propagating video frames: 100%|| 300/300 [00:23<00:00, 12.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask propagation completed in 23.13 seconds.\n",
      "Processing predicted masks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing video frames: 300it [00:01, 164.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 300 masks for evaluation.\n",
      "Masks saved to data/masks/yolo11x-seg/val/data-raw-SegSTRONGC_val-val-1-0-bg_change-left.pkl\n",
      "Loading ground truth masks for evaluation...\n",
      "Loaded 300 ground truth masks.\n",
      "Calculating evaluation metrics...\n",
      "Time taken for metrics calculation: 1.36 seconds.\n",
      "Mean IoU for data/raw/SegSTRONGC_val/val/1/0/bg_change/left: 0.3415\n",
      "Mean DSC for data/raw/SegSTRONGC_val/val/1/0/bg_change/left: 0.4572\n",
      "Loading existing results file: data/results/yolo11x-seg/val.json\n",
      "Results saved to data/results/yolo11x-seg/val.json\n",
      "Processing video took 29.36 seconds.\n",
      "==================================================\n",
      "Processing right camera video...\n",
      "==================================================\n",
      "Processing video: data/raw/SegSTRONGC_val/val/1/0/bg_change/right\n",
      "Domain: bg_change, Split: val, Camera: right\n",
      "Initializing Yolo for video...\n",
      "Initialization took 1.33 seconds.\n",
      "Starting mask propagation...\n",
      "Total images in video: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/0.jpg: 384x640 2 knifes, 1 cake, 77.0ms\n",
      "Speed: 1.8ms preprocess, 77.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/1.jpg: 384x640 2 knifes, 1 cake, 25.3ms\n",
      "Speed: 1.5ms preprocess, 25.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/2.jpg: 384x640 2 knifes, 1 cake, 24.3ms\n",
      "Speed: 2.6ms preprocess, 24.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/3.jpg: 384x640 2 knifes, 1 cake, 24.4ms\n",
      "Speed: 1.5ms preprocess, 24.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/4.jpg: 384x640 2 knifes, 1 hot dog, 1 cake, 25.3ms\n",
      "Speed: 1.6ms preprocess, 25.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/5.jpg: 384x640 2 knifes, 33.7ms\n",
      "Speed: 3.3ms preprocess, 33.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/6.jpg: 384x640 2 knifes, 1 hot dog, 1 cake, 36.8ms\n",
      "Speed: 1.6ms preprocess, 36.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/7.jpg: 384x640 2 knifes, 38.6ms\n",
      "Speed: 2.2ms preprocess, 38.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/8.jpg: 384x640 2 knifes, 25.8ms\n",
      "Speed: 1.5ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/9.jpg: 384x640 2 knifes, 1 cake, 38.7ms\n",
      "Speed: 1.9ms preprocess, 38.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/10.jpg: 384x640 2 knifes, 49.0ms\n",
      "Speed: 1.9ms preprocess, 49.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/11.jpg: 384x640 2 knifes, 29.8ms\n",
      "Speed: 2.5ms preprocess, 29.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/12.jpg: 384x640 2 knifes, 1 cake, 29.5ms\n",
      "Speed: 1.8ms preprocess, 29.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/13.jpg: 384x640 2 knifes, 1 cake, 44.9ms\n",
      "Speed: 2.8ms preprocess, 44.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/14.jpg: 384x640 2 knifes, 42.5ms\n",
      "Speed: 1.9ms preprocess, 42.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/15.jpg: 384x640 2 knifes, 1 hot dog, 40.5ms\n",
      "Speed: 2.8ms preprocess, 40.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/16.jpg: 384x640 2 knifes, 1 hot dog, 1 cake, 26.3ms\n",
      "Speed: 1.9ms preprocess, 26.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/17.jpg: 384x640 1 knife, 1 hot dog, 1 cake, 33.6ms\n",
      "Speed: 1.8ms preprocess, 33.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/18.jpg: 384x640 1 knife, 1 hot dog, 1 cake, 26.3ms\n",
      "Speed: 1.5ms preprocess, 26.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/19.jpg: 384x640 1 knife, 1 cake, 34.4ms\n",
      "Speed: 1.8ms preprocess, 34.4ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/20.jpg: 384x640 2 knifes, 1 hot dog, 1 pizza, 26.9ms\n",
      "Speed: 1.9ms preprocess, 26.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/21.jpg: 384x640 2 knifes, 56.9ms\n",
      "Speed: 1.9ms preprocess, 56.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/22.jpg: 384x640 1 knife, 1 cake, 39.4ms\n",
      "Speed: 2.0ms preprocess, 39.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/23.jpg: 384x640 1 knife, 1 hot dog, 37.9ms\n",
      "Speed: 3.0ms preprocess, 37.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/24.jpg: 384x640 2 knifes, 1 hot dog, 32.2ms\n",
      "Speed: 1.7ms preprocess, 32.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/25.jpg: 384x640 1 knife, 1 hot dog, 34.4ms\n",
      "Speed: 3.3ms preprocess, 34.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/26.jpg: 384x640 2 knifes, 27.3ms\n",
      "Speed: 1.8ms preprocess, 27.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/27.jpg: 384x640 2 knifes, 1 hot dog, 54.8ms\n",
      "Speed: 2.0ms preprocess, 54.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/28.jpg: 384x640 2 knifes, 1 hot dog, 33.0ms\n",
      "Speed: 1.8ms preprocess, 33.0ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/29.jpg: 384x640 2 knifes, 1 hot dog, 39.7ms\n",
      "Speed: 2.7ms preprocess, 39.7ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/30.jpg: 384x640 2 knifes, 1 cake, 33.3ms\n",
      "Speed: 1.8ms preprocess, 33.3ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/31.jpg: 384x640 2 knifes, 1 hot dog, 1 cake, 30.2ms\n",
      "Speed: 3.0ms preprocess, 30.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/32.jpg: 384x640 2 knifes, 1 hot dog, 52.3ms\n",
      "Speed: 2.1ms preprocess, 52.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/33.jpg: 384x640 2 knifes, 1 cake, 41.9ms\n",
      "Speed: 1.7ms preprocess, 41.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/34.jpg: 384x640 2 knifes, 1 hot dog, 1 pizza, 28.6ms\n",
      "Speed: 1.7ms preprocess, 28.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/35.jpg: 384x640 2 knifes, 30.6ms\n",
      "Speed: 2.3ms preprocess, 30.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/36.jpg: 384x640 2 knifes, 30.6ms\n",
      "Speed: 1.8ms preprocess, 30.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/37.jpg: 384x640 2 knifes, 28.6ms\n",
      "Speed: 1.7ms preprocess, 28.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/38.jpg: 384x640 2 knifes, 34.9ms\n",
      "Speed: 2.1ms preprocess, 34.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/39.jpg: 384x640 2 knifes, 58.1ms\n",
      "Speed: 2.0ms preprocess, 58.1ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/40.jpg: 384x640 1 knife, 1 hot dog, 30.0ms\n",
      "Speed: 1.8ms preprocess, 30.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/41.jpg: 384x640 1 knife, 1 hot dog, 45.9ms\n",
      "Speed: 3.2ms preprocess, 45.9ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/42.jpg: 384x640 2 knifes, 45.9ms\n",
      "Speed: 1.9ms preprocess, 45.9ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/43.jpg: 384x640 1 knife, 1 hot dog, 49.7ms\n",
      "Speed: 3.3ms preprocess, 49.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/44.jpg: 384x640 1 knife, 1 hot dog, 29.5ms\n",
      "Speed: 2.2ms preprocess, 29.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/45.jpg: 384x640 2 knifes, 1 hot dog, 27.6ms\n",
      "Speed: 2.0ms preprocess, 27.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/46.jpg: 384x640 1 knife, 1 spoon, 1 hot dog, 28.4ms\n",
      "Speed: 1.7ms preprocess, 28.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/47.jpg: 384x640 2 knifes, 43.9ms\n",
      "Speed: 4.8ms preprocess, 43.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/48.jpg: 384x640 2 knifes, 1 hot dog, 28.8ms\n",
      "Speed: 2.0ms preprocess, 28.8ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/49.jpg: 384x640 2 knifes, 1 hot dog, 1 cake, 38.6ms\n",
      "Speed: 2.3ms preprocess, 38.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/50.jpg: 384x640 1 knife, 1 cake, 26.6ms\n",
      "Speed: 1.7ms preprocess, 26.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/51.jpg: 384x640 2 knifes, 1 cake, 36.8ms\n",
      "Speed: 2.0ms preprocess, 36.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/52.jpg: 384x640 2 knifes, 1 hot dog, 1 cake, 31.8ms\n",
      "Speed: 2.0ms preprocess, 31.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/53.jpg: 384x640 2 knifes, 1 hot dog, 57.7ms\n",
      "Speed: 3.7ms preprocess, 57.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/54.jpg: 384x640 2 knifes, 1 hot dog, 1 cake, 33.9ms\n",
      "Speed: 1.7ms preprocess, 33.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/55.jpg: 384x640 1 knife, 1 hot dog, 1 cake, 37.4ms\n",
      "Speed: 3.0ms preprocess, 37.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/56.jpg: 384x640 1 knife, 1 hot dog, 30.6ms\n",
      "Speed: 2.0ms preprocess, 30.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/57.jpg: 384x640 2 knifes, 1 hot dog, 38.2ms\n",
      "Speed: 2.2ms preprocess, 38.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/58.jpg: 384x640 2 knifes, 46.1ms\n",
      "Speed: 1.8ms preprocess, 46.1ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/59.jpg: 384x640 2 knifes, 1 cake, 44.3ms\n",
      "Speed: 2.1ms preprocess, 44.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/60.jpg: 384x640 2 knifes, 1 hot dog, 29.9ms\n",
      "Speed: 1.8ms preprocess, 29.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/61.jpg: 384x640 1 knife, 1 hot dog, 27.3ms\n",
      "Speed: 1.9ms preprocess, 27.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/62.jpg: 384x640 2 knifes, 1 cake, 34.9ms\n",
      "Speed: 1.7ms preprocess, 34.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/63.jpg: 384x640 1 knife, 1 cake, 34.6ms\n",
      "Speed: 1.9ms preprocess, 34.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/64.jpg: 384x640 2 knifes, 1 cake, 31.1ms\n",
      "Speed: 1.9ms preprocess, 31.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/65.jpg: 384x640 2 knifes, 1 cake, 41.7ms\n",
      "Speed: 1.8ms preprocess, 41.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/66.jpg: 384x640 2 knifes, 1 cake, 28.9ms\n",
      "Speed: 1.8ms preprocess, 28.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/67.jpg: 384x640 2 knifes, 1 hot dog, 1 cake, 38.9ms\n",
      "Speed: 2.9ms preprocess, 38.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/68.jpg: 384x640 1 knife, 1 spoon, 1 hot dog, 1 cake, 28.6ms\n",
      "Speed: 1.7ms preprocess, 28.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/69.jpg: 384x640 2 knifes, 29.5ms\n",
      "Speed: 1.8ms preprocess, 29.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/70.jpg: 384x640 2 knifes, 27.4ms\n",
      "Speed: 1.6ms preprocess, 27.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/71.jpg: 384x640 2 knifes, 39.1ms\n",
      "Speed: 2.5ms preprocess, 39.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/72.jpg: 384x640 2 knifes, 1 hot dog, 1 cake, 27.6ms\n",
      "Speed: 2.0ms preprocess, 27.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/73.jpg: 384x640 2 knifes, 1 hot dog, 1 cake, 28.2ms\n",
      "Speed: 1.7ms preprocess, 28.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/74.jpg: 384x640 1 knife, 1 hot dog, 1 cake, 34.4ms\n",
      "Speed: 2.1ms preprocess, 34.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/75.jpg: 384x640 2 knifes, 1 hot dog, 39.8ms\n",
      "Speed: 1.8ms preprocess, 39.8ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/76.jpg: 384x640 2 knifes, 1 hot dog, 29.2ms\n",
      "Speed: 1.8ms preprocess, 29.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/77.jpg: 384x640 2 knifes, 36.3ms\n",
      "Speed: 1.7ms preprocess, 36.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/78.jpg: 384x640 1 knife, 1 spoon, 32.5ms\n",
      "Speed: 2.6ms preprocess, 32.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/79.jpg: 384x640 1 knife, 1 hot dog, 1 pizza, 38.2ms\n",
      "Speed: 2.0ms preprocess, 38.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/80.jpg: 384x640 1 knife, 49.3ms\n",
      "Speed: 1.9ms preprocess, 49.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/81.jpg: 384x640 1 knife, 1 cake, 37.4ms\n",
      "Speed: 1.8ms preprocess, 37.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/82.jpg: 384x640 1 knife, 1 spoon, 1 hot dog, 1 cake, 30.7ms\n",
      "Speed: 1.7ms preprocess, 30.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/83.jpg: 384x640 1 knife, 37.4ms\n",
      "Speed: 2.7ms preprocess, 37.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/84.jpg: 384x640 1 knife, 1 hot dog, 46.4ms\n",
      "Speed: 1.9ms preprocess, 46.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/85.jpg: 384x640 2 knifes, 1 carrot, 27.9ms\n",
      "Speed: 1.8ms preprocess, 27.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/86.jpg: 384x640 2 knifes, 42.3ms\n",
      "Speed: 1.8ms preprocess, 42.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/87.jpg: 384x640 2 knifes, 30.0ms\n",
      "Speed: 1.9ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/88.jpg: 384x640 2 knifes, 45.4ms\n",
      "Speed: 3.8ms preprocess, 45.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/89.jpg: 384x640 1 knife, 40.1ms\n",
      "Speed: 2.4ms preprocess, 40.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/90.jpg: 384x640 1 knife, 26.9ms\n",
      "Speed: 1.8ms preprocess, 26.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/91.jpg: 384x640 2 knifes, 31.9ms\n",
      "Speed: 1.8ms preprocess, 31.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/92.jpg: 384x640 2 knifes, 40.8ms\n",
      "Speed: 2.0ms preprocess, 40.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/93.jpg: 384x640 2 knifes, 46.8ms\n",
      "Speed: 1.7ms preprocess, 46.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/94.jpg: 384x640 1 knife, 1 hot dog, 26.4ms\n",
      "Speed: 1.6ms preprocess, 26.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/95.jpg: 384x640 1 knife, 33.6ms\n",
      "Speed: 2.0ms preprocess, 33.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/96.jpg: 384x640 2 knifes, 29.5ms\n",
      "Speed: 2.0ms preprocess, 29.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/97.jpg: 384x640 1 knife, 30.3ms\n",
      "Speed: 2.7ms preprocess, 30.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/98.jpg: 384x640 1 knife, 1 spoon, 30.7ms\n",
      "Speed: 1.6ms preprocess, 30.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/99.jpg: 384x640 1 knife, 1 spoon, 38.6ms\n",
      "Speed: 2.2ms preprocess, 38.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/100.jpg: 384x640 1 knife, 1 spoon, 32.0ms\n",
      "Speed: 1.8ms preprocess, 32.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/101.jpg: 384x640 1 knife, 1 spoon, 31.4ms\n",
      "Speed: 2.3ms preprocess, 31.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/102.jpg: 384x640 1 knife, 1 spoon, 1 pizza, 28.3ms\n",
      "Speed: 1.7ms preprocess, 28.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/103.jpg: 384x640 1 knife, 1 spoon, 51.0ms\n",
      "Speed: 1.9ms preprocess, 51.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/104.jpg: 384x640 1 fork, 1 knife, 1 cake, 27.0ms\n",
      "Speed: 1.8ms preprocess, 27.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/105.jpg: 384x640 1 knife, 34.7ms\n",
      "Speed: 4.0ms preprocess, 34.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/106.jpg: 384x640 1 knife, 30.6ms\n",
      "Speed: 1.6ms preprocess, 30.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/107.jpg: 384x640 1 knife, 30.9ms\n",
      "Speed: 1.7ms preprocess, 30.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/108.jpg: 384x640 1 knife, 41.6ms\n",
      "Speed: 1.7ms preprocess, 41.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/109.jpg: 384x640 1 knife, 1 hot dog, 52.8ms\n",
      "Speed: 1.9ms preprocess, 52.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/110.jpg: 384x640 1 knife, 1 hot dog, 26.1ms\n",
      "Speed: 1.7ms preprocess, 26.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/111.jpg: 384x640 2 knifes, 39.6ms\n",
      "Speed: 1.7ms preprocess, 39.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/112.jpg: 384x640 1 knife, 50.9ms\n",
      "Speed: 1.9ms preprocess, 50.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/113.jpg: 384x640 1 knife, 1 spoon, 33.7ms\n",
      "Speed: 2.0ms preprocess, 33.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/114.jpg: 384x640 1 knife, 1 hot dog, 26.3ms\n",
      "Speed: 2.1ms preprocess, 26.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/115.jpg: 384x640 1 knife, 1 spoon, 26.5ms\n",
      "Speed: 1.7ms preprocess, 26.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/116.jpg: 384x640 1 knife, 28.5ms\n",
      "Speed: 1.8ms preprocess, 28.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/117.jpg: 384x640 1 knife, 1 spoon, 1 hot dog, 39.7ms\n",
      "Speed: 1.7ms preprocess, 39.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/118.jpg: 384x640 1 knife, 1 hot dog, 26.5ms\n",
      "Speed: 2.0ms preprocess, 26.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/119.jpg: 384x640 1 knife, 1 cake, 26.9ms\n",
      "Speed: 1.5ms preprocess, 26.9ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/120.jpg: 384x640 1 knife, 1 hot dog, 46.8ms\n",
      "Speed: 1.9ms preprocess, 46.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/121.jpg: 384x640 1 knife, 1 hot dog, 1 cake, 36.5ms\n",
      "Speed: 2.1ms preprocess, 36.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/122.jpg: 384x640 1 knife, 39.8ms\n",
      "Speed: 1.7ms preprocess, 39.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/123.jpg: 384x640 1 knife, 1 hot dog, 27.3ms\n",
      "Speed: 1.7ms preprocess, 27.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/124.jpg: 384x640 1 knife, 1 cake, 41.5ms\n",
      "Speed: 1.8ms preprocess, 41.5ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/125.jpg: 384x640 1 knife, 31.4ms\n",
      "Speed: 1.8ms preprocess, 31.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/126.jpg: 384x640 2 knifes, 52.3ms\n",
      "Speed: 2.1ms preprocess, 52.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/127.jpg: 384x640 2 knifes, 1 hot dog, 40.7ms\n",
      "Speed: 2.0ms preprocess, 40.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/128.jpg: 384x640 1 knife, 47.0ms\n",
      "Speed: 2.0ms preprocess, 47.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/129.jpg: 384x640 1 knife, 1 cake, 38.6ms\n",
      "Speed: 2.2ms preprocess, 38.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/130.jpg: 384x640 1 fork, 29.0ms\n",
      "Speed: 1.9ms preprocess, 29.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/131.jpg: 384x640 1 spoon, 1 cake, 43.2ms\n",
      "Speed: 1.7ms preprocess, 43.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/132.jpg: 384x640 1 knife, 1 cake, 45.8ms\n",
      "Speed: 2.6ms preprocess, 45.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/133.jpg: 384x640 2 knifes, 1 cake, 25.3ms\n",
      "Speed: 1.8ms preprocess, 25.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/134.jpg: 384x640 1 bottle, 1 knife, 1 cake, 43.9ms\n",
      "Speed: 2.0ms preprocess, 43.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/135.jpg: 384x640 1 bottle, 1 knife, 1 cake, 29.5ms\n",
      "Speed: 3.1ms preprocess, 29.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/136.jpg: 384x640 1 bottle, 1 knife, 39.9ms\n",
      "Speed: 1.9ms preprocess, 39.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/137.jpg: 384x640 1 bottle, 1 knife, 25.6ms\n",
      "Speed: 1.8ms preprocess, 25.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/138.jpg: 384x640 1 bottle, 1 knife, 35.1ms\n",
      "Speed: 1.8ms preprocess, 35.1ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/139.jpg: 384x640 2 knifes, 35.9ms\n",
      "Speed: 1.9ms preprocess, 35.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/140.jpg: 384x640 1 bottle, 2 knifes, 46.7ms\n",
      "Speed: 2.1ms preprocess, 46.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/141.jpg: 384x640 2 knifes, 29.7ms\n",
      "Speed: 1.8ms preprocess, 29.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/142.jpg: 384x640 2 knifes, 34.7ms\n",
      "Speed: 1.9ms preprocess, 34.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/143.jpg: 384x640 1 knife, 29.0ms\n",
      "Speed: 1.8ms preprocess, 29.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/144.jpg: 384x640 1 bottle, 1 knife, 53.1ms\n",
      "Speed: 1.8ms preprocess, 53.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/145.jpg: 384x640 1 knife, 1 cake, 28.6ms\n",
      "Speed: 1.7ms preprocess, 28.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/146.jpg: 384x640 1 bottle, 1 knife, 1 cake, 54.8ms\n",
      "Speed: 1.8ms preprocess, 54.8ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/147.jpg: 384x640 1 spoon, 25.6ms\n",
      "Speed: 1.7ms preprocess, 25.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/148.jpg: 384x640 1 spoon, 38.5ms\n",
      "Speed: 1.9ms preprocess, 38.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/149.jpg: 384x640 2 knifes, 61.1ms\n",
      "Speed: 2.1ms preprocess, 61.1ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/150.jpg: 384x640 2 knifes, 34.4ms\n",
      "Speed: 1.9ms preprocess, 34.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/151.jpg: 384x640 2 knifes, 1 spoon, 34.5ms\n",
      "Speed: 1.8ms preprocess, 34.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/152.jpg: 384x640 2 knifes, 30.4ms\n",
      "Speed: 2.7ms preprocess, 30.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/153.jpg: 384x640 2 knifes, 46.3ms\n",
      "Speed: 2.1ms preprocess, 46.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/154.jpg: 384x640 1 knife, 1 pizza, 43.6ms\n",
      "Speed: 2.0ms preprocess, 43.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/155.jpg: 384x640 2 knifes, 55.6ms\n",
      "Speed: 1.8ms preprocess, 55.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/156.jpg: 384x640 2 knifes, 29.3ms\n",
      "Speed: 1.8ms preprocess, 29.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/157.jpg: 384x640 1 knife, 41.3ms\n",
      "Speed: 1.7ms preprocess, 41.3ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/158.jpg: 384x640 1 knife, 1 cake, 44.3ms\n",
      "Speed: 2.9ms preprocess, 44.3ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/159.jpg: 384x640 1 knife, 33.4ms\n",
      "Speed: 2.1ms preprocess, 33.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/160.jpg: 384x640 2 knifes, 32.0ms\n",
      "Speed: 2.7ms preprocess, 32.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/161.jpg: 384x640 2 knifes, 27.7ms\n",
      "Speed: 1.8ms preprocess, 27.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/162.jpg: 384x640 2 knifes, 53.6ms\n",
      "Speed: 6.1ms preprocess, 53.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/163.jpg: 384x640 1 knife, 1 spoon, 27.1ms\n",
      "Speed: 1.9ms preprocess, 27.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/164.jpg: 384x640 1 knife, 1 spoon, 32.7ms\n",
      "Speed: 2.7ms preprocess, 32.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/165.jpg: 384x640 1 fork, 1 knife, 1 spoon, 1 hot dog, 29.8ms\n",
      "Speed: 2.0ms preprocess, 29.8ms inference, 9.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/166.jpg: 384x640 1 knife, 1 spoon, 1 hot dog, 31.5ms\n",
      "Speed: 2.4ms preprocess, 31.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/167.jpg: 384x640 1 spoon, 1 cake, 63.7ms\n",
      "Speed: 3.2ms preprocess, 63.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/168.jpg: 384x640 1 spoon, 38.3ms\n",
      "Speed: 2.1ms preprocess, 38.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/169.jpg: 384x640 2 knifes, 39.6ms\n",
      "Speed: 1.7ms preprocess, 39.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/170.jpg: 384x640 2 knifes, 1 cake, 26.0ms\n",
      "Speed: 1.6ms preprocess, 26.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/171.jpg: 384x640 1 knife, 1 spoon, 1 hot dog, 38.4ms\n",
      "Speed: 1.8ms preprocess, 38.4ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/172.jpg: 384x640 1 spoon, 35.6ms\n",
      "Speed: 2.2ms preprocess, 35.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/173.jpg: 384x640 2 knifes, 34.8ms\n",
      "Speed: 1.8ms preprocess, 34.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/174.jpg: 384x640 2 knifes, 42.2ms\n",
      "Speed: 2.2ms preprocess, 42.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/175.jpg: 384x640 2 knifes, 37.3ms\n",
      "Speed: 1.7ms preprocess, 37.3ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/176.jpg: 384x640 2 knifes, 36.4ms\n",
      "Speed: 2.6ms preprocess, 36.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/177.jpg: 384x640 1 knife, 1 pizza, 30.2ms\n",
      "Speed: 1.7ms preprocess, 30.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/178.jpg: 384x640 2 knifes, 36.3ms\n",
      "Speed: 2.1ms preprocess, 36.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/179.jpg: 384x640 2 knifes, 32.7ms\n",
      "Speed: 2.0ms preprocess, 32.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/180.jpg: 384x640 2 knifes, 1 hot dog, 46.2ms\n",
      "Speed: 2.1ms preprocess, 46.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/181.jpg: 384x640 1 knife, 1 pizza, 33.8ms\n",
      "Speed: 1.9ms preprocess, 33.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/182.jpg: 384x640 2 knifes, 1 pizza, 41.4ms\n",
      "Speed: 1.8ms preprocess, 41.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/183.jpg: 384x640 2 knifes, 1 pizza, 29.1ms\n",
      "Speed: 1.9ms preprocess, 29.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/184.jpg: 384x640 2 knifes, 1 pizza, 44.0ms\n",
      "Speed: 2.8ms preprocess, 44.0ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/185.jpg: 384x640 2 knifes, 1 pizza, 27.2ms\n",
      "Speed: 1.9ms preprocess, 27.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/186.jpg: 384x640 2 knifes, 1 hot dog, 1 pizza, 54.3ms\n",
      "Speed: 1.9ms preprocess, 54.3ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/187.jpg: 384x640 2 knifes, 1 pizza, 44.3ms\n",
      "Speed: 3.5ms preprocess, 44.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/188.jpg: 384x640 2 knifes, 1 pizza, 41.0ms\n",
      "Speed: 3.7ms preprocess, 41.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/189.jpg: 384x640 2 knifes, 1 pizza, 25.8ms\n",
      "Speed: 1.8ms preprocess, 25.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/190.jpg: 384x640 2 knifes, 1 hot dog, 1 pizza, 47.1ms\n",
      "Speed: 2.0ms preprocess, 47.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/191.jpg: 384x640 2 knifes, 1 hot dog, 41.2ms\n",
      "Speed: 2.8ms preprocess, 41.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/192.jpg: 384x640 2 knifes, 1 pizza, 36.6ms\n",
      "Speed: 1.9ms preprocess, 36.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/193.jpg: 384x640 1 knife, 1 pizza, 58.9ms\n",
      "Speed: 3.4ms preprocess, 58.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/194.jpg: 384x640 1 knife, 1 hot dog, 1 cake, 37.5ms\n",
      "Speed: 2.0ms preprocess, 37.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/195.jpg: 384x640 2 knifes, 1 pizza, 32.2ms\n",
      "Speed: 2.1ms preprocess, 32.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/196.jpg: 384x640 2 knifes, 1 pizza, 34.8ms\n",
      "Speed: 2.1ms preprocess, 34.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/197.jpg: 384x640 2 knifes, 1 pizza, 49.1ms\n",
      "Speed: 5.4ms preprocess, 49.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/198.jpg: 384x640 1 knife, 1 hot dog, 1 pizza, 32.9ms\n",
      "Speed: 2.1ms preprocess, 32.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/199.jpg: 384x640 1 knife, 1 pizza, 33.8ms\n",
      "Speed: 2.3ms preprocess, 33.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/200.jpg: 384x640 1 knife, 1 spoon, 1 pizza, 46.8ms\n",
      "Speed: 2.2ms preprocess, 46.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/201.jpg: 384x640 1 knife, 1 spoon, 1 pizza, 49.8ms\n",
      "Speed: 2.0ms preprocess, 49.8ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/202.jpg: 384x640 1 knife, 1 spoon, 30.8ms\n",
      "Speed: 2.1ms preprocess, 30.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/203.jpg: 384x640 1 knife, 1 pizza, 40.3ms\n",
      "Speed: 1.9ms preprocess, 40.3ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/204.jpg: 384x640 2 knifes, 1 carrot, 1 pizza, 29.4ms\n",
      "Speed: 2.0ms preprocess, 29.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/205.jpg: 384x640 2 knifes, 1 pizza, 29.4ms\n",
      "Speed: 1.9ms preprocess, 29.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/206.jpg: 384x640 2 knifes, 1 carrot, 1 pizza, 50.0ms\n",
      "Speed: 1.9ms preprocess, 50.0ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/207.jpg: 384x640 2 knifes, 1 pizza, 33.5ms\n",
      "Speed: 1.8ms preprocess, 33.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/208.jpg: 384x640 2 knifes, 1 pizza, 34.8ms\n",
      "Speed: 2.0ms preprocess, 34.8ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/209.jpg: 384x640 1 knife, 31.2ms\n",
      "Speed: 1.6ms preprocess, 31.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/210.jpg: 384x640 1 knife, 1 spoon, 1 carrot, 1 hot dog, 1 pizza, 32.3ms\n",
      "Speed: 1.9ms preprocess, 32.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/211.jpg: 384x640 1 knife, 1 spoon, 1 carrot, 30.5ms\n",
      "Speed: 1.8ms preprocess, 30.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/212.jpg: 384x640 1 knife, 1 pizza, 31.8ms\n",
      "Speed: 2.0ms preprocess, 31.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/213.jpg: 384x640 2 knifes, 42.3ms\n",
      "Speed: 2.0ms preprocess, 42.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/214.jpg: 384x640 1 knife, 1 carrot, 35.0ms\n",
      "Speed: 2.1ms preprocess, 35.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/215.jpg: 384x640 2 knifes, 37.4ms\n",
      "Speed: 1.8ms preprocess, 37.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/216.jpg: 384x640 2 knifes, 1 pizza, 31.7ms\n",
      "Speed: 2.0ms preprocess, 31.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/217.jpg: 384x640 2 knifes, 39.3ms\n",
      "Speed: 2.1ms preprocess, 39.3ms inference, 9.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/218.jpg: 384x640 2 knifes, 42.1ms\n",
      "Speed: 2.5ms preprocess, 42.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/219.jpg: 384x640 1 knife, 1 spoon, 33.0ms\n",
      "Speed: 2.1ms preprocess, 33.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/220.jpg: 384x640 2 knifes, 1 pizza, 29.0ms\n",
      "Speed: 1.8ms preprocess, 29.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/221.jpg: 384x640 1 knife, 1 spoon, 1 pizza, 27.8ms\n",
      "Speed: 1.9ms preprocess, 27.8ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/222.jpg: 384x640 1 knife, 28.8ms\n",
      "Speed: 1.8ms preprocess, 28.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/223.jpg: 384x640 1 knife, 1 spoon, 27.5ms\n",
      "Speed: 1.6ms preprocess, 27.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/224.jpg: 384x640 1 knife, 28.1ms\n",
      "Speed: 1.6ms preprocess, 28.1ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/225.jpg: 384x640 1 knife, 1 spoon, 24.2ms\n",
      "Speed: 1.6ms preprocess, 24.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/226.jpg: 384x640 2 knifes, 26.6ms\n",
      "Speed: 1.7ms preprocess, 26.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/227.jpg: 384x640 2 knifes, 1 cake, 25.8ms\n",
      "Speed: 1.6ms preprocess, 25.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/228.jpg: 384x640 2 knifes, 29.6ms\n",
      "Speed: 1.8ms preprocess, 29.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/229.jpg: 384x640 2 knifes, 1 cake, 24.0ms\n",
      "Speed: 1.7ms preprocess, 24.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/230.jpg: 384x640 2 knifes, 1 hot dog, 31.5ms\n",
      "Speed: 1.8ms preprocess, 31.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/231.jpg: 384x640 1 knife, 25.7ms\n",
      "Speed: 1.8ms preprocess, 25.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/232.jpg: 384x640 1 knife, 1 spoon, 1 cake, 26.9ms\n",
      "Speed: 1.6ms preprocess, 26.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/233.jpg: 384x640 2 knifes, 1 cake, 24.8ms\n",
      "Speed: 1.7ms preprocess, 24.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/234.jpg: 384x640 2 knifes, 24.7ms\n",
      "Speed: 1.8ms preprocess, 24.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/235.jpg: 384x640 2 knifes, 1 cake, 28.8ms\n",
      "Speed: 1.9ms preprocess, 28.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/236.jpg: 384x640 2 knifes, 27.5ms\n",
      "Speed: 2.5ms preprocess, 27.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/237.jpg: 384x640 2 knifes, 1 hot dog, 37.1ms\n",
      "Speed: 1.8ms preprocess, 37.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/238.jpg: 384x640 1 knife, 1 hot dog, 27.6ms\n",
      "Speed: 1.8ms preprocess, 27.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/239.jpg: 384x640 1 knife, 30.0ms\n",
      "Speed: 1.7ms preprocess, 30.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/240.jpg: 384x640 2 knifes, 1 hot dog, 23.9ms\n",
      "Speed: 1.7ms preprocess, 23.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/241.jpg: 384x640 1 knife, 1 spoon, 1 hot dog, 26.5ms\n",
      "Speed: 1.5ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/242.jpg: 384x640 1 knife, 1 hot dog, 28.4ms\n",
      "Speed: 1.6ms preprocess, 28.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/243.jpg: 384x640 2 knifes, 25.7ms\n",
      "Speed: 1.8ms preprocess, 25.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/244.jpg: 384x640 1 knife, 1 pizza, 31.4ms\n",
      "Speed: 1.6ms preprocess, 31.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/245.jpg: 384x640 2 knifes, 44.8ms\n",
      "Speed: 1.6ms preprocess, 44.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/246.jpg: 384x640 2 knifes, 29.5ms\n",
      "Speed: 2.0ms preprocess, 29.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/247.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 24.6ms\n",
      "Speed: 1.4ms preprocess, 24.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/248.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 26.1ms\n",
      "Speed: 1.6ms preprocess, 26.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/249.jpg: 384x640 2 knifes, 1 hot dog, 1 pizza, 1 cake, 25.2ms\n",
      "Speed: 1.8ms preprocess, 25.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/250.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 29.9ms\n",
      "Speed: 1.7ms preprocess, 29.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/251.jpg: 384x640 2 knifes, 1 hot dog, 1 pizza, 1 cake, 26.5ms\n",
      "Speed: 1.7ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/252.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 23.9ms\n",
      "Speed: 1.6ms preprocess, 23.9ms inference, 7.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/253.jpg: 384x640 2 knifes, 1 hot dog, 1 pizza, 25.8ms\n",
      "Speed: 2.0ms preprocess, 25.8ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/254.jpg: 384x640 2 knifes, 1 hot dog, 1 pizza, 46.5ms\n",
      "Speed: 2.0ms preprocess, 46.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/255.jpg: 384x640 1 knife, 27.9ms\n",
      "Speed: 1.6ms preprocess, 27.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/256.jpg: 384x640 1 knife, 1 hot dog, 24.2ms\n",
      "Speed: 1.6ms preprocess, 24.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/257.jpg: 384x640 2 knifes, 1 hot dog, 31.4ms\n",
      "Speed: 2.8ms preprocess, 31.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/258.jpg: 384x640 2 knifes, 24.9ms\n",
      "Speed: 1.6ms preprocess, 24.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/259.jpg: 384x640 1 knife, 1 spoon, 29.2ms\n",
      "Speed: 1.6ms preprocess, 29.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/260.jpg: 384x640 2 knifes, 1 pizza, 36.9ms\n",
      "Speed: 2.8ms preprocess, 36.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/261.jpg: 384x640 2 knifes, 1 pizza, 24.8ms\n",
      "Speed: 1.7ms preprocess, 24.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/262.jpg: 384x640 2 knifes, 1 pizza, 29.3ms\n",
      "Speed: 3.0ms preprocess, 29.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/263.jpg: 384x640 2 knifes, 1 pizza, 24.4ms\n",
      "Speed: 1.9ms preprocess, 24.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/264.jpg: 384x640 2 knifes, 1 pizza, 40.8ms\n",
      "Speed: 2.0ms preprocess, 40.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/265.jpg: 384x640 2 knifes, 1 hot dog, 1 pizza, 35.2ms\n",
      "Speed: 2.0ms preprocess, 35.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/266.jpg: 384x640 2 knifes, 1 pizza, 48.4ms\n",
      "Speed: 1.8ms preprocess, 48.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/267.jpg: 384x640 2 knifes, 1 hot dog, 1 pizza, 27.7ms\n",
      "Speed: 1.7ms preprocess, 27.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/268.jpg: 384x640 2 knifes, 1 pizza, 37.7ms\n",
      "Speed: 1.9ms preprocess, 37.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/269.jpg: 384x640 2 knifes, 1 pizza, 37.8ms\n",
      "Speed: 3.3ms preprocess, 37.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/270.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 48.4ms\n",
      "Speed: 3.1ms preprocess, 48.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/271.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 24.9ms\n",
      "Speed: 1.6ms preprocess, 24.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/272.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 28.2ms\n",
      "Speed: 2.8ms preprocess, 28.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/273.jpg: 384x640 2 knifes, 1 cake, 32.7ms\n",
      "Speed: 2.9ms preprocess, 32.7ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/274.jpg: 384x640 2 knifes, 1 hot dog, 1 pizza, 42.3ms\n",
      "Speed: 2.1ms preprocess, 42.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/275.jpg: 384x640 2 knifes, 1 hot dog, 1 pizza, 1 cake, 28.2ms\n",
      "Speed: 2.1ms preprocess, 28.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/276.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 31.9ms\n",
      "Speed: 1.9ms preprocess, 31.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/277.jpg: 384x640 2 knifes, 1 hot dog, 36.7ms\n",
      "Speed: 1.7ms preprocess, 36.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/278.jpg: 384x640 1 knife, 1 spoon, 55.8ms\n",
      "Speed: 2.3ms preprocess, 55.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/279.jpg: 384x640 1 knife, 27.3ms\n",
      "Speed: 1.9ms preprocess, 27.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/280.jpg: 384x640 2 knifes, 38.2ms\n",
      "Speed: 2.1ms preprocess, 38.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/281.jpg: 384x640 1 knife, 1 hot dog, 28.6ms\n",
      "Speed: 1.6ms preprocess, 28.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/282.jpg: 384x640 1 knife, 1 hot dog, 32.8ms\n",
      "Speed: 1.7ms preprocess, 32.8ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/283.jpg: 384x640 2 knifes, 42.9ms\n",
      "Speed: 5.0ms preprocess, 42.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/284.jpg: 384x640 2 knifes, 31.1ms\n",
      "Speed: 1.8ms preprocess, 31.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/285.jpg: 384x640 2 knifes, 46.2ms\n",
      "Speed: 2.0ms preprocess, 46.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/286.jpg: 384x640 2 knifes, 1 hot dog, 34.4ms\n",
      "Speed: 2.6ms preprocess, 34.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/287.jpg: 384x640 2 knifes, 28.0ms\n",
      "Speed: 1.8ms preprocess, 28.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/288.jpg: 384x640 2 knifes, 1 hot dog, 1 cake, 30.6ms\n",
      "Speed: 1.8ms preprocess, 30.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/289.jpg: 384x640 2 knifes, 1 hot dog, 44.4ms\n",
      "Speed: 3.1ms preprocess, 44.4ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/290.jpg: 384x640 2 knifes, 27.2ms\n",
      "Speed: 2.1ms preprocess, 27.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/291.jpg: 384x640 2 knifes, 1 hot dog, 26.2ms\n",
      "Speed: 2.0ms preprocess, 26.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/292.jpg: 384x640 2 knifes, 1 hot dog, 32.6ms\n",
      "Speed: 1.8ms preprocess, 32.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/293.jpg: 384x640 1 knife, 29.3ms\n",
      "Speed: 2.9ms preprocess, 29.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/294.jpg: 384x640 2 knifes, 47.2ms\n",
      "Speed: 2.1ms preprocess, 47.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/295.jpg: 384x640 1 knife, 32.2ms\n",
      "Speed: 1.9ms preprocess, 32.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/296.jpg: 384x640 1 knife, 35.8ms\n",
      "Speed: 1.8ms preprocess, 35.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/297.jpg: 384x640 2 knifes, 43.3ms\n",
      "Speed: 2.0ms preprocess, 43.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/298.jpg: 384x640 2 knifes, 32.7ms\n",
      "Speed: 2.2ms preprocess, 32.7ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/bg_change/right/299.jpg: 384x640 2 knifes, 26.3ms\n",
      "Speed: 1.5ms preprocess, 26.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Propagating video frames: 100%|| 300/300 [00:19<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask propagation completed in 19.29 seconds.\n",
      "Processing predicted masks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing video frames: 300it [00:01, 200.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 300 masks for evaluation.\n",
      "Masks saved to data/masks/yolo11x-seg/val/data-raw-SegSTRONGC_val-val-1-0-bg_change-right.pkl\n",
      "Loading ground truth masks for evaluation...\n",
      "Loaded 300 ground truth masks.\n",
      "Calculating evaluation metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for metrics calculation: 1.40 seconds.\n",
      "Mean IoU for data/raw/SegSTRONGC_val/val/1/0/bg_change/right: 0.4881\n",
      "Mean DSC for data/raw/SegSTRONGC_val/val/1/0/bg_change/right: 0.6050\n",
      "Loading existing results file: data/results/yolo11x-seg/val.json\n",
      "Results saved to data/results/yolo11x-seg/val.json\n",
      "Processing video took 25.21 seconds.\n",
      "==================================================\n",
      "\n",
      "Results for data/raw/SegSTRONGC_val/val/1/0/bg_change:\n",
      "  Left: IoU=0.3415, DSC=0.4572\n",
      "  Right: IoU=0.4881, DSC=0.6050\n",
      "  Overall: IoU=0.4148, DSC=0.5311\n",
      "\n",
      "Processing domain: blood\n",
      "Processing left camera video...\n",
      "==================================================\n",
      "Processing video: data/raw/SegSTRONGC_val/val/1/0/blood/left\n",
      "Domain: blood, Split: val, Camera: left\n",
      "Initializing Yolo for video...\n",
      "Initialization took 0.13 seconds.\n",
      "Starting mask propagation...\n",
      "Total images in video: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/0.jpg: 384x640 2 baseball bats, 81.8ms\n",
      "Speed: 2.3ms preprocess, 81.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/1.jpg: 384x640 2 baseball bats, 26.9ms\n",
      "Speed: 2.2ms preprocess, 26.9ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/2.jpg: 384x640 2 baseball bats, 24.2ms\n",
      "Speed: 2.0ms preprocess, 24.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/3.jpg: 384x640 2 baseball bats, 23.9ms\n",
      "Speed: 1.5ms preprocess, 23.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/4.jpg: 384x640 2 baseball bats, 30.6ms\n",
      "Speed: 1.5ms preprocess, 30.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/5.jpg: 384x640 2 baseball bats, 37.0ms\n",
      "Speed: 1.6ms preprocess, 37.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/6.jpg: 384x640 2 baseball bats, 25.9ms\n",
      "Speed: 1.7ms preprocess, 25.9ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/7.jpg: 384x640 1 baseball bat, 1 knife, 33.4ms\n",
      "Speed: 1.9ms preprocess, 33.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/8.jpg: 384x640 2 baseball bats, 28.0ms\n",
      "Speed: 1.6ms preprocess, 28.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/9.jpg: 384x640 2 baseball bats, 28.5ms\n",
      "Speed: 3.0ms preprocess, 28.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/10.jpg: 384x640 2 baseball bats, 30.2ms\n",
      "Speed: 1.5ms preprocess, 30.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/11.jpg: 384x640 2 baseball bats, 36.1ms\n",
      "Speed: 1.8ms preprocess, 36.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/12.jpg: 384x640 2 baseball bats, 42.5ms\n",
      "Speed: 2.0ms preprocess, 42.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/13.jpg: 384x640 2 baseball bats, 42.1ms\n",
      "Speed: 2.1ms preprocess, 42.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/14.jpg: 384x640 2 baseball bats, 40.9ms\n",
      "Speed: 1.8ms preprocess, 40.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/15.jpg: 384x640 2 baseball bats, 30.9ms\n",
      "Speed: 2.5ms preprocess, 30.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/16.jpg: 384x640 2 baseball bats, 30.0ms\n",
      "Speed: 1.7ms preprocess, 30.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/17.jpg: 384x640 2 baseball bats, 31.9ms\n",
      "Speed: 2.7ms preprocess, 31.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/18.jpg: 384x640 2 baseball bats, 51.8ms\n",
      "Speed: 1.8ms preprocess, 51.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/19.jpg: 384x640 2 baseball bats, 33.0ms\n",
      "Speed: 1.8ms preprocess, 33.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/20.jpg: 384x640 2 baseball bats, 30.3ms\n",
      "Speed: 1.7ms preprocess, 30.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/21.jpg: 384x640 2 baseball bats, 32.8ms\n",
      "Speed: 2.3ms preprocess, 32.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/22.jpg: 384x640 2 baseball bats, 36.4ms\n",
      "Speed: 1.7ms preprocess, 36.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/23.jpg: 384x640 2 baseball bats, 43.0ms\n",
      "Speed: 1.6ms preprocess, 43.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/24.jpg: 384x640 2 baseball bats, 1 carrot, 24.4ms\n",
      "Speed: 1.8ms preprocess, 24.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/25.jpg: 384x640 2 baseball bats, 52.2ms\n",
      "Speed: 3.3ms preprocess, 52.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/26.jpg: 384x640 2 baseball bats, 1 bottle, 30.1ms\n",
      "Speed: 2.5ms preprocess, 30.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/27.jpg: 384x640 2 baseball bats, 36.3ms\n",
      "Speed: 3.1ms preprocess, 36.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/28.jpg: 384x640 2 baseball bats, 29.4ms\n",
      "Speed: 1.7ms preprocess, 29.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/29.jpg: 384x640 2 baseball bats, 51.9ms\n",
      "Speed: 2.5ms preprocess, 51.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/30.jpg: 384x640 2 baseball bats, 30.3ms\n",
      "Speed: 1.9ms preprocess, 30.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/31.jpg: 384x640 2 baseball bats, 42.6ms\n",
      "Speed: 1.9ms preprocess, 42.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/32.jpg: 384x640 2 baseball bats, 28.3ms\n",
      "Speed: 2.0ms preprocess, 28.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/33.jpg: 384x640 2 baseball bats, 48.9ms\n",
      "Speed: 1.9ms preprocess, 48.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/34.jpg: 384x640 2 baseball bats, 25.6ms\n",
      "Speed: 1.6ms preprocess, 25.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/35.jpg: 384x640 2 baseball bats, 1 knife, 44.7ms\n",
      "Speed: 1.8ms preprocess, 44.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/36.jpg: 384x640 2 baseball bats, 1 bottle, 33.5ms\n",
      "Speed: 2.0ms preprocess, 33.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/37.jpg: 384x640 2 baseball bats, 44.1ms\n",
      "Speed: 2.2ms preprocess, 44.1ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/38.jpg: 384x640 2 baseball bats, 32.3ms\n",
      "Speed: 1.9ms preprocess, 32.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/39.jpg: 384x640 1 baseball bat, 44.0ms\n",
      "Speed: 2.1ms preprocess, 44.0ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/40.jpg: 384x640 1 baseball bat, 30.9ms\n",
      "Speed: 1.9ms preprocess, 30.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/41.jpg: 384x640 2 baseball bats, 40.5ms\n",
      "Speed: 3.3ms preprocess, 40.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/42.jpg: 384x640 3 baseball bats, 39.1ms\n",
      "Speed: 2.6ms preprocess, 39.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/43.jpg: 384x640 2 baseball bats, 28.2ms\n",
      "Speed: 1.9ms preprocess, 28.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/44.jpg: 384x640 2 baseball bats, 1 knife, 31.8ms\n",
      "Speed: 1.8ms preprocess, 31.8ms inference, 7.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/45.jpg: 384x640 2 baseball bats, 34.5ms\n",
      "Speed: 2.7ms preprocess, 34.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/46.jpg: 384x640 2 baseball bats, 29.7ms\n",
      "Speed: 1.5ms preprocess, 29.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/47.jpg: 384x640 2 baseball bats, 53.1ms\n",
      "Speed: 2.3ms preprocess, 53.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/48.jpg: 384x640 2 baseball bats, 27.4ms\n",
      "Speed: 1.8ms preprocess, 27.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/49.jpg: 384x640 2 baseball bats, 41.9ms\n",
      "Speed: 2.6ms preprocess, 41.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/50.jpg: 384x640 2 baseball bats, 1 carrot, 32.9ms\n",
      "Speed: 1.6ms preprocess, 32.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/51.jpg: 384x640 2 baseball bats, 32.7ms\n",
      "Speed: 2.4ms preprocess, 32.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/52.jpg: 384x640 2 baseball bats, 41.4ms\n",
      "Speed: 2.1ms preprocess, 41.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/53.jpg: 384x640 1 baseball bat, 1 spoon, 1 carrot, 32.8ms\n",
      "Speed: 2.5ms preprocess, 32.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/54.jpg: 384x640 1 baseball bat, 27.6ms\n",
      "Speed: 1.5ms preprocess, 27.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/55.jpg: 384x640 2 baseball bats, 38.6ms\n",
      "Speed: 1.8ms preprocess, 38.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/56.jpg: 384x640 2 baseball bats, 34.9ms\n",
      "Speed: 2.6ms preprocess, 34.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/57.jpg: 384x640 2 baseball bats, 1 carrot, 38.7ms\n",
      "Speed: 2.0ms preprocess, 38.7ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/58.jpg: 384x640 2 baseball bats, 1 carrot, 36.3ms\n",
      "Speed: 2.4ms preprocess, 36.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/59.jpg: 384x640 2 baseball bats, 1 carrot, 47.5ms\n",
      "Speed: 1.8ms preprocess, 47.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/60.jpg: 384x640 2 baseball bats, 36.3ms\n",
      "Speed: 2.0ms preprocess, 36.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/61.jpg: 384x640 2 baseball bats, 48.1ms\n",
      "Speed: 1.9ms preprocess, 48.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/62.jpg: 384x640 2 baseball bats, 33.4ms\n",
      "Speed: 1.9ms preprocess, 33.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/63.jpg: 384x640 2 baseball bats, 36.7ms\n",
      "Speed: 2.6ms preprocess, 36.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/64.jpg: 384x640 2 baseball bats, 2 carrots, 39.7ms\n",
      "Speed: 2.0ms preprocess, 39.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/65.jpg: 384x640 2 baseball bats, 42.9ms\n",
      "Speed: 2.1ms preprocess, 42.9ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/66.jpg: 384x640 2 baseball bats, 42.9ms\n",
      "Speed: 2.0ms preprocess, 42.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/67.jpg: 384x640 2 baseball bats, 59.0ms\n",
      "Speed: 2.1ms preprocess, 59.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/68.jpg: 384x640 2 baseball bats, 29.4ms\n",
      "Speed: 1.9ms preprocess, 29.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/69.jpg: 384x640 2 baseball bats, 48.6ms\n",
      "Speed: 2.2ms preprocess, 48.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/70.jpg: 384x640 2 baseball bats, 50.2ms\n",
      "Speed: 1.9ms preprocess, 50.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/71.jpg: 384x640 2 baseball bats, 41.2ms\n",
      "Speed: 2.0ms preprocess, 41.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/72.jpg: 384x640 2 baseball bats, 41.0ms\n",
      "Speed: 1.9ms preprocess, 41.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/73.jpg: 384x640 2 baseball bats, 29.9ms\n",
      "Speed: 2.0ms preprocess, 29.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/74.jpg: 384x640 2 baseball bats, 32.8ms\n",
      "Speed: 1.7ms preprocess, 32.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/75.jpg: 384x640 2 baseball bats, 30.5ms\n",
      "Speed: 1.9ms preprocess, 30.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/76.jpg: 384x640 2 baseball bats, 33.1ms\n",
      "Speed: 1.6ms preprocess, 33.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/77.jpg: 384x640 1 baseball bat, 29.5ms\n",
      "Speed: 2.1ms preprocess, 29.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/78.jpg: 384x640 2 baseball bats, 40.1ms\n",
      "Speed: 1.9ms preprocess, 40.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/79.jpg: 384x640 2 baseball bats, 1 carrot, 30.9ms\n",
      "Speed: 2.3ms preprocess, 30.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/80.jpg: 384x640 2 baseball bats, 1 carrot, 47.5ms\n",
      "Speed: 1.7ms preprocess, 47.5ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/81.jpg: 384x640 2 baseball bats, 35.7ms\n",
      "Speed: 3.0ms preprocess, 35.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/82.jpg: 384x640 (no detections), 59.6ms\n",
      "Speed: 1.8ms preprocess, 59.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/83.jpg: 384x640 2 baseball bats, 2 carrots, 31.7ms\n",
      "Speed: 2.0ms preprocess, 31.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/84.jpg: 384x640 1 baseball bat, 1 carrot, 1 hot dog, 29.6ms\n",
      "Speed: 1.8ms preprocess, 29.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/85.jpg: 384x640 1 baseball bat, 1 carrot, 50.5ms\n",
      "Speed: 4.4ms preprocess, 50.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/86.jpg: 384x640 1 baseball bat, 1 carrot, 40.4ms\n",
      "Speed: 1.8ms preprocess, 40.4ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/87.jpg: 384x640 2 baseball bats, 1 carrot, 45.9ms\n",
      "Speed: 2.8ms preprocess, 45.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/88.jpg: 384x640 1 carrot, 1 toothbrush, 27.4ms\n",
      "Speed: 1.9ms preprocess, 27.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/89.jpg: 384x640 1 baseball bat, 1 bottle, 1 carrot, 43.6ms\n",
      "Speed: 1.8ms preprocess, 43.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/90.jpg: 384x640 1 baseball bat, 1 carrot, 38.4ms\n",
      "Speed: 1.7ms preprocess, 38.4ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/91.jpg: 384x640 1 spoon, 1 carrot, 26.5ms\n",
      "Speed: 1.7ms preprocess, 26.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/92.jpg: 384x640 1 baseball bat, 32.6ms\n",
      "Speed: 1.7ms preprocess, 32.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/93.jpg: 384x640 1 baseball bat, 1 knife, 25.6ms\n",
      "Speed: 1.7ms preprocess, 25.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/94.jpg: 384x640 1 baseball bat, 1 knife, 25.8ms\n",
      "Speed: 1.8ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/95.jpg: 384x640 1 baseball bat, 1 knife, 41.3ms\n",
      "Speed: 2.0ms preprocess, 41.3ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/96.jpg: 384x640 (no detections), 26.5ms\n",
      "Speed: 2.0ms preprocess, 26.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/97.jpg: 384x640 1 spoon, 32.6ms\n",
      "Speed: 1.8ms preprocess, 32.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/98.jpg: 384x640 1 knife, 1 spoon, 26.5ms\n",
      "Speed: 2.1ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/99.jpg: 384x640 1 spoon, 34.0ms\n",
      "Speed: 1.7ms preprocess, 34.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/100.jpg: 384x640 1 knife, 1 spoon, 1 toothbrush, 37.4ms\n",
      "Speed: 1.7ms preprocess, 37.4ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/101.jpg: 384x640 1 knife, 1 spoon, 1 toothbrush, 42.1ms\n",
      "Speed: 1.9ms preprocess, 42.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/102.jpg: 384x640 1 toothbrush, 36.2ms\n",
      "Speed: 2.2ms preprocess, 36.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/103.jpg: 384x640 1 knife, 25.8ms\n",
      "Speed: 1.9ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/104.jpg: 384x640 1 knife, 40.3ms\n",
      "Speed: 1.9ms preprocess, 40.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/105.jpg: 384x640 (no detections), 40.7ms\n",
      "Speed: 1.8ms preprocess, 40.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/106.jpg: 384x640 1 knife, 29.6ms\n",
      "Speed: 2.4ms preprocess, 29.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/107.jpg: 384x640 1 baseball bat, 1 knife, 1 spoon, 1 cake, 44.2ms\n",
      "Speed: 1.9ms preprocess, 44.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/108.jpg: 384x640 1 baseball bat, 1 spoon, 38.3ms\n",
      "Speed: 2.0ms preprocess, 38.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/109.jpg: 384x640 (no detections), 31.0ms\n",
      "Speed: 1.9ms preprocess, 31.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/110.jpg: 384x640 1 baseball bat, 1 knife, 1 carrot, 26.4ms\n",
      "Speed: 2.6ms preprocess, 26.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/111.jpg: 384x640 1 baseball bat, 1 hot dog, 31.3ms\n",
      "Speed: 3.3ms preprocess, 31.3ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/112.jpg: 384x640 1 baseball bat, 42.0ms\n",
      "Speed: 2.8ms preprocess, 42.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/113.jpg: 384x640 2 baseball bats, 1 bottle, 32.6ms\n",
      "Speed: 1.9ms preprocess, 32.6ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/114.jpg: 384x640 2 baseball bats, 30.4ms\n",
      "Speed: 2.0ms preprocess, 30.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/115.jpg: 384x640 2 baseball bats, 1 bottle, 1 carrot, 39.9ms\n",
      "Speed: 2.0ms preprocess, 39.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/116.jpg: 384x640 2 baseball bats, 29.9ms\n",
      "Speed: 1.7ms preprocess, 29.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/117.jpg: 384x640 2 baseball bats, 41.7ms\n",
      "Speed: 2.2ms preprocess, 41.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/118.jpg: 384x640 2 baseball bats, 1 knife, 36.9ms\n",
      "Speed: 2.0ms preprocess, 36.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/119.jpg: 384x640 2 baseball bats, 33.8ms\n",
      "Speed: 1.8ms preprocess, 33.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/120.jpg: 384x640 2 baseball bats, 32.0ms\n",
      "Speed: 2.0ms preprocess, 32.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/121.jpg: 384x640 2 baseball bats, 33.4ms\n",
      "Speed: 2.6ms preprocess, 33.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/122.jpg: 384x640 2 baseball bats, 40.4ms\n",
      "Speed: 2.8ms preprocess, 40.4ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/123.jpg: 384x640 2 baseball bats, 34.6ms\n",
      "Speed: 2.6ms preprocess, 34.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/124.jpg: 384x640 2 baseball bats, 1 bottle, 38.8ms\n",
      "Speed: 2.0ms preprocess, 38.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/125.jpg: 384x640 2 baseball bats, 1 bottle, 31.6ms\n",
      "Speed: 2.6ms preprocess, 31.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/126.jpg: 384x640 2 baseball bats, 2 bottles, 26.5ms\n",
      "Speed: 1.6ms preprocess, 26.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/127.jpg: 384x640 2 baseball bats, 26.0ms\n",
      "Speed: 1.9ms preprocess, 26.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/128.jpg: 384x640 1 baseball bat, 1 bottle, 46.3ms\n",
      "Speed: 2.2ms preprocess, 46.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/129.jpg: 384x640 1 bottle, 38.9ms\n",
      "Speed: 1.8ms preprocess, 38.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/130.jpg: 384x640 1 bottle, 30.5ms\n",
      "Speed: 1.7ms preprocess, 30.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/131.jpg: 384x640 (no detections), 27.3ms\n",
      "Speed: 1.8ms preprocess, 27.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/132.jpg: 384x640 1 bottle, 41.8ms\n",
      "Speed: 1.8ms preprocess, 41.8ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/133.jpg: 384x640 2 bottles, 39.9ms\n",
      "Speed: 2.6ms preprocess, 39.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/134.jpg: 384x640 1 bottle, 1 spoon, 27.1ms\n",
      "Speed: 1.7ms preprocess, 27.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/135.jpg: 384x640 1 bottle, 1 knife, 41.8ms\n",
      "Speed: 2.0ms preprocess, 41.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/136.jpg: 384x640 1 knife, 29.3ms\n",
      "Speed: 1.7ms preprocess, 29.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/137.jpg: 384x640 1 bottle, 1 knife, 40.3ms\n",
      "Speed: 2.5ms preprocess, 40.3ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/138.jpg: 384x640 1 knife, 26.6ms\n",
      "Speed: 1.8ms preprocess, 26.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/139.jpg: 384x640 1 bottle, 47.9ms\n",
      "Speed: 1.9ms preprocess, 47.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/140.jpg: 384x640 1 bottle, 1 knife, 25.6ms\n",
      "Speed: 1.7ms preprocess, 25.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/141.jpg: 384x640 1 bottle, 49.0ms\n",
      "Speed: 2.1ms preprocess, 49.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/142.jpg: 384x640 1 bottle, 1 spoon, 29.3ms\n",
      "Speed: 2.5ms preprocess, 29.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/143.jpg: 384x640 1 spoon, 44.8ms\n",
      "Speed: 2.0ms preprocess, 44.8ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/144.jpg: 384x640 1 knife, 37.8ms\n",
      "Speed: 2.0ms preprocess, 37.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/145.jpg: 384x640 1 bottle, 1 knife, 48.9ms\n",
      "Speed: 5.3ms preprocess, 48.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/146.jpg: 384x640 (no detections), 43.2ms\n",
      "Speed: 1.9ms preprocess, 43.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/147.jpg: 384x640 1 spoon, 33.0ms\n",
      "Speed: 2.8ms preprocess, 33.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/148.jpg: 384x640 (no detections), 47.4ms\n",
      "Speed: 1.9ms preprocess, 47.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/149.jpg: 384x640 2 bottles, 30.0ms\n",
      "Speed: 2.4ms preprocess, 30.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/150.jpg: 384x640 1 baseball bat, 1 bottle, 27.6ms\n",
      "Speed: 1.8ms preprocess, 27.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/151.jpg: 384x640 1 baseball bat, 37.4ms\n",
      "Speed: 2.9ms preprocess, 37.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/152.jpg: 384x640 1 bottle, 1 hot dog, 30.2ms\n",
      "Speed: 1.7ms preprocess, 30.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/153.jpg: 384x640 1 baseball bat, 1 bottle, 1 knife, 31.2ms\n",
      "Speed: 2.0ms preprocess, 31.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/154.jpg: 384x640 1 baseball bat, 1 knife, 1 hot dog, 46.9ms\n",
      "Speed: 2.9ms preprocess, 46.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/155.jpg: 384x640 1 knife, 1 hot dog, 62.5ms\n",
      "Speed: 2.1ms preprocess, 62.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/156.jpg: 384x640 1 baseball bat, 33.3ms\n",
      "Speed: 2.1ms preprocess, 33.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/157.jpg: 384x640 1 baseball bat, 1 bottle, 1 spoon, 28.9ms\n",
      "Speed: 1.9ms preprocess, 28.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/158.jpg: 384x640 1 baseball bat, 1 bottle, 45.1ms\n",
      "Speed: 3.4ms preprocess, 45.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/159.jpg: 384x640 1 baseball bat, 1 bottle, 1 knife, 33.5ms\n",
      "Speed: 1.8ms preprocess, 33.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/160.jpg: 384x640 1 baseball bat, 1 bottle, 1 knife, 1 spoon, 1 hot dog, 29.9ms\n",
      "Speed: 2.5ms preprocess, 29.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/161.jpg: 384x640 1 knife, 44.3ms\n",
      "Speed: 2.3ms preprocess, 44.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/162.jpg: 384x640 1 knife, 35.5ms\n",
      "Speed: 1.8ms preprocess, 35.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/163.jpg: 384x640 1 knife, 1 spoon, 1 toothbrush, 35.6ms\n",
      "Speed: 2.9ms preprocess, 35.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/164.jpg: 384x640 1 spoon, 47.1ms\n",
      "Speed: 2.2ms preprocess, 47.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/165.jpg: 384x640 1 spoon, 32.8ms\n",
      "Speed: 1.8ms preprocess, 32.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/166.jpg: 384x640 1 spoon, 32.4ms\n",
      "Speed: 2.1ms preprocess, 32.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/167.jpg: 384x640 1 knife, 1 spoon, 33.8ms\n",
      "Speed: 2.0ms preprocess, 33.8ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/168.jpg: 384x640 1 knife, 1 spoon, 50.1ms\n",
      "Speed: 1.7ms preprocess, 50.1ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/169.jpg: 384x640 1 knife, 30.2ms\n",
      "Speed: 1.9ms preprocess, 30.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/170.jpg: 384x640 1 knife, 36.6ms\n",
      "Speed: 1.8ms preprocess, 36.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/171.jpg: 384x640 1 knife, 1 spoon, 40.9ms\n",
      "Speed: 1.9ms preprocess, 40.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/172.jpg: 384x640 1 spoon, 30.5ms\n",
      "Speed: 2.0ms preprocess, 30.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/173.jpg: 384x640 1 knife, 25.8ms\n",
      "Speed: 1.6ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/174.jpg: 384x640 1 knife, 45.7ms\n",
      "Speed: 2.0ms preprocess, 45.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/175.jpg: 384x640 1 bottle, 1 knife, 31.8ms\n",
      "Speed: 2.3ms preprocess, 31.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/176.jpg: 384x640 1 baseball bat, 1 bottle, 1 knife, 1 hot dog, 37.3ms\n",
      "Speed: 2.0ms preprocess, 37.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/177.jpg: 384x640 1 bottle, 46.9ms\n",
      "Speed: 2.9ms preprocess, 46.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/178.jpg: 384x640 2 baseball bats, 40.1ms\n",
      "Speed: 3.4ms preprocess, 40.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/179.jpg: 384x640 2 baseball bats, 1 bottle, 40.8ms\n",
      "Speed: 2.0ms preprocess, 40.8ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/180.jpg: 384x640 3 baseball bats, 40.3ms\n",
      "Speed: 2.6ms preprocess, 40.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/181.jpg: 384x640 3 baseball bats, 46.8ms\n",
      "Speed: 2.4ms preprocess, 46.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/182.jpg: 384x640 2 baseball bats, 32.1ms\n",
      "Speed: 1.9ms preprocess, 32.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/183.jpg: 384x640 2 baseball bats, 30.4ms\n",
      "Speed: 1.9ms preprocess, 30.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/184.jpg: 384x640 2 baseball bats, 27.2ms\n",
      "Speed: 2.1ms preprocess, 27.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/185.jpg: 384x640 2 baseball bats, 37.1ms\n",
      "Speed: 3.6ms preprocess, 37.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/186.jpg: 384x640 2 baseball bats, 43.2ms\n",
      "Speed: 2.8ms preprocess, 43.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/187.jpg: 384x640 2 baseball bats, 33.5ms\n",
      "Speed: 2.4ms preprocess, 33.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/188.jpg: 384x640 2 baseball bats, 28.1ms\n",
      "Speed: 2.3ms preprocess, 28.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/189.jpg: 384x640 2 baseball bats, 1 spoon, 31.7ms\n",
      "Speed: 2.3ms preprocess, 31.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/190.jpg: 384x640 2 baseball bats, 29.7ms\n",
      "Speed: 2.0ms preprocess, 29.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/191.jpg: 384x640 2 baseball bats, 1 bottle, 49.6ms\n",
      "Speed: 2.1ms preprocess, 49.6ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/192.jpg: 384x640 1 baseball bat, 1 bottle, 42.5ms\n",
      "Speed: 1.9ms preprocess, 42.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/193.jpg: 384x640 2 baseball bats, 1 bottle, 30.5ms\n",
      "Speed: 2.2ms preprocess, 30.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/194.jpg: 384x640 1 baseball bat, 1 bottle, 34.5ms\n",
      "Speed: 1.9ms preprocess, 34.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/195.jpg: 384x640 2 baseball bats, 1 bottle, 31.3ms\n",
      "Speed: 2.0ms preprocess, 31.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/196.jpg: 384x640 2 baseball bats, 1 bottle, 28.3ms\n",
      "Speed: 1.8ms preprocess, 28.3ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/197.jpg: 384x640 2 baseball bats, 47.9ms\n",
      "Speed: 3.1ms preprocess, 47.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/198.jpg: 384x640 2 baseball bats, 1 carrot, 33.4ms\n",
      "Speed: 1.9ms preprocess, 33.4ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/199.jpg: 384x640 2 baseball bats, 33.3ms\n",
      "Speed: 1.9ms preprocess, 33.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/200.jpg: 384x640 2 baseball bats, 1 carrot, 40.4ms\n",
      "Speed: 1.7ms preprocess, 40.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/201.jpg: 384x640 2 baseball bats, 1 carrot, 44.0ms\n",
      "Speed: 2.0ms preprocess, 44.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/202.jpg: 384x640 1 baseball bat, 2 carrots, 28.8ms\n",
      "Speed: 1.5ms preprocess, 28.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/203.jpg: 384x640 1 baseball bat, 1 carrot, 1 hot dog, 36.9ms\n",
      "Speed: 1.9ms preprocess, 36.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/204.jpg: 384x640 2 carrots, 26.8ms\n",
      "Speed: 1.5ms preprocess, 26.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/205.jpg: 384x640 1 spoon, 1 carrot, 30.7ms\n",
      "Speed: 1.8ms preprocess, 30.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/206.jpg: 384x640 1 spoon, 2 carrots, 28.3ms\n",
      "Speed: 1.7ms preprocess, 28.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/207.jpg: 384x640 1 baseball bat, 3 carrots, 28.3ms\n",
      "Speed: 1.7ms preprocess, 28.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/208.jpg: 384x640 2 carrots, 38.3ms\n",
      "Speed: 2.7ms preprocess, 38.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/209.jpg: 384x640 1 baseball bat, 3 carrots, 30.8ms\n",
      "Speed: 2.4ms preprocess, 30.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/210.jpg: 384x640 2 baseball bats, 38.7ms\n",
      "Speed: 1.7ms preprocess, 38.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/211.jpg: 384x640 2 baseball bats, 3 carrots, 47.8ms\n",
      "Speed: 1.8ms preprocess, 47.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/212.jpg: 384x640 1 baseball bat, 2 carrots, 48.7ms\n",
      "Speed: 2.1ms preprocess, 48.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/213.jpg: 384x640 1 baseball bat, 2 carrots, 1 hot dog, 55.5ms\n",
      "Speed: 2.1ms preprocess, 55.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/214.jpg: 384x640 1 baseball bat, 2 carrots, 1 hot dog, 33.2ms\n",
      "Speed: 1.8ms preprocess, 33.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/215.jpg: 384x640 1 baseball bat, 2 carrots, 30.3ms\n",
      "Speed: 1.9ms preprocess, 30.3ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/216.jpg: 384x640 2 baseball bats, 1 carrot, 43.3ms\n",
      "Speed: 3.1ms preprocess, 43.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/217.jpg: 384x640 1 baseball bat, 2 carrots, 3 hot dogs, 35.9ms\n",
      "Speed: 1.9ms preprocess, 35.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/218.jpg: 384x640 1 baseball bat, 1 hot dog, 37.1ms\n",
      "Speed: 2.1ms preprocess, 37.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/219.jpg: 384x640 1 baseball bat, 2 hot dogs, 46.9ms\n",
      "Speed: 2.0ms preprocess, 46.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/220.jpg: 384x640 1 baseball bat, 2 hot dogs, 36.2ms\n",
      "Speed: 1.7ms preprocess, 36.2ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/221.jpg: 384x640 1 baseball bat, 42.6ms\n",
      "Speed: 2.6ms preprocess, 42.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/222.jpg: 384x640 1 baseball bat, 1 cake, 35.0ms\n",
      "Speed: 1.8ms preprocess, 35.0ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/223.jpg: 384x640 2 baseball bats, 25.8ms\n",
      "Speed: 1.8ms preprocess, 25.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/224.jpg: 384x640 1 knife, 50.5ms\n",
      "Speed: 2.3ms preprocess, 50.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/225.jpg: 384x640 1 baseball bat, 1 knife, 1 spoon, 31.1ms\n",
      "Speed: 2.2ms preprocess, 31.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/226.jpg: 384x640 1 knife, 27.9ms\n",
      "Speed: 1.7ms preprocess, 27.9ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/227.jpg: 384x640 2 baseball bats, 41.6ms\n",
      "Speed: 1.8ms preprocess, 41.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/228.jpg: 384x640 1 spoon, 45.0ms\n",
      "Speed: 1.9ms preprocess, 45.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/229.jpg: 384x640 1 baseball bat, 1 knife, 37.1ms\n",
      "Speed: 2.1ms preprocess, 37.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/230.jpg: 384x640 1 baseball bat, 1 knife, 1 spoon, 33.0ms\n",
      "Speed: 1.9ms preprocess, 33.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/231.jpg: 384x640 2 baseball bats, 39.6ms\n",
      "Speed: 1.7ms preprocess, 39.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/232.jpg: 384x640 2 baseball bats, 30.9ms\n",
      "Speed: 1.8ms preprocess, 30.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/233.jpg: 384x640 1 baseball bat, 1 knife, 1 spoon, 1 cake, 54.5ms\n",
      "Speed: 2.3ms preprocess, 54.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/234.jpg: 384x640 2 baseball bats, 1 knife, 1 spoon, 30.9ms\n",
      "Speed: 1.7ms preprocess, 30.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/235.jpg: 384x640 1 knife, 1 spoon, 38.4ms\n",
      "Speed: 2.8ms preprocess, 38.4ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/236.jpg: 384x640 2 baseball bats, 1 cake, 27.9ms\n",
      "Speed: 2.6ms preprocess, 27.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/237.jpg: 384x640 2 baseball bats, 1 cake, 33.2ms\n",
      "Speed: 2.1ms preprocess, 33.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/238.jpg: 384x640 2 baseball bats, 1 spoon, 30.4ms\n",
      "Speed: 1.9ms preprocess, 30.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/239.jpg: 384x640 1 knife, 1 spoon, 1 cake, 33.5ms\n",
      "Speed: 1.8ms preprocess, 33.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/240.jpg: 384x640 2 baseball bats, 29.8ms\n",
      "Speed: 1.7ms preprocess, 29.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/241.jpg: 384x640 1 baseball bat, 1 spoon, 34.5ms\n",
      "Speed: 2.0ms preprocess, 34.5ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/242.jpg: 384x640 2 spoons, 39.7ms\n",
      "Speed: 1.8ms preprocess, 39.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/243.jpg: 384x640 2 baseball bats, 32.8ms\n",
      "Speed: 2.3ms preprocess, 32.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/244.jpg: 384x640 1 baseball bat, 42.7ms\n",
      "Speed: 2.5ms preprocess, 42.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/245.jpg: 384x640 1 baseball bat, 1 knife, 1 spoon, 49.0ms\n",
      "Speed: 1.7ms preprocess, 49.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/246.jpg: 384x640 1 cake, 38.9ms\n",
      "Speed: 2.6ms preprocess, 38.9ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/247.jpg: 384x640 2 baseball bats, 38.9ms\n",
      "Speed: 2.0ms preprocess, 38.9ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/248.jpg: 384x640 2 baseball bats, 29.6ms\n",
      "Speed: 1.6ms preprocess, 29.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/249.jpg: 384x640 2 baseball bats, 48.3ms\n",
      "Speed: 2.0ms preprocess, 48.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/250.jpg: 384x640 2 baseball bats, 29.1ms\n",
      "Speed: 1.7ms preprocess, 29.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/251.jpg: 384x640 2 baseball bats, 31.4ms\n",
      "Speed: 2.2ms preprocess, 31.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/252.jpg: 384x640 2 baseball bats, 27.9ms\n",
      "Speed: 1.5ms preprocess, 27.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/253.jpg: 384x640 2 baseball bats, 36.7ms\n",
      "Speed: 2.5ms preprocess, 36.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/254.jpg: 384x640 2 baseball bats, 51.0ms\n",
      "Speed: 1.9ms preprocess, 51.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/255.jpg: 384x640 1 baseball bat, 1 spoon, 42.3ms\n",
      "Speed: 2.1ms preprocess, 42.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/256.jpg: 384x640 2 baseball bats, 1 knife, 33.5ms\n",
      "Speed: 1.7ms preprocess, 33.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/257.jpg: 384x640 1 baseball bat, 26.2ms\n",
      "Speed: 1.6ms preprocess, 26.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/258.jpg: 384x640 2 baseball bats, 1 carrot, 30.9ms\n",
      "Speed: 1.9ms preprocess, 30.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/259.jpg: 384x640 2 baseball bats, 43.7ms\n",
      "Speed: 3.0ms preprocess, 43.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/260.jpg: 384x640 1 spoon, 33.3ms\n",
      "Speed: 1.8ms preprocess, 33.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/261.jpg: 384x640 2 baseball bats, 1 carrot, 29.6ms\n",
      "Speed: 1.7ms preprocess, 29.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/262.jpg: 384x640 2 baseball bats, 42.8ms\n",
      "Speed: 1.8ms preprocess, 42.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/263.jpg: 384x640 2 baseball bats, 32.7ms\n",
      "Speed: 3.2ms preprocess, 32.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/264.jpg: 384x640 2 baseball bats, 32.0ms\n",
      "Speed: 1.7ms preprocess, 32.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/265.jpg: 384x640 2 baseball bats, 37.0ms\n",
      "Speed: 2.0ms preprocess, 37.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/266.jpg: 384x640 2 baseball bats, 1 spoon, 36.0ms\n",
      "Speed: 2.8ms preprocess, 36.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/267.jpg: 384x640 2 baseball bats, 35.2ms\n",
      "Speed: 1.8ms preprocess, 35.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/268.jpg: 384x640 2 baseball bats, 33.8ms\n",
      "Speed: 1.7ms preprocess, 33.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/269.jpg: 384x640 2 baseball bats, 56.1ms\n",
      "Speed: 2.2ms preprocess, 56.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/270.jpg: 384x640 2 baseball bats, 26.3ms\n",
      "Speed: 1.7ms preprocess, 26.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/271.jpg: 384x640 2 baseball bats, 28.1ms\n",
      "Speed: 2.1ms preprocess, 28.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/272.jpg: 384x640 2 baseball bats, 30.9ms\n",
      "Speed: 1.8ms preprocess, 30.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/273.jpg: 384x640 2 baseball bats, 28.9ms\n",
      "Speed: 2.1ms preprocess, 28.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/274.jpg: 384x640 2 baseball bats, 36.5ms\n",
      "Speed: 1.8ms preprocess, 36.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/275.jpg: 384x640 (no detections), 48.9ms\n",
      "Speed: 2.0ms preprocess, 48.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/276.jpg: 384x640 2 baseball bats, 29.8ms\n",
      "Speed: 2.0ms preprocess, 29.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/277.jpg: 384x640 2 baseball bats, 33.7ms\n",
      "Speed: 2.6ms preprocess, 33.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/278.jpg: 384x640 2 baseball bats, 29.9ms\n",
      "Speed: 1.8ms preprocess, 29.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/279.jpg: 384x640 1 baseball bat, 33.5ms\n",
      "Speed: 1.9ms preprocess, 33.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/280.jpg: 384x640 2 knifes, 1 spoon, 30.4ms\n",
      "Speed: 2.2ms preprocess, 30.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/281.jpg: 384x640 1 baseball bat, 1 spoon, 1 carrot, 31.3ms\n",
      "Speed: 1.9ms preprocess, 31.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/282.jpg: 384x640 (no detections), 33.9ms\n",
      "Speed: 2.1ms preprocess, 33.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/283.jpg: 384x640 1 baseball bat, 1 spoon, 34.9ms\n",
      "Speed: 2.1ms preprocess, 34.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/284.jpg: 384x640 1 baseball bat, 1 carrot, 29.4ms\n",
      "Speed: 2.7ms preprocess, 29.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/285.jpg: 384x640 1 spoon, 1 carrot, 1 hot dog, 49.7ms\n",
      "Speed: 1.9ms preprocess, 49.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/286.jpg: 384x640 1 spoon, 1 carrot, 2 hot dogs, 40.2ms\n",
      "Speed: 2.1ms preprocess, 40.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/287.jpg: 384x640 1 carrot, 33.4ms\n",
      "Speed: 2.0ms preprocess, 33.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/288.jpg: 384x640 1 spoon, 1 carrot, 38.1ms\n",
      "Speed: 2.0ms preprocess, 38.1ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/289.jpg: 384x640 1 spoon, 1 carrot, 35.7ms\n",
      "Speed: 2.0ms preprocess, 35.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/290.jpg: 384x640 1 baseball bat, 1 carrot, 27.4ms\n",
      "Speed: 1.8ms preprocess, 27.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/291.jpg: 384x640 1 baseball bat, 1 spoon, 1 carrot, 1 hot dog, 27.6ms\n",
      "Speed: 1.9ms preprocess, 27.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/292.jpg: 384x640 1 knife, 2 carrots, 39.9ms\n",
      "Speed: 1.8ms preprocess, 39.9ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/293.jpg: 384x640 1 baseball bat, 1 knife, 1 hot dog, 55.8ms\n",
      "Speed: 2.0ms preprocess, 55.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/294.jpg: 384x640 1 knife, 1 carrot, 2 hot dogs, 38.8ms\n",
      "Speed: 2.6ms preprocess, 38.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/295.jpg: 384x640 2 baseball bats, 1 knife, 27.8ms\n",
      "Speed: 1.8ms preprocess, 27.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/296.jpg: 384x640 2 knifes, 1 spoon, 27.2ms\n",
      "Speed: 1.9ms preprocess, 27.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/297.jpg: 384x640 2 knifes, 1 carrot, 46.9ms\n",
      "Speed: 2.4ms preprocess, 46.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/298.jpg: 384x640 2 knifes, 31.2ms\n",
      "Speed: 1.7ms preprocess, 31.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/left/299.jpg: 384x640 1 baseball bat, 1 knife, 31.4ms\n",
      "Speed: 1.8ms preprocess, 31.4ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Propagating video frames: 100%|| 300/300 [00:20<00:00, 14.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask propagation completed in 20.35 seconds.\n",
      "Processing predicted masks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing video frames: 300it [00:01, 249.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 300 masks for evaluation.\n",
      "Masks saved to data/masks/yolo11x-seg/val/data-raw-SegSTRONGC_val-val-1-0-blood-left.pkl\n",
      "Loading ground truth masks for evaluation...\n",
      "Loaded 300 ground truth masks.\n",
      "Calculating evaluation metrics...\n",
      "Time taken for metrics calculation: 1.46 seconds.\n",
      "Mean IoU for data/raw/SegSTRONGC_val/val/1/0/blood/left: 0.5838\n",
      "Mean DSC for data/raw/SegSTRONGC_val/val/1/0/blood/left: 0.6940\n",
      "Loading existing results file: data/results/yolo11x-seg/val.json\n",
      "Results saved to data/results/yolo11x-seg/val.json\n",
      "Processing video took 24.43 seconds.\n",
      "==================================================\n",
      "Processing right camera video...\n",
      "==================================================\n",
      "Processing video: data/raw/SegSTRONGC_val/val/1/0/blood/right\n",
      "Domain: blood, Split: val, Camera: right\n",
      "Initializing Yolo for video...\n",
      "Initialization took 0.15 seconds.\n",
      "Starting mask propagation...\n",
      "Total images in video: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/0.jpg: 384x640 2 spoons, 1 carrot, 80.7ms\n",
      "Speed: 2.3ms preprocess, 80.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/1.jpg: 384x640 (no detections), 31.9ms\n",
      "Speed: 1.5ms preprocess, 31.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/2.jpg: 384x640 2 spoons, 1 carrot, 36.4ms\n",
      "Speed: 1.8ms preprocess, 36.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/3.jpg: 384x640 1 baseball bat, 1 knife, 1 spoon, 28.3ms\n",
      "Speed: 1.8ms preprocess, 28.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/4.jpg: 384x640 1 baseball bat, 1 spoon, 34.0ms\n",
      "Speed: 1.9ms preprocess, 34.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/5.jpg: 384x640 1 baseball bat, 1 spoon, 39.8ms\n",
      "Speed: 1.8ms preprocess, 39.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/6.jpg: 384x640 2 baseball bats, 24.1ms\n",
      "Speed: 1.6ms preprocess, 24.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/7.jpg: 384x640 2 baseball bats, 1 spoon, 26.6ms\n",
      "Speed: 2.1ms preprocess, 26.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/8.jpg: 384x640 2 baseball bats, 1 spoon, 42.4ms\n",
      "Speed: 1.8ms preprocess, 42.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/9.jpg: 384x640 2 baseball bats, 1 spoon, 25.7ms\n",
      "Speed: 3.1ms preprocess, 25.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/10.jpg: 384x640 2 spoons, 41.6ms\n",
      "Speed: 2.0ms preprocess, 41.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/11.jpg: 384x640 1 baseball bat, 1 spoon, 1 carrot, 25.3ms\n",
      "Speed: 1.6ms preprocess, 25.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/12.jpg: 384x640 2 baseball bats, 1 spoon, 1 carrot, 54.4ms\n",
      "Speed: 1.6ms preprocess, 54.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/13.jpg: 384x640 1 baseball bat, 2 spoons, 24.7ms\n",
      "Speed: 1.5ms preprocess, 24.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/14.jpg: 384x640 2 baseball bats, 1 spoon, 26.1ms\n",
      "Speed: 1.5ms preprocess, 26.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/15.jpg: 384x640 1 baseball bat, 1 spoon, 39.7ms\n",
      "Speed: 1.7ms preprocess, 39.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/16.jpg: 384x640 2 baseball bats, 1 spoon, 39.3ms\n",
      "Speed: 1.7ms preprocess, 39.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/17.jpg: 384x640 2 baseball bats, 1 spoon, 1 carrot, 37.9ms\n",
      "Speed: 1.6ms preprocess, 37.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/18.jpg: 384x640 1 baseball bat, 1 spoon, 40.6ms\n",
      "Speed: 2.0ms preprocess, 40.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/19.jpg: 384x640 2 baseball bats, 25.6ms\n",
      "Speed: 1.7ms preprocess, 25.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/20.jpg: 384x640 2 baseball bats, 1 carrot, 33.7ms\n",
      "Speed: 2.1ms preprocess, 33.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/21.jpg: 384x640 2 baseball bats, 24.1ms\n",
      "Speed: 1.5ms preprocess, 24.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/22.jpg: 384x640 2 baseball bats, 31.3ms\n",
      "Speed: 3.0ms preprocess, 31.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/23.jpg: 384x640 2 baseball bats, 1 spoon, 1 carrot, 23.8ms\n",
      "Speed: 1.5ms preprocess, 23.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/24.jpg: 384x640 1 baseball bat, 23.9ms\n",
      "Speed: 2.1ms preprocess, 23.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/25.jpg: 384x640 2 baseball bats, 29.2ms\n",
      "Speed: 1.8ms preprocess, 29.2ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/26.jpg: 384x640 2 baseball bats, 35.2ms\n",
      "Speed: 2.1ms preprocess, 35.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/27.jpg: 384x640 2 spoons, 25.3ms\n",
      "Speed: 2.2ms preprocess, 25.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/28.jpg: 384x640 1 baseball bat, 1 spoon, 23.9ms\n",
      "Speed: 1.6ms preprocess, 23.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/29.jpg: 384x640 1 baseball bat, 1 spoon, 25.2ms\n",
      "Speed: 1.5ms preprocess, 25.2ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/30.jpg: 384x640 1 spoon, 38.2ms\n",
      "Speed: 1.9ms preprocess, 38.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/31.jpg: 384x640 2 knifes, 1 spoon, 24.2ms\n",
      "Speed: 1.5ms preprocess, 24.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/32.jpg: 384x640 1 baseball bat, 25.2ms\n",
      "Speed: 1.5ms preprocess, 25.2ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/33.jpg: 384x640 2 spoons, 29.2ms\n",
      "Speed: 2.1ms preprocess, 29.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/34.jpg: 384x640 2 baseball bats, 24.8ms\n",
      "Speed: 1.7ms preprocess, 24.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/35.jpg: 384x640 2 baseball bats, 32.1ms\n",
      "Speed: 1.6ms preprocess, 32.1ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/36.jpg: 384x640 2 baseball bats, 25.5ms\n",
      "Speed: 2.2ms preprocess, 25.5ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/37.jpg: 384x640 1 spoon, 25.1ms\n",
      "Speed: 1.6ms preprocess, 25.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/38.jpg: 384x640 2 baseball bats, 34.9ms\n",
      "Speed: 1.9ms preprocess, 34.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/39.jpg: 384x640 1 baseball bat, 1 carrot, 28.4ms\n",
      "Speed: 2.2ms preprocess, 28.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/40.jpg: 384x640 1 bottle, 25.5ms\n",
      "Speed: 1.6ms preprocess, 25.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/41.jpg: 384x640 1 baseball bat, 1 bottle, 1 carrot, 27.5ms\n",
      "Speed: 1.7ms preprocess, 27.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/42.jpg: 384x640 1 knife, 25.1ms\n",
      "Speed: 1.7ms preprocess, 25.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/43.jpg: 384x640 2 baseball bats, 1 carrot, 24.8ms\n",
      "Speed: 1.8ms preprocess, 24.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/44.jpg: 384x640 1 baseball bat, 1 carrot, 33.8ms\n",
      "Speed: 2.5ms preprocess, 33.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/45.jpg: 384x640 1 spoon, 1 carrot, 26.7ms\n",
      "Speed: 1.4ms preprocess, 26.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/46.jpg: 384x640 1 baseball bat, 1 carrot, 25.8ms\n",
      "Speed: 1.5ms preprocess, 25.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/47.jpg: 384x640 1 baseball bat, 1 carrot, 28.1ms\n",
      "Speed: 1.7ms preprocess, 28.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/48.jpg: 384x640 2 baseball bats, 25.6ms\n",
      "Speed: 1.9ms preprocess, 25.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/49.jpg: 384x640 2 baseball bats, 1 carrot, 25.3ms\n",
      "Speed: 1.4ms preprocess, 25.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/50.jpg: 384x640 1 spoon, 1 carrot, 36.5ms\n",
      "Speed: 1.9ms preprocess, 36.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/51.jpg: 384x640 2 spoons, 1 carrot, 24.6ms\n",
      "Speed: 1.7ms preprocess, 24.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/52.jpg: 384x640 1 baseball bat, 1 carrot, 26.8ms\n",
      "Speed: 1.7ms preprocess, 26.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/53.jpg: 384x640 1 carrot, 23.0ms\n",
      "Speed: 1.6ms preprocess, 23.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/54.jpg: 384x640 2 baseball bats, 1 carrot, 25.4ms\n",
      "Speed: 1.6ms preprocess, 25.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/55.jpg: 384x640 (no detections), 29.6ms\n",
      "Speed: 2.2ms preprocess, 29.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/56.jpg: 384x640 2 baseball bats, 1 spoon, 1 carrot, 26.3ms\n",
      "Speed: 1.6ms preprocess, 26.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/57.jpg: 384x640 1 baseball bat, 1 spoon, 1 carrot, 27.5ms\n",
      "Speed: 1.9ms preprocess, 27.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/58.jpg: 384x640 1 baseball bat, 27.4ms\n",
      "Speed: 2.1ms preprocess, 27.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/59.jpg: 384x640 1 baseball bat, 1 carrot, 40.4ms\n",
      "Speed: 1.7ms preprocess, 40.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/60.jpg: 384x640 1 baseball bat, 1 carrot, 31.3ms\n",
      "Speed: 2.0ms preprocess, 31.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/61.jpg: 384x640 2 baseball bats, 24.4ms\n",
      "Speed: 1.7ms preprocess, 24.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/62.jpg: 384x640 2 baseball bats, 32.6ms\n",
      "Speed: 2.2ms preprocess, 32.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/63.jpg: 384x640 1 spoon, 1 carrot, 25.6ms\n",
      "Speed: 2.1ms preprocess, 25.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/64.jpg: 384x640 2 spoons, 27.0ms\n",
      "Speed: 2.1ms preprocess, 27.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/65.jpg: 384x640 1 spoon, 24.4ms\n",
      "Speed: 1.6ms preprocess, 24.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/66.jpg: 384x640 1 baseball bat, 1 spoon, 29.2ms\n",
      "Speed: 1.7ms preprocess, 29.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/67.jpg: 384x640 1 baseball bat, 2 spoons, 35.8ms\n",
      "Speed: 1.7ms preprocess, 35.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/68.jpg: 384x640 2 baseball bats, 1 carrot, 27.7ms\n",
      "Speed: 1.9ms preprocess, 27.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/69.jpg: 384x640 1 baseball bat, 2 spoons, 28.4ms\n",
      "Speed: 1.5ms preprocess, 28.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/70.jpg: 384x640 2 spoons, 34.2ms\n",
      "Speed: 2.6ms preprocess, 34.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/71.jpg: 384x640 2 baseball bats, 1 spoon, 25.3ms\n",
      "Speed: 1.6ms preprocess, 25.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/72.jpg: 384x640 2 baseball bats, 28.8ms\n",
      "Speed: 2.1ms preprocess, 28.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/73.jpg: 384x640 2 baseball bats, 2 spoons, 25.8ms\n",
      "Speed: 1.5ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/74.jpg: 384x640 2 spoons, 43.6ms\n",
      "Speed: 1.9ms preprocess, 43.6ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/75.jpg: 384x640 1 knife, 23.4ms\n",
      "Speed: 1.7ms preprocess, 23.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/76.jpg: 384x640 1 spoon, 37.6ms\n",
      "Speed: 1.7ms preprocess, 37.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/77.jpg: 384x640 1 spoon, 2 carrots, 23.5ms\n",
      "Speed: 1.5ms preprocess, 23.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/78.jpg: 384x640 1 spoon, 1 carrot, 32.9ms\n",
      "Speed: 3.2ms preprocess, 32.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/79.jpg: 384x640 1 spoon, 1 carrot, 23.6ms\n",
      "Speed: 1.5ms preprocess, 23.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/80.jpg: 384x640 1 baseball bat, 1 spoon, 2 carrots, 31.8ms\n",
      "Speed: 2.2ms preprocess, 31.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/81.jpg: 384x640 1 baseball bat, 1 carrot, 28.4ms\n",
      "Speed: 1.6ms preprocess, 28.4ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/82.jpg: 384x640 1 carrot, 27.5ms\n",
      "Speed: 1.8ms preprocess, 27.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/83.jpg: 384x640 1 baseball bat, 1 spoon, 2 carrots, 25.2ms\n",
      "Speed: 1.7ms preprocess, 25.2ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/84.jpg: 384x640 1 baseball bat, 1 spoon, 4 carrots, 32.5ms\n",
      "Speed: 2.6ms preprocess, 32.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/85.jpg: 384x640 1 spoon, 1 carrot, 24.6ms\n",
      "Speed: 1.6ms preprocess, 24.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/86.jpg: 384x640 1 carrot, 30.4ms\n",
      "Speed: 1.8ms preprocess, 30.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/87.jpg: 384x640 1 baseball bat, 1 carrot, 26.3ms\n",
      "Speed: 1.8ms preprocess, 26.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/88.jpg: 384x640 2 spoons, 1 carrot, 45.2ms\n",
      "Speed: 1.7ms preprocess, 45.2ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/89.jpg: 384x640 (no detections), 41.4ms\n",
      "Speed: 1.8ms preprocess, 41.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/90.jpg: 384x640 2 spoons, 1 carrot, 32.1ms\n",
      "Speed: 1.6ms preprocess, 32.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/91.jpg: 384x640 2 spoons, 2 carrots, 24.1ms\n",
      "Speed: 1.6ms preprocess, 24.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/92.jpg: 384x640 1 knife, 1 spoon, 1 carrot, 51.0ms\n",
      "Speed: 1.9ms preprocess, 51.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/93.jpg: 384x640 1 baseball bat, 1 spoon, 46.9ms\n",
      "Speed: 1.6ms preprocess, 46.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/94.jpg: 384x640 1 baseball bat, 2 spoons, 28.8ms\n",
      "Speed: 1.6ms preprocess, 28.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/95.jpg: 384x640 1 baseball bat, 1 spoon, 23.6ms\n",
      "Speed: 1.6ms preprocess, 23.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/96.jpg: 384x640 1 spoon, 35.9ms\n",
      "Speed: 2.0ms preprocess, 35.9ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/97.jpg: 384x640 1 spoon, 26.3ms\n",
      "Speed: 1.6ms preprocess, 26.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/98.jpg: 384x640 1 spoon, 32.3ms\n",
      "Speed: 1.6ms preprocess, 32.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/99.jpg: 384x640 1 spoon, 38.2ms\n",
      "Speed: 1.6ms preprocess, 38.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/100.jpg: 384x640 1 knife, 1 spoon, 23.6ms\n",
      "Speed: 1.5ms preprocess, 23.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/101.jpg: 384x640 1 spoon, 27.1ms\n",
      "Speed: 1.5ms preprocess, 27.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/102.jpg: 384x640 1 spoon, 22.5ms\n",
      "Speed: 1.4ms preprocess, 22.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/103.jpg: 384x640 1 spoon, 1 carrot, 27.5ms\n",
      "Speed: 2.7ms preprocess, 27.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/104.jpg: 384x640 1 spoon, 25.2ms\n",
      "Speed: 1.6ms preprocess, 25.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/105.jpg: 384x640 1 spoon, 26.4ms\n",
      "Speed: 1.7ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/106.jpg: 384x640 1 spoon, 22.0ms\n",
      "Speed: 1.8ms preprocess, 22.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/107.jpg: 384x640 1 baseball bat, 1 knife, 1 spoon, 27.0ms\n",
      "Speed: 1.6ms preprocess, 27.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/108.jpg: 384x640 1 spoon, 35.8ms\n",
      "Speed: 2.4ms preprocess, 35.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/109.jpg: 384x640 2 spoons, 28.2ms\n",
      "Speed: 1.5ms preprocess, 28.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/110.jpg: 384x640 1 spoon, 2 carrots, 23.6ms\n",
      "Speed: 1.6ms preprocess, 23.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/111.jpg: 384x640 1 spoon, 1 carrot, 27.3ms\n",
      "Speed: 1.8ms preprocess, 27.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/112.jpg: 384x640 1 baseball bat, 1 carrot, 22.1ms\n",
      "Speed: 1.7ms preprocess, 22.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/113.jpg: 384x640 2 baseball bats, 2 carrots, 23.8ms\n",
      "Speed: 1.5ms preprocess, 23.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/114.jpg: 384x640 1 spoon, 1 carrot, 25.5ms\n",
      "Speed: 1.5ms preprocess, 25.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/115.jpg: 384x640 2 baseball bats, 1 spoon, 1 carrot, 23.1ms\n",
      "Speed: 1.4ms preprocess, 23.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/116.jpg: 384x640 2 baseball bats, 1 carrot, 26.6ms\n",
      "Speed: 2.0ms preprocess, 26.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/117.jpg: 384x640 2 baseball bats, 1 carrot, 25.8ms\n",
      "Speed: 1.7ms preprocess, 25.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/118.jpg: 384x640 2 baseball bats, 24.0ms\n",
      "Speed: 1.6ms preprocess, 24.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/119.jpg: 384x640 2 baseball bats, 1 carrot, 26.0ms\n",
      "Speed: 2.2ms preprocess, 26.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/120.jpg: 384x640 2 baseball bats, 23.6ms\n",
      "Speed: 1.5ms preprocess, 23.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/121.jpg: 384x640 1 baseball bat, 25.7ms\n",
      "Speed: 1.4ms preprocess, 25.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/122.jpg: 384x640 2 baseball bats, 2 spoons, 24.0ms\n",
      "Speed: 1.6ms preprocess, 24.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/123.jpg: 384x640 2 baseball bats, 1 spoon, 24.2ms\n",
      "Speed: 1.6ms preprocess, 24.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/124.jpg: 384x640 2 baseball bats, 2 spoons, 28.5ms\n",
      "Speed: 1.8ms preprocess, 28.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/125.jpg: 384x640 2 baseball bats, 25.8ms\n",
      "Speed: 1.6ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/126.jpg: 384x640 2 baseball bats, 1 spoon, 30.0ms\n",
      "Speed: 2.1ms preprocess, 30.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/127.jpg: 384x640 2 spoons, 22.8ms\n",
      "Speed: 1.5ms preprocess, 22.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/128.jpg: 384x640 2 spoons, 41.2ms\n",
      "Speed: 2.1ms preprocess, 41.2ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/129.jpg: 384x640 1 spoon, 22.7ms\n",
      "Speed: 1.6ms preprocess, 22.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/130.jpg: 384x640 1 spoon, 33.0ms\n",
      "Speed: 3.4ms preprocess, 33.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/131.jpg: 384x640 1 spoon, 25.1ms\n",
      "Speed: 1.6ms preprocess, 25.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/132.jpg: 384x640 1 spoon, 26.5ms\n",
      "Speed: 1.8ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/133.jpg: 384x640 1 bottle, 1 spoon, 49.7ms\n",
      "Speed: 1.5ms preprocess, 49.7ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/134.jpg: 384x640 1 spoon, 23.3ms\n",
      "Speed: 1.5ms preprocess, 23.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/135.jpg: 384x640 1 spoon, 25.8ms\n",
      "Speed: 1.4ms preprocess, 25.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/136.jpg: 384x640 (no detections), 22.3ms\n",
      "Speed: 1.8ms preprocess, 22.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/137.jpg: 384x640 1 spoon, 26.4ms\n",
      "Speed: 2.2ms preprocess, 26.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/138.jpg: 384x640 1 bottle, 1 knife, 1 spoon, 23.8ms\n",
      "Speed: 1.6ms preprocess, 23.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/139.jpg: 384x640 1 spoon, 29.8ms\n",
      "Speed: 1.9ms preprocess, 29.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/140.jpg: 384x640 1 knife, 23.8ms\n",
      "Speed: 1.6ms preprocess, 23.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/141.jpg: 384x640 1 knife, 1 spoon, 30.7ms\n",
      "Speed: 3.1ms preprocess, 30.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/142.jpg: 384x640 1 knife, 24.1ms\n",
      "Speed: 1.6ms preprocess, 24.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/143.jpg: 384x640 1 knife, 29.8ms\n",
      "Speed: 2.0ms preprocess, 29.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/144.jpg: 384x640 1 spoon, 1 toothbrush, 23.2ms\n",
      "Speed: 1.4ms preprocess, 23.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/145.jpg: 384x640 (no detections), 38.1ms\n",
      "Speed: 1.5ms preprocess, 38.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/146.jpg: 384x640 (no detections), 30.5ms\n",
      "Speed: 3.1ms preprocess, 30.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/147.jpg: 384x640 1 spoon, 45.7ms\n",
      "Speed: 1.9ms preprocess, 45.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/148.jpg: 384x640 1 spoon, 23.7ms\n",
      "Speed: 1.7ms preprocess, 23.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/149.jpg: 384x640 1 bottle, 36.0ms\n",
      "Speed: 1.9ms preprocess, 36.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/150.jpg: 384x640 1 bottle, 1 spoon, 24.6ms\n",
      "Speed: 1.8ms preprocess, 24.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/151.jpg: 384x640 1 bottle, 1 spoon, 32.0ms\n",
      "Speed: 1.6ms preprocess, 32.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/152.jpg: 384x640 1 baseball bat, 1 bottle, 1 spoon, 1 carrot, 28.8ms\n",
      "Speed: 2.9ms preprocess, 28.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/153.jpg: 384x640 1 bottle, 1 spoon, 2 carrots, 34.4ms\n",
      "Speed: 1.7ms preprocess, 34.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/154.jpg: 384x640 2 carrots, 25.0ms\n",
      "Speed: 1.6ms preprocess, 25.0ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/155.jpg: 384x640 1 baseball bat, 1 spoon, 2 carrots, 27.8ms\n",
      "Speed: 1.6ms preprocess, 27.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/156.jpg: 384x640 1 baseball bat, 1 bottle, 1 spoon, 1 carrot, 30.6ms\n",
      "Speed: 1.6ms preprocess, 30.6ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/157.jpg: 384x640 1 bottle, 1 carrot, 1 hot dog, 27.1ms\n",
      "Speed: 2.3ms preprocess, 27.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/158.jpg: 384x640 1 baseball bat, 33.8ms\n",
      "Speed: 1.7ms preprocess, 33.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/159.jpg: 384x640 1 baseball bat, 1 toothbrush, 27.0ms\n",
      "Speed: 1.8ms preprocess, 27.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/160.jpg: 384x640 1 spoon, 31.4ms\n",
      "Speed: 1.6ms preprocess, 31.4ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/161.jpg: 384x640 1 spoon, 22.6ms\n",
      "Speed: 1.5ms preprocess, 22.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/162.jpg: 384x640 2 spoons, 24.1ms\n",
      "Speed: 1.6ms preprocess, 24.1ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/163.jpg: 384x640 1 spoon, 26.9ms\n",
      "Speed: 1.8ms preprocess, 26.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/164.jpg: 384x640 1 spoon, 25.5ms\n",
      "Speed: 1.5ms preprocess, 25.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/165.jpg: 384x640 1 spoon, 27.0ms\n",
      "Speed: 1.9ms preprocess, 27.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/166.jpg: 384x640 1 spoon, 32.1ms\n",
      "Speed: 1.6ms preprocess, 32.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/167.jpg: 384x640 1 spoon, 27.0ms\n",
      "Speed: 1.6ms preprocess, 27.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/168.jpg: 384x640 1 spoon, 36.1ms\n",
      "Speed: 1.6ms preprocess, 36.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/169.jpg: 384x640 1 knife, 1 spoon, 23.0ms\n",
      "Speed: 3.0ms preprocess, 23.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/170.jpg: 384x640 2 spoons, 45.0ms\n",
      "Speed: 1.7ms preprocess, 45.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/171.jpg: 384x640 1 spoon, 27.0ms\n",
      "Speed: 1.6ms preprocess, 27.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/172.jpg: 384x640 1 spoon, 32.8ms\n",
      "Speed: 1.6ms preprocess, 32.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/173.jpg: 384x640 1 bottle, 1 knife, 22.3ms\n",
      "Speed: 1.8ms preprocess, 22.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/174.jpg: 384x640 1 bottle, 1 spoon, 24.3ms\n",
      "Speed: 1.6ms preprocess, 24.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/175.jpg: 384x640 (no detections), 31.1ms\n",
      "Speed: 1.6ms preprocess, 31.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/176.jpg: 384x640 1 bottle, 1 hot dog, 34.9ms\n",
      "Speed: 1.7ms preprocess, 34.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/177.jpg: 384x640 1 spoon, 1 hot dog, 25.5ms\n",
      "Speed: 2.9ms preprocess, 25.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/178.jpg: 384x640 1 spoon, 1 carrot, 31.2ms\n",
      "Speed: 1.6ms preprocess, 31.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/179.jpg: 384x640 1 baseball bat, 1 spoon, 1 carrot, 24.5ms\n",
      "Speed: 1.6ms preprocess, 24.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/180.jpg: 384x640 1 baseball bat, 1 carrot, 49.8ms\n",
      "Speed: 1.9ms preprocess, 49.8ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/181.jpg: 384x640 1 spoon, 4 carrots, 25.0ms\n",
      "Speed: 1.8ms preprocess, 25.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/182.jpg: 384x640 1 spoon, 1 carrot, 24.5ms\n",
      "Speed: 1.7ms preprocess, 24.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/183.jpg: 384x640 1 spoon, 2 carrots, 35.0ms\n",
      "Speed: 2.7ms preprocess, 35.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/184.jpg: 384x640 2 baseball bats, 1 spoon, 28.5ms\n",
      "Speed: 1.6ms preprocess, 28.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/185.jpg: 384x640 1 baseball bat, 1 spoon, 30.8ms\n",
      "Speed: 2.0ms preprocess, 30.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/186.jpg: 384x640 1 baseball bat, 1 spoon, 22.6ms\n",
      "Speed: 1.5ms preprocess, 22.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/187.jpg: 384x640 2 baseball bats, 1 spoon, 32.2ms\n",
      "Speed: 1.7ms preprocess, 32.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/188.jpg: 384x640 2 spoons, 1 carrot, 22.5ms\n",
      "Speed: 1.5ms preprocess, 22.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/189.jpg: 384x640 1 baseball bat, 2 spoons, 1 carrot, 36.6ms\n",
      "Speed: 1.7ms preprocess, 36.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/190.jpg: 384x640 2 spoons, 26.3ms\n",
      "Speed: 1.6ms preprocess, 26.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/191.jpg: 384x640 2 baseball bats, 1 spoon, 1 carrot, 25.8ms\n",
      "Speed: 2.3ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/192.jpg: 384x640 1 spoon, 24.9ms\n",
      "Speed: 1.6ms preprocess, 24.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/193.jpg: 384x640 1 baseball bat, 44.5ms\n",
      "Speed: 1.7ms preprocess, 44.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/194.jpg: 384x640 1 spoon, 1 carrot, 22.7ms\n",
      "Speed: 1.5ms preprocess, 22.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/195.jpg: 384x640 2 baseball bats, 2 spoons, 35.4ms\n",
      "Speed: 2.3ms preprocess, 35.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/196.jpg: 384x640 2 baseball bats, 1 carrot, 23.3ms\n",
      "Speed: 1.8ms preprocess, 23.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/197.jpg: 384x640 2 baseball bats, 1 spoon, 1 carrot, 44.3ms\n",
      "Speed: 1.9ms preprocess, 44.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/198.jpg: 384x640 2 baseball bats, 1 spoon, 1 carrot, 24.5ms\n",
      "Speed: 1.8ms preprocess, 24.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/199.jpg: 384x640 1 spoon, 1 carrot, 36.9ms\n",
      "Speed: 2.4ms preprocess, 36.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/200.jpg: 384x640 1 baseball bat, 2 carrots, 28.8ms\n",
      "Speed: 1.7ms preprocess, 28.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/201.jpg: 384x640 2 baseball bats, 1 spoon, 3 carrots, 37.6ms\n",
      "Speed: 1.6ms preprocess, 37.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/202.jpg: 384x640 1 baseball bat, 1 spoon, 3 carrots, 23.5ms\n",
      "Speed: 1.6ms preprocess, 23.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/203.jpg: 384x640 2 carrots, 26.9ms\n",
      "Speed: 1.8ms preprocess, 26.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/204.jpg: 384x640 1 spoon, 4 carrots, 25.5ms\n",
      "Speed: 1.6ms preprocess, 25.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/205.jpg: 384x640 3 carrots, 28.2ms\n",
      "Speed: 2.8ms preprocess, 28.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/206.jpg: 384x640 1 spoon, 3 carrots, 26.4ms\n",
      "Speed: 1.6ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/207.jpg: 384x640 1 baseball bat, 2 carrots, 47.6ms\n",
      "Speed: 1.6ms preprocess, 47.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/208.jpg: 384x640 3 carrots, 23.2ms\n",
      "Speed: 1.5ms preprocess, 23.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/209.jpg: 384x640 1 baseball bat, 1 spoon, 2 carrots, 35.6ms\n",
      "Speed: 2.6ms preprocess, 35.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/210.jpg: 384x640 1 baseball bat, 2 carrots, 27.5ms\n",
      "Speed: 1.5ms preprocess, 27.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/211.jpg: 384x640 1 baseball bat, 1 spoon, 4 carrots, 1 hot dog, 25.2ms\n",
      "Speed: 2.1ms preprocess, 25.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/212.jpg: 384x640 1 spoon, 2 carrots, 35.2ms\n",
      "Speed: 1.5ms preprocess, 35.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/213.jpg: 384x640 1 spoon, 2 carrots, 28.4ms\n",
      "Speed: 2.0ms preprocess, 28.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/214.jpg: 384x640 1 spoon, 3 carrots, 1 hot dog, 24.3ms\n",
      "Speed: 1.6ms preprocess, 24.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/215.jpg: 384x640 1 spoon, 3 carrots, 30.5ms\n",
      "Speed: 1.5ms preprocess, 30.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/216.jpg: 384x640 1 spoon, 3 carrots, 27.8ms\n",
      "Speed: 1.7ms preprocess, 27.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/217.jpg: 384x640 1 spoon, 3 carrots, 2 hot dogs, 29.3ms\n",
      "Speed: 1.6ms preprocess, 29.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/218.jpg: 384x640 1 spoon, 2 carrots, 28.1ms\n",
      "Speed: 3.4ms preprocess, 28.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/219.jpg: 384x640 1 spoon, 2 carrots, 36.1ms\n",
      "Speed: 2.0ms preprocess, 36.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/220.jpg: 384x640 1 spoon, 2 carrots, 39.0ms\n",
      "Speed: 1.6ms preprocess, 39.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/221.jpg: 384x640 1 baseball bat, 1 spoon, 30.3ms\n",
      "Speed: 1.7ms preprocess, 30.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/222.jpg: 384x640 1 knife, 2 spoons, 23.2ms\n",
      "Speed: 1.5ms preprocess, 23.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/223.jpg: 384x640 2 knifes, 1 spoon, 31.9ms\n",
      "Speed: 2.8ms preprocess, 31.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/224.jpg: 384x640 1 knife, 1 spoon, 42.7ms\n",
      "Speed: 1.4ms preprocess, 42.7ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/225.jpg: 384x640 2 spoons, 27.7ms\n",
      "Speed: 1.5ms preprocess, 27.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/226.jpg: 384x640 1 knife, 2 spoons, 22.9ms\n",
      "Speed: 1.6ms preprocess, 22.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/227.jpg: 384x640 2 spoons, 25.2ms\n",
      "Speed: 1.5ms preprocess, 25.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/228.jpg: 384x640 1 knife, 2 spoons, 1 carrot, 29.0ms\n",
      "Speed: 1.7ms preprocess, 29.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/229.jpg: 384x640 2 spoons, 30.0ms\n",
      "Speed: 2.4ms preprocess, 30.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/230.jpg: 384x640 2 spoons, 1 carrot, 29.3ms\n",
      "Speed: 2.0ms preprocess, 29.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/231.jpg: 384x640 2 spoons, 23.1ms\n",
      "Speed: 1.5ms preprocess, 23.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/232.jpg: 384x640 2 spoons, 1 carrot, 24.4ms\n",
      "Speed: 2.4ms preprocess, 24.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/233.jpg: 384x640 2 spoons, 27.4ms\n",
      "Speed: 1.5ms preprocess, 27.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/234.jpg: 384x640 1 knife, 2 spoons, 1 carrot, 30.3ms\n",
      "Speed: 1.6ms preprocess, 30.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/235.jpg: 384x640 1 baseball bat, 2 spoons, 1 carrot, 36.4ms\n",
      "Speed: 1.6ms preprocess, 36.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/236.jpg: 384x640 2 spoons, 28.4ms\n",
      "Speed: 1.8ms preprocess, 28.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/237.jpg: 384x640 1 baseball bat, 1 spoon, 26.7ms\n",
      "Speed: 1.5ms preprocess, 26.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/238.jpg: 384x640 2 spoons, 27.5ms\n",
      "Speed: 3.4ms preprocess, 27.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/239.jpg: 384x640 2 spoons, 22.7ms\n",
      "Speed: 1.5ms preprocess, 22.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/240.jpg: 384x640 1 baseball bat, 2 spoons, 28.2ms\n",
      "Speed: 1.8ms preprocess, 28.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/241.jpg: 384x640 2 spoons, 23.4ms\n",
      "Speed: 1.6ms preprocess, 23.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/242.jpg: 384x640 2 spoons, 30.6ms\n",
      "Speed: 1.9ms preprocess, 30.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/243.jpg: 384x640 2 spoons, 3 carrots, 25.5ms\n",
      "Speed: 1.7ms preprocess, 25.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/244.jpg: 384x640 2 spoons, 1 carrot, 37.1ms\n",
      "Speed: 1.7ms preprocess, 37.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/245.jpg: 384x640 2 spoons, 1 carrot, 30.9ms\n",
      "Speed: 1.6ms preprocess, 30.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/246.jpg: 384x640 2 spoons, 27.6ms\n",
      "Speed: 2.4ms preprocess, 27.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/247.jpg: 384x640 1 baseball bat, 1 spoon, 32.0ms\n",
      "Speed: 2.8ms preprocess, 32.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/248.jpg: 384x640 2 baseball bats, 2 spoons, 24.0ms\n",
      "Speed: 1.5ms preprocess, 24.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/249.jpg: 384x640 2 baseball bats, 2 spoons, 29.0ms\n",
      "Speed: 2.4ms preprocess, 29.0ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/250.jpg: 384x640 2 spoons, 2 carrots, 46.1ms\n",
      "Speed: 3.2ms preprocess, 46.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/251.jpg: 384x640 2 spoons, 23.5ms\n",
      "Speed: 1.4ms preprocess, 23.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/252.jpg: 384x640 1 baseball bat, 2 spoons, 34.8ms\n",
      "Speed: 1.8ms preprocess, 34.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/253.jpg: 384x640 1 baseball bat, 2 spoons, 23.4ms\n",
      "Speed: 2.3ms preprocess, 23.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/254.jpg: 384x640 2 spoons, 23.4ms\n",
      "Speed: 1.8ms preprocess, 23.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/255.jpg: 384x640 1 baseball bat, 25.3ms\n",
      "Speed: 1.5ms preprocess, 25.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/256.jpg: 384x640 1 spoon, 1 carrot, 23.4ms\n",
      "Speed: 1.5ms preprocess, 23.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/257.jpg: 384x640 1 spoon, 1 carrot, 23.6ms\n",
      "Speed: 1.5ms preprocess, 23.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/258.jpg: 384x640 2 carrots, 28.2ms\n",
      "Speed: 1.6ms preprocess, 28.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/259.jpg: 384x640 1 baseball bat, 1 spoon, 1 carrot, 23.1ms\n",
      "Speed: 1.6ms preprocess, 23.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/260.jpg: 384x640 1 spoon, 23.4ms\n",
      "Speed: 1.8ms preprocess, 23.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/261.jpg: 384x640 1 baseball bat, 1 spoon, 1 carrot, 22.6ms\n",
      "Speed: 1.4ms preprocess, 22.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/262.jpg: 384x640 2 baseball bats, 1 spoon, 22.8ms\n",
      "Speed: 1.6ms preprocess, 22.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/263.jpg: 384x640 2 baseball bats, 1 spoon, 49.0ms\n",
      "Speed: 2.7ms preprocess, 49.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/264.jpg: 384x640 2 spoons, 22.6ms\n",
      "Speed: 1.6ms preprocess, 22.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/265.jpg: 384x640 1 baseball bat, 2 spoons, 2 carrots, 24.4ms\n",
      "Speed: 2.5ms preprocess, 24.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/266.jpg: 384x640 2 spoons, 22.2ms\n",
      "Speed: 1.6ms preprocess, 22.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/267.jpg: 384x640 2 spoons, 1 bowl, 1 carrot, 29.7ms\n",
      "Speed: 1.6ms preprocess, 29.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/268.jpg: 384x640 1 spoon, 1 carrot, 25.2ms\n",
      "Speed: 2.1ms preprocess, 25.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/269.jpg: 384x640 1 spoon, 1 carrot, 23.4ms\n",
      "Speed: 1.5ms preprocess, 23.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/270.jpg: 384x640 2 spoons, 23.7ms\n",
      "Speed: 1.6ms preprocess, 23.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/271.jpg: 384x640 1 baseball bat, 31.6ms\n",
      "Speed: 2.8ms preprocess, 31.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/272.jpg: 384x640 1 baseball bat, 1 spoon, 26.0ms\n",
      "Speed: 2.2ms preprocess, 26.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/273.jpg: 384x640 2 spoons, 45.9ms\n",
      "Speed: 1.7ms preprocess, 45.9ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/274.jpg: 384x640 1 baseball bat, 2 spoons, 1 carrot, 23.0ms\n",
      "Speed: 1.8ms preprocess, 23.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/275.jpg: 384x640 1 baseball bat, 25.6ms\n",
      "Speed: 1.5ms preprocess, 25.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/276.jpg: 384x640 1 baseball bat, 1 spoon, 30.9ms\n",
      "Speed: 3.0ms preprocess, 30.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/277.jpg: 384x640 2 baseball bats, 22.2ms\n",
      "Speed: 1.5ms preprocess, 22.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/278.jpg: 384x640 2 baseball bats, 2 spoons, 25.1ms\n",
      "Speed: 3.1ms preprocess, 25.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/279.jpg: 384x640 1 baseball bat, 1 spoon, 22.7ms\n",
      "Speed: 1.6ms preprocess, 22.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/280.jpg: 384x640 2 baseball bats, 1 spoon, 2 carrots, 36.9ms\n",
      "Speed: 2.4ms preprocess, 36.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/281.jpg: 384x640 2 baseball bats, 1 spoon, 1 carrot, 33.1ms\n",
      "Speed: 1.8ms preprocess, 33.1ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/282.jpg: 384x640 2 spoons, 2 carrots, 29.1ms\n",
      "Speed: 1.9ms preprocess, 29.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/283.jpg: 384x640 2 spoons, 3 carrots, 29.3ms\n",
      "Speed: 1.5ms preprocess, 29.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/284.jpg: 384x640 1 spoon, 4 carrots, 31.7ms\n",
      "Speed: 1.8ms preprocess, 31.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/285.jpg: 384x640 2 spoons, 1 carrot, 22.1ms\n",
      "Speed: 1.3ms preprocess, 22.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/286.jpg: 384x640 1 knife, 2 spoons, 2 carrots, 23.4ms\n",
      "Speed: 1.8ms preprocess, 23.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/287.jpg: 384x640 2 spoons, 4 carrots, 38.9ms\n",
      "Speed: 1.8ms preprocess, 38.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/288.jpg: 384x640 2 spoons, 3 carrots, 23.0ms\n",
      "Speed: 1.6ms preprocess, 23.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/289.jpg: 384x640 1 spoon, 3 carrots, 22.0ms\n",
      "Speed: 1.5ms preprocess, 22.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/290.jpg: 384x640 2 spoons, 2 carrots, 22.8ms\n",
      "Speed: 1.6ms preprocess, 22.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/291.jpg: 384x640 1 spoon, 3 carrots, 22.1ms\n",
      "Speed: 1.5ms preprocess, 22.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/292.jpg: 384x640 1 spoon, 3 carrots, 25.3ms\n",
      "Speed: 1.5ms preprocess, 25.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/293.jpg: 384x640 1 carrot, 21.8ms\n",
      "Speed: 3.1ms preprocess, 21.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/294.jpg: 384x640 1 knife, 1 carrot, 24.0ms\n",
      "Speed: 1.4ms preprocess, 24.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/295.jpg: 384x640 1 knife, 2 spoons, 5 carrots, 23.4ms\n",
      "Speed: 1.7ms preprocess, 23.4ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/296.jpg: 384x640 1 spoon, 24.1ms\n",
      "Speed: 1.5ms preprocess, 24.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/297.jpg: 384x640 1 knife, 28.6ms\n",
      "Speed: 2.1ms preprocess, 28.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/298.jpg: 384x640 2 knifes, 22.6ms\n",
      "Speed: 1.4ms preprocess, 22.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/blood/right/299.jpg: 384x640 1 knife, 28.0ms\n",
      "Speed: 2.6ms preprocess, 28.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Propagating video frames: 100%|| 300/300 [00:18<00:00, 16.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask propagation completed in 18.71 seconds.\n",
      "Processing predicted masks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing video frames: 300it [00:01, 241.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 300 masks for evaluation.\n",
      "Masks saved to data/masks/yolo11x-seg/val/data-raw-SegSTRONGC_val-val-1-0-blood-right.pkl\n",
      "Loading ground truth masks for evaluation...\n",
      "Loaded 300 ground truth masks.\n",
      "Calculating evaluation metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for metrics calculation: 1.34 seconds.\n",
      "Mean IoU for data/raw/SegSTRONGC_val/val/1/0/blood/right: 0.5046\n",
      "Mean DSC for data/raw/SegSTRONGC_val/val/1/0/blood/right: 0.6149\n",
      "Loading existing results file: data/results/yolo11x-seg/val.json\n",
      "Results saved to data/results/yolo11x-seg/val.json\n",
      "Processing video took 22.71 seconds.\n",
      "==================================================\n",
      "\n",
      "Results for data/raw/SegSTRONGC_val/val/1/0/blood:\n",
      "  Left: IoU=0.5838, DSC=0.6940\n",
      "  Right: IoU=0.5046, DSC=0.6149\n",
      "  Overall: IoU=0.5442, DSC=0.6544\n",
      "\n",
      "Processing domain: low_brightness\n",
      "Processing left camera video...\n",
      "==================================================\n",
      "Processing video: data/raw/SegSTRONGC_val/val/1/0/low_brightness/left\n",
      "Domain: low_brightness, Split: val, Camera: left\n",
      "Initializing Yolo for video...\n",
      "Initialization took 0.12 seconds.\n",
      "Starting mask propagation...\n",
      "Total images in video: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/0.jpg: 384x640 (no detections), 64.5ms\n",
      "Speed: 2.5ms preprocess, 64.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/1.jpg: 384x640 (no detections), 64.4ms\n",
      "Speed: 2.0ms preprocess, 64.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/2.jpg: 384x640 1 motorcycle, 25.0ms\n",
      "Speed: 1.7ms preprocess, 25.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/3.jpg: 384x640 1 toothbrush, 28.0ms\n",
      "Speed: 1.9ms preprocess, 28.0ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/4.jpg: 384x640 1 toothbrush, 24.7ms\n",
      "Speed: 1.5ms preprocess, 24.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/5.jpg: 384x640 1 airplane, 25.0ms\n",
      "Speed: 1.4ms preprocess, 25.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/6.jpg: 384x640 (no detections), 26.2ms\n",
      "Speed: 1.6ms preprocess, 26.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/7.jpg: 384x640 1 toothbrush, 25.0ms\n",
      "Speed: 1.5ms preprocess, 25.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/8.jpg: 384x640 (no detections), 40.1ms\n",
      "Speed: 2.3ms preprocess, 40.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/9.jpg: 384x640 (no detections), 28.7ms\n",
      "Speed: 1.7ms preprocess, 28.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/10.jpg: 384x640 (no detections), 27.3ms\n",
      "Speed: 4.4ms preprocess, 27.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/11.jpg: 384x640 (no detections), 44.3ms\n",
      "Speed: 1.8ms preprocess, 44.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/12.jpg: 384x640 (no detections), 33.0ms\n",
      "Speed: 3.1ms preprocess, 33.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/13.jpg: 384x640 (no detections), 23.7ms\n",
      "Speed: 1.7ms preprocess, 23.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/14.jpg: 384x640 (no detections), 26.7ms\n",
      "Speed: 2.5ms preprocess, 26.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/15.jpg: 384x640 (no detections), 23.8ms\n",
      "Speed: 1.6ms preprocess, 23.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/16.jpg: 384x640 1 toothbrush, 25.5ms\n",
      "Speed: 3.1ms preprocess, 25.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/17.jpg: 384x640 (no detections), 23.4ms\n",
      "Speed: 1.6ms preprocess, 23.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/18.jpg: 384x640 1 toothbrush, 24.8ms\n",
      "Speed: 1.6ms preprocess, 24.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/19.jpg: 384x640 (no detections), 25.0ms\n",
      "Speed: 1.6ms preprocess, 25.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/20.jpg: 384x640 1 motorcycle, 52.1ms\n",
      "Speed: 1.5ms preprocess, 52.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/21.jpg: 384x640 (no detections), 22.9ms\n",
      "Speed: 1.5ms preprocess, 22.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/22.jpg: 384x640 1 toothbrush, 34.2ms\n",
      "Speed: 1.6ms preprocess, 34.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/23.jpg: 384x640 1 toothbrush, 22.6ms\n",
      "Speed: 1.4ms preprocess, 22.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/24.jpg: 384x640 (no detections), 45.9ms\n",
      "Speed: 1.5ms preprocess, 45.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/25.jpg: 384x640 1 toothbrush, 28.1ms\n",
      "Speed: 2.2ms preprocess, 28.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/26.jpg: 384x640 1 motorcycle, 36.7ms\n",
      "Speed: 2.4ms preprocess, 36.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/27.jpg: 384x640 (no detections), 34.0ms\n",
      "Speed: 2.0ms preprocess, 34.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/28.jpg: 384x640 (no detections), 37.8ms\n",
      "Speed: 1.6ms preprocess, 37.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/29.jpg: 384x640 (no detections), 24.8ms\n",
      "Speed: 1.6ms preprocess, 24.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/30.jpg: 384x640 1 toothbrush, 23.0ms\n",
      "Speed: 1.4ms preprocess, 23.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/31.jpg: 384x640 (no detections), 30.0ms\n",
      "Speed: 2.9ms preprocess, 30.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/32.jpg: 384x640 1 motorcycle, 32.0ms\n",
      "Speed: 2.0ms preprocess, 32.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/33.jpg: 384x640 (no detections), 34.5ms\n",
      "Speed: 1.9ms preprocess, 34.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/34.jpg: 384x640 1 toothbrush, 22.7ms\n",
      "Speed: 1.8ms preprocess, 22.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/35.jpg: 384x640 1 toothbrush, 35.4ms\n",
      "Speed: 1.8ms preprocess, 35.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/36.jpg: 384x640 (no detections), 31.0ms\n",
      "Speed: 1.5ms preprocess, 31.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/37.jpg: 384x640 1 toothbrush, 28.4ms\n",
      "Speed: 3.2ms preprocess, 28.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/38.jpg: 384x640 (no detections), 22.8ms\n",
      "Speed: 1.6ms preprocess, 22.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/39.jpg: 384x640 (no detections), 26.3ms\n",
      "Speed: 1.5ms preprocess, 26.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/40.jpg: 384x640 (no detections), 25.7ms\n",
      "Speed: 1.5ms preprocess, 25.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/41.jpg: 384x640 (no detections), 34.2ms\n",
      "Speed: 1.6ms preprocess, 34.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/42.jpg: 384x640 1 toothbrush, 29.2ms\n",
      "Speed: 1.9ms preprocess, 29.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/43.jpg: 384x640 1 airplane, 30.4ms\n",
      "Speed: 1.8ms preprocess, 30.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/44.jpg: 384x640 (no detections), 25.6ms\n",
      "Speed: 1.5ms preprocess, 25.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/45.jpg: 384x640 (no detections), 37.0ms\n",
      "Speed: 3.2ms preprocess, 37.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/46.jpg: 384x640 (no detections), 23.1ms\n",
      "Speed: 1.8ms preprocess, 23.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/47.jpg: 384x640 (no detections), 24.8ms\n",
      "Speed: 2.5ms preprocess, 24.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/48.jpg: 384x640 (no detections), 23.0ms\n",
      "Speed: 1.5ms preprocess, 23.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/49.jpg: 384x640 (no detections), 23.4ms\n",
      "Speed: 1.6ms preprocess, 23.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/50.jpg: 384x640 (no detections), 27.1ms\n",
      "Speed: 1.9ms preprocess, 27.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/51.jpg: 384x640 (no detections), 25.2ms\n",
      "Speed: 1.6ms preprocess, 25.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/52.jpg: 384x640 (no detections), 37.0ms\n",
      "Speed: 1.6ms preprocess, 37.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/53.jpg: 384x640 (no detections), 25.3ms\n",
      "Speed: 1.7ms preprocess, 25.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/54.jpg: 384x640 (no detections), 27.8ms\n",
      "Speed: 1.7ms preprocess, 27.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/55.jpg: 384x640 (no detections), 25.0ms\n",
      "Speed: 2.2ms preprocess, 25.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/56.jpg: 384x640 (no detections), 28.6ms\n",
      "Speed: 1.5ms preprocess, 28.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/57.jpg: 384x640 (no detections), 45.5ms\n",
      "Speed: 1.7ms preprocess, 45.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/58.jpg: 384x640 (no detections), 36.5ms\n",
      "Speed: 3.1ms preprocess, 36.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/59.jpg: 384x640 (no detections), 22.8ms\n",
      "Speed: 1.6ms preprocess, 22.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/60.jpg: 384x640 (no detections), 41.6ms\n",
      "Speed: 4.7ms preprocess, 41.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/61.jpg: 384x640 1 motorcycle, 22.3ms\n",
      "Speed: 1.5ms preprocess, 22.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/62.jpg: 384x640 (no detections), 31.4ms\n",
      "Speed: 2.6ms preprocess, 31.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/63.jpg: 384x640 (no detections), 27.4ms\n",
      "Speed: 1.9ms preprocess, 27.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/64.jpg: 384x640 (no detections), 36.3ms\n",
      "Speed: 1.7ms preprocess, 36.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/65.jpg: 384x640 (no detections), 23.7ms\n",
      "Speed: 1.7ms preprocess, 23.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/66.jpg: 384x640 (no detections), 47.6ms\n",
      "Speed: 1.9ms preprocess, 47.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/67.jpg: 384x640 (no detections), 31.7ms\n",
      "Speed: 1.6ms preprocess, 31.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/68.jpg: 384x640 (no detections), 32.9ms\n",
      "Speed: 1.7ms preprocess, 32.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/69.jpg: 384x640 (no detections), 30.6ms\n",
      "Speed: 1.7ms preprocess, 30.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/70.jpg: 384x640 (no detections), 23.6ms\n",
      "Speed: 1.7ms preprocess, 23.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/71.jpg: 384x640 (no detections), 24.4ms\n",
      "Speed: 1.9ms preprocess, 24.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/72.jpg: 384x640 (no detections), 23.9ms\n",
      "Speed: 1.4ms preprocess, 23.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/73.jpg: 384x640 (no detections), 38.6ms\n",
      "Speed: 1.6ms preprocess, 38.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/74.jpg: 384x640 (no detections), 22.9ms\n",
      "Speed: 1.7ms preprocess, 22.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/75.jpg: 384x640 (no detections), 22.6ms\n",
      "Speed: 1.6ms preprocess, 22.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/76.jpg: 384x640 (no detections), 21.8ms\n",
      "Speed: 1.7ms preprocess, 21.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/77.jpg: 384x640 (no detections), 27.1ms\n",
      "Speed: 1.6ms preprocess, 27.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/78.jpg: 384x640 (no detections), 22.6ms\n",
      "Speed: 1.7ms preprocess, 22.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/79.jpg: 384x640 1 toothbrush, 25.9ms\n",
      "Speed: 2.4ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/80.jpg: 384x640 1 toothbrush, 35.5ms\n",
      "Speed: 1.7ms preprocess, 35.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/81.jpg: 384x640 (no detections), 33.3ms\n",
      "Speed: 2.2ms preprocess, 33.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/82.jpg: 384x640 1 toothbrush, 47.4ms\n",
      "Speed: 1.7ms preprocess, 47.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/83.jpg: 384x640 (no detections), 30.5ms\n",
      "Speed: 1.7ms preprocess, 30.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/84.jpg: 384x640 (no detections), 25.7ms\n",
      "Speed: 1.5ms preprocess, 25.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/85.jpg: 384x640 (no detections), 23.6ms\n",
      "Speed: 1.9ms preprocess, 23.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/86.jpg: 384x640 (no detections), 24.5ms\n",
      "Speed: 1.5ms preprocess, 24.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/87.jpg: 384x640 1 toothbrush, 26.1ms\n",
      "Speed: 1.5ms preprocess, 26.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/88.jpg: 384x640 1 toothbrush, 32.0ms\n",
      "Speed: 3.0ms preprocess, 32.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/89.jpg: 384x640 1 toothbrush, 28.5ms\n",
      "Speed: 1.9ms preprocess, 28.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/90.jpg: 384x640 1 toothbrush, 27.3ms\n",
      "Speed: 1.6ms preprocess, 27.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/91.jpg: 384x640 1 toothbrush, 32.1ms\n",
      "Speed: 2.1ms preprocess, 32.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/92.jpg: 384x640 1 toothbrush, 23.3ms\n",
      "Speed: 1.6ms preprocess, 23.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/93.jpg: 384x640 (no detections), 24.6ms\n",
      "Speed: 1.6ms preprocess, 24.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/94.jpg: 384x640 (no detections), 29.5ms\n",
      "Speed: 1.6ms preprocess, 29.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/95.jpg: 384x640 (no detections), 23.9ms\n",
      "Speed: 1.7ms preprocess, 23.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/96.jpg: 384x640 (no detections), 40.8ms\n",
      "Speed: 1.9ms preprocess, 40.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/97.jpg: 384x640 (no detections), 27.2ms\n",
      "Speed: 1.7ms preprocess, 27.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/98.jpg: 384x640 1 scissors, 24.6ms\n",
      "Speed: 1.6ms preprocess, 24.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/99.jpg: 384x640 (no detections), 34.7ms\n",
      "Speed: 3.2ms preprocess, 34.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/100.jpg: 384x640 (no detections), 22.4ms\n",
      "Speed: 1.6ms preprocess, 22.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/101.jpg: 384x640 1 motorcycle, 26.6ms\n",
      "Speed: 1.8ms preprocess, 26.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/102.jpg: 384x640 1 motorcycle, 24.5ms\n",
      "Speed: 1.7ms preprocess, 24.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/103.jpg: 384x640 1 toothbrush, 47.1ms\n",
      "Speed: 3.2ms preprocess, 47.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/104.jpg: 384x640 1 toothbrush, 27.2ms\n",
      "Speed: 1.8ms preprocess, 27.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/105.jpg: 384x640 1 airplane, 39.9ms\n",
      "Speed: 1.8ms preprocess, 39.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/106.jpg: 384x640 (no detections), 21.8ms\n",
      "Speed: 1.4ms preprocess, 21.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/107.jpg: 384x640 1 toothbrush, 35.0ms\n",
      "Speed: 2.0ms preprocess, 35.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/108.jpg: 384x640 (no detections), 35.9ms\n",
      "Speed: 1.8ms preprocess, 35.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/109.jpg: 384x640 (no detections), 39.8ms\n",
      "Speed: 3.0ms preprocess, 39.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/110.jpg: 384x640 (no detections), 26.2ms\n",
      "Speed: 1.7ms preprocess, 26.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/111.jpg: 384x640 1 toothbrush, 26.4ms\n",
      "Speed: 1.6ms preprocess, 26.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/112.jpg: 384x640 (no detections), 25.0ms\n",
      "Speed: 1.6ms preprocess, 25.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/113.jpg: 384x640 (no detections), 40.0ms\n",
      "Speed: 3.3ms preprocess, 40.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/114.jpg: 384x640 1 motorcycle, 30.1ms\n",
      "Speed: 2.1ms preprocess, 30.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/115.jpg: 384x640 (no detections), 27.0ms\n",
      "Speed: 1.6ms preprocess, 27.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/116.jpg: 384x640 (no detections), 33.0ms\n",
      "Speed: 1.6ms preprocess, 33.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/117.jpg: 384x640 1 motorcycle, 24.7ms\n",
      "Speed: 1.9ms preprocess, 24.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/118.jpg: 384x640 (no detections), 46.8ms\n",
      "Speed: 1.7ms preprocess, 46.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/119.jpg: 384x640 (no detections), 29.4ms\n",
      "Speed: 1.9ms preprocess, 29.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/120.jpg: 384x640 (no detections), 25.8ms\n",
      "Speed: 1.8ms preprocess, 25.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/121.jpg: 384x640 (no detections), 22.7ms\n",
      "Speed: 1.6ms preprocess, 22.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/122.jpg: 384x640 1 motorcycle, 25.0ms\n",
      "Speed: 2.2ms preprocess, 25.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/123.jpg: 384x640 1 motorcycle, 26.7ms\n",
      "Speed: 1.8ms preprocess, 26.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/124.jpg: 384x640 1 motorcycle, 38.5ms\n",
      "Speed: 1.7ms preprocess, 38.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/125.jpg: 384x640 1 airplane, 25.2ms\n",
      "Speed: 1.6ms preprocess, 25.2ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/126.jpg: 384x640 1 motorcycle, 41.4ms\n",
      "Speed: 1.7ms preprocess, 41.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/127.jpg: 384x640 1 motorcycle, 24.6ms\n",
      "Speed: 1.6ms preprocess, 24.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/128.jpg: 384x640 1 motorcycle, 44.0ms\n",
      "Speed: 3.3ms preprocess, 44.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/129.jpg: 384x640 1 motorcycle, 39.0ms\n",
      "Speed: 1.7ms preprocess, 39.0ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/130.jpg: 384x640 1 toothbrush, 23.8ms\n",
      "Speed: 1.7ms preprocess, 23.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/131.jpg: 384x640 1 motorcycle, 28.0ms\n",
      "Speed: 1.5ms preprocess, 28.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/132.jpg: 384x640 (no detections), 31.9ms\n",
      "Speed: 1.6ms preprocess, 31.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/133.jpg: 384x640 (no detections), 29.7ms\n",
      "Speed: 1.9ms preprocess, 29.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/134.jpg: 384x640 (no detections), 41.9ms\n",
      "Speed: 1.9ms preprocess, 41.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/135.jpg: 384x640 1 motorcycle, 23.2ms\n",
      "Speed: 1.5ms preprocess, 23.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/136.jpg: 384x640 (no detections), 37.1ms\n",
      "Speed: 2.2ms preprocess, 37.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/137.jpg: 384x640 (no detections), 28.1ms\n",
      "Speed: 1.5ms preprocess, 28.1ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/138.jpg: 384x640 (no detections), 27.1ms\n",
      "Speed: 1.6ms preprocess, 27.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/139.jpg: 384x640 (no detections), 38.5ms\n",
      "Speed: 1.9ms preprocess, 38.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/140.jpg: 384x640 1 motorcycle, 35.6ms\n",
      "Speed: 4.2ms preprocess, 35.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/141.jpg: 384x640 1 motorcycle, 35.2ms\n",
      "Speed: 2.2ms preprocess, 35.2ms inference, 7.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/142.jpg: 384x640 1 motorcycle, 30.3ms\n",
      "Speed: 1.6ms preprocess, 30.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/143.jpg: 384x640 1 motorcycle, 28.0ms\n",
      "Speed: 1.5ms preprocess, 28.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/144.jpg: 384x640 (no detections), 32.2ms\n",
      "Speed: 2.2ms preprocess, 32.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/145.jpg: 384x640 (no detections), 26.7ms\n",
      "Speed: 1.6ms preprocess, 26.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/146.jpg: 384x640 (no detections), 40.4ms\n",
      "Speed: 1.7ms preprocess, 40.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/147.jpg: 384x640 1 motorcycle, 30.6ms\n",
      "Speed: 1.7ms preprocess, 30.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/148.jpg: 384x640 1 toothbrush, 59.8ms\n",
      "Speed: 2.0ms preprocess, 59.8ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/149.jpg: 384x640 1 motorcycle, 26.6ms\n",
      "Speed: 1.6ms preprocess, 26.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/150.jpg: 384x640 1 toothbrush, 44.1ms\n",
      "Speed: 1.7ms preprocess, 44.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/151.jpg: 384x640 1 toothbrush, 31.8ms\n",
      "Speed: 1.5ms preprocess, 31.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/152.jpg: 384x640 1 toothbrush, 51.1ms\n",
      "Speed: 1.8ms preprocess, 51.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/153.jpg: 384x640 (no detections), 28.4ms\n",
      "Speed: 1.6ms preprocess, 28.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/154.jpg: 384x640 1 toothbrush, 41.7ms\n",
      "Speed: 2.5ms preprocess, 41.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/155.jpg: 384x640 1 toothbrush, 24.0ms\n",
      "Speed: 1.6ms preprocess, 24.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/156.jpg: 384x640 (no detections), 36.6ms\n",
      "Speed: 3.2ms preprocess, 36.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/157.jpg: 384x640 (no detections), 29.0ms\n",
      "Speed: 1.6ms preprocess, 29.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/158.jpg: 384x640 (no detections), 31.4ms\n",
      "Speed: 2.1ms preprocess, 31.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/159.jpg: 384x640 1 airplane, 28.8ms\n",
      "Speed: 1.5ms preprocess, 28.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/160.jpg: 384x640 (no detections), 31.1ms\n",
      "Speed: 2.3ms preprocess, 31.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/161.jpg: 384x640 1 toothbrush, 26.0ms\n",
      "Speed: 1.8ms preprocess, 26.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/162.jpg: 384x640 (no detections), 36.1ms\n",
      "Speed: 2.0ms preprocess, 36.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/163.jpg: 384x640 (no detections), 24.9ms\n",
      "Speed: 1.4ms preprocess, 24.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/164.jpg: 384x640 1 airplane, 26.1ms\n",
      "Speed: 1.8ms preprocess, 26.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/165.jpg: 384x640 1 airplane, 27.6ms\n",
      "Speed: 1.5ms preprocess, 27.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/166.jpg: 384x640 1 airplane, 41.6ms\n",
      "Speed: 1.9ms preprocess, 41.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/167.jpg: 384x640 1 airplane, 24.8ms\n",
      "Speed: 1.6ms preprocess, 24.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/168.jpg: 384x640 (no detections), 26.7ms\n",
      "Speed: 1.8ms preprocess, 26.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/169.jpg: 384x640 1 airplane, 48.1ms\n",
      "Speed: 3.1ms preprocess, 48.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/170.jpg: 384x640 (no detections), 24.3ms\n",
      "Speed: 1.8ms preprocess, 24.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/171.jpg: 384x640 1 airplane, 23.6ms\n",
      "Speed: 1.8ms preprocess, 23.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/172.jpg: 384x640 (no detections), 34.2ms\n",
      "Speed: 5.5ms preprocess, 34.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/173.jpg: 384x640 (no detections), 24.1ms\n",
      "Speed: 1.6ms preprocess, 24.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/174.jpg: 384x640 1 toothbrush, 34.5ms\n",
      "Speed: 1.8ms preprocess, 34.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/175.jpg: 384x640 1 toothbrush, 36.8ms\n",
      "Speed: 1.5ms preprocess, 36.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/176.jpg: 384x640 1 toothbrush, 40.1ms\n",
      "Speed: 1.7ms preprocess, 40.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/177.jpg: 384x640 1 toothbrush, 23.9ms\n",
      "Speed: 1.4ms preprocess, 23.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/178.jpg: 384x640 1 toothbrush, 41.6ms\n",
      "Speed: 1.8ms preprocess, 41.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/179.jpg: 384x640 (no detections), 24.3ms\n",
      "Speed: 1.5ms preprocess, 24.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/180.jpg: 384x640 1 toothbrush, 25.4ms\n",
      "Speed: 1.8ms preprocess, 25.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/181.jpg: 384x640 (no detections), 27.0ms\n",
      "Speed: 2.4ms preprocess, 27.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/182.jpg: 384x640 (no detections), 38.2ms\n",
      "Speed: 1.7ms preprocess, 38.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/183.jpg: 384x640 (no detections), 42.3ms\n",
      "Speed: 1.6ms preprocess, 42.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/184.jpg: 384x640 (no detections), 24.1ms\n",
      "Speed: 1.5ms preprocess, 24.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/185.jpg: 384x640 1 toothbrush, 23.1ms\n",
      "Speed: 1.5ms preprocess, 23.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/186.jpg: 384x640 (no detections), 38.1ms\n",
      "Speed: 2.9ms preprocess, 38.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/187.jpg: 384x640 (no detections), 46.9ms\n",
      "Speed: 1.7ms preprocess, 46.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/188.jpg: 384x640 (no detections), 26.7ms\n",
      "Speed: 1.7ms preprocess, 26.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/189.jpg: 384x640 (no detections), 27.4ms\n",
      "Speed: 2.6ms preprocess, 27.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/190.jpg: 384x640 (no detections), 29.1ms\n",
      "Speed: 1.8ms preprocess, 29.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/191.jpg: 384x640 1 sink, 23.7ms\n",
      "Speed: 1.6ms preprocess, 23.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/192.jpg: 384x640 (no detections), 30.2ms\n",
      "Speed: 1.6ms preprocess, 30.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/193.jpg: 384x640 (no detections), 39.3ms\n",
      "Speed: 1.9ms preprocess, 39.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/194.jpg: 384x640 (no detections), 23.7ms\n",
      "Speed: 1.7ms preprocess, 23.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/195.jpg: 384x640 (no detections), 23.4ms\n",
      "Speed: 1.6ms preprocess, 23.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/196.jpg: 384x640 (no detections), 37.0ms\n",
      "Speed: 1.7ms preprocess, 37.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/197.jpg: 384x640 (no detections), 25.3ms\n",
      "Speed: 1.6ms preprocess, 25.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/198.jpg: 384x640 (no detections), 25.2ms\n",
      "Speed: 1.6ms preprocess, 25.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/199.jpg: 384x640 (no detections), 43.3ms\n",
      "Speed: 1.5ms preprocess, 43.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/200.jpg: 384x640 1 motorcycle, 23.5ms\n",
      "Speed: 1.6ms preprocess, 23.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/201.jpg: 384x640 (no detections), 29.0ms\n",
      "Speed: 1.8ms preprocess, 29.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/202.jpg: 384x640 (no detections), 30.3ms\n",
      "Speed: 1.7ms preprocess, 30.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/203.jpg: 384x640 (no detections), 46.8ms\n",
      "Speed: 2.0ms preprocess, 46.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/204.jpg: 384x640 (no detections), 26.3ms\n",
      "Speed: 1.6ms preprocess, 26.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/205.jpg: 384x640 1 toothbrush, 47.6ms\n",
      "Speed: 2.1ms preprocess, 47.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/206.jpg: 384x640 (no detections), 28.4ms\n",
      "Speed: 1.6ms preprocess, 28.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/207.jpg: 384x640 (no detections), 34.1ms\n",
      "Speed: 1.8ms preprocess, 34.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/208.jpg: 384x640 (no detections), 22.6ms\n",
      "Speed: 1.5ms preprocess, 22.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/209.jpg: 384x640 (no detections), 48.6ms\n",
      "Speed: 3.9ms preprocess, 48.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/210.jpg: 384x640 (no detections), 29.9ms\n",
      "Speed: 1.8ms preprocess, 29.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/211.jpg: 384x640 (no detections), 39.1ms\n",
      "Speed: 3.1ms preprocess, 39.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/212.jpg: 384x640 (no detections), 35.6ms\n",
      "Speed: 1.7ms preprocess, 35.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/213.jpg: 384x640 (no detections), 44.7ms\n",
      "Speed: 2.8ms preprocess, 44.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/214.jpg: 384x640 (no detections), 24.3ms\n",
      "Speed: 1.9ms preprocess, 24.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/215.jpg: 384x640 (no detections), 31.0ms\n",
      "Speed: 1.7ms preprocess, 31.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/216.jpg: 384x640 (no detections), 32.6ms\n",
      "Speed: 1.5ms preprocess, 32.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/217.jpg: 384x640 2 toothbrushs, 27.7ms\n",
      "Speed: 1.8ms preprocess, 27.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/218.jpg: 384x640 1 toothbrush, 23.7ms\n",
      "Speed: 1.5ms preprocess, 23.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/219.jpg: 384x640 (no detections), 34.5ms\n",
      "Speed: 1.9ms preprocess, 34.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/220.jpg: 384x640 (no detections), 35.6ms\n",
      "Speed: 1.7ms preprocess, 35.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/221.jpg: 384x640 (no detections), 40.6ms\n",
      "Speed: 1.7ms preprocess, 40.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/222.jpg: 384x640 (no detections), 26.0ms\n",
      "Speed: 1.7ms preprocess, 26.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/223.jpg: 384x640 (no detections), 40.2ms\n",
      "Speed: 1.9ms preprocess, 40.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/224.jpg: 384x640 (no detections), 24.2ms\n",
      "Speed: 1.6ms preprocess, 24.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/225.jpg: 384x640 (no detections), 37.2ms\n",
      "Speed: 2.0ms preprocess, 37.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/226.jpg: 384x640 (no detections), 24.2ms\n",
      "Speed: 1.7ms preprocess, 24.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/227.jpg: 384x640 (no detections), 34.4ms\n",
      "Speed: 1.9ms preprocess, 34.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/228.jpg: 384x640 (no detections), 24.9ms\n",
      "Speed: 2.9ms preprocess, 24.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/229.jpg: 384x640 (no detections), 27.2ms\n",
      "Speed: 1.8ms preprocess, 27.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/230.jpg: 384x640 (no detections), 29.3ms\n",
      "Speed: 3.5ms preprocess, 29.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/231.jpg: 384x640 (no detections), 40.5ms\n",
      "Speed: 1.7ms preprocess, 40.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/232.jpg: 384x640 (no detections), 38.1ms\n",
      "Speed: 1.7ms preprocess, 38.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/233.jpg: 384x640 (no detections), 25.0ms\n",
      "Speed: 1.6ms preprocess, 25.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/234.jpg: 384x640 1 motorcycle, 29.0ms\n",
      "Speed: 1.8ms preprocess, 29.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/235.jpg: 384x640 (no detections), 26.2ms\n",
      "Speed: 1.6ms preprocess, 26.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/236.jpg: 384x640 1 airplane, 24.3ms\n",
      "Speed: 1.5ms preprocess, 24.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/237.jpg: 384x640 (no detections), 25.8ms\n",
      "Speed: 1.7ms preprocess, 25.8ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/238.jpg: 384x640 (no detections), 25.7ms\n",
      "Speed: 1.7ms preprocess, 25.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/239.jpg: 384x640 (no detections), 30.9ms\n",
      "Speed: 1.9ms preprocess, 30.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/240.jpg: 384x640 (no detections), 24.6ms\n",
      "Speed: 1.9ms preprocess, 24.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/241.jpg: 384x640 (no detections), 25.3ms\n",
      "Speed: 1.4ms preprocess, 25.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/242.jpg: 384x640 (no detections), 28.4ms\n",
      "Speed: 1.7ms preprocess, 28.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/243.jpg: 384x640 (no detections), 43.5ms\n",
      "Speed: 2.0ms preprocess, 43.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/244.jpg: 384x640 (no detections), 25.5ms\n",
      "Speed: 1.8ms preprocess, 25.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/245.jpg: 384x640 (no detections), 28.6ms\n",
      "Speed: 2.0ms preprocess, 28.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/246.jpg: 384x640 (no detections), 31.5ms\n",
      "Speed: 1.6ms preprocess, 31.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/247.jpg: 384x640 (no detections), 29.9ms\n",
      "Speed: 1.9ms preprocess, 29.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/248.jpg: 384x640 (no detections), 23.8ms\n",
      "Speed: 1.7ms preprocess, 23.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/249.jpg: 384x640 (no detections), 26.8ms\n",
      "Speed: 1.8ms preprocess, 26.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/250.jpg: 384x640 1 motorcycle, 35.1ms\n",
      "Speed: 2.4ms preprocess, 35.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/251.jpg: 384x640 (no detections), 26.1ms\n",
      "Speed: 3.0ms preprocess, 26.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/252.jpg: 384x640 (no detections), 31.0ms\n",
      "Speed: 1.9ms preprocess, 31.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/253.jpg: 384x640 (no detections), 29.2ms\n",
      "Speed: 2.0ms preprocess, 29.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/254.jpg: 384x640 1 motorcycle, 29.0ms\n",
      "Speed: 3.1ms preprocess, 29.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/255.jpg: 384x640 (no detections), 38.2ms\n",
      "Speed: 1.7ms preprocess, 38.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/256.jpg: 384x640 1 motorcycle, 26.1ms\n",
      "Speed: 1.6ms preprocess, 26.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/257.jpg: 384x640 (no detections), 27.9ms\n",
      "Speed: 1.3ms preprocess, 27.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/258.jpg: 384x640 1 motorcycle, 36.7ms\n",
      "Speed: 1.9ms preprocess, 36.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/259.jpg: 384x640 (no detections), 37.8ms\n",
      "Speed: 1.7ms preprocess, 37.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/260.jpg: 384x640 (no detections), 26.2ms\n",
      "Speed: 1.8ms preprocess, 26.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/261.jpg: 384x640 (no detections), 31.5ms\n",
      "Speed: 3.1ms preprocess, 31.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/262.jpg: 384x640 1 motorcycle, 29.0ms\n",
      "Speed: 1.5ms preprocess, 29.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/263.jpg: 384x640 (no detections), 29.0ms\n",
      "Speed: 1.6ms preprocess, 29.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/264.jpg: 384x640 (no detections), 23.9ms\n",
      "Speed: 1.6ms preprocess, 23.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/265.jpg: 384x640 (no detections), 42.8ms\n",
      "Speed: 2.9ms preprocess, 42.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/266.jpg: 384x640 (no detections), 27.6ms\n",
      "Speed: 2.9ms preprocess, 27.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/267.jpg: 384x640 (no detections), 23.4ms\n",
      "Speed: 1.6ms preprocess, 23.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/268.jpg: 384x640 (no detections), 28.7ms\n",
      "Speed: 2.0ms preprocess, 28.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/269.jpg: 384x640 (no detections), 23.8ms\n",
      "Speed: 1.8ms preprocess, 23.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/270.jpg: 384x640 (no detections), 35.5ms\n",
      "Speed: 1.8ms preprocess, 35.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/271.jpg: 384x640 (no detections), 26.6ms\n",
      "Speed: 1.6ms preprocess, 26.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/272.jpg: 384x640 1 motorcycle, 38.8ms\n",
      "Speed: 2.4ms preprocess, 38.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/273.jpg: 384x640 1 motorcycle, 32.8ms\n",
      "Speed: 2.5ms preprocess, 32.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/274.jpg: 384x640 (no detections), 28.8ms\n",
      "Speed: 2.0ms preprocess, 28.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/275.jpg: 384x640 (no detections), 34.9ms\n",
      "Speed: 1.8ms preprocess, 34.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/276.jpg: 384x640 1 motorcycle, 28.0ms\n",
      "Speed: 1.5ms preprocess, 28.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/277.jpg: 384x640 (no detections), 36.3ms\n",
      "Speed: 3.2ms preprocess, 36.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/278.jpg: 384x640 (no detections), 44.5ms\n",
      "Speed: 1.8ms preprocess, 44.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/279.jpg: 384x640 1 motorcycle, 33.3ms\n",
      "Speed: 3.3ms preprocess, 33.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/280.jpg: 384x640 (no detections), 46.7ms\n",
      "Speed: 2.0ms preprocess, 46.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/281.jpg: 384x640 (no detections), 33.0ms\n",
      "Speed: 2.0ms preprocess, 33.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/282.jpg: 384x640 1 motorcycle, 39.5ms\n",
      "Speed: 2.9ms preprocess, 39.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/283.jpg: 384x640 (no detections), 28.6ms\n",
      "Speed: 1.9ms preprocess, 28.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/284.jpg: 384x640 1 motorcycle, 25.7ms\n",
      "Speed: 1.6ms preprocess, 25.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/285.jpg: 384x640 1 motorcycle, 24.5ms\n",
      "Speed: 1.6ms preprocess, 24.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/286.jpg: 384x640 (no detections), 33.8ms\n",
      "Speed: 1.6ms preprocess, 33.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/287.jpg: 384x640 (no detections), 24.7ms\n",
      "Speed: 1.7ms preprocess, 24.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/288.jpg: 384x640 (no detections), 28.2ms\n",
      "Speed: 1.8ms preprocess, 28.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/289.jpg: 384x640 (no detections), 27.0ms\n",
      "Speed: 3.5ms preprocess, 27.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/290.jpg: 384x640 (no detections), 32.4ms\n",
      "Speed: 2.1ms preprocess, 32.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/291.jpg: 384x640 (no detections), 27.0ms\n",
      "Speed: 1.4ms preprocess, 27.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/292.jpg: 384x640 (no detections), 30.2ms\n",
      "Speed: 1.7ms preprocess, 30.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/293.jpg: 384x640 (no detections), 36.5ms\n",
      "Speed: 2.3ms preprocess, 36.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/294.jpg: 384x640 (no detections), 31.1ms\n",
      "Speed: 2.8ms preprocess, 31.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/295.jpg: 384x640 (no detections), 32.8ms\n",
      "Speed: 2.5ms preprocess, 32.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/296.jpg: 384x640 (no detections), 42.1ms\n",
      "Speed: 2.0ms preprocess, 42.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/297.jpg: 384x640 (no detections), 46.3ms\n",
      "Speed: 2.1ms preprocess, 46.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/298.jpg: 384x640 (no detections), 29.3ms\n",
      "Speed: 2.5ms preprocess, 29.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/left/299.jpg: 384x640 (no detections), 26.6ms\n",
      "Speed: 1.5ms preprocess, 26.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Propagating video frames: 100%|| 300/300 [00:18<00:00, 15.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask propagation completed in 19.00 seconds.\n",
      "Processing predicted masks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing video frames: 300it [00:00, 1000.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 300 masks for evaluation.\n",
      "Masks saved to data/masks/yolo11x-seg/val/data-raw-SegSTRONGC_val-val-1-0-low_brightness-left.pkl\n",
      "Loading ground truth masks for evaluation...\n",
      "Loaded 300 ground truth masks.\n",
      "Calculating evaluation metrics...\n",
      "Time taken for metrics calculation: 1.43 seconds.\n",
      "Mean IoU for data/raw/SegSTRONGC_val/val/1/0/low_brightness/left: 0.1063\n",
      "Mean DSC for data/raw/SegSTRONGC_val/val/1/0/low_brightness/left: 0.1570\n",
      "Loading existing results file: data/results/yolo11x-seg/val.json\n",
      "Results saved to data/results/yolo11x-seg/val.json\n",
      "Processing video took 21.87 seconds.\n",
      "==================================================\n",
      "Processing right camera video...\n",
      "==================================================\n",
      "Processing video: data/raw/SegSTRONGC_val/val/1/0/low_brightness/right\n",
      "Domain: low_brightness, Split: val, Camera: right\n",
      "Initializing Yolo for video...\n",
      "Initialization took 0.13 seconds.\n",
      "Starting mask propagation...\n",
      "Total images in video: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/0.jpg: 384x640 1 toothbrush, 73.5ms\n",
      "Speed: 3.4ms preprocess, 73.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/1.jpg: 384x640 1 toothbrush, 46.4ms\n",
      "Speed: 2.8ms preprocess, 46.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/2.jpg: 384x640 1 toothbrush, 37.5ms\n",
      "Speed: 1.7ms preprocess, 37.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/3.jpg: 384x640 2 toothbrushs, 28.4ms\n",
      "Speed: 1.6ms preprocess, 28.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/4.jpg: 384x640 2 toothbrushs, 31.3ms\n",
      "Speed: 2.4ms preprocess, 31.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/5.jpg: 384x640 1 toothbrush, 42.2ms\n",
      "Speed: 1.5ms preprocess, 42.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/6.jpg: 384x640 1 toothbrush, 37.5ms\n",
      "Speed: 3.3ms preprocess, 37.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/7.jpg: 384x640 1 toothbrush, 28.9ms\n",
      "Speed: 1.6ms preprocess, 28.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/8.jpg: 384x640 1 toothbrush, 29.7ms\n",
      "Speed: 2.1ms preprocess, 29.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/9.jpg: 384x640 1 toothbrush, 24.3ms\n",
      "Speed: 1.9ms preprocess, 24.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/10.jpg: 384x640 1 toothbrush, 37.5ms\n",
      "Speed: 2.0ms preprocess, 37.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/11.jpg: 384x640 1 toothbrush, 24.3ms\n",
      "Speed: 1.8ms preprocess, 24.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/12.jpg: 384x640 1 toothbrush, 47.6ms\n",
      "Speed: 1.9ms preprocess, 47.6ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/13.jpg: 384x640 1 toothbrush, 26.5ms\n",
      "Speed: 1.9ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/14.jpg: 384x640 1 toothbrush, 30.2ms\n",
      "Speed: 1.7ms preprocess, 30.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/15.jpg: 384x640 (no detections), 32.6ms\n",
      "Speed: 3.3ms preprocess, 32.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/16.jpg: 384x640 1 toothbrush, 31.2ms\n",
      "Speed: 1.7ms preprocess, 31.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/17.jpg: 384x640 1 toothbrush, 26.4ms\n",
      "Speed: 1.8ms preprocess, 26.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/18.jpg: 384x640 1 toothbrush, 25.1ms\n",
      "Speed: 1.6ms preprocess, 25.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/19.jpg: 384x640 1 toothbrush, 36.0ms\n",
      "Speed: 1.8ms preprocess, 36.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/20.jpg: 384x640 1 toothbrush, 28.7ms\n",
      "Speed: 1.9ms preprocess, 28.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/21.jpg: 384x640 1 toothbrush, 24.3ms\n",
      "Speed: 2.1ms preprocess, 24.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/22.jpg: 384x640 1 toothbrush, 51.7ms\n",
      "Speed: 3.4ms preprocess, 51.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/23.jpg: 384x640 1 toothbrush, 35.5ms\n",
      "Speed: 2.0ms preprocess, 35.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/24.jpg: 384x640 (no detections), 29.1ms\n",
      "Speed: 2.1ms preprocess, 29.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/25.jpg: 384x640 1 toothbrush, 31.6ms\n",
      "Speed: 1.9ms preprocess, 31.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/26.jpg: 384x640 1 toothbrush, 43.6ms\n",
      "Speed: 1.6ms preprocess, 43.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/27.jpg: 384x640 1 toothbrush, 32.2ms\n",
      "Speed: 1.7ms preprocess, 32.2ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/28.jpg: 384x640 1 toothbrush, 37.3ms\n",
      "Speed: 1.7ms preprocess, 37.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/29.jpg: 384x640 (no detections), 24.2ms\n",
      "Speed: 1.6ms preprocess, 24.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/30.jpg: 384x640 1 toothbrush, 33.7ms\n",
      "Speed: 1.9ms preprocess, 33.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/31.jpg: 384x640 1 toothbrush, 23.1ms\n",
      "Speed: 1.7ms preprocess, 23.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/32.jpg: 384x640 1 toothbrush, 40.8ms\n",
      "Speed: 2.0ms preprocess, 40.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/33.jpg: 384x640 1 toothbrush, 24.2ms\n",
      "Speed: 1.6ms preprocess, 24.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/34.jpg: 384x640 (no detections), 24.3ms\n",
      "Speed: 1.6ms preprocess, 24.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/35.jpg: 384x640 (no detections), 30.5ms\n",
      "Speed: 1.7ms preprocess, 30.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/36.jpg: 384x640 (no detections), 34.1ms\n",
      "Speed: 1.9ms preprocess, 34.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/37.jpg: 384x640 1 toothbrush, 42.0ms\n",
      "Speed: 1.8ms preprocess, 42.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/38.jpg: 384x640 (no detections), 39.3ms\n",
      "Speed: 1.8ms preprocess, 39.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/39.jpg: 384x640 2 toothbrushs, 31.2ms\n",
      "Speed: 2.8ms preprocess, 31.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/40.jpg: 384x640 (no detections), 28.6ms\n",
      "Speed: 1.8ms preprocess, 28.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/41.jpg: 384x640 (no detections), 27.6ms\n",
      "Speed: 1.9ms preprocess, 27.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/42.jpg: 384x640 (no detections), 27.5ms\n",
      "Speed: 1.7ms preprocess, 27.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/43.jpg: 384x640 (no detections), 29.5ms\n",
      "Speed: 1.7ms preprocess, 29.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/44.jpg: 384x640 (no detections), 28.8ms\n",
      "Speed: 2.1ms preprocess, 28.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/45.jpg: 384x640 (no detections), 42.8ms\n",
      "Speed: 2.1ms preprocess, 42.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/46.jpg: 384x640 (no detections), 52.4ms\n",
      "Speed: 2.1ms preprocess, 52.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/47.jpg: 384x640 1 toothbrush, 30.4ms\n",
      "Speed: 1.9ms preprocess, 30.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/48.jpg: 384x640 2 toothbrushs, 30.3ms\n",
      "Speed: 1.7ms preprocess, 30.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/49.jpg: 384x640 1 toothbrush, 29.0ms\n",
      "Speed: 1.7ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/50.jpg: 384x640 (no detections), 37.4ms\n",
      "Speed: 1.6ms preprocess, 37.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/51.jpg: 384x640 1 toothbrush, 30.5ms\n",
      "Speed: 2.4ms preprocess, 30.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/52.jpg: 384x640 1 toothbrush, 31.0ms\n",
      "Speed: 2.7ms preprocess, 31.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/53.jpg: 384x640 1 toothbrush, 31.8ms\n",
      "Speed: 1.6ms preprocess, 31.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/54.jpg: 384x640 1 toothbrush, 25.2ms\n",
      "Speed: 1.8ms preprocess, 25.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/55.jpg: 384x640 1 toothbrush, 26.6ms\n",
      "Speed: 1.7ms preprocess, 26.6ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/56.jpg: 384x640 1 toothbrush, 35.5ms\n",
      "Speed: 2.1ms preprocess, 35.5ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/57.jpg: 384x640 2 toothbrushs, 38.4ms\n",
      "Speed: 1.9ms preprocess, 38.4ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/58.jpg: 384x640 1 toothbrush, 24.8ms\n",
      "Speed: 2.0ms preprocess, 24.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/59.jpg: 384x640 1 toothbrush, 30.6ms\n",
      "Speed: 1.8ms preprocess, 30.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/60.jpg: 384x640 1 toothbrush, 45.7ms\n",
      "Speed: 1.8ms preprocess, 45.7ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/61.jpg: 384x640 (no detections), 31.2ms\n",
      "Speed: 2.4ms preprocess, 31.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/62.jpg: 384x640 1 toothbrush, 41.4ms\n",
      "Speed: 1.8ms preprocess, 41.4ms inference, 7.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/63.jpg: 384x640 (no detections), 36.7ms\n",
      "Speed: 2.5ms preprocess, 36.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/64.jpg: 384x640 1 toothbrush, 33.1ms\n",
      "Speed: 2.0ms preprocess, 33.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/65.jpg: 384x640 (no detections), 23.3ms\n",
      "Speed: 1.6ms preprocess, 23.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/66.jpg: 384x640 (no detections), 34.8ms\n",
      "Speed: 1.7ms preprocess, 34.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/67.jpg: 384x640 (no detections), 25.9ms\n",
      "Speed: 1.8ms preprocess, 25.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/68.jpg: 384x640 (no detections), 36.0ms\n",
      "Speed: 1.6ms preprocess, 36.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/69.jpg: 384x640 1 toothbrush, 24.6ms\n",
      "Speed: 1.7ms preprocess, 24.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/70.jpg: 384x640 2 toothbrushs, 24.2ms\n",
      "Speed: 2.6ms preprocess, 24.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/71.jpg: 384x640 1 toothbrush, 24.1ms\n",
      "Speed: 1.8ms preprocess, 24.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/72.jpg: 384x640 1 toothbrush, 25.5ms\n",
      "Speed: 1.7ms preprocess, 25.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/73.jpg: 384x640 1 toothbrush, 27.9ms\n",
      "Speed: 2.0ms preprocess, 27.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/74.jpg: 384x640 1 toothbrush, 40.2ms\n",
      "Speed: 2.0ms preprocess, 40.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/75.jpg: 384x640 1 toothbrush, 33.7ms\n",
      "Speed: 1.9ms preprocess, 33.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/76.jpg: 384x640 1 toothbrush, 31.0ms\n",
      "Speed: 1.6ms preprocess, 31.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/77.jpg: 384x640 (no detections), 38.2ms\n",
      "Speed: 3.1ms preprocess, 38.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/78.jpg: 384x640 1 toothbrush, 44.8ms\n",
      "Speed: 1.8ms preprocess, 44.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/79.jpg: 384x640 1 toothbrush, 29.7ms\n",
      "Speed: 2.1ms preprocess, 29.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/80.jpg: 384x640 1 toothbrush, 28.8ms\n",
      "Speed: 1.6ms preprocess, 28.8ms inference, 7.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/81.jpg: 384x640 1 toothbrush, 36.9ms\n",
      "Speed: 2.2ms preprocess, 36.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/82.jpg: 384x640 1 toothbrush, 47.5ms\n",
      "Speed: 1.6ms preprocess, 47.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/83.jpg: 384x640 1 toothbrush, 35.9ms\n",
      "Speed: 1.7ms preprocess, 35.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/84.jpg: 384x640 (no detections), 37.8ms\n",
      "Speed: 1.7ms preprocess, 37.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/85.jpg: 384x640 1 toothbrush, 30.9ms\n",
      "Speed: 2.0ms preprocess, 30.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/86.jpg: 384x640 1 toothbrush, 38.2ms\n",
      "Speed: 1.9ms preprocess, 38.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/87.jpg: 384x640 1 toothbrush, 39.6ms\n",
      "Speed: 1.8ms preprocess, 39.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/88.jpg: 384x640 1 toothbrush, 31.6ms\n",
      "Speed: 1.7ms preprocess, 31.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/89.jpg: 384x640 1 toothbrush, 30.0ms\n",
      "Speed: 1.7ms preprocess, 30.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/90.jpg: 384x640 1 toothbrush, 43.3ms\n",
      "Speed: 2.3ms preprocess, 43.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/91.jpg: 384x640 1 toothbrush, 33.3ms\n",
      "Speed: 1.7ms preprocess, 33.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/92.jpg: 384x640 1 toothbrush, 31.5ms\n",
      "Speed: 1.6ms preprocess, 31.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/93.jpg: 384x640 1 toothbrush, 32.2ms\n",
      "Speed: 2.2ms preprocess, 32.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/94.jpg: 384x640 1 scissors, 24.5ms\n",
      "Speed: 1.6ms preprocess, 24.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/95.jpg: 384x640 (no detections), 35.8ms\n",
      "Speed: 2.6ms preprocess, 35.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/96.jpg: 384x640 1 scissors, 36.7ms\n",
      "Speed: 3.1ms preprocess, 36.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/97.jpg: 384x640 (no detections), 32.1ms\n",
      "Speed: 1.7ms preprocess, 32.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/98.jpg: 384x640 (no detections), 33.4ms\n",
      "Speed: 1.8ms preprocess, 33.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/99.jpg: 384x640 (no detections), 33.3ms\n",
      "Speed: 2.7ms preprocess, 33.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/100.jpg: 384x640 (no detections), 56.8ms\n",
      "Speed: 1.7ms preprocess, 56.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/101.jpg: 384x640 (no detections), 36.1ms\n",
      "Speed: 1.6ms preprocess, 36.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/102.jpg: 384x640 (no detections), 29.7ms\n",
      "Speed: 1.8ms preprocess, 29.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/103.jpg: 384x640 1 toothbrush, 37.3ms\n",
      "Speed: 2.0ms preprocess, 37.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/104.jpg: 384x640 1 toothbrush, 49.3ms\n",
      "Speed: 1.8ms preprocess, 49.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/105.jpg: 384x640 (no detections), 44.0ms\n",
      "Speed: 2.6ms preprocess, 44.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/106.jpg: 384x640 1 toothbrush, 34.3ms\n",
      "Speed: 3.2ms preprocess, 34.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/107.jpg: 384x640 1 toothbrush, 31.7ms\n",
      "Speed: 2.4ms preprocess, 31.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/108.jpg: 384x640 1 toothbrush, 25.4ms\n",
      "Speed: 1.7ms preprocess, 25.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/109.jpg: 384x640 1 toothbrush, 45.3ms\n",
      "Speed: 1.7ms preprocess, 45.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/110.jpg: 384x640 1 toothbrush, 30.9ms\n",
      "Speed: 2.4ms preprocess, 30.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/111.jpg: 384x640 (no detections), 38.6ms\n",
      "Speed: 1.8ms preprocess, 38.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/112.jpg: 384x640 (no detections), 32.7ms\n",
      "Speed: 2.2ms preprocess, 32.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/113.jpg: 384x640 (no detections), 29.8ms\n",
      "Speed: 1.8ms preprocess, 29.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/114.jpg: 384x640 (no detections), 36.9ms\n",
      "Speed: 1.7ms preprocess, 36.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/115.jpg: 384x640 1 toothbrush, 38.4ms\n",
      "Speed: 1.9ms preprocess, 38.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/116.jpg: 384x640 (no detections), 43.8ms\n",
      "Speed: 2.1ms preprocess, 43.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/117.jpg: 384x640 1 toothbrush, 30.5ms\n",
      "Speed: 1.7ms preprocess, 30.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/118.jpg: 384x640 (no detections), 28.1ms\n",
      "Speed: 1.7ms preprocess, 28.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/119.jpg: 384x640 1 toothbrush, 38.1ms\n",
      "Speed: 2.1ms preprocess, 38.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/120.jpg: 384x640 (no detections), 42.0ms\n",
      "Speed: 1.8ms preprocess, 42.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/121.jpg: 384x640 (no detections), 31.7ms\n",
      "Speed: 1.8ms preprocess, 31.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/122.jpg: 384x640 (no detections), 27.2ms\n",
      "Speed: 1.9ms preprocess, 27.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/123.jpg: 384x640 2 toothbrushs, 37.5ms\n",
      "Speed: 3.0ms preprocess, 37.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/124.jpg: 384x640 (no detections), 24.3ms\n",
      "Speed: 1.6ms preprocess, 24.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/125.jpg: 384x640 1 motorcycle, 32.1ms\n",
      "Speed: 2.4ms preprocess, 32.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/126.jpg: 384x640 1 motorcycle, 27.8ms\n",
      "Speed: 2.0ms preprocess, 27.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/127.jpg: 384x640 1 motorcycle, 33.5ms\n",
      "Speed: 1.7ms preprocess, 33.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/128.jpg: 384x640 1 toothbrush, 32.9ms\n",
      "Speed: 1.9ms preprocess, 32.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/129.jpg: 384x640 1 toothbrush, 27.6ms\n",
      "Speed: 2.0ms preprocess, 27.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/130.jpg: 384x640 1 toothbrush, 36.2ms\n",
      "Speed: 2.9ms preprocess, 36.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/131.jpg: 384x640 (no detections), 28.5ms\n",
      "Speed: 1.7ms preprocess, 28.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/132.jpg: 384x640 1 toothbrush, 48.8ms\n",
      "Speed: 2.4ms preprocess, 48.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/133.jpg: 384x640 1 toothbrush, 27.0ms\n",
      "Speed: 1.7ms preprocess, 27.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/134.jpg: 384x640 (no detections), 32.7ms\n",
      "Speed: 1.8ms preprocess, 32.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/135.jpg: 384x640 (no detections), 26.6ms\n",
      "Speed: 1.7ms preprocess, 26.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/136.jpg: 384x640 (no detections), 44.3ms\n",
      "Speed: 2.5ms preprocess, 44.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/137.jpg: 384x640 (no detections), 35.8ms\n",
      "Speed: 2.1ms preprocess, 35.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/138.jpg: 384x640 1 toothbrush, 27.1ms\n",
      "Speed: 1.7ms preprocess, 27.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/139.jpg: 384x640 (no detections), 27.4ms\n",
      "Speed: 1.8ms preprocess, 27.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/140.jpg: 384x640 1 spoon, 1 toothbrush, 36.7ms\n",
      "Speed: 1.9ms preprocess, 36.7ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/141.jpg: 384x640 (no detections), 44.5ms\n",
      "Speed: 1.9ms preprocess, 44.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/142.jpg: 384x640 1 toothbrush, 37.1ms\n",
      "Speed: 1.6ms preprocess, 37.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/143.jpg: 384x640 (no detections), 35.6ms\n",
      "Speed: 1.6ms preprocess, 35.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/144.jpg: 384x640 (no detections), 38.1ms\n",
      "Speed: 2.1ms preprocess, 38.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/145.jpg: 384x640 (no detections), 46.4ms\n",
      "Speed: 2.2ms preprocess, 46.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/146.jpg: 384x640 1 toothbrush, 31.2ms\n",
      "Speed: 2.4ms preprocess, 31.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/147.jpg: 384x640 1 toothbrush, 27.3ms\n",
      "Speed: 1.6ms preprocess, 27.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/148.jpg: 384x640 (no detections), 48.0ms\n",
      "Speed: 1.8ms preprocess, 48.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/149.jpg: 384x640 (no detections), 36.4ms\n",
      "Speed: 1.6ms preprocess, 36.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/150.jpg: 384x640 (no detections), 35.5ms\n",
      "Speed: 2.9ms preprocess, 35.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/151.jpg: 384x640 1 toothbrush, 42.6ms\n",
      "Speed: 1.6ms preprocess, 42.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/152.jpg: 384x640 (no detections), 49.8ms\n",
      "Speed: 2.6ms preprocess, 49.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/153.jpg: 384x640 (no detections), 29.4ms\n",
      "Speed: 2.5ms preprocess, 29.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/154.jpg: 384x640 1 toothbrush, 29.3ms\n",
      "Speed: 1.7ms preprocess, 29.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/155.jpg: 384x640 (no detections), 33.2ms\n",
      "Speed: 1.8ms preprocess, 33.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/156.jpg: 384x640 (no detections), 32.5ms\n",
      "Speed: 3.2ms preprocess, 32.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/157.jpg: 384x640 (no detections), 35.4ms\n",
      "Speed: 2.0ms preprocess, 35.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/158.jpg: 384x640 (no detections), 41.4ms\n",
      "Speed: 1.8ms preprocess, 41.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/159.jpg: 384x640 1 toothbrush, 37.7ms\n",
      "Speed: 1.8ms preprocess, 37.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/160.jpg: 384x640 (no detections), 32.4ms\n",
      "Speed: 1.7ms preprocess, 32.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/161.jpg: 384x640 (no detections), 28.7ms\n",
      "Speed: 1.8ms preprocess, 28.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/162.jpg: 384x640 (no detections), 35.8ms\n",
      "Speed: 2.7ms preprocess, 35.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/163.jpg: 384x640 (no detections), 29.9ms\n",
      "Speed: 2.2ms preprocess, 29.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/164.jpg: 384x640 (no detections), 33.2ms\n",
      "Speed: 2.7ms preprocess, 33.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/165.jpg: 384x640 (no detections), 28.2ms\n",
      "Speed: 1.7ms preprocess, 28.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/166.jpg: 384x640 1 toothbrush, 30.3ms\n",
      "Speed: 2.1ms preprocess, 30.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/167.jpg: 384x640 (no detections), 46.3ms\n",
      "Speed: 2.6ms preprocess, 46.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/168.jpg: 384x640 (no detections), 41.9ms\n",
      "Speed: 1.9ms preprocess, 41.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/169.jpg: 384x640 (no detections), 37.9ms\n",
      "Speed: 2.0ms preprocess, 37.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/170.jpg: 384x640 (no detections), 52.0ms\n",
      "Speed: 5.0ms preprocess, 52.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/171.jpg: 384x640 (no detections), 49.0ms\n",
      "Speed: 2.9ms preprocess, 49.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/172.jpg: 384x640 (no detections), 38.1ms\n",
      "Speed: 1.9ms preprocess, 38.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/173.jpg: 384x640 (no detections), 40.2ms\n",
      "Speed: 1.9ms preprocess, 40.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/174.jpg: 384x640 (no detections), 42.3ms\n",
      "Speed: 1.8ms preprocess, 42.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/175.jpg: 384x640 (no detections), 40.3ms\n",
      "Speed: 1.9ms preprocess, 40.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/176.jpg: 384x640 1 spoon, 47.5ms\n",
      "Speed: 1.8ms preprocess, 47.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/177.jpg: 384x640 (no detections), 42.5ms\n",
      "Speed: 2.1ms preprocess, 42.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/178.jpg: 384x640 (no detections), 36.7ms\n",
      "Speed: 3.3ms preprocess, 36.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/179.jpg: 384x640 (no detections), 32.8ms\n",
      "Speed: 2.5ms preprocess, 32.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/180.jpg: 384x640 1 toothbrush, 50.0ms\n",
      "Speed: 2.0ms preprocess, 50.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/181.jpg: 384x640 (no detections), 44.2ms\n",
      "Speed: 2.8ms preprocess, 44.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/182.jpg: 384x640 1 toothbrush, 35.0ms\n",
      "Speed: 2.2ms preprocess, 35.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/183.jpg: 384x640 1 toothbrush, 43.4ms\n",
      "Speed: 1.8ms preprocess, 43.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/184.jpg: 384x640 1 toothbrush, 49.9ms\n",
      "Speed: 1.7ms preprocess, 49.9ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/185.jpg: 384x640 1 toothbrush, 66.9ms\n",
      "Speed: 2.1ms preprocess, 66.9ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/186.jpg: 384x640 (no detections), 48.3ms\n",
      "Speed: 1.7ms preprocess, 48.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/187.jpg: 384x640 (no detections), 39.3ms\n",
      "Speed: 2.2ms preprocess, 39.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/188.jpg: 384x640 (no detections), 33.4ms\n",
      "Speed: 2.0ms preprocess, 33.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/189.jpg: 384x640 1 toothbrush, 49.8ms\n",
      "Speed: 2.6ms preprocess, 49.8ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/190.jpg: 384x640 (no detections), 42.7ms\n",
      "Speed: 2.6ms preprocess, 42.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/191.jpg: 384x640 (no detections), 28.4ms\n",
      "Speed: 1.9ms preprocess, 28.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/192.jpg: 384x640 (no detections), 65.4ms\n",
      "Speed: 3.0ms preprocess, 65.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/193.jpg: 384x640 (no detections), 31.7ms\n",
      "Speed: 1.8ms preprocess, 31.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/194.jpg: 384x640 (no detections), 51.1ms\n",
      "Speed: 3.3ms preprocess, 51.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/195.jpg: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.2ms preprocess, 48.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/196.jpg: 384x640 (no detections), 37.1ms\n",
      "Speed: 1.8ms preprocess, 37.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/197.jpg: 384x640 (no detections), 41.7ms\n",
      "Speed: 2.8ms preprocess, 41.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/198.jpg: 384x640 (no detections), 45.8ms\n",
      "Speed: 2.1ms preprocess, 45.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/199.jpg: 384x640 (no detections), 52.7ms\n",
      "Speed: 2.2ms preprocess, 52.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/200.jpg: 384x640 1 sink, 37.6ms\n",
      "Speed: 2.1ms preprocess, 37.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/201.jpg: 384x640 (no detections), 38.7ms\n",
      "Speed: 1.9ms preprocess, 38.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/202.jpg: 384x640 1 sink, 50.4ms\n",
      "Speed: 3.5ms preprocess, 50.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/203.jpg: 384x640 (no detections), 37.3ms\n",
      "Speed: 1.9ms preprocess, 37.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/204.jpg: 384x640 (no detections), 35.4ms\n",
      "Speed: 2.8ms preprocess, 35.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/205.jpg: 384x640 (no detections), 31.6ms\n",
      "Speed: 2.0ms preprocess, 31.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/206.jpg: 384x640 (no detections), 28.7ms\n",
      "Speed: 3.1ms preprocess, 28.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/207.jpg: 384x640 (no detections), 34.5ms\n",
      "Speed: 2.2ms preprocess, 34.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/208.jpg: 384x640 1 sink, 31.3ms\n",
      "Speed: 1.8ms preprocess, 31.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/209.jpg: 384x640 (no detections), 35.7ms\n",
      "Speed: 1.8ms preprocess, 35.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/210.jpg: 384x640 (no detections), 56.2ms\n",
      "Speed: 2.1ms preprocess, 56.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/211.jpg: 384x640 1 baseball bat, 42.7ms\n",
      "Speed: 1.7ms preprocess, 42.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/212.jpg: 384x640 (no detections), 47.7ms\n",
      "Speed: 1.9ms preprocess, 47.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/213.jpg: 384x640 (no detections), 41.2ms\n",
      "Speed: 2.2ms preprocess, 41.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/214.jpg: 384x640 (no detections), 32.3ms\n",
      "Speed: 2.6ms preprocess, 32.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/215.jpg: 384x640 (no detections), 37.6ms\n",
      "Speed: 2.1ms preprocess, 37.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/216.jpg: 384x640 (no detections), 41.0ms\n",
      "Speed: 2.3ms preprocess, 41.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/217.jpg: 384x640 (no detections), 36.6ms\n",
      "Speed: 2.5ms preprocess, 36.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/218.jpg: 384x640 (no detections), 50.6ms\n",
      "Speed: 1.9ms preprocess, 50.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/219.jpg: 384x640 1 toothbrush, 34.3ms\n",
      "Speed: 1.7ms preprocess, 34.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/220.jpg: 384x640 (no detections), 31.9ms\n",
      "Speed: 1.9ms preprocess, 31.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/221.jpg: 384x640 (no detections), 33.0ms\n",
      "Speed: 1.8ms preprocess, 33.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/222.jpg: 384x640 (no detections), 32.4ms\n",
      "Speed: 1.8ms preprocess, 32.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/223.jpg: 384x640 (no detections), 28.5ms\n",
      "Speed: 2.9ms preprocess, 28.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/224.jpg: 384x640 (no detections), 38.6ms\n",
      "Speed: 2.5ms preprocess, 38.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/225.jpg: 384x640 (no detections), 48.4ms\n",
      "Speed: 2.0ms preprocess, 48.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/226.jpg: 384x640 1 toothbrush, 47.0ms\n",
      "Speed: 3.0ms preprocess, 47.0ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/227.jpg: 384x640 (no detections), 36.0ms\n",
      "Speed: 2.1ms preprocess, 36.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/228.jpg: 384x640 1 toothbrush, 30.4ms\n",
      "Speed: 3.1ms preprocess, 30.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/229.jpg: 384x640 1 toothbrush, 39.4ms\n",
      "Speed: 2.7ms preprocess, 39.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/230.jpg: 384x640 (no detections), 34.4ms\n",
      "Speed: 2.1ms preprocess, 34.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/231.jpg: 384x640 (no detections), 32.7ms\n",
      "Speed: 1.7ms preprocess, 32.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/232.jpg: 384x640 (no detections), 42.3ms\n",
      "Speed: 2.0ms preprocess, 42.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/233.jpg: 384x640 (no detections), 41.9ms\n",
      "Speed: 2.1ms preprocess, 41.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/234.jpg: 384x640 (no detections), 32.8ms\n",
      "Speed: 1.9ms preprocess, 32.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/235.jpg: 384x640 (no detections), 26.7ms\n",
      "Speed: 1.9ms preprocess, 26.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/236.jpg: 384x640 1 toothbrush, 28.4ms\n",
      "Speed: 1.9ms preprocess, 28.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/237.jpg: 384x640 (no detections), 35.4ms\n",
      "Speed: 2.0ms preprocess, 35.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/238.jpg: 384x640 (no detections), 32.7ms\n",
      "Speed: 1.8ms preprocess, 32.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/239.jpg: 384x640 (no detections), 37.4ms\n",
      "Speed: 2.0ms preprocess, 37.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/240.jpg: 384x640 (no detections), 33.4ms\n",
      "Speed: 1.8ms preprocess, 33.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/241.jpg: 384x640 1 toothbrush, 44.6ms\n",
      "Speed: 3.1ms preprocess, 44.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/242.jpg: 384x640 1 toothbrush, 31.4ms\n",
      "Speed: 2.2ms preprocess, 31.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/243.jpg: 384x640 1 toothbrush, 53.4ms\n",
      "Speed: 2.1ms preprocess, 53.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/244.jpg: 384x640 (no detections), 57.0ms\n",
      "Speed: 2.2ms preprocess, 57.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/245.jpg: 384x640 (no detections), 35.2ms\n",
      "Speed: 1.8ms preprocess, 35.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/246.jpg: 384x640 (no detections), 39.3ms\n",
      "Speed: 2.3ms preprocess, 39.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/247.jpg: 384x640 (no detections), 30.8ms\n",
      "Speed: 1.5ms preprocess, 30.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/248.jpg: 384x640 (no detections), 34.4ms\n",
      "Speed: 2.0ms preprocess, 34.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/249.jpg: 384x640 (no detections), 47.5ms\n",
      "Speed: 1.9ms preprocess, 47.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/250.jpg: 384x640 (no detections), 38.2ms\n",
      "Speed: 3.0ms preprocess, 38.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/251.jpg: 384x640 (no detections), 29.1ms\n",
      "Speed: 1.7ms preprocess, 29.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/252.jpg: 384x640 (no detections), 40.8ms\n",
      "Speed: 2.1ms preprocess, 40.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/253.jpg: 384x640 (no detections), 33.9ms\n",
      "Speed: 1.8ms preprocess, 33.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/254.jpg: 384x640 (no detections), 42.6ms\n",
      "Speed: 2.7ms preprocess, 42.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/255.jpg: 384x640 1 toothbrush, 28.4ms\n",
      "Speed: 1.8ms preprocess, 28.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/256.jpg: 384x640 (no detections), 48.2ms\n",
      "Speed: 1.9ms preprocess, 48.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/257.jpg: 384x640 (no detections), 35.8ms\n",
      "Speed: 4.1ms preprocess, 35.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/258.jpg: 384x640 (no detections), 37.0ms\n",
      "Speed: 1.9ms preprocess, 37.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/259.jpg: 384x640 (no detections), 27.2ms\n",
      "Speed: 1.8ms preprocess, 27.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/260.jpg: 384x640 (no detections), 30.2ms\n",
      "Speed: 1.9ms preprocess, 30.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/261.jpg: 384x640 (no detections), 34.7ms\n",
      "Speed: 1.9ms preprocess, 34.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/262.jpg: 384x640 (no detections), 33.2ms\n",
      "Speed: 1.9ms preprocess, 33.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/263.jpg: 384x640 (no detections), 37.1ms\n",
      "Speed: 1.9ms preprocess, 37.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/264.jpg: 384x640 (no detections), 38.5ms\n",
      "Speed: 3.2ms preprocess, 38.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/265.jpg: 384x640 (no detections), 25.6ms\n",
      "Speed: 1.6ms preprocess, 25.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/266.jpg: 384x640 1 motorcycle, 32.3ms\n",
      "Speed: 1.8ms preprocess, 32.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/267.jpg: 384x640 1 clock, 39.0ms\n",
      "Speed: 3.3ms preprocess, 39.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/268.jpg: 384x640 (no detections), 29.4ms\n",
      "Speed: 1.7ms preprocess, 29.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/269.jpg: 384x640 (no detections), 40.7ms\n",
      "Speed: 3.4ms preprocess, 40.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/270.jpg: 384x640 (no detections), 44.9ms\n",
      "Speed: 2.0ms preprocess, 44.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/271.jpg: 384x640 (no detections), 40.2ms\n",
      "Speed: 2.4ms preprocess, 40.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/272.jpg: 384x640 (no detections), 38.0ms\n",
      "Speed: 1.9ms preprocess, 38.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/273.jpg: 384x640 (no detections), 40.4ms\n",
      "Speed: 1.8ms preprocess, 40.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/274.jpg: 384x640 (no detections), 39.5ms\n",
      "Speed: 2.0ms preprocess, 39.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/275.jpg: 384x640 (no detections), 36.5ms\n",
      "Speed: 1.9ms preprocess, 36.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/276.jpg: 384x640 (no detections), 37.7ms\n",
      "Speed: 1.9ms preprocess, 37.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/277.jpg: 384x640 1 toothbrush, 32.1ms\n",
      "Speed: 3.0ms preprocess, 32.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/278.jpg: 384x640 (no detections), 27.8ms\n",
      "Speed: 1.9ms preprocess, 27.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/279.jpg: 384x640 (no detections), 35.9ms\n",
      "Speed: 1.8ms preprocess, 35.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/280.jpg: 384x640 1 toothbrush, 34.5ms\n",
      "Speed: 2.5ms preprocess, 34.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/281.jpg: 384x640 (no detections), 40.4ms\n",
      "Speed: 2.4ms preprocess, 40.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/282.jpg: 384x640 1 toothbrush, 40.9ms\n",
      "Speed: 2.3ms preprocess, 40.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/283.jpg: 384x640 (no detections), 27.1ms\n",
      "Speed: 1.7ms preprocess, 27.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/284.jpg: 384x640 1 spoon, 1 toothbrush, 33.4ms\n",
      "Speed: 1.8ms preprocess, 33.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/285.jpg: 384x640 (no detections), 35.4ms\n",
      "Speed: 1.9ms preprocess, 35.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/286.jpg: 384x640 2 toothbrushs, 33.5ms\n",
      "Speed: 2.2ms preprocess, 33.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/287.jpg: 384x640 (no detections), 33.6ms\n",
      "Speed: 2.1ms preprocess, 33.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/288.jpg: 384x640 1 toothbrush, 39.1ms\n",
      "Speed: 2.1ms preprocess, 39.1ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/289.jpg: 384x640 (no detections), 36.1ms\n",
      "Speed: 2.0ms preprocess, 36.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/290.jpg: 384x640 2 spoons, 1 toothbrush, 34.6ms\n",
      "Speed: 2.0ms preprocess, 34.6ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/291.jpg: 384x640 1 spoon, 1 sink, 1 toothbrush, 29.4ms\n",
      "Speed: 1.8ms preprocess, 29.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/292.jpg: 384x640 (no detections), 48.7ms\n",
      "Speed: 1.8ms preprocess, 48.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/293.jpg: 384x640 (no detections), 28.6ms\n",
      "Speed: 2.6ms preprocess, 28.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/294.jpg: 384x640 1 toothbrush, 29.6ms\n",
      "Speed: 2.6ms preprocess, 29.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/295.jpg: 384x640 (no detections), 36.4ms\n",
      "Speed: 1.7ms preprocess, 36.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/296.jpg: 384x640 (no detections), 35.1ms\n",
      "Speed: 1.8ms preprocess, 35.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/297.jpg: 384x640 (no detections), 53.7ms\n",
      "Speed: 1.7ms preprocess, 53.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/298.jpg: 384x640 (no detections), 26.8ms\n",
      "Speed: 1.8ms preprocess, 26.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/low_brightness/right/299.jpg: 384x640 (no detections), 38.7ms\n",
      "Speed: 1.7ms preprocess, 38.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Propagating video frames: 100%|| 300/300 [00:18<00:00, 15.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask propagation completed in 18.84 seconds.\n",
      "Processing predicted masks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing video frames: 300it [00:00, 613.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 300 masks for evaluation.\n",
      "Masks saved to data/masks/yolo11x-seg/val/data-raw-SegSTRONGC_val-val-1-0-low_brightness-right.pkl\n",
      "Loading ground truth masks for evaluation...\n",
      "Loaded 300 ground truth masks.\n",
      "Calculating evaluation metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for metrics calculation: 1.43 seconds.\n",
      "Mean IoU for data/raw/SegSTRONGC_val/val/1/0/low_brightness/right: 0.1386\n",
      "Mean DSC for data/raw/SegSTRONGC_val/val/1/0/low_brightness/right: 0.2082\n",
      "Loading existing results file: data/results/yolo11x-seg/val.json\n",
      "Results saved to data/results/yolo11x-seg/val.json\n",
      "Processing video took 22.03 seconds.\n",
      "==================================================\n",
      "\n",
      "Results for data/raw/SegSTRONGC_val/val/1/0/low_brightness:\n",
      "  Left: IoU=0.1063, DSC=0.1570\n",
      "  Right: IoU=0.1386, DSC=0.2082\n",
      "  Overall: IoU=0.1225, DSC=0.1826\n",
      "\n",
      "Processing domain: regular\n",
      "Processing left camera video...\n",
      "==================================================\n",
      "Processing video: data/raw/SegSTRONGC_val/val/1/0/regular/left\n",
      "Domain: regular, Split: val, Camera: left\n",
      "Initializing Yolo for video...\n",
      "Initialization took 0.14 seconds.\n",
      "Starting mask propagation...\n",
      "Total images in video: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/0.jpg: 384x640 2 baseball bats, 69.4ms\n",
      "Speed: 1.8ms preprocess, 69.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/1.jpg: 384x640 2 baseball bats, 1 cake, 23.9ms\n",
      "Speed: 1.6ms preprocess, 23.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/2.jpg: 384x640 2 baseball bats, 27.8ms\n",
      "Speed: 2.8ms preprocess, 27.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/3.jpg: 384x640 2 baseball bats, 23.6ms\n",
      "Speed: 1.6ms preprocess, 23.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/4.jpg: 384x640 2 baseball bats, 31.2ms\n",
      "Speed: 1.7ms preprocess, 31.2ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/5.jpg: 384x640 2 baseball bats, 28.9ms\n",
      "Speed: 1.9ms preprocess, 28.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/6.jpg: 384x640 2 baseball bats, 24.8ms\n",
      "Speed: 2.0ms preprocess, 24.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/7.jpg: 384x640 2 baseball bats, 24.4ms\n",
      "Speed: 1.5ms preprocess, 24.4ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/8.jpg: 384x640 2 baseball bats, 51.9ms\n",
      "Speed: 1.7ms preprocess, 51.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/9.jpg: 384x640 2 baseball bats, 28.6ms\n",
      "Speed: 2.0ms preprocess, 28.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/10.jpg: 384x640 2 baseball bats, 39.7ms\n",
      "Speed: 2.0ms preprocess, 39.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/11.jpg: 384x640 2 baseball bats, 30.4ms\n",
      "Speed: 1.8ms preprocess, 30.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/12.jpg: 384x640 2 baseball bats, 33.4ms\n",
      "Speed: 1.9ms preprocess, 33.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/13.jpg: 384x640 2 baseball bats, 1 knife, 26.5ms\n",
      "Speed: 1.9ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/14.jpg: 384x640 2 baseball bats, 24.2ms\n",
      "Speed: 1.6ms preprocess, 24.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/15.jpg: 384x640 2 baseball bats, 42.2ms\n",
      "Speed: 2.6ms preprocess, 42.2ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/16.jpg: 384x640 2 baseball bats, 1 knife, 35.7ms\n",
      "Speed: 1.9ms preprocess, 35.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/17.jpg: 384x640 2 baseball bats, 1 knife, 35.8ms\n",
      "Speed: 1.8ms preprocess, 35.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/18.jpg: 384x640 2 baseball bats, 29.5ms\n",
      "Speed: 2.6ms preprocess, 29.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/19.jpg: 384x640 1 baseball bat, 1 knife, 26.5ms\n",
      "Speed: 1.8ms preprocess, 26.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/20.jpg: 384x640 2 baseball bats, 35.6ms\n",
      "Speed: 2.8ms preprocess, 35.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/21.jpg: 384x640 1 baseball bat, 1 knife, 35.9ms\n",
      "Speed: 2.8ms preprocess, 35.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/22.jpg: 384x640 2 baseball bats, 24.6ms\n",
      "Speed: 1.6ms preprocess, 24.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/23.jpg: 384x640 2 baseball bats, 42.2ms\n",
      "Speed: 1.8ms preprocess, 42.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/24.jpg: 384x640 (no detections), 28.4ms\n",
      "Speed: 1.7ms preprocess, 28.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/25.jpg: 384x640 1 baseball bat, 31.6ms\n",
      "Speed: 1.9ms preprocess, 31.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/26.jpg: 384x640 2 baseball bats, 59.3ms\n",
      "Speed: 1.8ms preprocess, 59.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/27.jpg: 384x640 2 baseball bats, 26.2ms\n",
      "Speed: 1.8ms preprocess, 26.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/28.jpg: 384x640 2 baseball bats, 25.6ms\n",
      "Speed: 2.0ms preprocess, 25.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/29.jpg: 384x640 2 baseball bats, 39.9ms\n",
      "Speed: 1.8ms preprocess, 39.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/30.jpg: 384x640 2 baseball bats, 39.7ms\n",
      "Speed: 2.2ms preprocess, 39.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/31.jpg: 384x640 2 baseball bats, 46.6ms\n",
      "Speed: 2.5ms preprocess, 46.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/32.jpg: 384x640 2 baseball bats, 33.9ms\n",
      "Speed: 1.7ms preprocess, 33.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/33.jpg: 384x640 1 baseball bat, 39.1ms\n",
      "Speed: 2.0ms preprocess, 39.1ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/34.jpg: 384x640 2 baseball bats, 42.7ms\n",
      "Speed: 1.9ms preprocess, 42.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/35.jpg: 384x640 2 baseball bats, 1 bottle, 39.7ms\n",
      "Speed: 1.8ms preprocess, 39.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/36.jpg: 384x640 2 baseball bats, 1 bottle, 39.9ms\n",
      "Speed: 2.3ms preprocess, 39.9ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/37.jpg: 384x640 2 baseball bats, 50.5ms\n",
      "Speed: 1.9ms preprocess, 50.5ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/38.jpg: 384x640 2 baseball bats, 39.9ms\n",
      "Speed: 2.0ms preprocess, 39.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/39.jpg: 384x640 1 baseball bat, 1 bottle, 47.4ms\n",
      "Speed: 2.8ms preprocess, 47.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/40.jpg: 384x640 2 baseball bats, 1 bottle, 50.0ms\n",
      "Speed: 3.2ms preprocess, 50.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/41.jpg: 384x640 2 baseball bats, 58.9ms\n",
      "Speed: 2.1ms preprocess, 58.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/42.jpg: 384x640 2 baseball bats, 34.0ms\n",
      "Speed: 2.4ms preprocess, 34.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/43.jpg: 384x640 2 baseball bats, 1 bottle, 52.6ms\n",
      "Speed: 1.9ms preprocess, 52.6ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/44.jpg: 384x640 1 baseball bat, 1 bottle, 32.4ms\n",
      "Speed: 2.0ms preprocess, 32.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/45.jpg: 384x640 1 baseball bat, 36.6ms\n",
      "Speed: 2.8ms preprocess, 36.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/46.jpg: 384x640 2 baseball bats, 1 carrot, 43.0ms\n",
      "Speed: 1.8ms preprocess, 43.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/47.jpg: 384x640 1 baseball bat, 41.1ms\n",
      "Speed: 1.9ms preprocess, 41.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/48.jpg: 384x640 2 baseball bats, 49.6ms\n",
      "Speed: 2.0ms preprocess, 49.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/49.jpg: 384x640 2 baseball bats, 37.4ms\n",
      "Speed: 2.1ms preprocess, 37.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/50.jpg: 384x640 2 baseball bats, 30.2ms\n",
      "Speed: 1.8ms preprocess, 30.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/51.jpg: 384x640 2 baseball bats, 36.6ms\n",
      "Speed: 1.8ms preprocess, 36.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/52.jpg: 384x640 2 baseball bats, 1 carrot, 42.4ms\n",
      "Speed: 2.6ms preprocess, 42.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/53.jpg: 384x640 2 baseball bats, 26.8ms\n",
      "Speed: 1.6ms preprocess, 26.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/54.jpg: 384x640 2 baseball bats, 26.4ms\n",
      "Speed: 1.8ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/55.jpg: 384x640 2 baseball bats, 29.1ms\n",
      "Speed: 1.8ms preprocess, 29.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/56.jpg: 384x640 1 spoon, 1 carrot, 35.5ms\n",
      "Speed: 2.4ms preprocess, 35.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/57.jpg: 384x640 2 baseball bats, 41.8ms\n",
      "Speed: 2.3ms preprocess, 41.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/58.jpg: 384x640 1 knife, 28.1ms\n",
      "Speed: 1.9ms preprocess, 28.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/59.jpg: 384x640 (no detections), 28.3ms\n",
      "Speed: 2.0ms preprocess, 28.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/60.jpg: 384x640 2 baseball bats, 27.4ms\n",
      "Speed: 1.8ms preprocess, 27.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/61.jpg: 384x640 2 baseball bats, 1 carrot, 31.5ms\n",
      "Speed: 2.0ms preprocess, 31.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/62.jpg: 384x640 2 baseball bats, 29.6ms\n",
      "Speed: 1.8ms preprocess, 29.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/63.jpg: 384x640 2 baseball bats, 31.0ms\n",
      "Speed: 3.6ms preprocess, 31.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/64.jpg: 384x640 1 knife, 32.9ms\n",
      "Speed: 2.1ms preprocess, 32.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/65.jpg: 384x640 2 baseball bats, 24.8ms\n",
      "Speed: 1.6ms preprocess, 24.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/66.jpg: 384x640 1 baseball bat, 31.3ms\n",
      "Speed: 3.2ms preprocess, 31.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/67.jpg: 384x640 1 baseball bat, 36.4ms\n",
      "Speed: 1.8ms preprocess, 36.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/68.jpg: 384x640 2 baseball bats, 42.6ms\n",
      "Speed: 1.9ms preprocess, 42.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/69.jpg: 384x640 2 baseball bats, 33.1ms\n",
      "Speed: 2.1ms preprocess, 33.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/70.jpg: 384x640 2 baseball bats, 25.3ms\n",
      "Speed: 1.6ms preprocess, 25.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/71.jpg: 384x640 2 baseball bats, 35.2ms\n",
      "Speed: 1.7ms preprocess, 35.2ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/72.jpg: 384x640 2 baseball bats, 31.9ms\n",
      "Speed: 2.0ms preprocess, 31.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/73.jpg: 384x640 2 baseball bats, 40.8ms\n",
      "Speed: 2.6ms preprocess, 40.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/74.jpg: 384x640 2 baseball bats, 48.9ms\n",
      "Speed: 4.9ms preprocess, 48.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/75.jpg: 384x640 2 baseball bats, 31.8ms\n",
      "Speed: 2.7ms preprocess, 31.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/76.jpg: 384x640 2 baseball bats, 1 bottle, 30.3ms\n",
      "Speed: 2.1ms preprocess, 30.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/77.jpg: 384x640 2 baseball bats, 29.7ms\n",
      "Speed: 2.2ms preprocess, 29.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/78.jpg: 384x640 2 baseball bats, 37.8ms\n",
      "Speed: 2.1ms preprocess, 37.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/79.jpg: 384x640 1 carrot, 32.2ms\n",
      "Speed: 2.1ms preprocess, 32.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/80.jpg: 384x640 1 carrot, 25.0ms\n",
      "Speed: 1.6ms preprocess, 25.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/81.jpg: 384x640 (no detections), 31.6ms\n",
      "Speed: 1.9ms preprocess, 31.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/82.jpg: 384x640 1 knife, 1 carrot, 30.3ms\n",
      "Speed: 1.6ms preprocess, 30.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/83.jpg: 384x640 (no detections), 30.2ms\n",
      "Speed: 1.8ms preprocess, 30.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/84.jpg: 384x640 2 baseball bats, 1 carrot, 37.1ms\n",
      "Speed: 1.8ms preprocess, 37.1ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/85.jpg: 384x640 1 cake, 38.7ms\n",
      "Speed: 1.8ms preprocess, 38.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/86.jpg: 384x640 1 cake, 30.2ms\n",
      "Speed: 2.9ms preprocess, 30.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/87.jpg: 384x640 1 knife, 27.3ms\n",
      "Speed: 1.9ms preprocess, 27.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/88.jpg: 384x640 1 knife, 1 carrot, 37.3ms\n",
      "Speed: 2.1ms preprocess, 37.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/89.jpg: 384x640 1 knife, 1 cake, 35.3ms\n",
      "Speed: 3.1ms preprocess, 35.3ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/90.jpg: 384x640 1 baseball bat, 1 cake, 25.0ms\n",
      "Speed: 1.7ms preprocess, 25.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/91.jpg: 384x640 2 knifes, 50.5ms\n",
      "Speed: 1.9ms preprocess, 50.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/92.jpg: 384x640 1 baseball bat, 1 knife, 1 cake, 38.0ms\n",
      "Speed: 1.9ms preprocess, 38.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/93.jpg: 384x640 1 knife, 1 cake, 43.1ms\n",
      "Speed: 2.0ms preprocess, 43.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/94.jpg: 384x640 1 baseball bat, 1 knife, 33.3ms\n",
      "Speed: 2.0ms preprocess, 33.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/95.jpg: 384x640 2 baseball bats, 1 knife, 45.3ms\n",
      "Speed: 2.3ms preprocess, 45.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/96.jpg: 384x640 1 knife, 44.7ms\n",
      "Speed: 3.3ms preprocess, 44.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/97.jpg: 384x640 (no detections), 42.2ms\n",
      "Speed: 2.8ms preprocess, 42.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/98.jpg: 384x640 1 knife, 36.3ms\n",
      "Speed: 1.9ms preprocess, 36.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/99.jpg: 384x640 1 fork, 1 knife, 40.2ms\n",
      "Speed: 2.1ms preprocess, 40.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/100.jpg: 384x640 1 knife, 1 spoon, 51.8ms\n",
      "Speed: 2.0ms preprocess, 51.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/101.jpg: 384x640 1 knife, 1 toothbrush, 50.6ms\n",
      "Speed: 3.1ms preprocess, 50.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/102.jpg: 384x640 1 knife, 1 toothbrush, 39.0ms\n",
      "Speed: 1.8ms preprocess, 39.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/103.jpg: 384x640 1 knife, 1 toothbrush, 64.3ms\n",
      "Speed: 2.3ms preprocess, 64.3ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/104.jpg: 384x640 1 knife, 38.6ms\n",
      "Speed: 2.4ms preprocess, 38.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/105.jpg: 384x640 (no detections), 61.2ms\n",
      "Speed: 2.6ms preprocess, 61.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/106.jpg: 384x640 1 knife, 56.8ms\n",
      "Speed: 2.0ms preprocess, 56.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/107.jpg: 384x640 2 knifes, 33.5ms\n",
      "Speed: 1.9ms preprocess, 33.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/108.jpg: 384x640 1 baseball bat, 1 knife, 38.8ms\n",
      "Speed: 2.4ms preprocess, 38.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/109.jpg: 384x640 (no detections), 38.8ms\n",
      "Speed: 1.9ms preprocess, 38.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/110.jpg: 384x640 1 baseball bat, 1 knife, 1 cake, 46.7ms\n",
      "Speed: 2.4ms preprocess, 46.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/111.jpg: 384x640 1 baseball bat, 1 knife, 1 carrot, 1 hot dog, 42.3ms\n",
      "Speed: 2.2ms preprocess, 42.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/112.jpg: 384x640 2 baseball bats, 1 bottle, 1 carrot, 43.4ms\n",
      "Speed: 2.7ms preprocess, 43.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/113.jpg: 384x640 2 baseball bats, 1 bottle, 29.5ms\n",
      "Speed: 1.9ms preprocess, 29.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/114.jpg: 384x640 1 baseball bat, 1 bottle, 35.8ms\n",
      "Speed: 2.7ms preprocess, 35.8ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/115.jpg: 384x640 2 baseball bats, 1 carrot, 27.8ms\n",
      "Speed: 2.0ms preprocess, 27.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/116.jpg: 384x640 2 baseball bats, 44.7ms\n",
      "Speed: 2.0ms preprocess, 44.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/117.jpg: 384x640 2 baseball bats, 41.3ms\n",
      "Speed: 1.9ms preprocess, 41.3ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/118.jpg: 384x640 2 baseball bats, 60.9ms\n",
      "Speed: 3.8ms preprocess, 60.9ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/119.jpg: 384x640 2 baseball bats, 1 carrot, 55.3ms\n",
      "Speed: 2.1ms preprocess, 55.3ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/120.jpg: 384x640 2 baseball bats, 46.6ms\n",
      "Speed: 2.1ms preprocess, 46.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/121.jpg: 384x640 2 baseball bats, 37.9ms\n",
      "Speed: 2.1ms preprocess, 37.9ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/122.jpg: 384x640 2 baseball bats, 36.0ms\n",
      "Speed: 2.1ms preprocess, 36.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/123.jpg: 384x640 2 baseball bats, 42.7ms\n",
      "Speed: 3.1ms preprocess, 42.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/124.jpg: 384x640 2 baseball bats, 33.9ms\n",
      "Speed: 2.1ms preprocess, 33.9ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/125.jpg: 384x640 2 baseball bats, 1 bottle, 50.6ms\n",
      "Speed: 2.0ms preprocess, 50.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/126.jpg: 384x640 1 baseball bat, 1 bottle, 45.2ms\n",
      "Speed: 2.1ms preprocess, 45.2ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/127.jpg: 384x640 1 baseball bat, 31.8ms\n",
      "Speed: 2.0ms preprocess, 31.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/128.jpg: 384x640 1 baseball bat, 1 bottle, 46.0ms\n",
      "Speed: 1.9ms preprocess, 46.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/129.jpg: 384x640 1 bottle, 28.8ms\n",
      "Speed: 2.4ms preprocess, 28.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/130.jpg: 384x640 1 bottle, 53.8ms\n",
      "Speed: 2.2ms preprocess, 53.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/131.jpg: 384x640 (no detections), 34.7ms\n",
      "Speed: 2.0ms preprocess, 34.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/132.jpg: 384x640 1 bottle, 1 spoon, 31.0ms\n",
      "Speed: 1.8ms preprocess, 31.0ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/133.jpg: 384x640 1 bottle, 1 knife, 29.3ms\n",
      "Speed: 2.0ms preprocess, 29.3ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/134.jpg: 384x640 1 bottle, 1 knife, 48.7ms\n",
      "Speed: 1.7ms preprocess, 48.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/135.jpg: 384x640 1 bottle, 1 knife, 39.5ms\n",
      "Speed: 2.1ms preprocess, 39.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/136.jpg: 384x640 1 bottle, 1 knife, 34.1ms\n",
      "Speed: 1.9ms preprocess, 34.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/137.jpg: 384x640 1 knife, 50.9ms\n",
      "Speed: 3.4ms preprocess, 50.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/138.jpg: 384x640 1 bottle, 1 knife, 49.9ms\n",
      "Speed: 1.9ms preprocess, 49.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/139.jpg: 384x640 1 bottle, 40.2ms\n",
      "Speed: 1.7ms preprocess, 40.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/140.jpg: 384x640 1 bottle, 1 knife, 35.5ms\n",
      "Speed: 2.0ms preprocess, 35.5ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/141.jpg: 384x640 1 bottle, 1 knife, 37.6ms\n",
      "Speed: 1.8ms preprocess, 37.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/142.jpg: 384x640 1 bottle, 30.6ms\n",
      "Speed: 1.8ms preprocess, 30.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/143.jpg: 384x640 1 bottle, 1 knife, 41.9ms\n",
      "Speed: 3.0ms preprocess, 41.9ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/144.jpg: 384x640 1 bottle, 1 knife, 52.7ms\n",
      "Speed: 3.2ms preprocess, 52.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/145.jpg: 384x640 2 bottles, 40.9ms\n",
      "Speed: 2.0ms preprocess, 40.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/146.jpg: 384x640 1 bottle, 37.6ms\n",
      "Speed: 1.7ms preprocess, 37.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/147.jpg: 384x640 1 bottle, 49.1ms\n",
      "Speed: 1.8ms preprocess, 49.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/148.jpg: 384x640 1 bottle, 1 spoon, 29.6ms\n",
      "Speed: 1.9ms preprocess, 29.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/149.jpg: 384x640 1 bottle, 1 knife, 40.0ms\n",
      "Speed: 1.7ms preprocess, 40.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/150.jpg: 384x640 1 bottle, 37.0ms\n",
      "Speed: 1.8ms preprocess, 37.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/151.jpg: 384x640 1 knife, 44.0ms\n",
      "Speed: 1.8ms preprocess, 44.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/152.jpg: 384x640 1 baseball bat, 1 bottle, 45.8ms\n",
      "Speed: 1.8ms preprocess, 45.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/153.jpg: 384x640 1 baseball bat, 1 cake, 30.0ms\n",
      "Speed: 1.8ms preprocess, 30.0ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/154.jpg: 384x640 1 baseball bat, 1 bottle, 1 knife, 35.5ms\n",
      "Speed: 1.9ms preprocess, 35.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/155.jpg: 384x640 1 baseball bat, 1 knife, 33.2ms\n",
      "Speed: 2.0ms preprocess, 33.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/156.jpg: 384x640 1 baseball bat, 1 bottle, 1 knife, 38.7ms\n",
      "Speed: 2.0ms preprocess, 38.7ms inference, 9.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/157.jpg: 384x640 1 baseball bat, 1 knife, 1 hot dog, 42.6ms\n",
      "Speed: 3.2ms preprocess, 42.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/158.jpg: 384x640 1 baseball bat, 1 knife, 1 cake, 29.2ms\n",
      "Speed: 2.0ms preprocess, 29.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/159.jpg: 384x640 1 baseball bat, 1 cake, 52.8ms\n",
      "Speed: 3.6ms preprocess, 52.8ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/160.jpg: 384x640 1 baseball bat, 1 knife, 45.7ms\n",
      "Speed: 2.2ms preprocess, 45.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/161.jpg: 384x640 1 knife, 41.7ms\n",
      "Speed: 2.1ms preprocess, 41.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/162.jpg: 384x640 1 baseball bat, 1 knife, 37.7ms\n",
      "Speed: 2.2ms preprocess, 37.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/163.jpg: 384x640 1 fork, 1 spoon, 32.0ms\n",
      "Speed: 2.3ms preprocess, 32.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/164.jpg: 384x640 1 knife, 1 spoon, 32.3ms\n",
      "Speed: 2.0ms preprocess, 32.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/165.jpg: 384x640 1 fork, 1 spoon, 41.2ms\n",
      "Speed: 1.8ms preprocess, 41.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/166.jpg: 384x640 1 spoon, 30.1ms\n",
      "Speed: 1.9ms preprocess, 30.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/167.jpg: 384x640 1 spoon, 35.5ms\n",
      "Speed: 1.9ms preprocess, 35.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/168.jpg: 384x640 1 knife, 1 spoon, 25.9ms\n",
      "Speed: 1.8ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/169.jpg: 384x640 1 knife, 33.2ms\n",
      "Speed: 2.0ms preprocess, 33.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/170.jpg: 384x640 1 knife, 48.9ms\n",
      "Speed: 1.7ms preprocess, 48.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/171.jpg: 384x640 1 spoon, 26.8ms\n",
      "Speed: 1.9ms preprocess, 26.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/172.jpg: 384x640 1 spoon, 30.4ms\n",
      "Speed: 2.8ms preprocess, 30.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/173.jpg: 384x640 1 bottle, 63.3ms\n",
      "Speed: 2.4ms preprocess, 63.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/174.jpg: 384x640 (no detections), 41.5ms\n",
      "Speed: 1.8ms preprocess, 41.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/175.jpg: 384x640 1 bottle, 1 knife, 33.2ms\n",
      "Speed: 2.7ms preprocess, 33.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/176.jpg: 384x640 1 baseball bat, 1 bottle, 1 knife, 38.3ms\n",
      "Speed: 2.2ms preprocess, 38.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/177.jpg: 384x640 1 knife, 47.0ms\n",
      "Speed: 3.1ms preprocess, 47.0ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/178.jpg: 384x640 1 bottle, 30.2ms\n",
      "Speed: 1.8ms preprocess, 30.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/179.jpg: 384x640 2 baseball bats, 40.3ms\n",
      "Speed: 2.0ms preprocess, 40.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/180.jpg: 384x640 1 baseball bat, 1 bottle, 42.3ms\n",
      "Speed: 2.8ms preprocess, 42.3ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/181.jpg: 384x640 2 baseball bats, 40.3ms\n",
      "Speed: 2.0ms preprocess, 40.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/182.jpg: 384x640 2 baseball bats, 46.9ms\n",
      "Speed: 2.0ms preprocess, 46.9ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/183.jpg: 384x640 2 baseball bats, 38.9ms\n",
      "Speed: 2.3ms preprocess, 38.9ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/184.jpg: 384x640 2 baseball bats, 44.2ms\n",
      "Speed: 2.0ms preprocess, 44.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/185.jpg: 384x640 2 baseball bats, 56.2ms\n",
      "Speed: 2.6ms preprocess, 56.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/186.jpg: 384x640 2 baseball bats, 30.7ms\n",
      "Speed: 2.3ms preprocess, 30.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/187.jpg: 384x640 2 baseball bats, 43.0ms\n",
      "Speed: 2.7ms preprocess, 43.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/188.jpg: 384x640 2 baseball bats, 33.0ms\n",
      "Speed: 1.9ms preprocess, 33.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/189.jpg: 384x640 2 baseball bats, 33.0ms\n",
      "Speed: 2.2ms preprocess, 33.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/190.jpg: 384x640 2 baseball bats, 1 carrot, 34.7ms\n",
      "Speed: 2.0ms preprocess, 34.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/191.jpg: 384x640 2 baseball bats, 35.8ms\n",
      "Speed: 3.1ms preprocess, 35.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/192.jpg: 384x640 1 baseball bat, 1 bottle, 29.9ms\n",
      "Speed: 1.8ms preprocess, 29.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/193.jpg: 384x640 1 baseball bat, 42.2ms\n",
      "Speed: 2.4ms preprocess, 42.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/194.jpg: 384x640 1 baseball bat, 43.9ms\n",
      "Speed: 1.9ms preprocess, 43.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/195.jpg: 384x640 1 baseball bat, 31.0ms\n",
      "Speed: 1.8ms preprocess, 31.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/196.jpg: 384x640 2 baseball bats, 28.1ms\n",
      "Speed: 1.9ms preprocess, 28.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/197.jpg: 384x640 1 knife, 55.0ms\n",
      "Speed: 2.0ms preprocess, 55.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/198.jpg: 384x640 2 baseball bats, 1 bottle, 57.2ms\n",
      "Speed: 3.1ms preprocess, 57.2ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/199.jpg: 384x640 1 baseball bat, 27.5ms\n",
      "Speed: 2.0ms preprocess, 27.5ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/200.jpg: 384x640 1 baseball bat, 2 hot dogs, 34.4ms\n",
      "Speed: 2.1ms preprocess, 34.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/201.jpg: 384x640 2 baseball bats, 1 carrot, 33.3ms\n",
      "Speed: 2.4ms preprocess, 33.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/202.jpg: 384x640 1 baseball bat, 1 carrot, 1 hot dog, 36.0ms\n",
      "Speed: 1.8ms preprocess, 36.0ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/203.jpg: 384x640 1 baseball bat, 1 carrot, 32.7ms\n",
      "Speed: 2.0ms preprocess, 32.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/204.jpg: 384x640 2 carrots, 38.0ms\n",
      "Speed: 1.8ms preprocess, 38.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/205.jpg: 384x640 1 knife, 33.1ms\n",
      "Speed: 1.8ms preprocess, 33.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/206.jpg: 384x640 1 bottle, 1 carrot, 32.0ms\n",
      "Speed: 1.8ms preprocess, 32.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/207.jpg: 384x640 1 knife, 1 carrot, 33.3ms\n",
      "Speed: 1.6ms preprocess, 33.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/208.jpg: 384x640 1 baseball bat, 1 spoon, 1 hot dog, 29.7ms\n",
      "Speed: 2.1ms preprocess, 29.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/209.jpg: 384x640 1 baseball bat, 1 carrot, 30.2ms\n",
      "Speed: 2.9ms preprocess, 30.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/210.jpg: 384x640 1 baseball bat, 1 carrot, 39.9ms\n",
      "Speed: 2.0ms preprocess, 39.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/211.jpg: 384x640 2 baseball bats, 2 carrots, 29.2ms\n",
      "Speed: 2.7ms preprocess, 29.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/212.jpg: 384x640 2 baseball bats, 1 carrot, 65.2ms\n",
      "Speed: 2.7ms preprocess, 65.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/213.jpg: 384x640 2 knifes, 1 carrot, 57.4ms\n",
      "Speed: 2.0ms preprocess, 57.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/214.jpg: 384x640 1 spoon, 1 carrot, 1 hot dog, 51.4ms\n",
      "Speed: 2.2ms preprocess, 51.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/215.jpg: 384x640 1 baseball bat, 1 carrot, 53.3ms\n",
      "Speed: 3.1ms preprocess, 53.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/216.jpg: 384x640 1 baseball bat, 1 carrot, 40.9ms\n",
      "Speed: 2.2ms preprocess, 40.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/217.jpg: 384x640 3 hot dogs, 44.7ms\n",
      "Speed: 2.2ms preprocess, 44.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/218.jpg: 384x640 1 knife, 1 hot dog, 33.5ms\n",
      "Speed: 1.9ms preprocess, 33.5ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/219.jpg: 384x640 1 knife, 1 hot dog, 45.7ms\n",
      "Speed: 3.1ms preprocess, 45.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/220.jpg: 384x640 1 baseball bat, 55.1ms\n",
      "Speed: 3.6ms preprocess, 55.1ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/221.jpg: 384x640 1 baseball bat, 1 knife, 1 cake, 35.2ms\n",
      "Speed: 2.0ms preprocess, 35.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/222.jpg: 384x640 2 baseball bats, 2 knifes, 45.5ms\n",
      "Speed: 2.9ms preprocess, 45.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/223.jpg: 384x640 2 baseball bats, 1 knife, 54.2ms\n",
      "Speed: 2.9ms preprocess, 54.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/224.jpg: 384x640 1 knife, 1 spoon, 38.0ms\n",
      "Speed: 2.1ms preprocess, 38.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/225.jpg: 384x640 1 baseball bat, 1 knife, 1 spoon, 41.2ms\n",
      "Speed: 2.0ms preprocess, 41.2ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/226.jpg: 384x640 1 baseball bat, 1 knife, 1 spoon, 30.8ms\n",
      "Speed: 1.8ms preprocess, 30.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/227.jpg: 384x640 1 knife, 1 spoon, 40.4ms\n",
      "Speed: 1.8ms preprocess, 40.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/228.jpg: 384x640 1 baseball bat, 1 knife, 1 spoon, 46.2ms\n",
      "Speed: 3.2ms preprocess, 46.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/229.jpg: 384x640 2 knifes, 1 spoon, 42.5ms\n",
      "Speed: 2.0ms preprocess, 42.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/230.jpg: 384x640 1 baseball bat, 58.1ms\n",
      "Speed: 2.5ms preprocess, 58.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/231.jpg: 384x640 2 spoons, 69.9ms\n",
      "Speed: 2.4ms preprocess, 69.9ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/232.jpg: 384x640 2 baseball bats, 41.4ms\n",
      "Speed: 3.2ms preprocess, 41.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/233.jpg: 384x640 1 baseball bat, 1 cake, 50.1ms\n",
      "Speed: 2.0ms preprocess, 50.1ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/234.jpg: 384x640 2 baseball bats, 30.5ms\n",
      "Speed: 2.0ms preprocess, 30.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/235.jpg: 384x640 2 baseball bats, 1 spoon, 45.5ms\n",
      "Speed: 2.7ms preprocess, 45.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/236.jpg: 384x640 2 knifes, 1 spoon, 31.3ms\n",
      "Speed: 1.9ms preprocess, 31.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/237.jpg: 384x640 2 baseball bats, 38.3ms\n",
      "Speed: 1.9ms preprocess, 38.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/238.jpg: 384x640 1 knife, 49.1ms\n",
      "Speed: 2.1ms preprocess, 49.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/239.jpg: 384x640 2 knifes, 1 cake, 45.9ms\n",
      "Speed: 2.0ms preprocess, 45.9ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/240.jpg: 384x640 1 baseball bat, 33.6ms\n",
      "Speed: 2.2ms preprocess, 33.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/241.jpg: 384x640 1 spoon, 50.3ms\n",
      "Speed: 2.0ms preprocess, 50.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/242.jpg: 384x640 2 baseball bats, 1 spoon, 1 cake, 45.5ms\n",
      "Speed: 2.8ms preprocess, 45.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/243.jpg: 384x640 1 spoon, 1 cake, 54.8ms\n",
      "Speed: 3.6ms preprocess, 54.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/244.jpg: 384x640 1 baseball bat, 1 knife, 1 spoon, 55.8ms\n",
      "Speed: 3.6ms preprocess, 55.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/245.jpg: 384x640 1 baseball bat, 1 spoon, 54.0ms\n",
      "Speed: 2.6ms preprocess, 54.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/246.jpg: 384x640 1 spoon, 41.9ms\n",
      "Speed: 2.1ms preprocess, 41.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/247.jpg: 384x640 1 baseball bat, 44.5ms\n",
      "Speed: 2.3ms preprocess, 44.5ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/248.jpg: 384x640 2 baseball bats, 51.3ms\n",
      "Speed: 1.9ms preprocess, 51.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/249.jpg: 384x640 2 baseball bats, 42.3ms\n",
      "Speed: 3.0ms preprocess, 42.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/250.jpg: 384x640 1 spoon, 42.1ms\n",
      "Speed: 2.2ms preprocess, 42.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/251.jpg: 384x640 1 baseball bat, 33.6ms\n",
      "Speed: 1.8ms preprocess, 33.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/252.jpg: 384x640 2 baseball bats, 1 spoon, 62.0ms\n",
      "Speed: 1.9ms preprocess, 62.0ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/253.jpg: 384x640 2 baseball bats, 64.7ms\n",
      "Speed: 1.9ms preprocess, 64.7ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/254.jpg: 384x640 1 baseball bat, 1 spoon, 45.8ms\n",
      "Speed: 2.0ms preprocess, 45.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/255.jpg: 384x640 2 baseball bats, 65.7ms\n",
      "Speed: 2.2ms preprocess, 65.7ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/256.jpg: 384x640 1 baseball bat, 56.0ms\n",
      "Speed: 3.8ms preprocess, 56.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/257.jpg: 384x640 1 baseball bat, 54.7ms\n",
      "Speed: 2.2ms preprocess, 54.7ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/258.jpg: 384x640 1 baseball bat, 1 knife, 1 carrot, 35.8ms\n",
      "Speed: 2.2ms preprocess, 35.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/259.jpg: 384x640 (no detections), 33.6ms\n",
      "Speed: 2.2ms preprocess, 33.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/260.jpg: 384x640 2 baseball bats, 32.6ms\n",
      "Speed: 2.3ms preprocess, 32.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/261.jpg: 384x640 1 baseball bat, 1 spoon, 48.9ms\n",
      "Speed: 2.5ms preprocess, 48.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/262.jpg: 384x640 2 baseball bats, 1 carrot, 37.8ms\n",
      "Speed: 2.0ms preprocess, 37.8ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/263.jpg: 384x640 2 baseball bats, 49.5ms\n",
      "Speed: 2.1ms preprocess, 49.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/264.jpg: 384x640 2 baseball bats, 49.2ms\n",
      "Speed: 2.4ms preprocess, 49.2ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/265.jpg: 384x640 2 baseball bats, 61.6ms\n",
      "Speed: 3.2ms preprocess, 61.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/266.jpg: 384x640 2 baseball bats, 51.4ms\n",
      "Speed: 2.9ms preprocess, 51.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/267.jpg: 384x640 2 baseball bats, 43.7ms\n",
      "Speed: 3.0ms preprocess, 43.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/268.jpg: 384x640 2 baseball bats, 58.7ms\n",
      "Speed: 2.2ms preprocess, 58.7ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/269.jpg: 384x640 1 spoon, 38.2ms\n",
      "Speed: 2.3ms preprocess, 38.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/270.jpg: 384x640 1 baseball bat, 56.0ms\n",
      "Speed: 2.2ms preprocess, 56.0ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/271.jpg: 384x640 2 baseball bats, 42.8ms\n",
      "Speed: 2.1ms preprocess, 42.8ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/272.jpg: 384x640 1 knife, 45.1ms\n",
      "Speed: 2.1ms preprocess, 45.1ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/273.jpg: 384x640 1 baseball bat, 1 spoon, 47.1ms\n",
      "Speed: 3.1ms preprocess, 47.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/274.jpg: 384x640 1 baseball bat, 34.5ms\n",
      "Speed: 2.2ms preprocess, 34.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/275.jpg: 384x640 (no detections), 61.4ms\n",
      "Speed: 2.2ms preprocess, 61.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/276.jpg: 384x640 2 baseball bats, 36.8ms\n",
      "Speed: 2.2ms preprocess, 36.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/277.jpg: 384x640 1 baseball bat, 1 spoon, 55.7ms\n",
      "Speed: 3.1ms preprocess, 55.7ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/278.jpg: 384x640 2 baseball bats, 44.3ms\n",
      "Speed: 2.1ms preprocess, 44.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/279.jpg: 384x640 2 baseball bats, 52.5ms\n",
      "Speed: 3.0ms preprocess, 52.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/280.jpg: 384x640 2 knifes, 1 spoon, 36.7ms\n",
      "Speed: 2.1ms preprocess, 36.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/281.jpg: 384x640 1 baseball bat, 1 knife, 1 spoon, 54.5ms\n",
      "Speed: 6.0ms preprocess, 54.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/282.jpg: 384x640 1 knife, 1 carrot, 34.4ms\n",
      "Speed: 2.0ms preprocess, 34.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/283.jpg: 384x640 2 knifes, 1 spoon, 1 carrot, 36.8ms\n",
      "Speed: 2.7ms preprocess, 36.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/284.jpg: 384x640 1 knife, 1 spoon, 41.4ms\n",
      "Speed: 1.9ms preprocess, 41.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/285.jpg: 384x640 2 baseball bats, 35.6ms\n",
      "Speed: 2.3ms preprocess, 35.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/286.jpg: 384x640 2 knifes, 1 spoon, 1 carrot, 48.1ms\n",
      "Speed: 2.2ms preprocess, 48.1ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/287.jpg: 384x640 2 knifes, 45.7ms\n",
      "Speed: 2.1ms preprocess, 45.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/288.jpg: 384x640 1 baseball bat, 32.3ms\n",
      "Speed: 1.8ms preprocess, 32.3ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/289.jpg: 384x640 1 knife, 2 spoons, 33.3ms\n",
      "Speed: 1.6ms preprocess, 33.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/290.jpg: 384x640 1 knife, 1 spoon, 1 cake, 51.1ms\n",
      "Speed: 1.9ms preprocess, 51.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/291.jpg: 384x640 1 knife, 1 spoon, 1 cake, 48.2ms\n",
      "Speed: 3.3ms preprocess, 48.2ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/292.jpg: 384x640 1 knife, 1 spoon, 1 carrot, 102.7ms\n",
      "Speed: 2.0ms preprocess, 102.7ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/293.jpg: 384x640 2 knifes, 1 carrot, 33.6ms\n",
      "Speed: 2.1ms preprocess, 33.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/294.jpg: 384x640 2 knifes, 1 spoon, 1 carrot, 45.3ms\n",
      "Speed: 2.9ms preprocess, 45.3ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/295.jpg: 384x640 1 knife, 1 spoon, 1 carrot, 53.9ms\n",
      "Speed: 2.3ms preprocess, 53.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/296.jpg: 384x640 2 knifes, 1 carrot, 57.6ms\n",
      "Speed: 3.2ms preprocess, 57.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/297.jpg: 384x640 1 knife, 1 spoon, 40.8ms\n",
      "Speed: 2.4ms preprocess, 40.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/298.jpg: 384x640 2 knifes, 58.2ms\n",
      "Speed: 2.5ms preprocess, 58.2ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/left/299.jpg: 384x640 2 knifes, 41.9ms\n",
      "Speed: 2.6ms preprocess, 41.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Propagating video frames: 100%|| 300/300 [00:22<00:00, 13.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask propagation completed in 22.56 seconds.\n",
      "Processing predicted masks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing video frames: 300it [00:02, 132.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 300 masks for evaluation.\n",
      "Masks saved to data/masks/yolo11x-seg/val/data-raw-SegSTRONGC_val-val-1-0-regular-left.pkl\n",
      "Loading ground truth masks for evaluation...\n",
      "Loaded 300 ground truth masks.\n",
      "Calculating evaluation metrics...\n",
      "Time taken for metrics calculation: 1.88 seconds.\n",
      "Mean IoU for data/raw/SegSTRONGC_val/val/1/0/regular/left: 0.5866\n",
      "Mean DSC for data/raw/SegSTRONGC_val/val/1/0/regular/left: 0.6925\n",
      "Loading existing results file: data/results/yolo11x-seg/val.json\n",
      "Results saved to data/results/yolo11x-seg/val.json\n",
      "Processing video took 28.85 seconds.\n",
      "==================================================\n",
      "Processing right camera video...\n",
      "==================================================\n",
      "Processing video: data/raw/SegSTRONGC_val/val/1/0/regular/right\n",
      "Domain: regular, Split: val, Camera: right\n",
      "Initializing Yolo for video...\n",
      "Initialization took 1.56 seconds.\n",
      "Starting mask propagation...\n",
      "Total images in video: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/0.jpg: 384x640 1 knife, 1 carrot, 64.1ms\n",
      "Speed: 3.3ms preprocess, 64.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/1.jpg: 384x640 2 knifes, 33.4ms\n",
      "Speed: 2.0ms preprocess, 33.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/2.jpg: 384x640 2 knifes, 49.3ms\n",
      "Speed: 1.9ms preprocess, 49.3ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/3.jpg: 384x640 1 knife, 34.5ms\n",
      "Speed: 2.2ms preprocess, 34.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/4.jpg: 384x640 1 knife, 27.6ms\n",
      "Speed: 1.7ms preprocess, 27.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/5.jpg: 384x640 1 knife, 1 spoon, 37.0ms\n",
      "Speed: 3.2ms preprocess, 37.0ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/6.jpg: 384x640 1 knife, 1 spoon, 46.5ms\n",
      "Speed: 1.8ms preprocess, 46.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/7.jpg: 384x640 1 knife, 1 spoon, 33.1ms\n",
      "Speed: 1.8ms preprocess, 33.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/8.jpg: 384x640 1 spoon, 47.4ms\n",
      "Speed: 2.0ms preprocess, 47.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/9.jpg: 384x640 1 knife, 2 spoons, 37.9ms\n",
      "Speed: 2.6ms preprocess, 37.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/10.jpg: 384x640 1 spoon, 29.9ms\n",
      "Speed: 1.8ms preprocess, 29.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/11.jpg: 384x640 2 spoons, 28.7ms\n",
      "Speed: 1.9ms preprocess, 28.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/12.jpg: 384x640 1 knife, 26.4ms\n",
      "Speed: 2.0ms preprocess, 26.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/13.jpg: 384x640 1 knife, 2 spoons, 34.1ms\n",
      "Speed: 2.1ms preprocess, 34.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/14.jpg: 384x640 1 knife, 29.1ms\n",
      "Speed: 2.4ms preprocess, 29.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/15.jpg: 384x640 2 spoons, 28.1ms\n",
      "Speed: 2.0ms preprocess, 28.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/16.jpg: 384x640 1 knife, 38.3ms\n",
      "Speed: 1.9ms preprocess, 38.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/17.jpg: 384x640 1 knife, 48.2ms\n",
      "Speed: 3.2ms preprocess, 48.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/18.jpg: 384x640 1 knife, 32.4ms\n",
      "Speed: 2.0ms preprocess, 32.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/19.jpg: 384x640 1 baseball bat, 1 knife, 51.8ms\n",
      "Speed: 1.7ms preprocess, 51.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/20.jpg: 384x640 1 knife, 40.3ms\n",
      "Speed: 2.1ms preprocess, 40.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/21.jpg: 384x640 1 baseball bat, 44.2ms\n",
      "Speed: 2.1ms preprocess, 44.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/22.jpg: 384x640 1 knife, 41.8ms\n",
      "Speed: 2.0ms preprocess, 41.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/23.jpg: 384x640 1 knife, 31.2ms\n",
      "Speed: 1.9ms preprocess, 31.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/24.jpg: 384x640 (no detections), 39.9ms\n",
      "Speed: 2.0ms preprocess, 39.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/25.jpg: 384x640 1 knife, 32.2ms\n",
      "Speed: 2.0ms preprocess, 32.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/26.jpg: 384x640 1 knife, 1 spoon, 34.9ms\n",
      "Speed: 2.3ms preprocess, 34.9ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/27.jpg: 384x640 1 spoon, 41.5ms\n",
      "Speed: 2.3ms preprocess, 41.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/28.jpg: 384x640 1 knife, 1 spoon, 32.3ms\n",
      "Speed: 2.0ms preprocess, 32.3ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/29.jpg: 384x640 1 knife, 50.8ms\n",
      "Speed: 1.9ms preprocess, 50.8ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/30.jpg: 384x640 1 spoon, 1 carrot, 39.6ms\n",
      "Speed: 2.1ms preprocess, 39.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/31.jpg: 384x640 1 knife, 1 spoon, 1 carrot, 50.3ms\n",
      "Speed: 2.1ms preprocess, 50.3ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/32.jpg: 384x640 1 knife, 41.7ms\n",
      "Speed: 2.1ms preprocess, 41.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/33.jpg: 384x640 1 knife, 2 spoons, 1 carrot, 35.9ms\n",
      "Speed: 2.0ms preprocess, 35.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/34.jpg: 384x640 2 spoons, 46.9ms\n",
      "Speed: 2.2ms preprocess, 46.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/35.jpg: 384x640 (no detections), 37.3ms\n",
      "Speed: 1.8ms preprocess, 37.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/36.jpg: 384x640 (no detections), 45.1ms\n",
      "Speed: 1.9ms preprocess, 45.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/37.jpg: 384x640 1 knife, 39.7ms\n",
      "Speed: 3.0ms preprocess, 39.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/38.jpg: 384x640 1 baseball bat, 41.2ms\n",
      "Speed: 2.3ms preprocess, 41.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/39.jpg: 384x640 1 baseball bat, 1 bottle, 35.5ms\n",
      "Speed: 2.2ms preprocess, 35.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/40.jpg: 384x640 1 knife, 40.6ms\n",
      "Speed: 2.2ms preprocess, 40.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/41.jpg: 384x640 (no detections), 42.2ms\n",
      "Speed: 2.3ms preprocess, 42.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/42.jpg: 384x640 1 baseball bat, 1 carrot, 33.7ms\n",
      "Speed: 2.1ms preprocess, 33.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/43.jpg: 384x640 (no detections), 39.5ms\n",
      "Speed: 1.9ms preprocess, 39.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/44.jpg: 384x640 (no detections), 43.1ms\n",
      "Speed: 2.2ms preprocess, 43.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/45.jpg: 384x640 1 baseball bat, 1 spoon, 44.3ms\n",
      "Speed: 2.2ms preprocess, 44.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/46.jpg: 384x640 1 spoon, 33.7ms\n",
      "Speed: 2.1ms preprocess, 33.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/47.jpg: 384x640 1 baseball bat, 1 carrot, 37.0ms\n",
      "Speed: 2.1ms preprocess, 37.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/48.jpg: 384x640 1 carrot, 40.0ms\n",
      "Speed: 3.4ms preprocess, 40.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/49.jpg: 384x640 1 carrot, 56.0ms\n",
      "Speed: 2.3ms preprocess, 56.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/50.jpg: 384x640 1 knife, 2 spoons, 1 carrot, 41.6ms\n",
      "Speed: 1.8ms preprocess, 41.6ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/51.jpg: 384x640 1 knife, 2 spoons, 2 carrots, 42.6ms\n",
      "Speed: 2.1ms preprocess, 42.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/52.jpg: 384x640 1 spoon, 2 carrots, 34.4ms\n",
      "Speed: 2.9ms preprocess, 34.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/53.jpg: 384x640 3 carrots, 45.1ms\n",
      "Speed: 2.2ms preprocess, 45.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/54.jpg: 384x640 (no detections), 47.8ms\n",
      "Speed: 2.0ms preprocess, 47.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/55.jpg: 384x640 (no detections), 37.1ms\n",
      "Speed: 2.2ms preprocess, 37.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/56.jpg: 384x640 1 knife, 2 spoons, 38.7ms\n",
      "Speed: 2.8ms preprocess, 38.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/57.jpg: 384x640 1 knife, 1 spoon, 38.6ms\n",
      "Speed: 2.3ms preprocess, 38.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/58.jpg: 384x640 1 knife, 45.4ms\n",
      "Speed: 2.6ms preprocess, 45.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/59.jpg: 384x640 1 spoon, 33.7ms\n",
      "Speed: 2.1ms preprocess, 33.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/60.jpg: 384x640 1 knife, 1 spoon, 36.8ms\n",
      "Speed: 2.8ms preprocess, 36.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/61.jpg: 384x640 1 knife, 40.1ms\n",
      "Speed: 2.1ms preprocess, 40.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/62.jpg: 384x640 1 spoon, 46.5ms\n",
      "Speed: 1.9ms preprocess, 46.5ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/63.jpg: 384x640 1 knife, 1 spoon, 35.5ms\n",
      "Speed: 2.2ms preprocess, 35.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/64.jpg: 384x640 1 spoon, 44.6ms\n",
      "Speed: 2.1ms preprocess, 44.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/65.jpg: 384x640 1 knife, 55.1ms\n",
      "Speed: 2.0ms preprocess, 55.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/66.jpg: 384x640 1 spoon, 38.2ms\n",
      "Speed: 3.6ms preprocess, 38.2ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/67.jpg: 384x640 1 spoon, 35.3ms\n",
      "Speed: 2.1ms preprocess, 35.3ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/68.jpg: 384x640 2 spoons, 34.6ms\n",
      "Speed: 2.3ms preprocess, 34.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/69.jpg: 384x640 2 spoons, 45.0ms\n",
      "Speed: 2.0ms preprocess, 45.0ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/70.jpg: 384x640 2 spoons, 34.2ms\n",
      "Speed: 2.5ms preprocess, 34.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/71.jpg: 384x640 (no detections), 41.2ms\n",
      "Speed: 1.8ms preprocess, 41.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/72.jpg: 384x640 (no detections), 52.5ms\n",
      "Speed: 2.5ms preprocess, 52.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/73.jpg: 384x640 1 spoon, 34.1ms\n",
      "Speed: 2.2ms preprocess, 34.1ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/74.jpg: 384x640 (no detections), 54.4ms\n",
      "Speed: 3.2ms preprocess, 54.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/75.jpg: 384x640 (no detections), 50.0ms\n",
      "Speed: 2.2ms preprocess, 50.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/76.jpg: 384x640 1 knife, 1 spoon, 42.5ms\n",
      "Speed: 1.9ms preprocess, 42.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/77.jpg: 384x640 1 knife, 48.2ms\n",
      "Speed: 2.1ms preprocess, 48.2ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/78.jpg: 384x640 1 knife, 51.8ms\n",
      "Speed: 3.1ms preprocess, 51.8ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/79.jpg: 384x640 1 knife, 1 carrot, 34.7ms\n",
      "Speed: 2.2ms preprocess, 34.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/80.jpg: 384x640 1 spoon, 1 carrot, 40.4ms\n",
      "Speed: 2.2ms preprocess, 40.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/81.jpg: 384x640 1 carrot, 39.3ms\n",
      "Speed: 2.9ms preprocess, 39.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/82.jpg: 384x640 1 knife, 1 spoon, 44.4ms\n",
      "Speed: 2.1ms preprocess, 44.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/83.jpg: 384x640 1 knife, 1 spoon, 1 carrot, 49.0ms\n",
      "Speed: 2.0ms preprocess, 49.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/84.jpg: 384x640 1 knife, 44.9ms\n",
      "Speed: 1.9ms preprocess, 44.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/85.jpg: 384x640 1 knife, 34.7ms\n",
      "Speed: 2.1ms preprocess, 34.7ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/86.jpg: 384x640 1 knife, 38.0ms\n",
      "Speed: 2.1ms preprocess, 38.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/87.jpg: 384x640 2 knifes, 1 carrot, 43.3ms\n",
      "Speed: 2.2ms preprocess, 43.3ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/88.jpg: 384x640 1 knife, 1 spoon, 33.4ms\n",
      "Speed: 2.1ms preprocess, 33.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/89.jpg: 384x640 1 spoon, 42.9ms\n",
      "Speed: 2.0ms preprocess, 42.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/90.jpg: 384x640 2 spoons, 35.0ms\n",
      "Speed: 1.9ms preprocess, 35.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/91.jpg: 384x640 2 spoons, 1 cake, 39.5ms\n",
      "Speed: 2.1ms preprocess, 39.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/92.jpg: 384x640 2 knifes, 1 cake, 32.3ms\n",
      "Speed: 2.0ms preprocess, 32.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/93.jpg: 384x640 2 knifes, 32.1ms\n",
      "Speed: 2.0ms preprocess, 32.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/94.jpg: 384x640 2 spoons, 31.4ms\n",
      "Speed: 1.7ms preprocess, 31.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/95.jpg: 384x640 2 spoons, 31.9ms\n",
      "Speed: 2.0ms preprocess, 31.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/96.jpg: 384x640 1 knife, 1 spoon, 31.5ms\n",
      "Speed: 1.8ms preprocess, 31.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/97.jpg: 384x640 (no detections), 34.9ms\n",
      "Speed: 2.6ms preprocess, 34.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/98.jpg: 384x640 1 knife, 1 spoon, 35.4ms\n",
      "Speed: 1.9ms preprocess, 35.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/99.jpg: 384x640 1 knife, 1 spoon, 43.9ms\n",
      "Speed: 2.1ms preprocess, 43.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/100.jpg: 384x640 1 knife, 1 spoon, 32.4ms\n",
      "Speed: 2.0ms preprocess, 32.4ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/101.jpg: 384x640 1 knife, 1 spoon, 38.3ms\n",
      "Speed: 2.8ms preprocess, 38.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/102.jpg: 384x640 1 spoon, 32.9ms\n",
      "Speed: 1.7ms preprocess, 32.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/103.jpg: 384x640 1 spoon, 35.0ms\n",
      "Speed: 2.5ms preprocess, 35.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/104.jpg: 384x640 1 knife, 1 spoon, 32.8ms\n",
      "Speed: 2.7ms preprocess, 32.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/105.jpg: 384x640 1 spoon, 43.4ms\n",
      "Speed: 2.4ms preprocess, 43.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/106.jpg: 384x640 1 knife, 29.4ms\n",
      "Speed: 1.8ms preprocess, 29.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/107.jpg: 384x640 1 knife, 1 spoon, 30.6ms\n",
      "Speed: 2.1ms preprocess, 30.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/108.jpg: 384x640 1 knife, 1 cake, 41.8ms\n",
      "Speed: 1.9ms preprocess, 41.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/109.jpg: 384x640 2 spoons, 49.3ms\n",
      "Speed: 1.9ms preprocess, 49.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/110.jpg: 384x640 1 spoon, 28.0ms\n",
      "Speed: 2.0ms preprocess, 28.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/111.jpg: 384x640 1 spoon, 31.8ms\n",
      "Speed: 2.0ms preprocess, 31.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/112.jpg: 384x640 1 carrot, 29.7ms\n",
      "Speed: 2.7ms preprocess, 29.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/113.jpg: 384x640 1 spoon, 1 carrot, 48.7ms\n",
      "Speed: 3.0ms preprocess, 48.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/114.jpg: 384x640 1 baseball bat, 1 carrot, 37.0ms\n",
      "Speed: 1.8ms preprocess, 37.0ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/115.jpg: 384x640 1 baseball bat, 1 carrot, 34.8ms\n",
      "Speed: 2.1ms preprocess, 34.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/116.jpg: 384x640 1 baseball bat, 1 carrot, 29.7ms\n",
      "Speed: 2.8ms preprocess, 29.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/117.jpg: 384x640 1 baseball bat, 1 carrot, 32.5ms\n",
      "Speed: 2.4ms preprocess, 32.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/118.jpg: 384x640 1 baseball bat, 2 carrots, 40.6ms\n",
      "Speed: 1.8ms preprocess, 40.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/119.jpg: 384x640 2 spoons, 1 carrot, 40.8ms\n",
      "Speed: 1.9ms preprocess, 40.8ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/120.jpg: 384x640 1 knife, 1 spoon, 52.4ms\n",
      "Speed: 2.0ms preprocess, 52.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/121.jpg: 384x640 1 baseball bat, 29.5ms\n",
      "Speed: 2.2ms preprocess, 29.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/122.jpg: 384x640 1 knife, 32.4ms\n",
      "Speed: 1.9ms preprocess, 32.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/123.jpg: 384x640 1 baseball bat, 1 spoon, 30.3ms\n",
      "Speed: 1.7ms preprocess, 30.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/124.jpg: 384x640 2 baseball bats, 40.6ms\n",
      "Speed: 2.0ms preprocess, 40.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/125.jpg: 384x640 1 baseball bat, 28.7ms\n",
      "Speed: 1.8ms preprocess, 28.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/126.jpg: 384x640 1 baseball bat, 41.8ms\n",
      "Speed: 3.3ms preprocess, 41.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/127.jpg: 384x640 (no detections), 36.1ms\n",
      "Speed: 2.0ms preprocess, 36.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/128.jpg: 384x640 (no detections), 40.5ms\n",
      "Speed: 2.0ms preprocess, 40.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/129.jpg: 384x640 1 knife, 35.0ms\n",
      "Speed: 1.9ms preprocess, 35.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/130.jpg: 384x640 (no detections), 43.8ms\n",
      "Speed: 1.8ms preprocess, 43.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/131.jpg: 384x640 (no detections), 38.5ms\n",
      "Speed: 1.9ms preprocess, 38.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/132.jpg: 384x640 1 spoon, 29.3ms\n",
      "Speed: 2.4ms preprocess, 29.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/133.jpg: 384x640 1 knife, 1 spoon, 31.2ms\n",
      "Speed: 2.3ms preprocess, 31.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/134.jpg: 384x640 1 bottle, 1 spoon, 28.8ms\n",
      "Speed: 1.8ms preprocess, 28.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/135.jpg: 384x640 1 bottle, 1 spoon, 28.5ms\n",
      "Speed: 2.0ms preprocess, 28.5ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/136.jpg: 384x640 1 bottle, 1 knife, 1 spoon, 28.9ms\n",
      "Speed: 2.0ms preprocess, 28.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/137.jpg: 384x640 1 bottle, 1 knife, 1 spoon, 28.4ms\n",
      "Speed: 2.1ms preprocess, 28.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/138.jpg: 384x640 1 bottle, 1 knife, 40.1ms\n",
      "Speed: 2.1ms preprocess, 40.1ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/139.jpg: 384x640 1 bottle, 1 spoon, 40.9ms\n",
      "Speed: 1.9ms preprocess, 40.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/140.jpg: 384x640 1 bottle, 1 spoon, 42.0ms\n",
      "Speed: 2.5ms preprocess, 42.0ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/141.jpg: 384x640 1 bottle, 1 knife, 1 spoon, 43.9ms\n",
      "Speed: 1.9ms preprocess, 43.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/142.jpg: 384x640 1 knife, 1 spoon, 40.5ms\n",
      "Speed: 2.9ms preprocess, 40.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/143.jpg: 384x640 1 bottle, 1 spoon, 31.7ms\n",
      "Speed: 2.2ms preprocess, 31.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/144.jpg: 384x640 1 spoon, 42.0ms\n",
      "Speed: 2.4ms preprocess, 42.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/145.jpg: 384x640 1 bottle, 1 knife, 44.7ms\n",
      "Speed: 2.1ms preprocess, 44.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/146.jpg: 384x640 1 bottle, 28.1ms\n",
      "Speed: 2.0ms preprocess, 28.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/147.jpg: 384x640 1 spoon, 37.7ms\n",
      "Speed: 2.0ms preprocess, 37.7ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/148.jpg: 384x640 1 spoon, 45.4ms\n",
      "Speed: 2.0ms preprocess, 45.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/149.jpg: 384x640 1 bottle, 1 carrot, 40.5ms\n",
      "Speed: 2.2ms preprocess, 40.5ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/150.jpg: 384x640 2 bottles, 39.6ms\n",
      "Speed: 1.9ms preprocess, 39.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/151.jpg: 384x640 1 bottle, 1 spoon, 43.8ms\n",
      "Speed: 2.3ms preprocess, 43.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/152.jpg: 384x640 2 spoons, 1 carrot, 32.7ms\n",
      "Speed: 1.9ms preprocess, 32.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/153.jpg: 384x640 1 spoon, 46.2ms\n",
      "Speed: 2.1ms preprocess, 46.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/154.jpg: 384x640 1 bottle, 2 carrots, 36.2ms\n",
      "Speed: 2.1ms preprocess, 36.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/155.jpg: 384x640 1 bottle, 1 cake, 45.2ms\n",
      "Speed: 2.3ms preprocess, 45.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/156.jpg: 384x640 2 spoons, 2 carrots, 37.4ms\n",
      "Speed: 2.9ms preprocess, 37.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/157.jpg: 384x640 1 bottle, 37.5ms\n",
      "Speed: 1.8ms preprocess, 37.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/158.jpg: 384x640 1 cake, 46.5ms\n",
      "Speed: 3.2ms preprocess, 46.5ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/159.jpg: 384x640 1 knife, 1 spoon, 41.0ms\n",
      "Speed: 2.2ms preprocess, 41.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/160.jpg: 384x640 2 spoons, 32.3ms\n",
      "Speed: 2.0ms preprocess, 32.3ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/161.jpg: 384x640 2 knifes, 1 spoon, 36.4ms\n",
      "Speed: 2.8ms preprocess, 36.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/162.jpg: 384x640 1 spoon, 47.8ms\n",
      "Speed: 2.7ms preprocess, 47.8ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/163.jpg: 384x640 1 spoon, 38.6ms\n",
      "Speed: 2.4ms preprocess, 38.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/164.jpg: 384x640 1 spoon, 53.6ms\n",
      "Speed: 2.9ms preprocess, 53.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/165.jpg: 384x640 1 spoon, 33.7ms\n",
      "Speed: 1.8ms preprocess, 33.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/166.jpg: 384x640 1 spoon, 38.6ms\n",
      "Speed: 1.9ms preprocess, 38.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/167.jpg: 384x640 1 spoon, 34.3ms\n",
      "Speed: 2.7ms preprocess, 34.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/168.jpg: 384x640 1 spoon, 34.7ms\n",
      "Speed: 3.1ms preprocess, 34.7ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/169.jpg: 384x640 1 knife, 1 spoon, 29.0ms\n",
      "Speed: 1.7ms preprocess, 29.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/170.jpg: 384x640 1 spoon, 42.4ms\n",
      "Speed: 2.8ms preprocess, 42.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/171.jpg: 384x640 1 spoon, 46.2ms\n",
      "Speed: 2.1ms preprocess, 46.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/172.jpg: 384x640 1 spoon, 80.3ms\n",
      "Speed: 2.4ms preprocess, 80.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/173.jpg: 384x640 1 bottle, 1 spoon, 42.8ms\n",
      "Speed: 1.8ms preprocess, 42.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/174.jpg: 384x640 2 bottles, 47.1ms\n",
      "Speed: 2.0ms preprocess, 47.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/175.jpg: 384x640 2 bottles, 56.6ms\n",
      "Speed: 2.6ms preprocess, 56.6ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/176.jpg: 384x640 1 bottle, 35.7ms\n",
      "Speed: 2.4ms preprocess, 35.7ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/177.jpg: 384x640 (no detections), 46.6ms\n",
      "Speed: 2.9ms preprocess, 46.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/178.jpg: 384x640 1 bottle, 36.7ms\n",
      "Speed: 2.1ms preprocess, 36.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/179.jpg: 384x640 (no detections), 39.0ms\n",
      "Speed: 2.3ms preprocess, 39.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/180.jpg: 384x640 1 spoon, 44.2ms\n",
      "Speed: 2.4ms preprocess, 44.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/181.jpg: 384x640 2 carrots, 44.4ms\n",
      "Speed: 3.3ms preprocess, 44.4ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/182.jpg: 384x640 (no detections), 48.7ms\n",
      "Speed: 2.2ms preprocess, 48.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/183.jpg: 384x640 1 baseball bat, 1 spoon, 2 carrots, 44.6ms\n",
      "Speed: 2.1ms preprocess, 44.6ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/184.jpg: 384x640 1 baseball bat, 34.3ms\n",
      "Speed: 2.4ms preprocess, 34.3ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/185.jpg: 384x640 1 baseball bat, 1 spoon, 52.9ms\n",
      "Speed: 3.8ms preprocess, 52.9ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/186.jpg: 384x640 1 spoon, 42.5ms\n",
      "Speed: 2.2ms preprocess, 42.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/187.jpg: 384x640 1 baseball bat, 1 spoon, 36.5ms\n",
      "Speed: 2.0ms preprocess, 36.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/188.jpg: 384x640 1 baseball bat, 1 spoon, 42.0ms\n",
      "Speed: 3.2ms preprocess, 42.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/189.jpg: 384x640 1 spoon, 1 carrot, 38.0ms\n",
      "Speed: 2.1ms preprocess, 38.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/190.jpg: 384x640 2 spoons, 34.0ms\n",
      "Speed: 2.0ms preprocess, 34.0ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/191.jpg: 384x640 2 spoons, 1 carrot, 33.6ms\n",
      "Speed: 2.7ms preprocess, 33.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/192.jpg: 384x640 1 knife, 1 spoon, 1 carrot, 39.0ms\n",
      "Speed: 2.6ms preprocess, 39.0ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/193.jpg: 384x640 1 knife, 2 spoons, 1 carrot, 43.8ms\n",
      "Speed: 1.8ms preprocess, 43.8ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/194.jpg: 384x640 2 spoons, 1 carrot, 33.4ms\n",
      "Speed: 2.3ms preprocess, 33.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/195.jpg: 384x640 2 spoons, 1 carrot, 42.3ms\n",
      "Speed: 3.5ms preprocess, 42.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/196.jpg: 384x640 2 spoons, 1 carrot, 48.6ms\n",
      "Speed: 3.2ms preprocess, 48.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/197.jpg: 384x640 1 spoon, 39.6ms\n",
      "Speed: 3.2ms preprocess, 39.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/198.jpg: 384x640 1 spoon, 1 carrot, 33.8ms\n",
      "Speed: 2.1ms preprocess, 33.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/199.jpg: 384x640 1 spoon, 1 carrot, 38.5ms\n",
      "Speed: 3.5ms preprocess, 38.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/200.jpg: 384x640 1 spoon, 2 carrots, 50.3ms\n",
      "Speed: 3.4ms preprocess, 50.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/201.jpg: 384x640 1 spoon, 3 carrots, 42.1ms\n",
      "Speed: 2.0ms preprocess, 42.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/202.jpg: 384x640 1 spoon, 2 carrots, 33.3ms\n",
      "Speed: 2.0ms preprocess, 33.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/203.jpg: 384x640 1 baseball bat, 2 carrots, 31.7ms\n",
      "Speed: 2.8ms preprocess, 31.7ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/204.jpg: 384x640 1 spoon, 2 carrots, 35.8ms\n",
      "Speed: 2.4ms preprocess, 35.8ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/205.jpg: 384x640 1 spoon, 2 carrots, 41.6ms\n",
      "Speed: 3.6ms preprocess, 41.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/206.jpg: 384x640 1 spoon, 2 carrots, 39.1ms\n",
      "Speed: 2.1ms preprocess, 39.1ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/207.jpg: 384x640 1 spoon, 2 carrots, 32.9ms\n",
      "Speed: 2.5ms preprocess, 32.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/208.jpg: 384x640 1 spoon, 2 carrots, 46.9ms\n",
      "Speed: 3.0ms preprocess, 46.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/209.jpg: 384x640 1 spoon, 2 carrots, 41.8ms\n",
      "Speed: 2.5ms preprocess, 41.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/210.jpg: 384x640 1 spoon, 2 carrots, 28.5ms\n",
      "Speed: 1.7ms preprocess, 28.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/211.jpg: 384x640 1 spoon, 2 carrots, 38.4ms\n",
      "Speed: 2.6ms preprocess, 38.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/212.jpg: 384x640 1 spoon, 2 carrots, 52.9ms\n",
      "Speed: 1.8ms preprocess, 52.9ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/213.jpg: 384x640 1 baseball bat, 2 carrots, 33.9ms\n",
      "Speed: 2.3ms preprocess, 33.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/214.jpg: 384x640 1 spoon, 2 carrots, 37.4ms\n",
      "Speed: 2.6ms preprocess, 37.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/215.jpg: 384x640 1 spoon, 2 carrots, 51.9ms\n",
      "Speed: 1.9ms preprocess, 51.9ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/216.jpg: 384x640 1 spoon, 2 carrots, 46.6ms\n",
      "Speed: 2.1ms preprocess, 46.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/217.jpg: 384x640 1 spoon, 2 carrots, 42.8ms\n",
      "Speed: 1.9ms preprocess, 42.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/218.jpg: 384x640 1 spoon, 3 carrots, 43.2ms\n",
      "Speed: 2.3ms preprocess, 43.2ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/219.jpg: 384x640 1 spoon, 1 carrot, 1 hot dog, 33.3ms\n",
      "Speed: 2.2ms preprocess, 33.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/220.jpg: 384x640 1 spoon, 1 cake, 38.4ms\n",
      "Speed: 2.0ms preprocess, 38.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/221.jpg: 384x640 1 knife, 42.9ms\n",
      "Speed: 2.7ms preprocess, 42.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/222.jpg: 384x640 1 knife, 1 spoon, 48.0ms\n",
      "Speed: 1.9ms preprocess, 48.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/223.jpg: 384x640 1 knife, 2 spoons, 28.1ms\n",
      "Speed: 1.8ms preprocess, 28.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/224.jpg: 384x640 1 knife, 1 spoon, 34.5ms\n",
      "Speed: 2.0ms preprocess, 34.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/225.jpg: 384x640 1 knife, 2 spoons, 33.6ms\n",
      "Speed: 2.3ms preprocess, 33.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/226.jpg: 384x640 1 knife, 2 spoons, 34.9ms\n",
      "Speed: 2.5ms preprocess, 34.9ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/227.jpg: 384x640 1 knife, 1 spoon, 58.7ms\n",
      "Speed: 3.1ms preprocess, 58.7ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/228.jpg: 384x640 1 knife, 2 spoons, 38.0ms\n",
      "Speed: 2.6ms preprocess, 38.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/229.jpg: 384x640 1 knife, 2 spoons, 71.2ms\n",
      "Speed: 2.1ms preprocess, 71.2ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/230.jpg: 384x640 2 spoons, 37.9ms\n",
      "Speed: 2.0ms preprocess, 37.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/231.jpg: 384x640 1 knife, 1 spoon, 43.2ms\n",
      "Speed: 2.1ms preprocess, 43.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/232.jpg: 384x640 1 knife, 2 spoons, 42.1ms\n",
      "Speed: 3.0ms preprocess, 42.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/233.jpg: 384x640 1 spoon, 47.4ms\n",
      "Speed: 2.3ms preprocess, 47.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/234.jpg: 384x640 2 spoons, 37.3ms\n",
      "Speed: 2.0ms preprocess, 37.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/235.jpg: 384x640 1 knife, 2 spoons, 48.4ms\n",
      "Speed: 2.9ms preprocess, 48.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/236.jpg: 384x640 1 knife, 1 spoon, 33.4ms\n",
      "Speed: 3.3ms preprocess, 33.4ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/237.jpg: 384x640 1 knife, 1 spoon, 1 cake, 40.1ms\n",
      "Speed: 2.3ms preprocess, 40.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/238.jpg: 384x640 1 knife, 2 spoons, 1 cake, 40.4ms\n",
      "Speed: 1.9ms preprocess, 40.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/239.jpg: 384x640 1 knife, 2 spoons, 35.4ms\n",
      "Speed: 2.9ms preprocess, 35.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/240.jpg: 384x640 1 spoon, 34.7ms\n",
      "Speed: 2.0ms preprocess, 34.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/241.jpg: 384x640 2 spoons, 32.2ms\n",
      "Speed: 1.7ms preprocess, 32.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/242.jpg: 384x640 1 knife, 36.0ms\n",
      "Speed: 2.8ms preprocess, 36.0ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/243.jpg: 384x640 2 spoons, 34.4ms\n",
      "Speed: 1.8ms preprocess, 34.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/244.jpg: 384x640 2 spoons, 34.8ms\n",
      "Speed: 1.9ms preprocess, 34.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/245.jpg: 384x640 2 spoons, 39.3ms\n",
      "Speed: 1.9ms preprocess, 39.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/246.jpg: 384x640 1 knife, 2 spoons, 35.8ms\n",
      "Speed: 2.6ms preprocess, 35.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/247.jpg: 384x640 2 spoons, 42.6ms\n",
      "Speed: 2.9ms preprocess, 42.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/248.jpg: 384x640 1 baseball bat, 2 spoons, 48.8ms\n",
      "Speed: 2.7ms preprocess, 48.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/249.jpg: 384x640 2 spoons, 47.0ms\n",
      "Speed: 2.3ms preprocess, 47.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/250.jpg: 384x640 2 spoons, 42.3ms\n",
      "Speed: 2.1ms preprocess, 42.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/251.jpg: 384x640 2 spoons, 30.7ms\n",
      "Speed: 1.8ms preprocess, 30.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/252.jpg: 384x640 2 spoons, 33.5ms\n",
      "Speed: 1.9ms preprocess, 33.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/253.jpg: 384x640 2 spoons, 29.3ms\n",
      "Speed: 1.9ms preprocess, 29.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/254.jpg: 384x640 2 spoons, 27.8ms\n",
      "Speed: 2.2ms preprocess, 27.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/255.jpg: 384x640 2 spoons, 42.8ms\n",
      "Speed: 2.1ms preprocess, 42.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/256.jpg: 384x640 2 spoons, 27.0ms\n",
      "Speed: 3.2ms preprocess, 27.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/257.jpg: 384x640 2 spoons, 31.9ms\n",
      "Speed: 1.7ms preprocess, 31.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/258.jpg: 384x640 1 spoon, 36.0ms\n",
      "Speed: 2.6ms preprocess, 36.0ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/259.jpg: 384x640 1 knife, 1 cake, 28.8ms\n",
      "Speed: 1.9ms preprocess, 28.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/260.jpg: 384x640 1 spoon, 37.9ms\n",
      "Speed: 2.2ms preprocess, 37.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/261.jpg: 384x640 2 spoons, 38.0ms\n",
      "Speed: 2.9ms preprocess, 38.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/262.jpg: 384x640 2 spoons, 39.9ms\n",
      "Speed: 2.8ms preprocess, 39.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/263.jpg: 384x640 2 spoons, 48.7ms\n",
      "Speed: 2.2ms preprocess, 48.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/264.jpg: 384x640 2 spoons, 33.0ms\n",
      "Speed: 2.2ms preprocess, 33.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/265.jpg: 384x640 2 spoons, 36.1ms\n",
      "Speed: 2.0ms preprocess, 36.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/266.jpg: 384x640 2 spoons, 27.8ms\n",
      "Speed: 2.4ms preprocess, 27.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/267.jpg: 384x640 2 spoons, 1 bowl, 36.1ms\n",
      "Speed: 2.4ms preprocess, 36.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/268.jpg: 384x640 2 spoons, 52.2ms\n",
      "Speed: 2.3ms preprocess, 52.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/269.jpg: 384x640 2 spoons, 72.8ms\n",
      "Speed: 1.9ms preprocess, 72.8ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/270.jpg: 384x640 2 spoons, 29.6ms\n",
      "Speed: 1.8ms preprocess, 29.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/271.jpg: 384x640 2 spoons, 31.3ms\n",
      "Speed: 1.9ms preprocess, 31.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/272.jpg: 384x640 2 spoons, 1 carrot, 34.6ms\n",
      "Speed: 2.1ms preprocess, 34.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/273.jpg: 384x640 2 spoons, 42.5ms\n",
      "Speed: 1.9ms preprocess, 42.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/274.jpg: 384x640 2 spoons, 51.3ms\n",
      "Speed: 2.1ms preprocess, 51.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/275.jpg: 384x640 2 spoons, 34.7ms\n",
      "Speed: 2.0ms preprocess, 34.7ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/276.jpg: 384x640 1 knife, 2 spoons, 34.6ms\n",
      "Speed: 1.8ms preprocess, 34.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/277.jpg: 384x640 2 spoons, 42.5ms\n",
      "Speed: 2.0ms preprocess, 42.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/278.jpg: 384x640 1 spoon, 34.7ms\n",
      "Speed: 2.9ms preprocess, 34.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/279.jpg: 384x640 2 spoons, 43.1ms\n",
      "Speed: 2.3ms preprocess, 43.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/280.jpg: 384x640 1 knife, 2 spoons, 28.2ms\n",
      "Speed: 2.0ms preprocess, 28.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/281.jpg: 384x640 2 spoons, 32.1ms\n",
      "Speed: 1.8ms preprocess, 32.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/282.jpg: 384x640 2 spoons, 32.2ms\n",
      "Speed: 1.9ms preprocess, 32.2ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/283.jpg: 384x640 1 spoon, 32.6ms\n",
      "Speed: 1.9ms preprocess, 32.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/284.jpg: 384x640 2 knifes, 2 spoons, 1 carrot, 28.6ms\n",
      "Speed: 2.5ms preprocess, 28.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/285.jpg: 384x640 2 knifes, 2 spoons, 30.4ms\n",
      "Speed: 1.9ms preprocess, 30.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/286.jpg: 384x640 2 knifes, 2 spoons, 2 carrots, 29.4ms\n",
      "Speed: 1.8ms preprocess, 29.4ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/287.jpg: 384x640 2 knifes, 1 spoon, 29.7ms\n",
      "Speed: 1.5ms preprocess, 29.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/288.jpg: 384x640 1 knife, 1 spoon, 33.7ms\n",
      "Speed: 1.8ms preprocess, 33.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/289.jpg: 384x640 1 knife, 2 spoons, 33.0ms\n",
      "Speed: 1.9ms preprocess, 33.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/290.jpg: 384x640 2 knifes, 2 spoons, 1 cake, 64.5ms\n",
      "Speed: 2.3ms preprocess, 64.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/291.jpg: 384x640 1 knife, 2 spoons, 38.7ms\n",
      "Speed: 2.1ms preprocess, 38.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/292.jpg: 384x640 2 spoons, 35.7ms\n",
      "Speed: 2.0ms preprocess, 35.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/293.jpg: 384x640 2 spoons, 29.8ms\n",
      "Speed: 2.2ms preprocess, 29.8ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/294.jpg: 384x640 2 knifes, 1 spoon, 49.2ms\n",
      "Speed: 3.1ms preprocess, 49.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/295.jpg: 384x640 1 knife, 2 spoons, 50.6ms\n",
      "Speed: 2.7ms preprocess, 50.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/296.jpg: 384x640 2 spoons, 25.4ms\n",
      "Speed: 1.9ms preprocess, 25.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/297.jpg: 384x640 1 knife, 2 spoons, 39.5ms\n",
      "Speed: 1.8ms preprocess, 39.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/298.jpg: 384x640 1 knife, 33.8ms\n",
      "Speed: 2.0ms preprocess, 33.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/regular/right/299.jpg: 384x640 2 spoons, 27.0ms\n",
      "Speed: 1.8ms preprocess, 27.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Propagating video frames: 100%|| 300/300 [00:23<00:00, 12.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask propagation completed in 23.91 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing predicted masks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing video frames: 300it [00:01, 259.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 300 masks for evaluation.\n",
      "Masks saved to data/masks/yolo11x-seg/val/data-raw-SegSTRONGC_val-val-1-0-regular-right.pkl\n",
      "Loading ground truth masks for evaluation...\n",
      "Loaded 300 ground truth masks.\n",
      "Calculating evaluation metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for metrics calculation: 1.43 seconds.\n",
      "Mean IoU for data/raw/SegSTRONGC_val/val/1/0/regular/right: 0.5052\n",
      "Mean DSC for data/raw/SegSTRONGC_val/val/1/0/regular/right: 0.6106\n",
      "Loading existing results file: data/results/yolo11x-seg/val.json\n",
      "Results saved to data/results/yolo11x-seg/val.json\n",
      "Processing video took 30.16 seconds.\n",
      "==================================================\n",
      "\n",
      "Results for data/raw/SegSTRONGC_val/val/1/0/regular:\n",
      "  Left: IoU=0.5866, DSC=0.6925\n",
      "  Right: IoU=0.5052, DSC=0.6106\n",
      "  Overall: IoU=0.5459, DSC=0.6516\n",
      "\n",
      "Processing domain: smoke\n",
      "Processing left camera video...\n",
      "==================================================\n",
      "Processing video: data/raw/SegSTRONGC_val/val/1/0/smoke/left\n",
      "Domain: smoke, Split: val, Camera: left\n",
      "Initializing Yolo for video...\n",
      "Initialization took 0.21 seconds.\n",
      "Starting mask propagation...\n",
      "Total images in video: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/0.jpg: 384x640 1 airplane, 36.9ms\n",
      "Speed: 3.2ms preprocess, 36.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/1.jpg: 384x640 2 airplanes, 24.6ms\n",
      "Speed: 1.7ms preprocess, 24.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/2.jpg: 384x640 1 sink, 24.2ms\n",
      "Speed: 1.9ms preprocess, 24.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/3.jpg: 384x640 (no detections), 24.1ms\n",
      "Speed: 1.8ms preprocess, 24.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/4.jpg: 384x640 1 bird, 32.4ms\n",
      "Speed: 2.4ms preprocess, 32.4ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/5.jpg: 384x640 (no detections), 23.9ms\n",
      "Speed: 2.1ms preprocess, 23.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/6.jpg: 384x640 (no detections), 32.8ms\n",
      "Speed: 1.9ms preprocess, 32.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/7.jpg: 384x640 (no detections), 32.0ms\n",
      "Speed: 1.8ms preprocess, 32.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/8.jpg: 384x640 (no detections), 37.2ms\n",
      "Speed: 1.5ms preprocess, 37.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/9.jpg: 384x640 1 bird, 1 kite, 28.3ms\n",
      "Speed: 1.8ms preprocess, 28.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/10.jpg: 384x640 1 bird, 25.6ms\n",
      "Speed: 2.2ms preprocess, 25.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/11.jpg: 384x640 2 airplanes, 1 bird, 22.7ms\n",
      "Speed: 1.5ms preprocess, 22.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/12.jpg: 384x640 (no detections), 23.3ms\n",
      "Speed: 1.9ms preprocess, 23.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/13.jpg: 384x640 (no detections), 23.2ms\n",
      "Speed: 1.7ms preprocess, 23.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/14.jpg: 384x640 1 airplane, 31.4ms\n",
      "Speed: 1.8ms preprocess, 31.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/15.jpg: 384x640 1 knife, 31.8ms\n",
      "Speed: 2.0ms preprocess, 31.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/16.jpg: 384x640 (no detections), 29.5ms\n",
      "Speed: 2.6ms preprocess, 29.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/17.jpg: 384x640 (no detections), 26.6ms\n",
      "Speed: 1.7ms preprocess, 26.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/18.jpg: 384x640 (no detections), 32.5ms\n",
      "Speed: 1.8ms preprocess, 32.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/19.jpg: 384x640 (no detections), 25.5ms\n",
      "Speed: 1.9ms preprocess, 25.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/20.jpg: 384x640 2 baseball bats, 24.8ms\n",
      "Speed: 1.5ms preprocess, 24.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/21.jpg: 384x640 (no detections), 28.9ms\n",
      "Speed: 2.0ms preprocess, 28.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/22.jpg: 384x640 (no detections), 28.3ms\n",
      "Speed: 1.6ms preprocess, 28.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/23.jpg: 384x640 (no detections), 31.0ms\n",
      "Speed: 2.7ms preprocess, 31.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/24.jpg: 384x640 2 airplanes, 26.0ms\n",
      "Speed: 1.5ms preprocess, 26.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/25.jpg: 384x640 (no detections), 22.9ms\n",
      "Speed: 1.8ms preprocess, 22.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/26.jpg: 384x640 2 airplanes, 25.6ms\n",
      "Speed: 1.6ms preprocess, 25.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/27.jpg: 384x640 2 baseball bats, 1 bottle, 25.8ms\n",
      "Speed: 1.7ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/28.jpg: 384x640 (no detections), 45.5ms\n",
      "Speed: 4.8ms preprocess, 45.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/29.jpg: 384x640 1 airplane, 32.3ms\n",
      "Speed: 2.4ms preprocess, 32.3ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/30.jpg: 384x640 (no detections), 33.4ms\n",
      "Speed: 2.6ms preprocess, 33.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/31.jpg: 384x640 (no detections), 52.1ms\n",
      "Speed: 2.1ms preprocess, 52.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/32.jpg: 384x640 2 baseball bats, 24.8ms\n",
      "Speed: 2.4ms preprocess, 24.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/33.jpg: 384x640 2 baseball bats, 22.5ms\n",
      "Speed: 1.8ms preprocess, 22.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/34.jpg: 384x640 (no detections), 29.9ms\n",
      "Speed: 1.9ms preprocess, 29.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/35.jpg: 384x640 (no detections), 41.1ms\n",
      "Speed: 1.8ms preprocess, 41.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/36.jpg: 384x640 1 airplane, 27.5ms\n",
      "Speed: 2.1ms preprocess, 27.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/37.jpg: 384x640 (no detections), 34.3ms\n",
      "Speed: 1.8ms preprocess, 34.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/38.jpg: 384x640 (no detections), 25.0ms\n",
      "Speed: 1.7ms preprocess, 25.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/39.jpg: 384x640 1 airplane, 38.3ms\n",
      "Speed: 3.5ms preprocess, 38.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/40.jpg: 384x640 (no detections), 42.5ms\n",
      "Speed: 3.4ms preprocess, 42.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/41.jpg: 384x640 (no detections), 24.0ms\n",
      "Speed: 1.7ms preprocess, 24.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/42.jpg: 384x640 (no detections), 26.9ms\n",
      "Speed: 1.6ms preprocess, 26.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/43.jpg: 384x640 1 sink, 25.2ms\n",
      "Speed: 1.9ms preprocess, 25.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/44.jpg: 384x640 2 baseball bats, 1 bottle, 38.1ms\n",
      "Speed: 1.6ms preprocess, 38.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/45.jpg: 384x640 (no detections), 40.1ms\n",
      "Speed: 1.6ms preprocess, 40.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/46.jpg: 384x640 (no detections), 33.0ms\n",
      "Speed: 1.7ms preprocess, 33.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/47.jpg: 384x640 2 baseball bats, 27.2ms\n",
      "Speed: 1.5ms preprocess, 27.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/48.jpg: 384x640 1 baseball bat, 24.1ms\n",
      "Speed: 1.6ms preprocess, 24.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/49.jpg: 384x640 (no detections), 33.8ms\n",
      "Speed: 1.3ms preprocess, 33.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/50.jpg: 384x640 2 baseball bats, 31.8ms\n",
      "Speed: 1.8ms preprocess, 31.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/51.jpg: 384x640 (no detections), 30.5ms\n",
      "Speed: 2.0ms preprocess, 30.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/52.jpg: 384x640 (no detections), 30.1ms\n",
      "Speed: 1.7ms preprocess, 30.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/53.jpg: 384x640 (no detections), 25.3ms\n",
      "Speed: 2.4ms preprocess, 25.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/54.jpg: 384x640 (no detections), 31.9ms\n",
      "Speed: 1.7ms preprocess, 31.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/55.jpg: 384x640 (no detections), 40.4ms\n",
      "Speed: 3.0ms preprocess, 40.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/56.jpg: 384x640 2 spoons, 38.6ms\n",
      "Speed: 1.9ms preprocess, 38.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/57.jpg: 384x640 (no detections), 26.3ms\n",
      "Speed: 1.9ms preprocess, 26.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/58.jpg: 384x640 (no detections), 33.2ms\n",
      "Speed: 2.6ms preprocess, 33.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/59.jpg: 384x640 (no detections), 25.5ms\n",
      "Speed: 1.5ms preprocess, 25.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/60.jpg: 384x640 (no detections), 26.6ms\n",
      "Speed: 2.5ms preprocess, 26.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/61.jpg: 384x640 (no detections), 25.1ms\n",
      "Speed: 1.6ms preprocess, 25.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/62.jpg: 384x640 (no detections), 27.4ms\n",
      "Speed: 3.5ms preprocess, 27.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/63.jpg: 384x640 1 knife, 25.1ms\n",
      "Speed: 1.6ms preprocess, 25.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/64.jpg: 384x640 (no detections), 24.6ms\n",
      "Speed: 1.4ms preprocess, 24.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/65.jpg: 384x640 (no detections), 25.1ms\n",
      "Speed: 1.4ms preprocess, 25.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/66.jpg: 384x640 1 sink, 42.2ms\n",
      "Speed: 1.7ms preprocess, 42.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/67.jpg: 384x640 (no detections), 24.8ms\n",
      "Speed: 1.8ms preprocess, 24.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/68.jpg: 384x640 (no detections), 38.0ms\n",
      "Speed: 1.8ms preprocess, 38.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/69.jpg: 384x640 (no detections), 22.5ms\n",
      "Speed: 1.6ms preprocess, 22.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/70.jpg: 384x640 2 baseball bats, 1 sink, 40.1ms\n",
      "Speed: 1.8ms preprocess, 40.1ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/71.jpg: 384x640 (no detections), 23.8ms\n",
      "Speed: 1.8ms preprocess, 23.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/72.jpg: 384x640 2 baseball bats, 26.0ms\n",
      "Speed: 1.7ms preprocess, 26.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/73.jpg: 384x640 1 airplane, 34.9ms\n",
      "Speed: 2.7ms preprocess, 34.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/74.jpg: 384x640 (no detections), 43.2ms\n",
      "Speed: 2.2ms preprocess, 43.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/75.jpg: 384x640 (no detections), 23.1ms\n",
      "Speed: 1.7ms preprocess, 23.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/76.jpg: 384x640 1 baseball bat, 1 bottle, 24.5ms\n",
      "Speed: 1.9ms preprocess, 24.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/77.jpg: 384x640 (no detections), 31.1ms\n",
      "Speed: 1.9ms preprocess, 31.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/78.jpg: 384x640 (no detections), 22.4ms\n",
      "Speed: 1.7ms preprocess, 22.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/79.jpg: 384x640 1 clock, 24.1ms\n",
      "Speed: 1.7ms preprocess, 24.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/80.jpg: 384x640 1 sink, 29.4ms\n",
      "Speed: 3.1ms preprocess, 29.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/81.jpg: 384x640 (no detections), 25.9ms\n",
      "Speed: 1.6ms preprocess, 25.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/82.jpg: 384x640 (no detections), 37.2ms\n",
      "Speed: 2.0ms preprocess, 37.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/83.jpg: 384x640 (no detections), 31.8ms\n",
      "Speed: 1.7ms preprocess, 31.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/84.jpg: 384x640 (no detections), 34.6ms\n",
      "Speed: 1.8ms preprocess, 34.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/85.jpg: 384x640 1 sink, 23.2ms\n",
      "Speed: 2.0ms preprocess, 23.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/86.jpg: 384x640 (no detections), 32.8ms\n",
      "Speed: 1.8ms preprocess, 32.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/87.jpg: 384x640 1 bird, 31.0ms\n",
      "Speed: 2.5ms preprocess, 31.0ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/88.jpg: 384x640 (no detections), 42.6ms\n",
      "Speed: 1.7ms preprocess, 42.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/89.jpg: 384x640 1 bird, 25.8ms\n",
      "Speed: 1.6ms preprocess, 25.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/90.jpg: 384x640 (no detections), 25.2ms\n",
      "Speed: 1.6ms preprocess, 25.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/91.jpg: 384x640 (no detections), 30.1ms\n",
      "Speed: 2.8ms preprocess, 30.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/92.jpg: 384x640 1 bird, 24.8ms\n",
      "Speed: 2.5ms preprocess, 24.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/93.jpg: 384x640 (no detections), 33.6ms\n",
      "Speed: 1.5ms preprocess, 33.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/94.jpg: 384x640 1 knife, 23.1ms\n",
      "Speed: 1.6ms preprocess, 23.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/95.jpg: 384x640 1 bird, 38.3ms\n",
      "Speed: 3.0ms preprocess, 38.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/96.jpg: 384x640 1 knife, 50.4ms\n",
      "Speed: 2.0ms preprocess, 50.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/97.jpg: 384x640 (no detections), 23.8ms\n",
      "Speed: 1.5ms preprocess, 23.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/98.jpg: 384x640 1 knife, 25.2ms\n",
      "Speed: 2.3ms preprocess, 25.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/99.jpg: 384x640 (no detections), 36.5ms\n",
      "Speed: 1.8ms preprocess, 36.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/100.jpg: 384x640 (no detections), 23.9ms\n",
      "Speed: 1.8ms preprocess, 23.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/101.jpg: 384x640 1 airplane, 25.1ms\n",
      "Speed: 2.2ms preprocess, 25.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/102.jpg: 384x640 2 birds, 34.0ms\n",
      "Speed: 2.8ms preprocess, 34.0ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/103.jpg: 384x640 (no detections), 24.6ms\n",
      "Speed: 1.7ms preprocess, 24.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/104.jpg: 384x640 (no detections), 25.5ms\n",
      "Speed: 2.0ms preprocess, 25.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/105.jpg: 384x640 (no detections), 37.3ms\n",
      "Speed: 2.0ms preprocess, 37.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/106.jpg: 384x640 (no detections), 25.4ms\n",
      "Speed: 1.7ms preprocess, 25.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/107.jpg: 384x640 1 bird, 24.6ms\n",
      "Speed: 1.6ms preprocess, 24.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/108.jpg: 384x640 (no detections), 41.5ms\n",
      "Speed: 3.0ms preprocess, 41.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/109.jpg: 384x640 1 bird, 24.4ms\n",
      "Speed: 1.5ms preprocess, 24.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/110.jpg: 384x640 1 boat, 24.8ms\n",
      "Speed: 1.5ms preprocess, 24.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/111.jpg: 384x640 1 sink, 1 toothbrush, 25.0ms\n",
      "Speed: 2.0ms preprocess, 25.0ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/112.jpg: 384x640 (no detections), 29.1ms\n",
      "Speed: 1.9ms preprocess, 29.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/113.jpg: 384x640 1 bottle, 24.8ms\n",
      "Speed: 1.5ms preprocess, 24.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/114.jpg: 384x640 (no detections), 25.0ms\n",
      "Speed: 1.7ms preprocess, 25.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/115.jpg: 384x640 (no detections), 39.2ms\n",
      "Speed: 3.8ms preprocess, 39.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/116.jpg: 384x640 1 person, 32.4ms\n",
      "Speed: 1.7ms preprocess, 32.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/117.jpg: 384x640 (no detections), 25.2ms\n",
      "Speed: 2.8ms preprocess, 25.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/118.jpg: 384x640 (no detections), 29.1ms\n",
      "Speed: 1.6ms preprocess, 29.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/119.jpg: 384x640 (no detections), 29.3ms\n",
      "Speed: 1.9ms preprocess, 29.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/120.jpg: 384x640 (no detections), 41.1ms\n",
      "Speed: 2.0ms preprocess, 41.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/121.jpg: 384x640 1 airplane, 39.3ms\n",
      "Speed: 1.7ms preprocess, 39.3ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/122.jpg: 384x640 1 airplane, 25.1ms\n",
      "Speed: 1.5ms preprocess, 25.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/123.jpg: 384x640 1 airplane, 24.8ms\n",
      "Speed: 1.5ms preprocess, 24.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/124.jpg: 384x640 2 airplanes, 23.7ms\n",
      "Speed: 1.5ms preprocess, 23.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/125.jpg: 384x640 (no detections), 38.2ms\n",
      "Speed: 1.9ms preprocess, 38.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/126.jpg: 384x640 1 baseball bat, 24.9ms\n",
      "Speed: 1.8ms preprocess, 24.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/127.jpg: 384x640 1 bird, 24.1ms\n",
      "Speed: 1.7ms preprocess, 24.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/128.jpg: 384x640 1 airplane, 24.1ms\n",
      "Speed: 1.5ms preprocess, 24.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/129.jpg: 384x640 1 bottle, 48.5ms\n",
      "Speed: 1.6ms preprocess, 48.5ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/130.jpg: 384x640 1 airplane, 28.3ms\n",
      "Speed: 1.7ms preprocess, 28.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/131.jpg: 384x640 1 airplane, 43.9ms\n",
      "Speed: 3.6ms preprocess, 43.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/132.jpg: 384x640 1 bottle, 24.1ms\n",
      "Speed: 1.6ms preprocess, 24.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/133.jpg: 384x640 1 airplane, 24.0ms\n",
      "Speed: 1.7ms preprocess, 24.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/134.jpg: 384x640 (no detections), 27.1ms\n",
      "Speed: 1.6ms preprocess, 27.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/135.jpg: 384x640 1 bottle, 1 knife, 25.2ms\n",
      "Speed: 1.6ms preprocess, 25.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/136.jpg: 384x640 (no detections), 23.4ms\n",
      "Speed: 1.7ms preprocess, 23.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/137.jpg: 384x640 2 airplanes, 33.0ms\n",
      "Speed: 2.5ms preprocess, 33.0ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/138.jpg: 384x640 (no detections), 25.3ms\n",
      "Speed: 1.7ms preprocess, 25.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/139.jpg: 384x640 1 airplane, 33.3ms\n",
      "Speed: 2.0ms preprocess, 33.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/140.jpg: 384x640 1 airplane, 35.7ms\n",
      "Speed: 2.1ms preprocess, 35.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/141.jpg: 384x640 2 airplanes, 39.9ms\n",
      "Speed: 3.3ms preprocess, 39.9ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/142.jpg: 384x640 1 bottle, 26.9ms\n",
      "Speed: 1.6ms preprocess, 26.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/143.jpg: 384x640 (no detections), 27.7ms\n",
      "Speed: 2.4ms preprocess, 27.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/144.jpg: 384x640 1 bird, 1 bottle, 1 knife, 35.0ms\n",
      "Speed: 1.6ms preprocess, 35.0ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/145.jpg: 384x640 1 bottle, 1 knife, 26.1ms\n",
      "Speed: 1.8ms preprocess, 26.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/146.jpg: 384x640 (no detections), 30.1ms\n",
      "Speed: 2.4ms preprocess, 30.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/147.jpg: 384x640 (no detections), 32.6ms\n",
      "Speed: 1.8ms preprocess, 32.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/148.jpg: 384x640 1 toothbrush, 23.8ms\n",
      "Speed: 1.5ms preprocess, 23.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/149.jpg: 384x640 1 person, 1 boat, 25.6ms\n",
      "Speed: 1.6ms preprocess, 25.6ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/150.jpg: 384x640 (no detections), 24.9ms\n",
      "Speed: 2.2ms preprocess, 24.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/151.jpg: 384x640 1 knife, 33.4ms\n",
      "Speed: 1.7ms preprocess, 33.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/152.jpg: 384x640 (no detections), 45.5ms\n",
      "Speed: 2.3ms preprocess, 45.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/153.jpg: 384x640 (no detections), 26.9ms\n",
      "Speed: 1.6ms preprocess, 26.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/154.jpg: 384x640 1 knife, 43.1ms\n",
      "Speed: 3.1ms preprocess, 43.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/155.jpg: 384x640 (no detections), 25.0ms\n",
      "Speed: 1.7ms preprocess, 25.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/156.jpg: 384x640 1 baseball bat, 23.6ms\n",
      "Speed: 1.8ms preprocess, 23.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/157.jpg: 384x640 4 airplanes, 33.5ms\n",
      "Speed: 2.5ms preprocess, 33.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/158.jpg: 384x640 1 airplane, 29.9ms\n",
      "Speed: 1.8ms preprocess, 29.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/159.jpg: 384x640 (no detections), 42.3ms\n",
      "Speed: 1.8ms preprocess, 42.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/160.jpg: 384x640 1 baseball bat, 1 bottle, 1 knife, 1 cake, 23.6ms\n",
      "Speed: 2.6ms preprocess, 23.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/161.jpg: 384x640 1 knife, 26.2ms\n",
      "Speed: 1.5ms preprocess, 26.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/162.jpg: 384x640 1 bird, 22.6ms\n",
      "Speed: 1.9ms preprocess, 22.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/163.jpg: 384x640 1 knife, 1 spoon, 27.0ms\n",
      "Speed: 1.7ms preprocess, 27.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/164.jpg: 384x640 (no detections), 31.1ms\n",
      "Speed: 1.6ms preprocess, 31.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/165.jpg: 384x640 1 airplane, 31.7ms\n",
      "Speed: 1.5ms preprocess, 31.7ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/166.jpg: 384x640 (no detections), 33.6ms\n",
      "Speed: 2.0ms preprocess, 33.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/167.jpg: 384x640 (no detections), 26.7ms\n",
      "Speed: 3.4ms preprocess, 26.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/168.jpg: 384x640 1 knife, 24.0ms\n",
      "Speed: 1.8ms preprocess, 24.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/169.jpg: 384x640 1 knife, 40.6ms\n",
      "Speed: 3.0ms preprocess, 40.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/170.jpg: 384x640 1 bird, 23.7ms\n",
      "Speed: 1.6ms preprocess, 23.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/171.jpg: 384x640 (no detections), 23.3ms\n",
      "Speed: 1.6ms preprocess, 23.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/172.jpg: 384x640 1 spoon, 42.9ms\n",
      "Speed: 1.6ms preprocess, 42.9ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/173.jpg: 384x640 1 knife, 22.6ms\n",
      "Speed: 1.6ms preprocess, 22.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/174.jpg: 384x640 (no detections), 26.9ms\n",
      "Speed: 1.8ms preprocess, 26.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/175.jpg: 384x640 (no detections), 27.8ms\n",
      "Speed: 1.8ms preprocess, 27.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/176.jpg: 384x640 1 bottle, 1 knife, 22.5ms\n",
      "Speed: 1.7ms preprocess, 22.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/177.jpg: 384x640 (no detections), 25.6ms\n",
      "Speed: 1.5ms preprocess, 25.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/178.jpg: 384x640 1 person, 26.9ms\n",
      "Speed: 1.7ms preprocess, 26.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/179.jpg: 384x640 1 boat, 29.8ms\n",
      "Speed: 2.2ms preprocess, 29.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/180.jpg: 384x640 (no detections), 24.5ms\n",
      "Speed: 1.6ms preprocess, 24.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/181.jpg: 384x640 (no detections), 35.8ms\n",
      "Speed: 1.6ms preprocess, 35.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/182.jpg: 384x640 2 baseball bats, 1 bottle, 24.8ms\n",
      "Speed: 1.8ms preprocess, 24.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/183.jpg: 384x640 (no detections), 36.4ms\n",
      "Speed: 2.3ms preprocess, 36.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/184.jpg: 384x640 1 person, 31.0ms\n",
      "Speed: 1.7ms preprocess, 31.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/185.jpg: 384x640 (no detections), 25.3ms\n",
      "Speed: 3.0ms preprocess, 25.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/186.jpg: 384x640 (no detections), 26.0ms\n",
      "Speed: 1.6ms preprocess, 26.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/187.jpg: 384x640 1 person, 1 airplane, 24.5ms\n",
      "Speed: 1.7ms preprocess, 24.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/188.jpg: 384x640 2 baseball bats, 27.9ms\n",
      "Speed: 1.7ms preprocess, 27.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/189.jpg: 384x640 2 baseball bats, 24.1ms\n",
      "Speed: 1.6ms preprocess, 24.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/190.jpg: 384x640 2 baseball bats, 25.0ms\n",
      "Speed: 1.9ms preprocess, 25.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/191.jpg: 384x640 (no detections), 28.1ms\n",
      "Speed: 1.9ms preprocess, 28.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/192.jpg: 384x640 (no detections), 26.0ms\n",
      "Speed: 1.6ms preprocess, 26.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/193.jpg: 384x640 1 airplane, 23.4ms\n",
      "Speed: 1.6ms preprocess, 23.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/194.jpg: 384x640 2 baseball bats, 26.7ms\n",
      "Speed: 2.9ms preprocess, 26.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/195.jpg: 384x640 (no detections), 22.9ms\n",
      "Speed: 1.6ms preprocess, 22.9ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/196.jpg: 384x640 (no detections), 23.4ms\n",
      "Speed: 2.2ms preprocess, 23.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/197.jpg: 384x640 1 person, 1 knife, 25.8ms\n",
      "Speed: 1.8ms preprocess, 25.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/198.jpg: 384x640 (no detections), 38.5ms\n",
      "Speed: 1.7ms preprocess, 38.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/199.jpg: 384x640 (no detections), 28.5ms\n",
      "Speed: 1.6ms preprocess, 28.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/200.jpg: 384x640 1 airplane, 23.5ms\n",
      "Speed: 1.6ms preprocess, 23.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/201.jpg: 384x640 1 boat, 25.7ms\n",
      "Speed: 1.6ms preprocess, 25.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/202.jpg: 384x640 2 airplanes, 22.7ms\n",
      "Speed: 1.7ms preprocess, 22.7ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/203.jpg: 384x640 (no detections), 25.5ms\n",
      "Speed: 1.6ms preprocess, 25.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/204.jpg: 384x640 1 knife, 1 toothbrush, 49.4ms\n",
      "Speed: 2.3ms preprocess, 49.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/205.jpg: 384x640 (no detections), 23.4ms\n",
      "Speed: 1.7ms preprocess, 23.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/206.jpg: 384x640 (no detections), 29.1ms\n",
      "Speed: 2.2ms preprocess, 29.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/207.jpg: 384x640 1 spoon, 1 carrot, 25.4ms\n",
      "Speed: 1.7ms preprocess, 25.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/208.jpg: 384x640 1 knife, 55.4ms\n",
      "Speed: 4.2ms preprocess, 55.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/209.jpg: 384x640 1 baseball bat, 2 carrots, 27.1ms\n",
      "Speed: 1.7ms preprocess, 27.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/210.jpg: 384x640 2 baseball bats, 25.5ms\n",
      "Speed: 2.9ms preprocess, 25.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/211.jpg: 384x640 (no detections), 24.2ms\n",
      "Speed: 1.6ms preprocess, 24.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/212.jpg: 384x640 1 knife, 35.0ms\n",
      "Speed: 2.0ms preprocess, 35.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/213.jpg: 384x640 (no detections), 24.1ms\n",
      "Speed: 1.6ms preprocess, 24.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/214.jpg: 384x640 1 toothbrush, 29.9ms\n",
      "Speed: 2.0ms preprocess, 29.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/215.jpg: 384x640 (no detections), 24.1ms\n",
      "Speed: 1.9ms preprocess, 24.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/216.jpg: 384x640 1 knife, 22.7ms\n",
      "Speed: 1.6ms preprocess, 22.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/217.jpg: 384x640 (no detections), 24.3ms\n",
      "Speed: 3.1ms preprocess, 24.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/218.jpg: 384x640 (no detections), 30.7ms\n",
      "Speed: 1.6ms preprocess, 30.7ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/219.jpg: 384x640 1 knife, 22.9ms\n",
      "Speed: 1.6ms preprocess, 22.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/220.jpg: 384x640 1 baseball bat, 1 knife, 25.3ms\n",
      "Speed: 1.9ms preprocess, 25.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/221.jpg: 384x640 (no detections), 30.1ms\n",
      "Speed: 1.6ms preprocess, 30.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/222.jpg: 384x640 (no detections), 25.7ms\n",
      "Speed: 1.6ms preprocess, 25.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/223.jpg: 384x640 2 baseball bats, 48.4ms\n",
      "Speed: 2.1ms preprocess, 48.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/224.jpg: 384x640 (no detections), 33.3ms\n",
      "Speed: 1.8ms preprocess, 33.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/225.jpg: 384x640 1 knife, 30.2ms\n",
      "Speed: 2.2ms preprocess, 30.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/226.jpg: 384x640 (no detections), 27.5ms\n",
      "Speed: 1.7ms preprocess, 27.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/227.jpg: 384x640 (no detections), 23.7ms\n",
      "Speed: 1.5ms preprocess, 23.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/228.jpg: 384x640 (no detections), 36.7ms\n",
      "Speed: 1.6ms preprocess, 36.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/229.jpg: 384x640 (no detections), 28.4ms\n",
      "Speed: 2.0ms preprocess, 28.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/230.jpg: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.3ms preprocess, 25.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/231.jpg: 384x640 1 person, 1 surfboard, 23.3ms\n",
      "Speed: 1.7ms preprocess, 23.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/232.jpg: 384x640 1 baseball bat, 1 knife, 24.5ms\n",
      "Speed: 1.5ms preprocess, 24.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/233.jpg: 384x640 2 baseball bats, 31.7ms\n",
      "Speed: 2.4ms preprocess, 31.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/234.jpg: 384x640 1 airplane, 31.5ms\n",
      "Speed: 2.0ms preprocess, 31.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/235.jpg: 384x640 2 persons, 29.5ms\n",
      "Speed: 1.9ms preprocess, 29.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/236.jpg: 384x640 (no detections), 23.0ms\n",
      "Speed: 1.6ms preprocess, 23.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/237.jpg: 384x640 2 baseball bats, 1 knife, 30.3ms\n",
      "Speed: 1.8ms preprocess, 30.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/238.jpg: 384x640 1 bird, 45.3ms\n",
      "Speed: 2.1ms preprocess, 45.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/239.jpg: 384x640 1 kite, 38.4ms\n",
      "Speed: 1.7ms preprocess, 38.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/240.jpg: 384x640 1 person, 30.4ms\n",
      "Speed: 1.9ms preprocess, 30.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/241.jpg: 384x640 1 baseball bat, 28.8ms\n",
      "Speed: 1.6ms preprocess, 28.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/242.jpg: 384x640 1 person, 24.0ms\n",
      "Speed: 1.6ms preprocess, 24.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/243.jpg: 384x640 1 person, 24.9ms\n",
      "Speed: 1.7ms preprocess, 24.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/244.jpg: 384x640 (no detections), 27.1ms\n",
      "Speed: 1.6ms preprocess, 27.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/245.jpg: 384x640 1 baseball bat, 1 knife, 1 spoon, 26.1ms\n",
      "Speed: 1.7ms preprocess, 26.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/246.jpg: 384x640 (no detections), 31.3ms\n",
      "Speed: 1.6ms preprocess, 31.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/247.jpg: 384x640 1 knife, 27.4ms\n",
      "Speed: 1.8ms preprocess, 27.4ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/248.jpg: 384x640 (no detections), 23.0ms\n",
      "Speed: 1.5ms preprocess, 23.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/249.jpg: 384x640 (no detections), 31.9ms\n",
      "Speed: 1.7ms preprocess, 31.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/250.jpg: 384x640 (no detections), 35.1ms\n",
      "Speed: 1.8ms preprocess, 35.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/251.jpg: 384x640 (no detections), 25.1ms\n",
      "Speed: 1.7ms preprocess, 25.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/252.jpg: 384x640 (no detections), 33.8ms\n",
      "Speed: 1.8ms preprocess, 33.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/253.jpg: 384x640 (no detections), 24.7ms\n",
      "Speed: 1.8ms preprocess, 24.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/254.jpg: 384x640 1 bird, 23.9ms\n",
      "Speed: 1.6ms preprocess, 23.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/255.jpg: 384x640 2 persons, 25.9ms\n",
      "Speed: 1.7ms preprocess, 25.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/256.jpg: 384x640 1 baseball bat, 1 knife, 25.7ms\n",
      "Speed: 1.6ms preprocess, 25.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/257.jpg: 384x640 (no detections), 23.8ms\n",
      "Speed: 1.6ms preprocess, 23.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/258.jpg: 384x640 1 baseball bat, 1 toothbrush, 24.8ms\n",
      "Speed: 1.7ms preprocess, 24.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/259.jpg: 384x640 1 baseball bat, 1 knife, 22.6ms\n",
      "Speed: 1.7ms preprocess, 22.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/260.jpg: 384x640 1 baseball bat, 1 toothbrush, 24.8ms\n",
      "Speed: 1.6ms preprocess, 24.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/261.jpg: 384x640 (no detections), 41.4ms\n",
      "Speed: 1.6ms preprocess, 41.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/262.jpg: 384x640 2 baseball bats, 26.9ms\n",
      "Speed: 1.5ms preprocess, 26.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/263.jpg: 384x640 1 person, 26.4ms\n",
      "Speed: 2.0ms preprocess, 26.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/264.jpg: 384x640 1 bird, 29.9ms\n",
      "Speed: 1.6ms preprocess, 29.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/265.jpg: 384x640 1 airplane, 27.9ms\n",
      "Speed: 1.4ms preprocess, 27.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/266.jpg: 384x640 1 toothbrush, 27.2ms\n",
      "Speed: 2.0ms preprocess, 27.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/267.jpg: 384x640 (no detections), 28.7ms\n",
      "Speed: 2.1ms preprocess, 28.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/268.jpg: 384x640 1 knife, 30.1ms\n",
      "Speed: 1.9ms preprocess, 30.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/269.jpg: 384x640 (no detections), 29.9ms\n",
      "Speed: 1.9ms preprocess, 29.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/270.jpg: 384x640 1 baseball bat, 1 toothbrush, 42.8ms\n",
      "Speed: 1.7ms preprocess, 42.8ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/271.jpg: 384x640 1 airplane, 33.1ms\n",
      "Speed: 1.7ms preprocess, 33.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/272.jpg: 384x640 (no detections), 24.2ms\n",
      "Speed: 1.6ms preprocess, 24.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/273.jpg: 384x640 (no detections), 22.3ms\n",
      "Speed: 1.5ms preprocess, 22.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/274.jpg: 384x640 2 knifes, 35.0ms\n",
      "Speed: 1.7ms preprocess, 35.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/275.jpg: 384x640 (no detections), 28.1ms\n",
      "Speed: 1.8ms preprocess, 28.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/276.jpg: 384x640 (no detections), 23.2ms\n",
      "Speed: 1.6ms preprocess, 23.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/277.jpg: 384x640 (no detections), 24.6ms\n",
      "Speed: 3.4ms preprocess, 24.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/278.jpg: 384x640 (no detections), 25.7ms\n",
      "Speed: 1.5ms preprocess, 25.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/279.jpg: 384x640 1 motorcycle, 1 knife, 25.5ms\n",
      "Speed: 1.6ms preprocess, 25.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/280.jpg: 384x640 1 sink, 29.2ms\n",
      "Speed: 1.7ms preprocess, 29.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/281.jpg: 384x640 1 bottle, 1 knife, 37.0ms\n",
      "Speed: 1.3ms preprocess, 37.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/282.jpg: 384x640 (no detections), 29.2ms\n",
      "Speed: 1.7ms preprocess, 29.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/283.jpg: 384x640 (no detections), 22.5ms\n",
      "Speed: 1.5ms preprocess, 22.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/284.jpg: 384x640 (no detections), 23.6ms\n",
      "Speed: 1.6ms preprocess, 23.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/285.jpg: 384x640 (no detections), 29.2ms\n",
      "Speed: 3.0ms preprocess, 29.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/286.jpg: 384x640 1 spoon, 37.4ms\n",
      "Speed: 1.9ms preprocess, 37.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/287.jpg: 384x640 (no detections), 23.2ms\n",
      "Speed: 1.9ms preprocess, 23.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/288.jpg: 384x640 (no detections), 24.8ms\n",
      "Speed: 1.8ms preprocess, 24.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/289.jpg: 384x640 (no detections), 30.3ms\n",
      "Speed: 2.0ms preprocess, 30.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/290.jpg: 384x640 1 knife, 1 spoon, 35.2ms\n",
      "Speed: 1.4ms preprocess, 35.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/291.jpg: 384x640 (no detections), 41.6ms\n",
      "Speed: 1.9ms preprocess, 41.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/292.jpg: 384x640 (no detections), 24.0ms\n",
      "Speed: 1.7ms preprocess, 24.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/293.jpg: 384x640 (no detections), 51.2ms\n",
      "Speed: 1.8ms preprocess, 51.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/294.jpg: 384x640 (no detections), 39.7ms\n",
      "Speed: 3.1ms preprocess, 39.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/295.jpg: 384x640 2 knifes, 23.7ms\n",
      "Speed: 1.9ms preprocess, 23.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/296.jpg: 384x640 2 knifes, 27.1ms\n",
      "Speed: 1.7ms preprocess, 27.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/297.jpg: 384x640 1 clock, 25.1ms\n",
      "Speed: 1.5ms preprocess, 25.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/298.jpg: 384x640 (no detections), 33.8ms\n",
      "Speed: 1.9ms preprocess, 33.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/left/299.jpg: 384x640 1 boat, 43.4ms\n",
      "Speed: 1.6ms preprocess, 43.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Propagating video frames: 100%|| 300/300 [00:19<00:00, 15.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask propagation completed in 19.27 seconds.\n",
      "Processing predicted masks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing video frames: 300it [00:00, 557.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 300 masks for evaluation.\n",
      "Masks saved to data/masks/yolo11x-seg/val/data-raw-SegSTRONGC_val-val-1-0-smoke-left.pkl\n",
      "Loading ground truth masks for evaluation...\n",
      "Loaded 300 ground truth masks.\n",
      "Calculating evaluation metrics...\n",
      "Time taken for metrics calculation: 1.37 seconds.\n",
      "Mean IoU for data/raw/SegSTRONGC_val/val/1/0/smoke/left: 0.1802\n",
      "Mean DSC for data/raw/SegSTRONGC_val/val/1/0/smoke/left: 0.2290\n",
      "Loading existing results file: data/results/yolo11x-seg/val.json\n",
      "Results saved to data/results/yolo11x-seg/val.json\n",
      "Processing video took 23.14 seconds.\n",
      "==================================================\n",
      "Processing right camera video...\n",
      "==================================================\n",
      "Processing video: data/raw/SegSTRONGC_val/val/1/0/smoke/right\n",
      "Domain: smoke, Split: val, Camera: right\n",
      "Initializing Yolo for video...\n",
      "Initialization took 0.15 seconds.\n",
      "Starting mask propagation...\n",
      "Total images in video: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/0.jpg: 384x640 (no detections), 71.1ms\n",
      "Speed: 2.2ms preprocess, 71.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/1.jpg: 384x640 (no detections), 64.1ms\n",
      "Speed: 2.4ms preprocess, 64.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/2.jpg: 384x640 2 knifes, 1 sink, 27.9ms\n",
      "Speed: 2.3ms preprocess, 27.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/3.jpg: 384x640 (no detections), 28.9ms\n",
      "Speed: 1.6ms preprocess, 28.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/4.jpg: 384x640 (no detections), 31.4ms\n",
      "Speed: 5.0ms preprocess, 31.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/5.jpg: 384x640 (no detections), 24.7ms\n",
      "Speed: 1.5ms preprocess, 24.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/6.jpg: 384x640 (no detections), 62.5ms\n",
      "Speed: 4.2ms preprocess, 62.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/7.jpg: 384x640 (no detections), 27.5ms\n",
      "Speed: 1.7ms preprocess, 27.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/8.jpg: 384x640 (no detections), 42.0ms\n",
      "Speed: 1.9ms preprocess, 42.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/9.jpg: 384x640 (no detections), 29.8ms\n",
      "Speed: 3.5ms preprocess, 29.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/10.jpg: 384x640 (no detections), 32.5ms\n",
      "Speed: 1.8ms preprocess, 32.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/11.jpg: 384x640 (no detections), 27.1ms\n",
      "Speed: 1.5ms preprocess, 27.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/12.jpg: 384x640 1 knife, 1 sink, 26.2ms\n",
      "Speed: 2.2ms preprocess, 26.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/13.jpg: 384x640 (no detections), 29.3ms\n",
      "Speed: 1.6ms preprocess, 29.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/14.jpg: 384x640 (no detections), 28.2ms\n",
      "Speed: 1.9ms preprocess, 28.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/15.jpg: 384x640 1 knife, 31.5ms\n",
      "Speed: 1.8ms preprocess, 31.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/16.jpg: 384x640 (no detections), 30.4ms\n",
      "Speed: 2.2ms preprocess, 30.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/17.jpg: 384x640 (no detections), 28.4ms\n",
      "Speed: 1.6ms preprocess, 28.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/18.jpg: 384x640 (no detections), 25.0ms\n",
      "Speed: 2.0ms preprocess, 25.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/19.jpg: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.1ms preprocess, 26.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/20.jpg: 384x640 (no detections), 34.8ms\n",
      "Speed: 1.7ms preprocess, 34.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/21.jpg: 384x640 (no detections), 54.7ms\n",
      "Speed: 2.5ms preprocess, 54.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/22.jpg: 384x640 (no detections), 27.0ms\n",
      "Speed: 1.7ms preprocess, 27.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/23.jpg: 384x640 (no detections), 25.7ms\n",
      "Speed: 1.8ms preprocess, 25.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/24.jpg: 384x640 (no detections), 22.8ms\n",
      "Speed: 1.4ms preprocess, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/25.jpg: 384x640 (no detections), 38.7ms\n",
      "Speed: 1.8ms preprocess, 38.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/26.jpg: 384x640 (no detections), 25.0ms\n",
      "Speed: 1.6ms preprocess, 25.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/27.jpg: 384x640 (no detections), 28.2ms\n",
      "Speed: 1.8ms preprocess, 28.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/28.jpg: 384x640 (no detections), 40.3ms\n",
      "Speed: 1.6ms preprocess, 40.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/29.jpg: 384x640 (no detections), 30.6ms\n",
      "Speed: 2.0ms preprocess, 30.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/30.jpg: 384x640 1 toothbrush, 25.9ms\n",
      "Speed: 1.6ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/31.jpg: 384x640 1 toothbrush, 24.4ms\n",
      "Speed: 1.9ms preprocess, 24.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/32.jpg: 384x640 1 knife, 2 spoons, 24.7ms\n",
      "Speed: 1.8ms preprocess, 24.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/33.jpg: 384x640 2 spoons, 44.7ms\n",
      "Speed: 2.0ms preprocess, 44.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/34.jpg: 384x640 (no detections), 32.2ms\n",
      "Speed: 2.9ms preprocess, 32.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/35.jpg: 384x640 (no detections), 24.4ms\n",
      "Speed: 1.7ms preprocess, 24.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/36.jpg: 384x640 (no detections), 28.2ms\n",
      "Speed: 1.6ms preprocess, 28.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/37.jpg: 384x640 (no detections), 30.3ms\n",
      "Speed: 2.6ms preprocess, 30.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/38.jpg: 384x640 (no detections), 40.4ms\n",
      "Speed: 2.0ms preprocess, 40.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/39.jpg: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.2ms preprocess, 25.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/40.jpg: 384x640 (no detections), 30.4ms\n",
      "Speed: 1.6ms preprocess, 30.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/41.jpg: 384x640 1 knife, 35.9ms\n",
      "Speed: 2.4ms preprocess, 35.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/42.jpg: 384x640 (no detections), 38.8ms\n",
      "Speed: 1.9ms preprocess, 38.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/43.jpg: 384x640 1 knife, 1 sink, 25.7ms\n",
      "Speed: 2.4ms preprocess, 25.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/44.jpg: 384x640 1 spoon, 1 carrot, 27.3ms\n",
      "Speed: 2.6ms preprocess, 27.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/45.jpg: 384x640 1 spoon, 36.7ms\n",
      "Speed: 1.7ms preprocess, 36.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/46.jpg: 384x640 (no detections), 22.8ms\n",
      "Speed: 1.6ms preprocess, 22.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/47.jpg: 384x640 1 baseball bat, 1 spoon, 28.6ms\n",
      "Speed: 1.9ms preprocess, 28.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/48.jpg: 384x640 1 spoon, 28.7ms\n",
      "Speed: 1.7ms preprocess, 28.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/49.jpg: 384x640 (no detections), 22.3ms\n",
      "Speed: 1.6ms preprocess, 22.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/50.jpg: 384x640 1 knife, 2 spoons, 23.5ms\n",
      "Speed: 1.6ms preprocess, 23.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/51.jpg: 384x640 (no detections), 26.9ms\n",
      "Speed: 2.1ms preprocess, 26.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/52.jpg: 384x640 1 sink, 2 toothbrushs, 39.7ms\n",
      "Speed: 5.0ms preprocess, 39.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/53.jpg: 384x640 (no detections), 42.4ms\n",
      "Speed: 1.9ms preprocess, 42.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/54.jpg: 384x640 (no detections), 32.7ms\n",
      "Speed: 1.9ms preprocess, 32.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/55.jpg: 384x640 1 spoon, 1 toothbrush, 28.5ms\n",
      "Speed: 1.9ms preprocess, 28.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/56.jpg: 384x640 (no detections), 33.2ms\n",
      "Speed: 1.6ms preprocess, 33.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/57.jpg: 384x640 (no detections), 26.3ms\n",
      "Speed: 1.7ms preprocess, 26.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/58.jpg: 384x640 (no detections), 27.4ms\n",
      "Speed: 1.5ms preprocess, 27.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/59.jpg: 384x640 (no detections), 48.3ms\n",
      "Speed: 1.7ms preprocess, 48.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/60.jpg: 384x640 (no detections), 24.8ms\n",
      "Speed: 1.7ms preprocess, 24.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/61.jpg: 384x640 (no detections), 23.0ms\n",
      "Speed: 1.8ms preprocess, 23.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/62.jpg: 384x640 (no detections), 27.8ms\n",
      "Speed: 1.7ms preprocess, 27.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/63.jpg: 384x640 2 spoons, 23.4ms\n",
      "Speed: 1.8ms preprocess, 23.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/64.jpg: 384x640 (no detections), 27.3ms\n",
      "Speed: 1.9ms preprocess, 27.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/65.jpg: 384x640 (no detections), 25.5ms\n",
      "Speed: 1.5ms preprocess, 25.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/66.jpg: 384x640 1 spoon, 1 sink, 29.5ms\n",
      "Speed: 1.5ms preprocess, 29.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/67.jpg: 384x640 (no detections), 27.3ms\n",
      "Speed: 1.5ms preprocess, 27.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/68.jpg: 384x640 1 spoon, 40.4ms\n",
      "Speed: 2.3ms preprocess, 40.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/69.jpg: 384x640 (no detections), 24.5ms\n",
      "Speed: 1.7ms preprocess, 24.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/70.jpg: 384x640 2 spoons, 42.1ms\n",
      "Speed: 1.8ms preprocess, 42.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/71.jpg: 384x640 (no detections), 28.9ms\n",
      "Speed: 1.7ms preprocess, 28.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/72.jpg: 384x640 1 spoon, 1 sink, 23.4ms\n",
      "Speed: 1.6ms preprocess, 23.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/73.jpg: 384x640 (no detections), 30.7ms\n",
      "Speed: 2.0ms preprocess, 30.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/74.jpg: 384x640 1 toothbrush, 47.9ms\n",
      "Speed: 2.6ms preprocess, 47.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/75.jpg: 384x640 (no detections), 47.7ms\n",
      "Speed: 1.8ms preprocess, 47.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/76.jpg: 384x640 2 spoons, 24.1ms\n",
      "Speed: 1.7ms preprocess, 24.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/77.jpg: 384x640 (no detections), 26.8ms\n",
      "Speed: 1.8ms preprocess, 26.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/78.jpg: 384x640 (no detections), 31.7ms\n",
      "Speed: 1.7ms preprocess, 31.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/79.jpg: 384x640 (no detections), 42.5ms\n",
      "Speed: 2.2ms preprocess, 42.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/80.jpg: 384x640 1 toothbrush, 25.5ms\n",
      "Speed: 1.8ms preprocess, 25.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/81.jpg: 384x640 (no detections), 23.0ms\n",
      "Speed: 1.6ms preprocess, 23.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/82.jpg: 384x640 (no detections), 24.0ms\n",
      "Speed: 1.7ms preprocess, 24.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/83.jpg: 384x640 1 sink, 1 toothbrush, 34.1ms\n",
      "Speed: 1.6ms preprocess, 34.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/84.jpg: 384x640 (no detections), 25.8ms\n",
      "Speed: 1.9ms preprocess, 25.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/85.jpg: 384x640 1 knife, 1 sink, 27.2ms\n",
      "Speed: 1.7ms preprocess, 27.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/86.jpg: 384x640 (no detections), 26.3ms\n",
      "Speed: 2.3ms preprocess, 26.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/87.jpg: 384x640 (no detections), 23.9ms\n",
      "Speed: 1.7ms preprocess, 23.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/88.jpg: 384x640 (no detections), 26.6ms\n",
      "Speed: 1.5ms preprocess, 26.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/89.jpg: 384x640 1 spoon, 1 toothbrush, 41.3ms\n",
      "Speed: 2.0ms preprocess, 41.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/90.jpg: 384x640 (no detections), 28.2ms\n",
      "Speed: 1.7ms preprocess, 28.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/91.jpg: 384x640 (no detections), 30.6ms\n",
      "Speed: 2.3ms preprocess, 30.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/92.jpg: 384x640 1 toothbrush, 38.2ms\n",
      "Speed: 1.8ms preprocess, 38.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/93.jpg: 384x640 1 bird, 29.6ms\n",
      "Speed: 1.5ms preprocess, 29.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/94.jpg: 384x640 1 knife, 2 spoons, 24.6ms\n",
      "Speed: 1.6ms preprocess, 24.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/95.jpg: 384x640 2 spoons, 1 toothbrush, 30.7ms\n",
      "Speed: 2.5ms preprocess, 30.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/96.jpg: 384x640 1 knife, 1 spoon, 24.0ms\n",
      "Speed: 1.7ms preprocess, 24.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/97.jpg: 384x640 (no detections), 29.9ms\n",
      "Speed: 1.9ms preprocess, 29.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/98.jpg: 384x640 1 spoon, 1 apple, 30.2ms\n",
      "Speed: 1.6ms preprocess, 30.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/99.jpg: 384x640 (no detections), 24.3ms\n",
      "Speed: 1.6ms preprocess, 24.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/100.jpg: 384x640 (no detections), 30.1ms\n",
      "Speed: 1.7ms preprocess, 30.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/101.jpg: 384x640 (no detections), 24.6ms\n",
      "Speed: 1.7ms preprocess, 24.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/102.jpg: 384x640 (no detections), 52.4ms\n",
      "Speed: 3.1ms preprocess, 52.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/103.jpg: 384x640 1 airplane, 29.6ms\n",
      "Speed: 1.7ms preprocess, 29.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/104.jpg: 384x640 (no detections), 29.6ms\n",
      "Speed: 1.8ms preprocess, 29.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/105.jpg: 384x640 (no detections), 29.3ms\n",
      "Speed: 1.7ms preprocess, 29.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/106.jpg: 384x640 (no detections), 33.9ms\n",
      "Speed: 1.8ms preprocess, 33.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/107.jpg: 384x640 2 spoons, 24.7ms\n",
      "Speed: 3.0ms preprocess, 24.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/108.jpg: 384x640 (no detections), 36.7ms\n",
      "Speed: 2.9ms preprocess, 36.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/109.jpg: 384x640 1 sink, 1 toothbrush, 25.6ms\n",
      "Speed: 1.7ms preprocess, 25.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/110.jpg: 384x640 (no detections), 23.7ms\n",
      "Speed: 2.0ms preprocess, 23.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/111.jpg: 384x640 1 sink, 32.1ms\n",
      "Speed: 1.7ms preprocess, 32.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/112.jpg: 384x640 1 bottle, 1 toothbrush, 36.8ms\n",
      "Speed: 1.7ms preprocess, 36.8ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/113.jpg: 384x640 1 spoon, 24.5ms\n",
      "Speed: 1.6ms preprocess, 24.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/114.jpg: 384x640 1 spoon, 30.5ms\n",
      "Speed: 1.8ms preprocess, 30.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/115.jpg: 384x640 (no detections), 37.2ms\n",
      "Speed: 1.7ms preprocess, 37.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/116.jpg: 384x640 1 toothbrush, 27.9ms\n",
      "Speed: 1.7ms preprocess, 27.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/117.jpg: 384x640 (no detections), 39.5ms\n",
      "Speed: 1.6ms preprocess, 39.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/118.jpg: 384x640 (no detections), 33.6ms\n",
      "Speed: 2.3ms preprocess, 33.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/119.jpg: 384x640 (no detections), 24.6ms\n",
      "Speed: 1.5ms preprocess, 24.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/120.jpg: 384x640 2 toothbrushs, 27.8ms\n",
      "Speed: 1.6ms preprocess, 27.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/121.jpg: 384x640 (no detections), 42.2ms\n",
      "Speed: 1.6ms preprocess, 42.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/122.jpg: 384x640 1 motorcycle, 25.6ms\n",
      "Speed: 1.7ms preprocess, 25.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/123.jpg: 384x640 (no detections), 24.5ms\n",
      "Speed: 2.2ms preprocess, 24.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/124.jpg: 384x640 1 airplane, 24.4ms\n",
      "Speed: 1.5ms preprocess, 24.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/125.jpg: 384x640 2 baseball bats, 1 bottle, 36.9ms\n",
      "Speed: 2.6ms preprocess, 36.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/126.jpg: 384x640 2 baseball bats, 1 spoon, 34.0ms\n",
      "Speed: 1.6ms preprocess, 34.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/127.jpg: 384x640 (no detections), 27.5ms\n",
      "Speed: 1.4ms preprocess, 27.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/128.jpg: 384x640 1 toothbrush, 27.8ms\n",
      "Speed: 1.6ms preprocess, 27.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/129.jpg: 384x640 1 knife, 30.5ms\n",
      "Speed: 2.7ms preprocess, 30.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/130.jpg: 384x640 (no detections), 31.3ms\n",
      "Speed: 1.6ms preprocess, 31.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/131.jpg: 384x640 1 airplane, 29.1ms\n",
      "Speed: 1.5ms preprocess, 29.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/132.jpg: 384x640 1 bottle, 1 spoon, 1 sink, 26.5ms\n",
      "Speed: 1.7ms preprocess, 26.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/133.jpg: 384x640 1 airplane, 23.0ms\n",
      "Speed: 1.8ms preprocess, 23.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/134.jpg: 384x640 (no detections), 26.0ms\n",
      "Speed: 1.7ms preprocess, 26.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/135.jpg: 384x640 1 bottle, 1 spoon, 34.8ms\n",
      "Speed: 2.0ms preprocess, 34.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/136.jpg: 384x640 (no detections), 56.3ms\n",
      "Speed: 1.6ms preprocess, 56.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/137.jpg: 384x640 (no detections), 28.4ms\n",
      "Speed: 1.5ms preprocess, 28.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/138.jpg: 384x640 (no detections), 24.8ms\n",
      "Speed: 1.7ms preprocess, 24.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/139.jpg: 384x640 (no detections), 30.5ms\n",
      "Speed: 1.7ms preprocess, 30.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/140.jpg: 384x640 (no detections), 42.2ms\n",
      "Speed: 1.9ms preprocess, 42.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/141.jpg: 384x640 1 airplane, 30.3ms\n",
      "Speed: 1.6ms preprocess, 30.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/142.jpg: 384x640 1 knife, 1 spoon, 25.2ms\n",
      "Speed: 2.8ms preprocess, 25.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/143.jpg: 384x640 1 airplane, 26.4ms\n",
      "Speed: 1.4ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/144.jpg: 384x640 1 knife, 1 sink, 23.5ms\n",
      "Speed: 1.6ms preprocess, 23.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/145.jpg: 384x640 1 bottle, 1 spoon, 26.6ms\n",
      "Speed: 1.8ms preprocess, 26.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/146.jpg: 384x640 1 bottle, 40.7ms\n",
      "Speed: 1.6ms preprocess, 40.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/147.jpg: 384x640 1 toothbrush, 25.1ms\n",
      "Speed: 1.7ms preprocess, 25.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/148.jpg: 384x640 1 spoon, 25.0ms\n",
      "Speed: 1.6ms preprocess, 25.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/149.jpg: 384x640 1 airplane, 23.2ms\n",
      "Speed: 1.4ms preprocess, 23.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/150.jpg: 384x640 1 knife, 1 toothbrush, 25.9ms\n",
      "Speed: 1.5ms preprocess, 25.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/151.jpg: 384x640 1 knife, 27.0ms\n",
      "Speed: 2.0ms preprocess, 27.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/152.jpg: 384x640 (no detections), 34.3ms\n",
      "Speed: 1.7ms preprocess, 34.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/153.jpg: 384x640 1 knife, 1 spoon, 1 toothbrush, 25.4ms\n",
      "Speed: 2.8ms preprocess, 25.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/154.jpg: 384x640 1 spoon, 46.1ms\n",
      "Speed: 2.7ms preprocess, 46.1ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/155.jpg: 384x640 (no detections), 26.4ms\n",
      "Speed: 2.8ms preprocess, 26.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/156.jpg: 384x640 2 spoons, 2 carrots, 26.8ms\n",
      "Speed: 1.6ms preprocess, 26.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/157.jpg: 384x640 (no detections), 24.0ms\n",
      "Speed: 1.5ms preprocess, 24.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/158.jpg: 384x640 (no detections), 24.0ms\n",
      "Speed: 1.6ms preprocess, 24.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/159.jpg: 384x640 (no detections), 39.3ms\n",
      "Speed: 1.8ms preprocess, 39.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/160.jpg: 384x640 2 spoons, 30.8ms\n",
      "Speed: 1.9ms preprocess, 30.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/161.jpg: 384x640 1 knife, 1 spoon, 1 toothbrush, 22.7ms\n",
      "Speed: 1.6ms preprocess, 22.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/162.jpg: 384x640 (no detections), 26.0ms\n",
      "Speed: 2.2ms preprocess, 26.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/163.jpg: 384x640 1 spoon, 32.1ms\n",
      "Speed: 1.8ms preprocess, 32.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/164.jpg: 384x640 (no detections), 28.0ms\n",
      "Speed: 1.5ms preprocess, 28.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/165.jpg: 384x640 (no detections), 23.6ms\n",
      "Speed: 2.1ms preprocess, 23.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/166.jpg: 384x640 (no detections), 25.4ms\n",
      "Speed: 1.5ms preprocess, 25.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/167.jpg: 384x640 1 spoon, 29.4ms\n",
      "Speed: 1.7ms preprocess, 29.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/168.jpg: 384x640 1 spoon, 30.8ms\n",
      "Speed: 1.9ms preprocess, 30.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/169.jpg: 384x640 1 knife, 1 spoon, 34.8ms\n",
      "Speed: 1.7ms preprocess, 34.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/170.jpg: 384x640 2 spoons, 1 toothbrush, 29.6ms\n",
      "Speed: 1.6ms preprocess, 29.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/171.jpg: 384x640 (no detections), 34.4ms\n",
      "Speed: 2.8ms preprocess, 34.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/172.jpg: 384x640 1 spoon, 37.4ms\n",
      "Speed: 1.6ms preprocess, 37.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/173.jpg: 384x640 1 spoon, 27.3ms\n",
      "Speed: 1.7ms preprocess, 27.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/174.jpg: 384x640 (no detections), 38.5ms\n",
      "Speed: 2.4ms preprocess, 38.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/175.jpg: 384x640 (no detections), 33.6ms\n",
      "Speed: 2.0ms preprocess, 33.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/176.jpg: 384x640 1 bottle, 32.3ms\n",
      "Speed: 3.7ms preprocess, 32.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/177.jpg: 384x640 2 toothbrushs, 29.7ms\n",
      "Speed: 1.8ms preprocess, 29.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/178.jpg: 384x640 (no detections), 28.3ms\n",
      "Speed: 1.6ms preprocess, 28.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/179.jpg: 384x640 (no detections), 26.1ms\n",
      "Speed: 1.5ms preprocess, 26.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/180.jpg: 384x640 (no detections), 27.8ms\n",
      "Speed: 1.4ms preprocess, 27.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/181.jpg: 384x640 1 spoon, 1 toothbrush, 25.3ms\n",
      "Speed: 1.5ms preprocess, 25.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/182.jpg: 384x640 1 baseball bat, 1 bottle, 25.0ms\n",
      "Speed: 2.1ms preprocess, 25.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/183.jpg: 384x640 1 spoon, 1 toothbrush, 31.9ms\n",
      "Speed: 1.5ms preprocess, 31.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/184.jpg: 384x640 (no detections), 26.8ms\n",
      "Speed: 1.9ms preprocess, 26.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/185.jpg: 384x640 (no detections), 28.9ms\n",
      "Speed: 1.5ms preprocess, 28.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/186.jpg: 384x640 (no detections), 25.4ms\n",
      "Speed: 1.6ms preprocess, 25.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/187.jpg: 384x640 (no detections), 31.4ms\n",
      "Speed: 1.7ms preprocess, 31.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/188.jpg: 384x640 2 spoons, 1 carrot, 29.0ms\n",
      "Speed: 2.1ms preprocess, 29.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/189.jpg: 384x640 2 spoons, 1 carrot, 39.2ms\n",
      "Speed: 1.6ms preprocess, 39.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/190.jpg: 384x640 2 spoons, 1 carrot, 30.0ms\n",
      "Speed: 1.6ms preprocess, 30.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/191.jpg: 384x640 1 spoon, 27.2ms\n",
      "Speed: 1.6ms preprocess, 27.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/192.jpg: 384x640 1 toothbrush, 30.7ms\n",
      "Speed: 3.1ms preprocess, 30.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/193.jpg: 384x640 (no detections), 23.4ms\n",
      "Speed: 1.8ms preprocess, 23.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/194.jpg: 384x640 2 spoons, 25.9ms\n",
      "Speed: 1.7ms preprocess, 25.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/195.jpg: 384x640 1 motorcycle, 46.9ms\n",
      "Speed: 1.7ms preprocess, 46.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/196.jpg: 384x640 1 clock, 24.8ms\n",
      "Speed: 1.7ms preprocess, 24.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/197.jpg: 384x640 (no detections), 25.6ms\n",
      "Speed: 1.8ms preprocess, 25.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/198.jpg: 384x640 (no detections), 34.6ms\n",
      "Speed: 1.7ms preprocess, 34.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/199.jpg: 384x640 (no detections), 33.1ms\n",
      "Speed: 1.8ms preprocess, 33.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/200.jpg: 384x640 (no detections), 27.8ms\n",
      "Speed: 1.7ms preprocess, 27.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/201.jpg: 384x640 (no detections), 39.9ms\n",
      "Speed: 1.6ms preprocess, 39.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/202.jpg: 384x640 1 clock, 22.5ms\n",
      "Speed: 1.9ms preprocess, 22.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/203.jpg: 384x640 (no detections), 23.2ms\n",
      "Speed: 1.5ms preprocess, 23.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/204.jpg: 384x640 1 spoon, 1 bowl, 1 apple, 1 toothbrush, 24.2ms\n",
      "Speed: 1.6ms preprocess, 24.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/205.jpg: 384x640 1 toothbrush, 32.7ms\n",
      "Speed: 3.1ms preprocess, 32.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/206.jpg: 384x640 1 toothbrush, 24.8ms\n",
      "Speed: 1.7ms preprocess, 24.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/207.jpg: 384x640 2 spoons, 3 carrots, 28.7ms\n",
      "Speed: 2.0ms preprocess, 28.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/208.jpg: 384x640 1 spoon, 1 sink, 26.8ms\n",
      "Speed: 1.6ms preprocess, 26.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/209.jpg: 384x640 1 spoon, 1 toothbrush, 23.8ms\n",
      "Speed: 2.1ms preprocess, 23.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/210.jpg: 384x640 1 baseball bat, 2 spoons, 1 carrot, 69.7ms\n",
      "Speed: 1.8ms preprocess, 69.7ms inference, 7.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/211.jpg: 384x640 1 spoon, 26.7ms\n",
      "Speed: 2.5ms preprocess, 26.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/212.jpg: 384x640 (no detections), 34.5ms\n",
      "Speed: 2.6ms preprocess, 34.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/213.jpg: 384x640 (no detections), 27.8ms\n",
      "Speed: 2.9ms preprocess, 27.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/214.jpg: 384x640 1 spoon, 22.2ms\n",
      "Speed: 1.8ms preprocess, 22.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/215.jpg: 384x640 (no detections), 35.8ms\n",
      "Speed: 1.9ms preprocess, 35.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/216.jpg: 384x640 1 knife, 1 sink, 29.0ms\n",
      "Speed: 2.4ms preprocess, 29.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/217.jpg: 384x640 1 sink, 28.8ms\n",
      "Speed: 1.9ms preprocess, 28.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/218.jpg: 384x640 (no detections), 42.3ms\n",
      "Speed: 1.6ms preprocess, 42.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/219.jpg: 384x640 1 spoon, 24.8ms\n",
      "Speed: 1.8ms preprocess, 24.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/220.jpg: 384x640 1 spoon, 23.3ms\n",
      "Speed: 1.6ms preprocess, 23.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/221.jpg: 384x640 1 toothbrush, 37.5ms\n",
      "Speed: 2.6ms preprocess, 37.5ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/222.jpg: 384x640 1 motorcycle, 28.5ms\n",
      "Speed: 1.5ms preprocess, 28.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/223.jpg: 384x640 2 spoons, 38.2ms\n",
      "Speed: 1.7ms preprocess, 38.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/224.jpg: 384x640 (no detections), 40.0ms\n",
      "Speed: 1.8ms preprocess, 40.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/225.jpg: 384x640 2 spoons, 31.4ms\n",
      "Speed: 1.7ms preprocess, 31.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/226.jpg: 384x640 (no detections), 26.4ms\n",
      "Speed: 2.4ms preprocess, 26.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/227.jpg: 384x640 (no detections), 36.9ms\n",
      "Speed: 1.7ms preprocess, 36.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/228.jpg: 384x640 1 person, 25.2ms\n",
      "Speed: 1.9ms preprocess, 25.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/229.jpg: 384x640 (no detections), 24.1ms\n",
      "Speed: 1.5ms preprocess, 24.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/230.jpg: 384x640 1 spoon, 1 sink, 1 toothbrush, 24.5ms\n",
      "Speed: 1.5ms preprocess, 24.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/231.jpg: 384x640 (no detections), 27.1ms\n",
      "Speed: 5.0ms preprocess, 27.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/232.jpg: 384x640 1 spoon, 30.0ms\n",
      "Speed: 1.8ms preprocess, 30.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/233.jpg: 384x640 2 spoons, 28.8ms\n",
      "Speed: 1.6ms preprocess, 28.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/234.jpg: 384x640 (no detections), 23.1ms\n",
      "Speed: 1.7ms preprocess, 23.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/235.jpg: 384x640 (no detections), 23.4ms\n",
      "Speed: 1.3ms preprocess, 23.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/236.jpg: 384x640 1 spoon, 1 sink, 23.8ms\n",
      "Speed: 1.6ms preprocess, 23.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/237.jpg: 384x640 1 baseball bat, 2 spoons, 1 sink, 31.4ms\n",
      "Speed: 2.4ms preprocess, 31.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/238.jpg: 384x640 (no detections), 38.8ms\n",
      "Speed: 1.6ms preprocess, 38.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/239.jpg: 384x640 1 bird, 28.8ms\n",
      "Speed: 1.7ms preprocess, 28.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/240.jpg: 384x640 1 sink, 24.1ms\n",
      "Speed: 1.6ms preprocess, 24.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/241.jpg: 384x640 1 spoon, 25.9ms\n",
      "Speed: 1.5ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/242.jpg: 384x640 (no detections), 25.8ms\n",
      "Speed: 1.7ms preprocess, 25.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/243.jpg: 384x640 (no detections), 37.9ms\n",
      "Speed: 2.3ms preprocess, 37.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/244.jpg: 384x640 (no detections), 25.1ms\n",
      "Speed: 1.5ms preprocess, 25.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/245.jpg: 384x640 2 spoons, 31.8ms\n",
      "Speed: 1.7ms preprocess, 31.8ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/246.jpg: 384x640 (no detections), 25.6ms\n",
      "Speed: 1.7ms preprocess, 25.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/247.jpg: 384x640 1 spoon, 1 sink, 1 toothbrush, 23.8ms\n",
      "Speed: 1.6ms preprocess, 23.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/248.jpg: 384x640 1 toothbrush, 24.8ms\n",
      "Speed: 1.4ms preprocess, 24.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/249.jpg: 384x640 1 toothbrush, 23.5ms\n",
      "Speed: 1.5ms preprocess, 23.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/250.jpg: 384x640 (no detections), 26.9ms\n",
      "Speed: 1.8ms preprocess, 26.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/251.jpg: 384x640 1 airplane, 26.9ms\n",
      "Speed: 1.9ms preprocess, 26.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/252.jpg: 384x640 1 airplane, 23.1ms\n",
      "Speed: 1.6ms preprocess, 23.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/253.jpg: 384x640 (no detections), 24.7ms\n",
      "Speed: 2.2ms preprocess, 24.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/254.jpg: 384x640 (no detections), 29.4ms\n",
      "Speed: 1.7ms preprocess, 29.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/255.jpg: 384x640 (no detections), 25.6ms\n",
      "Speed: 1.6ms preprocess, 25.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/256.jpg: 384x640 1 spoon, 24.4ms\n",
      "Speed: 1.6ms preprocess, 24.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/257.jpg: 384x640 1 clock, 28.2ms\n",
      "Speed: 1.7ms preprocess, 28.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/258.jpg: 384x640 1 baseball bat, 1 spoon, 34.4ms\n",
      "Speed: 1.7ms preprocess, 34.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/259.jpg: 384x640 2 spoons, 33.2ms\n",
      "Speed: 1.7ms preprocess, 33.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/260.jpg: 384x640 2 spoons, 1 toothbrush, 27.8ms\n",
      "Speed: 1.6ms preprocess, 27.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/261.jpg: 384x640 (no detections), 24.6ms\n",
      "Speed: 2.2ms preprocess, 24.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/262.jpg: 384x640 1 spoon, 22.7ms\n",
      "Speed: 1.5ms preprocess, 22.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/263.jpg: 384x640 2 toothbrushs, 23.0ms\n",
      "Speed: 1.6ms preprocess, 23.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/264.jpg: 384x640 (no detections), 28.3ms\n",
      "Speed: 2.2ms preprocess, 28.3ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/265.jpg: 384x640 1 airplane, 33.9ms\n",
      "Speed: 1.8ms preprocess, 33.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/266.jpg: 384x640 1 spoon, 2 toothbrushs, 36.2ms\n",
      "Speed: 1.8ms preprocess, 36.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/267.jpg: 384x640 (no detections), 22.9ms\n",
      "Speed: 1.7ms preprocess, 22.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/268.jpg: 384x640 2 spoons, 1 toothbrush, 24.3ms\n",
      "Speed: 1.7ms preprocess, 24.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/269.jpg: 384x640 (no detections), 30.8ms\n",
      "Speed: 1.7ms preprocess, 30.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/270.jpg: 384x640 1 knife, 32.4ms\n",
      "Speed: 1.9ms preprocess, 32.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/271.jpg: 384x640 (no detections), 26.0ms\n",
      "Speed: 1.7ms preprocess, 26.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/272.jpg: 384x640 1 clock, 46.4ms\n",
      "Speed: 1.7ms preprocess, 46.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/273.jpg: 384x640 (no detections), 24.5ms\n",
      "Speed: 1.6ms preprocess, 24.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/274.jpg: 384x640 1 bottle, 1 knife, 1 sink, 35.4ms\n",
      "Speed: 1.7ms preprocess, 35.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/275.jpg: 384x640 (no detections), 30.2ms\n",
      "Speed: 1.7ms preprocess, 30.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/276.jpg: 384x640 1 sink, 2 toothbrushs, 46.1ms\n",
      "Speed: 2.4ms preprocess, 46.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/277.jpg: 384x640 1 person, 1 bottle, 33.7ms\n",
      "Speed: 1.7ms preprocess, 33.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/278.jpg: 384x640 1 knife, 1 spoon, 24.5ms\n",
      "Speed: 1.7ms preprocess, 24.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/279.jpg: 384x640 1 motorcycle, 1 toothbrush, 24.2ms\n",
      "Speed: 1.7ms preprocess, 24.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/280.jpg: 384x640 (no detections), 29.5ms\n",
      "Speed: 2.3ms preprocess, 29.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/281.jpg: 384x640 1 sink, 24.0ms\n",
      "Speed: 1.8ms preprocess, 24.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/282.jpg: 384x640 2 spoons, 1 toothbrush, 27.7ms\n",
      "Speed: 1.4ms preprocess, 27.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/283.jpg: 384x640 2 spoons, 1 toothbrush, 32.5ms\n",
      "Speed: 1.7ms preprocess, 32.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/284.jpg: 384x640 (no detections), 34.0ms\n",
      "Speed: 1.7ms preprocess, 34.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/285.jpg: 384x640 (no detections), 44.2ms\n",
      "Speed: 3.1ms preprocess, 44.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/286.jpg: 384x640 2 spoons, 1 carrot, 27.4ms\n",
      "Speed: 1.8ms preprocess, 27.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/287.jpg: 384x640 (no detections), 33.6ms\n",
      "Speed: 2.0ms preprocess, 33.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/288.jpg: 384x640 1 fork, 28.0ms\n",
      "Speed: 2.2ms preprocess, 28.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/289.jpg: 384x640 (no detections), 29.2ms\n",
      "Speed: 1.8ms preprocess, 29.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/290.jpg: 384x640 2 knifes, 24.3ms\n",
      "Speed: 1.6ms preprocess, 24.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/291.jpg: 384x640 (no detections), 26.7ms\n",
      "Speed: 1.8ms preprocess, 26.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/292.jpg: 384x640 (no detections), 27.5ms\n",
      "Speed: 1.6ms preprocess, 27.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/293.jpg: 384x640 (no detections), 39.1ms\n",
      "Speed: 1.9ms preprocess, 39.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/294.jpg: 384x640 (no detections), 28.7ms\n",
      "Speed: 1.7ms preprocess, 28.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/295.jpg: 384x640 1 knife, 2 spoons, 25.1ms\n",
      "Speed: 1.7ms preprocess, 25.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/296.jpg: 384x640 2 spoons, 26.7ms\n",
      "Speed: 1.5ms preprocess, 26.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/297.jpg: 384x640 1 clock, 25.8ms\n",
      "Speed: 1.7ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/298.jpg: 384x640 (no detections), 45.6ms\n",
      "Speed: 2.1ms preprocess, 45.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/0/smoke/right/299.jpg: 384x640 1 baseball bat, 2 spoons, 1 toothbrush, 50.2ms\n",
      "Speed: 2.9ms preprocess, 50.2ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Propagating video frames: 100%|| 300/300 [00:17<00:00, 17.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask propagation completed in 17.04 seconds.\n",
      "Processing predicted masks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing video frames: 300it [00:00, 538.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 300 masks for evaluation.\n",
      "Masks saved to data/masks/yolo11x-seg/val/data-raw-SegSTRONGC_val-val-1-0-smoke-right.pkl\n",
      "Loading ground truth masks for evaluation...\n",
      "Loaded 300 ground truth masks.\n",
      "Calculating evaluation metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing domains: 100%|| 5/5 [04:07<00:00, 49.60s/it]\n",
      "Processing sub-directories:  67%|   | 2/3 [08:24<04:11, 251.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for metrics calculation: 1.34 seconds.\n",
      "Mean IoU for data/raw/SegSTRONGC_val/val/1/0/smoke/right: 0.2313\n",
      "Mean DSC for data/raw/SegSTRONGC_val/val/1/0/smoke/right: 0.2906\n",
      "Loading existing results file: data/results/yolo11x-seg/val.json\n",
      "Results saved to data/results/yolo11x-seg/val.json\n",
      "Processing video took 20.22 seconds.\n",
      "==================================================\n",
      "\n",
      "Results for data/raw/SegSTRONGC_val/val/1/0/smoke:\n",
      "  Left: IoU=0.1802, DSC=0.2290\n",
      "  Right: IoU=0.2313, DSC=0.2906\n",
      "  Overall: IoU=0.2058, DSC=0.2598\n",
      "\n",
      "------------------------------------------------------------\n",
      "Processing sub-directory: data/raw/SegSTRONGC_val/val/1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing domain: bg_change\n",
      "Processing left camera video...\n",
      "==================================================\n",
      "Processing video: data/raw/SegSTRONGC_val/val/1/1/bg_change/left\n",
      "Domain: bg_change, Split: val, Camera: left\n",
      "Initializing Yolo for video...\n",
      "Initialization took 0.19 seconds.\n",
      "Starting mask propagation...\n",
      "Total images in video: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/0.jpg: 384x640 2 knifes, 1 cake, 67.9ms\n",
      "Speed: 2.4ms preprocess, 67.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/1.jpg: 384x640 1 knife, 1 cake, 65.8ms\n",
      "Speed: 2.7ms preprocess, 65.8ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/2.jpg: 384x640 1 knife, 1 cake, 34.6ms\n",
      "Speed: 2.4ms preprocess, 34.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/3.jpg: 384x640 1 knife, 1 cake, 28.5ms\n",
      "Speed: 1.9ms preprocess, 28.5ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/4.jpg: 384x640 1 knife, 1 cake, 37.8ms\n",
      "Speed: 3.4ms preprocess, 37.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/5.jpg: 384x640 2 knifes, 1 cake, 29.2ms\n",
      "Speed: 2.2ms preprocess, 29.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/6.jpg: 384x640 2 knifes, 1 cake, 39.6ms\n",
      "Speed: 1.9ms preprocess, 39.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/7.jpg: 384x640 2 knifes, 1 cake, 25.6ms\n",
      "Speed: 1.5ms preprocess, 25.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/8.jpg: 384x640 1 knife, 1 cake, 23.7ms\n",
      "Speed: 1.8ms preprocess, 23.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/9.jpg: 384x640 1 cake, 28.9ms\n",
      "Speed: 1.6ms preprocess, 28.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/10.jpg: 384x640 1 cake, 34.8ms\n",
      "Speed: 1.6ms preprocess, 34.8ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/11.jpg: 384x640 1 knife, 1 spoon, 41.7ms\n",
      "Speed: 1.6ms preprocess, 41.7ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/12.jpg: 384x640 2 knifes, 1 cake, 28.8ms\n",
      "Speed: 1.5ms preprocess, 28.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/13.jpg: 384x640 1 knife, 1 cake, 41.3ms\n",
      "Speed: 1.7ms preprocess, 41.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/14.jpg: 384x640 1 knife, 1 cake, 42.8ms\n",
      "Speed: 1.7ms preprocess, 42.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/15.jpg: 384x640 1 knife, 1 cake, 28.4ms\n",
      "Speed: 1.5ms preprocess, 28.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/16.jpg: 384x640 1 knife, 1 cake, 33.6ms\n",
      "Speed: 2.5ms preprocess, 33.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/17.jpg: 384x640 1 knife, 1 cake, 41.8ms\n",
      "Speed: 1.9ms preprocess, 41.8ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/18.jpg: 384x640 1 knife, 1 cake, 28.5ms\n",
      "Speed: 1.9ms preprocess, 28.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/19.jpg: 384x640 1 fork, 1 spoon, 1 cake, 32.0ms\n",
      "Speed: 1.6ms preprocess, 32.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/20.jpg: 384x640 2 knifes, 1 cake, 33.1ms\n",
      "Speed: 3.5ms preprocess, 33.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/21.jpg: 384x640 1 knife, 1 cake, 49.1ms\n",
      "Speed: 2.6ms preprocess, 49.1ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/22.jpg: 384x640 1 cake, 33.4ms\n",
      "Speed: 2.0ms preprocess, 33.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/23.jpg: 384x640 1 knife, 1 cake, 27.7ms\n",
      "Speed: 1.6ms preprocess, 27.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/24.jpg: 384x640 2 knifes, 1 cake, 32.4ms\n",
      "Speed: 1.9ms preprocess, 32.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/25.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 37.8ms\n",
      "Speed: 1.8ms preprocess, 37.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/26.jpg: 384x640 2 knifes, 1 cake, 33.2ms\n",
      "Speed: 2.0ms preprocess, 33.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/27.jpg: 384x640 2 knifes, 1 cake, 28.2ms\n",
      "Speed: 1.6ms preprocess, 28.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/28.jpg: 384x640 2 knifes, 1 cake, 36.1ms\n",
      "Speed: 2.0ms preprocess, 36.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/29.jpg: 384x640 2 knifes, 1 cake, 28.2ms\n",
      "Speed: 1.6ms preprocess, 28.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/30.jpg: 384x640 2 knifes, 1 cake, 27.7ms\n",
      "Speed: 1.9ms preprocess, 27.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/31.jpg: 384x640 1 knife, 1 cake, 25.4ms\n",
      "Speed: 1.6ms preprocess, 25.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/32.jpg: 384x640 2 knifes, 1 cake, 35.8ms\n",
      "Speed: 2.8ms preprocess, 35.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/33.jpg: 384x640 2 knifes, 1 cake, 27.5ms\n",
      "Speed: 1.7ms preprocess, 27.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/34.jpg: 384x640 2 knifes, 1 cake, 34.8ms\n",
      "Speed: 1.9ms preprocess, 34.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/35.jpg: 384x640 2 knifes, 1 cake, 31.9ms\n",
      "Speed: 3.8ms preprocess, 31.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/36.jpg: 384x640 2 knifes, 1 cake, 29.9ms\n",
      "Speed: 1.7ms preprocess, 29.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/37.jpg: 384x640 1 knife, 1 cake, 64.2ms\n",
      "Speed: 2.0ms preprocess, 64.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/38.jpg: 384x640 2 knifes, 1 cake, 32.1ms\n",
      "Speed: 2.0ms preprocess, 32.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/39.jpg: 384x640 2 knifes, 1 cake, 22.4ms\n",
      "Speed: 1.5ms preprocess, 22.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/40.jpg: 384x640 2 knifes, 1 cake, 25.6ms\n",
      "Speed: 1.9ms preprocess, 25.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/41.jpg: 384x640 2 knifes, 1 cake, 25.1ms\n",
      "Speed: 1.5ms preprocess, 25.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/42.jpg: 384x640 2 knifes, 1 cake, 24.9ms\n",
      "Speed: 1.6ms preprocess, 24.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/43.jpg: 384x640 2 knifes, 1 cake, 23.4ms\n",
      "Speed: 1.7ms preprocess, 23.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/44.jpg: 384x640 2 knifes, 1 cake, 27.9ms\n",
      "Speed: 1.6ms preprocess, 27.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/45.jpg: 384x640 1 knife, 1 cake, 28.4ms\n",
      "Speed: 1.9ms preprocess, 28.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/46.jpg: 384x640 1 knife, 1 cake, 34.3ms\n",
      "Speed: 1.9ms preprocess, 34.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/47.jpg: 384x640 2 knifes, 1 cake, 38.5ms\n",
      "Speed: 1.8ms preprocess, 38.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/48.jpg: 384x640 1 knife, 1 cake, 31.2ms\n",
      "Speed: 1.8ms preprocess, 31.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/49.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 28.2ms\n",
      "Speed: 1.6ms preprocess, 28.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/50.jpg: 384x640 2 bottles, 1 knife, 1 cake, 25.7ms\n",
      "Speed: 1.6ms preprocess, 25.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/51.jpg: 384x640 1 knife, 1 cake, 45.2ms\n",
      "Speed: 1.9ms preprocess, 45.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/52.jpg: 384x640 1 knife, 1 cake, 41.3ms\n",
      "Speed: 1.8ms preprocess, 41.3ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/53.jpg: 384x640 1 knife, 1 cake, 47.3ms\n",
      "Speed: 3.2ms preprocess, 47.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/54.jpg: 384x640 1 knife, 1 pizza, 1 cake, 30.6ms\n",
      "Speed: 2.6ms preprocess, 30.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/55.jpg: 384x640 1 bottle, 1 cake, 35.1ms\n",
      "Speed: 1.5ms preprocess, 35.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/56.jpg: 384x640 1 knife, 1 cake, 29.4ms\n",
      "Speed: 2.4ms preprocess, 29.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/57.jpg: 384x640 1 cake, 31.0ms\n",
      "Speed: 1.7ms preprocess, 31.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/58.jpg: 384x640 1 knife, 1 pizza, 1 cake, 35.6ms\n",
      "Speed: 2.7ms preprocess, 35.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/59.jpg: 384x640 1 knife, 1 pizza, 23.1ms\n",
      "Speed: 1.6ms preprocess, 23.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/60.jpg: 384x640 1 knife, 1 cake, 33.5ms\n",
      "Speed: 1.7ms preprocess, 33.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/61.jpg: 384x640 1 knife, 1 cake, 32.6ms\n",
      "Speed: 1.7ms preprocess, 32.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/62.jpg: 384x640 1 knife, 68.0ms\n",
      "Speed: 1.9ms preprocess, 68.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/63.jpg: 384x640 2 knifes, 1 cake, 29.8ms\n",
      "Speed: 1.7ms preprocess, 29.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/64.jpg: 384x640 2 knifes, 29.4ms\n",
      "Speed: 1.7ms preprocess, 29.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/65.jpg: 384x640 1 knife, 1 cake, 31.6ms\n",
      "Speed: 1.8ms preprocess, 31.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/66.jpg: 384x640 1 knife, 1 cake, 46.4ms\n",
      "Speed: 1.6ms preprocess, 46.4ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/67.jpg: 384x640 2 knifes, 1 cake, 36.9ms\n",
      "Speed: 2.0ms preprocess, 36.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/68.jpg: 384x640 1 knife, 1 cake, 23.7ms\n",
      "Speed: 1.5ms preprocess, 23.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/69.jpg: 384x640 1 knife, 1 cake, 31.0ms\n",
      "Speed: 2.2ms preprocess, 31.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/70.jpg: 384x640 2 knifes, 1 cake, 30.7ms\n",
      "Speed: 1.7ms preprocess, 30.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/71.jpg: 384x640 1 knife, 1 cake, 39.0ms\n",
      "Speed: 1.7ms preprocess, 39.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/72.jpg: 384x640 1 knife, 1 cake, 40.9ms\n",
      "Speed: 1.8ms preprocess, 40.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/73.jpg: 384x640 2 knifes, 1 cake, 39.0ms\n",
      "Speed: 2.7ms preprocess, 39.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/74.jpg: 384x640 1 knife, 1 cake, 26.3ms\n",
      "Speed: 1.4ms preprocess, 26.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/75.jpg: 384x640 2 knifes, 1 cake, 30.0ms\n",
      "Speed: 1.7ms preprocess, 30.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/76.jpg: 384x640 1 knife, 1 cake, 48.4ms\n",
      "Speed: 3.0ms preprocess, 48.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/77.jpg: 384x640 2 knifes, 1 cake, 30.8ms\n",
      "Speed: 1.8ms preprocess, 30.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/78.jpg: 384x640 1 knife, 41.2ms\n",
      "Speed: 3.0ms preprocess, 41.2ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/79.jpg: 384x640 1 knife, 25.6ms\n",
      "Speed: 2.5ms preprocess, 25.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/80.jpg: 384x640 1 knife, 26.6ms\n",
      "Speed: 2.0ms preprocess, 26.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/81.jpg: 384x640 1 knife, 41.7ms\n",
      "Speed: 3.3ms preprocess, 41.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/82.jpg: 384x640 1 knife, 28.4ms\n",
      "Speed: 4.4ms preprocess, 28.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/83.jpg: 384x640 2 knifes, 27.6ms\n",
      "Speed: 1.6ms preprocess, 27.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/84.jpg: 384x640 2 knifes, 30.7ms\n",
      "Speed: 1.7ms preprocess, 30.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/85.jpg: 384x640 2 knifes, 1 cake, 24.7ms\n",
      "Speed: 1.9ms preprocess, 24.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/86.jpg: 384x640 2 knifes, 1 cake, 27.1ms\n",
      "Speed: 1.6ms preprocess, 27.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/87.jpg: 384x640 1 knife, 29.4ms\n",
      "Speed: 3.1ms preprocess, 29.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/88.jpg: 384x640 2 knifes, 48.5ms\n",
      "Speed: 1.9ms preprocess, 48.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/89.jpg: 384x640 1 knife, 22.7ms\n",
      "Speed: 1.6ms preprocess, 22.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/90.jpg: 384x640 1 knife, 1 pizza, 30.6ms\n",
      "Speed: 1.7ms preprocess, 30.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/91.jpg: 384x640 2 knifes, 1 pizza, 23.8ms\n",
      "Speed: 1.4ms preprocess, 23.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/92.jpg: 384x640 2 knifes, 1 pizza, 25.4ms\n",
      "Speed: 1.7ms preprocess, 25.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/93.jpg: 384x640 1 knife, 1 pizza, 32.4ms\n",
      "Speed: 2.9ms preprocess, 32.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/94.jpg: 384x640 (no detections), 25.5ms\n",
      "Speed: 1.8ms preprocess, 25.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/95.jpg: 384x640 1 knife, 52.8ms\n",
      "Speed: 2.0ms preprocess, 52.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/96.jpg: 384x640 1 fork, 1 knife, 23.2ms\n",
      "Speed: 2.4ms preprocess, 23.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/97.jpg: 384x640 1 knife, 40.0ms\n",
      "Speed: 1.7ms preprocess, 40.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/98.jpg: 384x640 1 fork, 1 knife, 24.4ms\n",
      "Speed: 1.7ms preprocess, 24.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/99.jpg: 384x640 1 fork, 1 knife, 43.5ms\n",
      "Speed: 2.3ms preprocess, 43.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/100.jpg: 384x640 1 fork, 1 knife, 49.2ms\n",
      "Speed: 1.6ms preprocess, 49.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/101.jpg: 384x640 1 knife, 33.3ms\n",
      "Speed: 1.6ms preprocess, 33.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/102.jpg: 384x640 1 knife, 23.1ms\n",
      "Speed: 1.6ms preprocess, 23.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/103.jpg: 384x640 1 knife, 1 cake, 30.0ms\n",
      "Speed: 1.5ms preprocess, 30.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/104.jpg: 384x640 1 knife, 1 cake, 43.0ms\n",
      "Speed: 2.0ms preprocess, 43.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/105.jpg: 384x640 1 knife, 1 cake, 26.0ms\n",
      "Speed: 1.6ms preprocess, 26.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/106.jpg: 384x640 1 bottle, 1 knife, 1 cake, 46.4ms\n",
      "Speed: 1.7ms preprocess, 46.4ms inference, 8.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/107.jpg: 384x640 2 knifes, 1 cake, 36.4ms\n",
      "Speed: 1.9ms preprocess, 36.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/108.jpg: 384x640 1 knife, 1 cake, 29.2ms\n",
      "Speed: 3.0ms preprocess, 29.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/109.jpg: 384x640 1 knife, 1 cake, 24.9ms\n",
      "Speed: 2.0ms preprocess, 24.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/110.jpg: 384x640 1 knife, 1 cake, 29.9ms\n",
      "Speed: 1.8ms preprocess, 29.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/111.jpg: 384x640 1 knife, 1 cake, 35.1ms\n",
      "Speed: 2.4ms preprocess, 35.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/112.jpg: 384x640 1 fork, 1 knife, 1 cake, 33.3ms\n",
      "Speed: 1.7ms preprocess, 33.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/113.jpg: 384x640 1 fork, 1 knife, 1 cake, 25.2ms\n",
      "Speed: 1.6ms preprocess, 25.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/114.jpg: 384x640 1 knife, 1 cake, 42.2ms\n",
      "Speed: 2.0ms preprocess, 42.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/115.jpg: 384x640 1 knife, 1 pizza, 1 cake, 33.2ms\n",
      "Speed: 1.8ms preprocess, 33.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/116.jpg: 384x640 1 knife, 1 cake, 22.8ms\n",
      "Speed: 1.5ms preprocess, 22.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/117.jpg: 384x640 1 knife, 1 cake, 26.1ms\n",
      "Speed: 1.6ms preprocess, 26.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/118.jpg: 384x640 1 fork, 2 knifes, 1 cake, 26.5ms\n",
      "Speed: 1.9ms preprocess, 26.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/119.jpg: 384x640 1 knife, 1 cake, 38.7ms\n",
      "Speed: 1.9ms preprocess, 38.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/120.jpg: 384x640 1 fork, 1 knife, 1 cake, 31.5ms\n",
      "Speed: 1.6ms preprocess, 31.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/121.jpg: 384x640 1 knife, 1 pizza, 1 cake, 22.8ms\n",
      "Speed: 1.3ms preprocess, 22.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/122.jpg: 384x640 1 knife, 1 cake, 29.4ms\n",
      "Speed: 1.9ms preprocess, 29.4ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/123.jpg: 384x640 1 fork, 1 knife, 1 cake, 23.2ms\n",
      "Speed: 2.5ms preprocess, 23.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/124.jpg: 384x640 1 knife, 1 cake, 42.2ms\n",
      "Speed: 1.8ms preprocess, 42.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/125.jpg: 384x640 1 fork, 1 cake, 48.4ms\n",
      "Speed: 2.8ms preprocess, 48.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/126.jpg: 384x640 1 fork, 1 knife, 1 spoon, 67.9ms\n",
      "Speed: 3.3ms preprocess, 67.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/127.jpg: 384x640 1 fork, 1 spoon, 1 pizza, 25.3ms\n",
      "Speed: 1.6ms preprocess, 25.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/128.jpg: 384x640 1 fork, 1 knife, 25.6ms\n",
      "Speed: 1.7ms preprocess, 25.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/129.jpg: 384x640 1 fork, 37.4ms\n",
      "Speed: 1.7ms preprocess, 37.4ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/130.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 31.0ms\n",
      "Speed: 1.9ms preprocess, 31.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/131.jpg: 384x640 1 bottle, 1 knife, 1 cake, 29.0ms\n",
      "Speed: 2.2ms preprocess, 29.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/132.jpg: 384x640 1 knife, 1 pizza, 1 cake, 27.8ms\n",
      "Speed: 1.7ms preprocess, 27.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/133.jpg: 384x640 1 knife, 1 cake, 34.3ms\n",
      "Speed: 1.6ms preprocess, 34.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/134.jpg: 384x640 1 fork, 1 cake, 32.4ms\n",
      "Speed: 1.8ms preprocess, 32.4ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/135.jpg: 384x640 1 cake, 31.6ms\n",
      "Speed: 1.8ms preprocess, 31.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/136.jpg: 384x640 1 cake, 27.3ms\n",
      "Speed: 2.0ms preprocess, 27.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/137.jpg: 384x640 1 fork, 1 knife, 1 cake, 27.9ms\n",
      "Speed: 3.1ms preprocess, 27.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/138.jpg: 384x640 1 knife, 1 cake, 26.1ms\n",
      "Speed: 1.6ms preprocess, 26.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/139.jpg: 384x640 1 knife, 1 cake, 36.3ms\n",
      "Speed: 1.6ms preprocess, 36.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/140.jpg: 384x640 1 knife, 1 cake, 36.7ms\n",
      "Speed: 2.0ms preprocess, 36.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/141.jpg: 384x640 2 bottles, 1 cake, 24.8ms\n",
      "Speed: 2.4ms preprocess, 24.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/142.jpg: 384x640 1 knife, 39.3ms\n",
      "Speed: 1.8ms preprocess, 39.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/143.jpg: 384x640 1 knife, 43.3ms\n",
      "Speed: 2.5ms preprocess, 43.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/144.jpg: 384x640 2 knifes, 1 cake, 29.8ms\n",
      "Speed: 1.8ms preprocess, 29.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/145.jpg: 384x640 1 knife, 36.8ms\n",
      "Speed: 1.9ms preprocess, 36.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/146.jpg: 384x640 1 knife, 1 pizza, 1 cake, 29.6ms\n",
      "Speed: 1.9ms preprocess, 29.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/147.jpg: 384x640 2 knifes, 1 cake, 34.3ms\n",
      "Speed: 1.6ms preprocess, 34.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/148.jpg: 384x640 2 knifes, 1 cake, 31.7ms\n",
      "Speed: 1.6ms preprocess, 31.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/149.jpg: 384x640 2 knifes, 1 cake, 41.8ms\n",
      "Speed: 3.0ms preprocess, 41.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/150.jpg: 384x640 2 knifes, 1 cake, 24.9ms\n",
      "Speed: 1.8ms preprocess, 24.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/151.jpg: 384x640 2 knifes, 1 cake, 38.2ms\n",
      "Speed: 3.0ms preprocess, 38.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/152.jpg: 384x640 2 knifes, 1 cake, 48.8ms\n",
      "Speed: 1.9ms preprocess, 48.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/153.jpg: 384x640 2 knifes, 1 cake, 35.2ms\n",
      "Speed: 1.9ms preprocess, 35.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/154.jpg: 384x640 2 knifes, 1 cake, 30.5ms\n",
      "Speed: 2.4ms preprocess, 30.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/155.jpg: 384x640 1 knife, 1 cake, 23.2ms\n",
      "Speed: 1.5ms preprocess, 23.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/156.jpg: 384x640 2 knifes, 1 cake, 34.3ms\n",
      "Speed: 1.6ms preprocess, 34.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/157.jpg: 384x640 2 knifes, 1 cake, 35.2ms\n",
      "Speed: 2.0ms preprocess, 35.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/158.jpg: 384x640 2 knifes, 1 cake, 26.1ms\n",
      "Speed: 1.6ms preprocess, 26.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/159.jpg: 384x640 2 knifes, 1 cake, 34.1ms\n",
      "Speed: 1.6ms preprocess, 34.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/160.jpg: 384x640 1 knife, 1 cake, 48.3ms\n",
      "Speed: 1.9ms preprocess, 48.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/161.jpg: 384x640 1 knife, 1 cake, 35.0ms\n",
      "Speed: 1.7ms preprocess, 35.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/162.jpg: 384x640 1 knife, 1 cake, 28.9ms\n",
      "Speed: 1.6ms preprocess, 28.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/163.jpg: 384x640 1 knife, 1 pizza, 1 cake, 26.0ms\n",
      "Speed: 2.4ms preprocess, 26.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/164.jpg: 384x640 1 knife, 1 pizza, 1 cake, 24.1ms\n",
      "Speed: 1.7ms preprocess, 24.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/165.jpg: 384x640 1 knife, 1 pizza, 1 cake, 52.0ms\n",
      "Speed: 2.8ms preprocess, 52.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/166.jpg: 384x640 1 knife, 1 pizza, 1 cake, 34.8ms\n",
      "Speed: 1.6ms preprocess, 34.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/167.jpg: 384x640 1 knife, 1 cake, 45.2ms\n",
      "Speed: 1.7ms preprocess, 45.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/168.jpg: 384x640 1 knife, 1 cake, 33.8ms\n",
      "Speed: 1.7ms preprocess, 33.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/169.jpg: 384x640 1 knife, 1 cake, 49.3ms\n",
      "Speed: 1.8ms preprocess, 49.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/170.jpg: 384x640 1 knife, 1 cake, 49.3ms\n",
      "Speed: 1.9ms preprocess, 49.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/171.jpg: 384x640 1 knife, 1 pizza, 1 cake, 31.3ms\n",
      "Speed: 1.6ms preprocess, 31.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/172.jpg: 384x640 1 knife, 1 cake, 38.8ms\n",
      "Speed: 2.0ms preprocess, 38.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/173.jpg: 384x640 1 fork, 1 knife, 1 cake, 35.4ms\n",
      "Speed: 1.5ms preprocess, 35.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/174.jpg: 384x640 1 knife, 1 cake, 36.8ms\n",
      "Speed: 1.6ms preprocess, 36.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/175.jpg: 384x640 1 knife, 1 cake, 27.0ms\n",
      "Speed: 1.6ms preprocess, 27.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/176.jpg: 384x640 1 knife, 1 pizza, 1 cake, 35.0ms\n",
      "Speed: 2.8ms preprocess, 35.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/177.jpg: 384x640 1 knife, 1 cake, 24.5ms\n",
      "Speed: 1.8ms preprocess, 24.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/178.jpg: 384x640 1 fork, 1 knife, 1 cake, 59.1ms\n",
      "Speed: 2.1ms preprocess, 59.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/179.jpg: 384x640 1 knife, 1 cake, 30.2ms\n",
      "Speed: 2.1ms preprocess, 30.2ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/180.jpg: 384x640 1 knife, 1 cake, 25.0ms\n",
      "Speed: 1.6ms preprocess, 25.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/181.jpg: 384x640 1 knife, 1 cake, 29.1ms\n",
      "Speed: 1.7ms preprocess, 29.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/182.jpg: 384x640 1 knife, 1 cake, 29.1ms\n",
      "Speed: 2.0ms preprocess, 29.1ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/183.jpg: 384x640 1 fork, 1 knife, 1 cake, 24.1ms\n",
      "Speed: 1.5ms preprocess, 24.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/184.jpg: 384x640 1 knife, 1 cake, 30.8ms\n",
      "Speed: 1.7ms preprocess, 30.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/185.jpg: 384x640 1 knife, 1 cake, 25.2ms\n",
      "Speed: 1.7ms preprocess, 25.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/186.jpg: 384x640 1 knife, 1 cake, 36.1ms\n",
      "Speed: 1.7ms preprocess, 36.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/187.jpg: 384x640 1 knife, 1 cake, 29.6ms\n",
      "Speed: 2.4ms preprocess, 29.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/188.jpg: 384x640 1 cake, 42.7ms\n",
      "Speed: 2.0ms preprocess, 42.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/189.jpg: 384x640 1 knife, 1 cake, 26.4ms\n",
      "Speed: 1.9ms preprocess, 26.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/190.jpg: 384x640 1 knife, 1 cake, 32.6ms\n",
      "Speed: 2.3ms preprocess, 32.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/191.jpg: 384x640 1 knife, 1 cake, 28.4ms\n",
      "Speed: 2.0ms preprocess, 28.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/192.jpg: 384x640 1 knife, 1 cake, 27.6ms\n",
      "Speed: 1.6ms preprocess, 27.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/193.jpg: 384x640 1 knife, 1 cake, 47.6ms\n",
      "Speed: 1.8ms preprocess, 47.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/194.jpg: 384x640 1 knife, 1 cake, 27.1ms\n",
      "Speed: 1.7ms preprocess, 27.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/195.jpg: 384x640 1 knife, 1 cake, 26.1ms\n",
      "Speed: 1.5ms preprocess, 26.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/196.jpg: 384x640 1 knife, 1 cake, 25.4ms\n",
      "Speed: 1.6ms preprocess, 25.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/197.jpg: 384x640 1 knife, 1 cake, 51.7ms\n",
      "Speed: 3.0ms preprocess, 51.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/198.jpg: 384x640 1 knife, 1 cake, 32.1ms\n",
      "Speed: 1.7ms preprocess, 32.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/199.jpg: 384x640 1 knife, 1 cake, 24.2ms\n",
      "Speed: 1.5ms preprocess, 24.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/200.jpg: 384x640 2 knifes, 1 cake, 35.1ms\n",
      "Speed: 2.5ms preprocess, 35.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/201.jpg: 384x640 2 knifes, 1 cake, 31.3ms\n",
      "Speed: 3.0ms preprocess, 31.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/202.jpg: 384x640 2 knifes, 1 cake, 25.5ms\n",
      "Speed: 1.6ms preprocess, 25.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/203.jpg: 384x640 2 knifes, 1 cake, 25.7ms\n",
      "Speed: 2.1ms preprocess, 25.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/204.jpg: 384x640 2 knifes, 1 cake, 29.9ms\n",
      "Speed: 1.5ms preprocess, 29.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/205.jpg: 384x640 2 knifes, 1 cake, 27.9ms\n",
      "Speed: 2.2ms preprocess, 27.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/206.jpg: 384x640 2 knifes, 1 cake, 36.7ms\n",
      "Speed: 1.8ms preprocess, 36.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/207.jpg: 384x640 2 knifes, 1 cake, 33.1ms\n",
      "Speed: 1.7ms preprocess, 33.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/208.jpg: 384x640 2 knifes, 1 cake, 34.5ms\n",
      "Speed: 1.7ms preprocess, 34.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/209.jpg: 384x640 2 knifes, 1 cake, 24.3ms\n",
      "Speed: 1.5ms preprocess, 24.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/210.jpg: 384x640 2 knifes, 1 cake, 25.5ms\n",
      "Speed: 1.7ms preprocess, 25.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/211.jpg: 384x640 2 knifes, 1 cake, 41.6ms\n",
      "Speed: 1.8ms preprocess, 41.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/212.jpg: 384x640 2 knifes, 1 cake, 39.8ms\n",
      "Speed: 1.9ms preprocess, 39.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/213.jpg: 384x640 2 knifes, 1 cake, 27.4ms\n",
      "Speed: 1.9ms preprocess, 27.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/214.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 27.7ms\n",
      "Speed: 2.0ms preprocess, 27.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/215.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 23.4ms\n",
      "Speed: 1.6ms preprocess, 23.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/216.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 47.3ms\n",
      "Speed: 2.3ms preprocess, 47.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/217.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 23.8ms\n",
      "Speed: 1.7ms preprocess, 23.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/218.jpg: 384x640 2 knifes, 1 pizza, 44.8ms\n",
      "Speed: 2.0ms preprocess, 44.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/219.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 53.6ms\n",
      "Speed: 2.0ms preprocess, 53.6ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/220.jpg: 384x640 1 knife, 1 pizza, 22.9ms\n",
      "Speed: 1.7ms preprocess, 22.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/221.jpg: 384x640 2 knifes, 1 pizza, 24.4ms\n",
      "Speed: 1.9ms preprocess, 24.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/222.jpg: 384x640 1 knife, 1 pizza, 27.3ms\n",
      "Speed: 1.7ms preprocess, 27.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/223.jpg: 384x640 1 knife, 1 cake, 23.6ms\n",
      "Speed: 1.7ms preprocess, 23.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/224.jpg: 384x640 1 knife, 1 cake, 30.6ms\n",
      "Speed: 2.0ms preprocess, 30.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/225.jpg: 384x640 1 knife, 1 cake, 25.6ms\n",
      "Speed: 1.8ms preprocess, 25.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/226.jpg: 384x640 1 knife, 1 pizza, 34.9ms\n",
      "Speed: 1.7ms preprocess, 34.9ms inference, 8.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/227.jpg: 384x640 1 knife, 1 cake, 27.2ms\n",
      "Speed: 2.9ms preprocess, 27.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/228.jpg: 384x640 1 knife, 1 cake, 45.9ms\n",
      "Speed: 1.8ms preprocess, 45.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/229.jpg: 384x640 2 knifes, 1 cake, 27.7ms\n",
      "Speed: 1.8ms preprocess, 27.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/230.jpg: 384x640 1 knife, 1 cake, 38.5ms\n",
      "Speed: 1.8ms preprocess, 38.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/231.jpg: 384x640 2 knifes, 1 cake, 25.1ms\n",
      "Speed: 1.6ms preprocess, 25.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/232.jpg: 384x640 2 knifes, 1 pizza, 35.5ms\n",
      "Speed: 1.9ms preprocess, 35.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/233.jpg: 384x640 1 fork, 1 knife, 1 spoon, 30.4ms\n",
      "Speed: 1.6ms preprocess, 30.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/234.jpg: 384x640 1 knife, 1 spoon, 1 cake, 36.3ms\n",
      "Speed: 1.6ms preprocess, 36.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/235.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 40.2ms\n",
      "Speed: 1.8ms preprocess, 40.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/236.jpg: 384x640 1 knife, 1 cake, 22.7ms\n",
      "Speed: 2.2ms preprocess, 22.7ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/237.jpg: 384x640 1 cake, 24.4ms\n",
      "Speed: 1.7ms preprocess, 24.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/238.jpg: 384x640 1 knife, 1 cake, 39.7ms\n",
      "Speed: 2.1ms preprocess, 39.7ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/239.jpg: 384x640 1 knife, 1 cake, 27.0ms\n",
      "Speed: 1.8ms preprocess, 27.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/240.jpg: 384x640 1 knife, 1 cake, 38.8ms\n",
      "Speed: 1.8ms preprocess, 38.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/241.jpg: 384x640 1 knife, 1 cake, 33.7ms\n",
      "Speed: 2.0ms preprocess, 33.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/242.jpg: 384x640 1 knife, 1 cake, 42.8ms\n",
      "Speed: 3.1ms preprocess, 42.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/243.jpg: 384x640 1 knife, 1 cake, 31.9ms\n",
      "Speed: 2.0ms preprocess, 31.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/244.jpg: 384x640 1 knife, 1 cake, 25.4ms\n",
      "Speed: 1.6ms preprocess, 25.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/245.jpg: 384x640 1 knife, 1 cake, 35.4ms\n",
      "Speed: 2.2ms preprocess, 35.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/246.jpg: 384x640 1 knife, 1 pizza, 1 cake, 56.3ms\n",
      "Speed: 1.7ms preprocess, 56.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/247.jpg: 384x640 1 knife, 1 cake, 23.4ms\n",
      "Speed: 1.6ms preprocess, 23.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/248.jpg: 384x640 1 knife, 1 cake, 40.9ms\n",
      "Speed: 1.8ms preprocess, 40.9ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/249.jpg: 384x640 1 knife, 1 cake, 52.9ms\n",
      "Speed: 1.8ms preprocess, 52.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/250.jpg: 384x640 1 knife, 31.8ms\n",
      "Speed: 1.9ms preprocess, 31.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/251.jpg: 384x640 1 knife, 1 cake, 28.0ms\n",
      "Speed: 1.8ms preprocess, 28.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/252.jpg: 384x640 1 knife, 1 cake, 24.2ms\n",
      "Speed: 1.8ms preprocess, 24.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/253.jpg: 384x640 1 knife, 34.8ms\n",
      "Speed: 1.7ms preprocess, 34.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/254.jpg: 384x640 1 knife, 28.3ms\n",
      "Speed: 1.5ms preprocess, 28.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/255.jpg: 384x640 1 knife, 1 pizza, 23.9ms\n",
      "Speed: 2.1ms preprocess, 23.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/256.jpg: 384x640 1 knife, 1 pizza, 1 cake, 45.4ms\n",
      "Speed: 1.7ms preprocess, 45.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/257.jpg: 384x640 1 knife, 1 cake, 24.8ms\n",
      "Speed: 1.7ms preprocess, 24.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/258.jpg: 384x640 1 knife, 1 cake, 44.1ms\n",
      "Speed: 1.9ms preprocess, 44.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/259.jpg: 384x640 1 knife, 55.5ms\n",
      "Speed: 1.8ms preprocess, 55.5ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/260.jpg: 384x640 2 knifes, 1 cake, 26.7ms\n",
      "Speed: 2.4ms preprocess, 26.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/261.jpg: 384x640 1 knife, 1 cake, 32.6ms\n",
      "Speed: 2.6ms preprocess, 32.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/262.jpg: 384x640 1 knife, 1 cake, 51.4ms\n",
      "Speed: 2.0ms preprocess, 51.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/263.jpg: 384x640 1 knife, 1 cake, 27.4ms\n",
      "Speed: 1.7ms preprocess, 27.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/264.jpg: 384x640 1 knife, 35.8ms\n",
      "Speed: 2.3ms preprocess, 35.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/265.jpg: 384x640 1 knife, 1 cake, 24.2ms\n",
      "Speed: 1.7ms preprocess, 24.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/266.jpg: 384x640 1 knife, 23.1ms\n",
      "Speed: 1.5ms preprocess, 23.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/267.jpg: 384x640 2 knifes, 1 cake, 23.7ms\n",
      "Speed: 1.6ms preprocess, 23.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/268.jpg: 384x640 2 knifes, 1 cake, 45.4ms\n",
      "Speed: 1.6ms preprocess, 45.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/269.jpg: 384x640 1 knife, 1 cake, 28.0ms\n",
      "Speed: 1.7ms preprocess, 28.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/270.jpg: 384x640 1 knife, 27.7ms\n",
      "Speed: 1.7ms preprocess, 27.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/271.jpg: 384x640 1 knife, 1 pizza, 25.7ms\n",
      "Speed: 1.7ms preprocess, 25.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/272.jpg: 384x640 1 knife, 34.6ms\n",
      "Speed: 3.1ms preprocess, 34.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/273.jpg: 384x640 1 knife, 1 pizza, 22.4ms\n",
      "Speed: 1.7ms preprocess, 22.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/274.jpg: 384x640 1 knife, 1 cake, 43.4ms\n",
      "Speed: 1.9ms preprocess, 43.4ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/275.jpg: 384x640 1 knife, 1 cake, 38.5ms\n",
      "Speed: 3.7ms preprocess, 38.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/276.jpg: 384x640 1 knife, 1 pizza, 22.9ms\n",
      "Speed: 1.5ms preprocess, 22.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/277.jpg: 384x640 1 knife, 1 cake, 22.5ms\n",
      "Speed: 1.5ms preprocess, 22.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/278.jpg: 384x640 1 knife, 25.3ms\n",
      "Speed: 1.6ms preprocess, 25.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/279.jpg: 384x640 1 knife, 1 pizza, 22.7ms\n",
      "Speed: 2.2ms preprocess, 22.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/280.jpg: 384x640 1 knife, 1 cake, 26.1ms\n",
      "Speed: 1.6ms preprocess, 26.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/281.jpg: 384x640 1 knife, 1 cake, 23.6ms\n",
      "Speed: 2.6ms preprocess, 23.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/282.jpg: 384x640 1 knife, 1 cake, 23.4ms\n",
      "Speed: 3.2ms preprocess, 23.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/283.jpg: 384x640 1 knife, 1 cake, 27.9ms\n",
      "Speed: 1.5ms preprocess, 27.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/284.jpg: 384x640 2 knifes, 1 cake, 29.9ms\n",
      "Speed: 2.2ms preprocess, 29.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/285.jpg: 384x640 1 knife, 1 spoon, 25.8ms\n",
      "Speed: 1.9ms preprocess, 25.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/286.jpg: 384x640 1 fork, 1 knife, 1 spoon, 50.2ms\n",
      "Speed: 2.6ms preprocess, 50.2ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/287.jpg: 384x640 1 knife, 1 spoon, 1 cake, 24.1ms\n",
      "Speed: 1.6ms preprocess, 24.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/288.jpg: 384x640 1 knife, 1 cake, 29.8ms\n",
      "Speed: 1.7ms preprocess, 29.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/289.jpg: 384x640 2 knifes, 1 cake, 23.9ms\n",
      "Speed: 1.6ms preprocess, 23.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/290.jpg: 384x640 2 knifes, 1 cake, 35.3ms\n",
      "Speed: 1.8ms preprocess, 35.3ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/291.jpg: 384x640 2 knifes, 1 cake, 28.3ms\n",
      "Speed: 2.3ms preprocess, 28.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/292.jpg: 384x640 1 knife, 1 pizza, 1 cake, 24.6ms\n",
      "Speed: 2.5ms preprocess, 24.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/293.jpg: 384x640 2 knifes, 1 cake, 31.2ms\n",
      "Speed: 1.8ms preprocess, 31.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/294.jpg: 384x640 2 knifes, 1 cake, 26.3ms\n",
      "Speed: 2.0ms preprocess, 26.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/295.jpg: 384x640 2 knifes, 1 cake, 42.6ms\n",
      "Speed: 2.6ms preprocess, 42.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/296.jpg: 384x640 1 knife, 1 cake, 44.2ms\n",
      "Speed: 2.7ms preprocess, 44.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/297.jpg: 384x640 1 knife, 1 cake, 35.7ms\n",
      "Speed: 2.1ms preprocess, 35.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/298.jpg: 384x640 1 knife, 1 cake, 56.3ms\n",
      "Speed: 1.7ms preprocess, 56.3ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/left/299.jpg: 384x640 1 knife, 1 cake, 42.2ms\n",
      "Speed: 1.9ms preprocess, 42.2ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Propagating video frames: 100%|| 300/300 [00:18<00:00, 16.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask propagation completed in 18.53 seconds.\n",
      "Processing predicted masks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing video frames: 300it [00:01, 181.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 300 masks for evaluation.\n",
      "Masks saved to data/masks/yolo11x-seg/val/data-raw-SegSTRONGC_val-val-1-1-bg_change-left.pkl\n",
      "Loading ground truth masks for evaluation...\n",
      "Loaded 300 ground truth masks.\n",
      "Calculating evaluation metrics...\n",
      "Time taken for metrics calculation: 1.46 seconds.\n",
      "Mean IoU for data/raw/SegSTRONGC_val/val/1/1/bg_change/left: 0.1956\n",
      "Mean DSC for data/raw/SegSTRONGC_val/val/1/1/bg_change/left: 0.2985\n",
      "Loading existing results file: data/results/yolo11x-seg/val.json\n",
      "Results saved to data/results/yolo11x-seg/val.json\n",
      "Processing video took 23.06 seconds.\n",
      "==================================================\n",
      "Processing right camera video...\n",
      "==================================================\n",
      "Processing video: data/raw/SegSTRONGC_val/val/1/1/bg_change/right\n",
      "Domain: bg_change, Split: val, Camera: right\n",
      "Initializing Yolo for video...\n",
      "Initialization took 0.12 seconds.\n",
      "Starting mask propagation...\n",
      "Total images in video: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/0.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 72.1ms\n",
      "Speed: 2.3ms preprocess, 72.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/1.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 27.6ms\n",
      "Speed: 1.6ms preprocess, 27.6ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/2.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 44.5ms\n",
      "Speed: 1.8ms preprocess, 44.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/3.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 49.8ms\n",
      "Speed: 1.8ms preprocess, 49.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/4.jpg: 384x640 2 knifes, 1 pizza, 40.4ms\n",
      "Speed: 1.5ms preprocess, 40.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/5.jpg: 384x640 2 knifes, 1 pizza, 25.9ms\n",
      "Speed: 1.6ms preprocess, 25.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/6.jpg: 384x640 2 knifes, 1 pizza, 45.8ms\n",
      "Speed: 2.9ms preprocess, 45.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/7.jpg: 384x640 2 knifes, 1 pizza, 29.0ms\n",
      "Speed: 2.2ms preprocess, 29.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/8.jpg: 384x640 2 knifes, 1 pizza, 24.3ms\n",
      "Speed: 1.6ms preprocess, 24.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/9.jpg: 384x640 1 fork, 1 pizza, 30.1ms\n",
      "Speed: 2.1ms preprocess, 30.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/10.jpg: 384x640 1 fork, 1 knife, 1 spoon, 1 pizza, 52.8ms\n",
      "Speed: 1.7ms preprocess, 52.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/11.jpg: 384x640 1 spoon, 1 pizza, 26.2ms\n",
      "Speed: 2.4ms preprocess, 26.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/12.jpg: 384x640 2 knifes, 1 pizza, 26.7ms\n",
      "Speed: 1.7ms preprocess, 26.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/13.jpg: 384x640 2 knifes, 1 pizza, 28.0ms\n",
      "Speed: 3.7ms preprocess, 28.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/14.jpg: 384x640 1 knife, 1 pizza, 24.1ms\n",
      "Speed: 1.6ms preprocess, 24.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/15.jpg: 384x640 1 knife, 1 pizza, 43.4ms\n",
      "Speed: 2.3ms preprocess, 43.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/16.jpg: 384x640 1 knife, 1 pizza, 31.9ms\n",
      "Speed: 1.8ms preprocess, 31.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/17.jpg: 384x640 1 knife, 1 pizza, 29.9ms\n",
      "Speed: 2.9ms preprocess, 29.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/18.jpg: 384x640 1 knife, 1 pizza, 27.8ms\n",
      "Speed: 1.9ms preprocess, 27.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/19.jpg: 384x640 1 fork, 1 spoon, 1 pizza, 30.5ms\n",
      "Speed: 1.6ms preprocess, 30.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/20.jpg: 384x640 2 knifes, 1 pizza, 28.1ms\n",
      "Speed: 2.6ms preprocess, 28.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/21.jpg: 384x640 2 knifes, 1 cake, 38.1ms\n",
      "Speed: 2.3ms preprocess, 38.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/22.jpg: 384x640 2 knifes, 1 cake, 23.0ms\n",
      "Speed: 1.5ms preprocess, 23.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/23.jpg: 384x640 2 knifes, 1 cake, 40.8ms\n",
      "Speed: 1.6ms preprocess, 40.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/24.jpg: 384x640 2 knifes, 1 pizza, 37.9ms\n",
      "Speed: 1.8ms preprocess, 37.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/25.jpg: 384x640 2 knifes, 1 pizza, 28.4ms\n",
      "Speed: 2.1ms preprocess, 28.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/26.jpg: 384x640 2 knifes, 1 pizza, 45.3ms\n",
      "Speed: 1.8ms preprocess, 45.3ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/27.jpg: 384x640 2 knifes, 1 pizza, 38.6ms\n",
      "Speed: 3.1ms preprocess, 38.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/28.jpg: 384x640 2 knifes, 1 pizza, 33.7ms\n",
      "Speed: 1.6ms preprocess, 33.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/29.jpg: 384x640 2 knifes, 1 pizza, 33.5ms\n",
      "Speed: 1.6ms preprocess, 33.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/30.jpg: 384x640 2 knifes, 1 pizza, 42.4ms\n",
      "Speed: 3.7ms preprocess, 42.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/31.jpg: 384x640 2 knifes, 1 pizza, 28.9ms\n",
      "Speed: 1.9ms preprocess, 28.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/32.jpg: 384x640 2 knifes, 1 pizza, 32.7ms\n",
      "Speed: 3.3ms preprocess, 32.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/33.jpg: 384x640 2 knifes, 1 pizza, 33.4ms\n",
      "Speed: 1.8ms preprocess, 33.4ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/34.jpg: 384x640 2 knifes, 1 pizza, 41.4ms\n",
      "Speed: 5.4ms preprocess, 41.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/35.jpg: 384x640 2 knifes, 1 pizza, 23.6ms\n",
      "Speed: 1.7ms preprocess, 23.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/36.jpg: 384x640 2 knifes, 1 pizza, 46.3ms\n",
      "Speed: 1.5ms preprocess, 46.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/37.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 29.3ms\n",
      "Speed: 2.1ms preprocess, 29.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/38.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 35.7ms\n",
      "Speed: 1.7ms preprocess, 35.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/39.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 31.4ms\n",
      "Speed: 1.6ms preprocess, 31.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/40.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 30.8ms\n",
      "Speed: 1.9ms preprocess, 30.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/41.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 23.9ms\n",
      "Speed: 1.7ms preprocess, 23.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/42.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 25.2ms\n",
      "Speed: 1.3ms preprocess, 25.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/43.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 28.6ms\n",
      "Speed: 2.0ms preprocess, 28.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/44.jpg: 384x640 2 knifes, 1 cake, 45.1ms\n",
      "Speed: 2.2ms preprocess, 45.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/45.jpg: 384x640 2 knifes, 1 cake, 36.5ms\n",
      "Speed: 1.7ms preprocess, 36.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/46.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 31.2ms\n",
      "Speed: 3.0ms preprocess, 31.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/47.jpg: 384x640 1 knife, 1 pizza, 24.9ms\n",
      "Speed: 2.0ms preprocess, 24.9ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/48.jpg: 384x640 1 knife, 1 pizza, 32.1ms\n",
      "Speed: 2.3ms preprocess, 32.1ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/49.jpg: 384x640 1 knife, 1 pizza, 25.4ms\n",
      "Speed: 2.2ms preprocess, 25.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/50.jpg: 384x640 1 knife, 1 pizza, 36.7ms\n",
      "Speed: 2.5ms preprocess, 36.7ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/51.jpg: 384x640 1 knife, 1 pizza, 29.6ms\n",
      "Speed: 1.7ms preprocess, 29.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/52.jpg: 384x640 1 knife, 1 pizza, 1 cake, 37.8ms\n",
      "Speed: 2.0ms preprocess, 37.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/53.jpg: 384x640 1 knife, 1 pizza, 1 cake, 23.9ms\n",
      "Speed: 1.5ms preprocess, 23.9ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/54.jpg: 384x640 1 knife, 1 pizza, 1 cake, 41.7ms\n",
      "Speed: 1.9ms preprocess, 41.7ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/55.jpg: 384x640 1 knife, 1 pizza, 30.6ms\n",
      "Speed: 1.7ms preprocess, 30.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/56.jpg: 384x640 1 pizza, 1 cake, 25.3ms\n",
      "Speed: 1.6ms preprocess, 25.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/57.jpg: 384x640 1 knife, 1 pizza, 1 cake, 23.5ms\n",
      "Speed: 1.6ms preprocess, 23.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/58.jpg: 384x640 1 knife, 1 cake, 36.4ms\n",
      "Speed: 2.1ms preprocess, 36.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/59.jpg: 384x640 1 pizza, 22.9ms\n",
      "Speed: 1.7ms preprocess, 22.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/60.jpg: 384x640 1 knife, 1 pizza, 25.6ms\n",
      "Speed: 1.7ms preprocess, 25.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/61.jpg: 384x640 1 knife, 1 cake, 33.4ms\n",
      "Speed: 2.9ms preprocess, 33.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/62.jpg: 384x640 1 knife, 1 pizza, 1 cake, 23.1ms\n",
      "Speed: 1.6ms preprocess, 23.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/63.jpg: 384x640 1 knife, 1 pizza, 1 cake, 50.1ms\n",
      "Speed: 2.1ms preprocess, 50.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/64.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 50.3ms\n",
      "Speed: 3.4ms preprocess, 50.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/65.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 51.3ms\n",
      "Speed: 3.3ms preprocess, 51.3ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/66.jpg: 384x640 1 knife, 1 pizza, 1 cake, 25.6ms\n",
      "Speed: 1.6ms preprocess, 25.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/67.jpg: 384x640 2 knifes, 1 cake, 26.5ms\n",
      "Speed: 2.0ms preprocess, 26.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/68.jpg: 384x640 1 knife, 1 cake, 34.6ms\n",
      "Speed: 2.0ms preprocess, 34.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/69.jpg: 384x640 1 knife, 1 spoon, 1 cake, 25.8ms\n",
      "Speed: 1.9ms preprocess, 25.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/70.jpg: 384x640 2 knifes, 1 cake, 40.7ms\n",
      "Speed: 2.2ms preprocess, 40.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/71.jpg: 384x640 2 knifes, 1 cake, 40.2ms\n",
      "Speed: 2.0ms preprocess, 40.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/72.jpg: 384x640 2 knifes, 1 cake, 51.3ms\n",
      "Speed: 2.0ms preprocess, 51.3ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/73.jpg: 384x640 2 knifes, 1 cake, 35.3ms\n",
      "Speed: 2.2ms preprocess, 35.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/74.jpg: 384x640 1 knife, 1 cake, 26.1ms\n",
      "Speed: 1.7ms preprocess, 26.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/75.jpg: 384x640 1 knife, 1 cake, 28.8ms\n",
      "Speed: 1.5ms preprocess, 28.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/76.jpg: 384x640 1 knife, 1 cake, 25.3ms\n",
      "Speed: 1.5ms preprocess, 25.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/77.jpg: 384x640 1 knife, 1 cake, 44.7ms\n",
      "Speed: 2.5ms preprocess, 44.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/78.jpg: 384x640 2 knifes, 1 cake, 43.9ms\n",
      "Speed: 2.6ms preprocess, 43.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/79.jpg: 384x640 1 knife, 1 cake, 45.3ms\n",
      "Speed: 3.2ms preprocess, 45.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/80.jpg: 384x640 2 knifes, 1 cake, 24.5ms\n",
      "Speed: 1.8ms preprocess, 24.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/81.jpg: 384x640 1 knife, 1 cake, 26.2ms\n",
      "Speed: 1.7ms preprocess, 26.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/82.jpg: 384x640 2 knifes, 1 cake, 22.3ms\n",
      "Speed: 2.0ms preprocess, 22.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/83.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 35.1ms\n",
      "Speed: 1.7ms preprocess, 35.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/84.jpg: 384x640 2 knifes, 1 cake, 24.7ms\n",
      "Speed: 1.8ms preprocess, 24.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/85.jpg: 384x640 2 knifes, 1 cake, 62.8ms\n",
      "Speed: 1.8ms preprocess, 62.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/86.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 25.9ms\n",
      "Speed: 2.1ms preprocess, 25.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/87.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 29.5ms\n",
      "Speed: 1.9ms preprocess, 29.5ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/88.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 26.1ms\n",
      "Speed: 1.8ms preprocess, 26.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/89.jpg: 384x640 2 knifes, 1 pizza, 42.8ms\n",
      "Speed: 1.6ms preprocess, 42.8ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/90.jpg: 384x640 2 knifes, 1 pizza, 28.2ms\n",
      "Speed: 1.9ms preprocess, 28.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/91.jpg: 384x640 2 knifes, 1 pizza, 36.3ms\n",
      "Speed: 4.4ms preprocess, 36.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/92.jpg: 384x640 2 knifes, 1 pizza, 24.6ms\n",
      "Speed: 1.8ms preprocess, 24.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/93.jpg: 384x640 1 knife, 1 pizza, 25.7ms\n",
      "Speed: 1.9ms preprocess, 25.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/94.jpg: 384x640 1 pizza, 33.2ms\n",
      "Speed: 1.6ms preprocess, 33.2ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/95.jpg: 384x640 1 fork, 1 pizza, 29.6ms\n",
      "Speed: 1.7ms preprocess, 29.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/96.jpg: 384x640 1 fork, 1 knife, 1 pizza, 43.2ms\n",
      "Speed: 1.8ms preprocess, 43.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/97.jpg: 384x640 1 fork, 1 knife, 1 pizza, 22.6ms\n",
      "Speed: 1.5ms preprocess, 22.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/98.jpg: 384x640 1 fork, 1 knife, 1 pizza, 23.7ms\n",
      "Speed: 1.7ms preprocess, 23.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/99.jpg: 384x640 1 fork, 1 knife, 1 pizza, 42.8ms\n",
      "Speed: 1.7ms preprocess, 42.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/100.jpg: 384x640 1 fork, 1 knife, 1 pizza, 22.6ms\n",
      "Speed: 1.6ms preprocess, 22.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/101.jpg: 384x640 1 fork, 1 knife, 1 pizza, 24.7ms\n",
      "Speed: 1.7ms preprocess, 24.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/102.jpg: 384x640 2 knifes, 1 pizza, 49.1ms\n",
      "Speed: 1.7ms preprocess, 49.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/103.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 37.9ms\n",
      "Speed: 1.7ms preprocess, 37.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/104.jpg: 384x640 2 knifes, 1 pizza, 28.8ms\n",
      "Speed: 3.4ms preprocess, 28.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/105.jpg: 384x640 2 knifes, 1 pizza, 33.9ms\n",
      "Speed: 1.8ms preprocess, 33.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/106.jpg: 384x640 1 bottle, 1 knife, 1 pizza, 1 cake, 29.8ms\n",
      "Speed: 2.0ms preprocess, 29.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/107.jpg: 384x640 1 knife, 1 cake, 31.3ms\n",
      "Speed: 3.4ms preprocess, 31.3ms inference, 7.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/108.jpg: 384x640 1 bottle, 1 knife, 1 pizza, 38.6ms\n",
      "Speed: 2.0ms preprocess, 38.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/109.jpg: 384x640 1 bottle, 1 fork, 2 knifes, 1 pizza, 1 cake, 42.5ms\n",
      "Speed: 1.7ms preprocess, 42.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/110.jpg: 384x640 1 bottle, 1 knife, 1 pizza, 1 cake, 25.5ms\n",
      "Speed: 1.8ms preprocess, 25.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/111.jpg: 384x640 1 knife, 1 pizza, 1 cake, 40.8ms\n",
      "Speed: 2.0ms preprocess, 40.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/112.jpg: 384x640 1 pizza, 1 cake, 35.7ms\n",
      "Speed: 1.7ms preprocess, 35.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/113.jpg: 384x640 1 bottle, 1 pizza, 1 cake, 34.2ms\n",
      "Speed: 2.1ms preprocess, 34.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/114.jpg: 384x640 1 knife, 1 pizza, 1 cake, 29.0ms\n",
      "Speed: 1.8ms preprocess, 29.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/115.jpg: 384x640 1 knife, 1 pizza, 38.7ms\n",
      "Speed: 2.1ms preprocess, 38.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/116.jpg: 384x640 1 knife, 1 pizza, 39.5ms\n",
      "Speed: 2.0ms preprocess, 39.5ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/117.jpg: 384x640 1 knife, 1 pizza, 36.1ms\n",
      "Speed: 2.4ms preprocess, 36.1ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/118.jpg: 384x640 2 knifes, 1 pizza, 33.9ms\n",
      "Speed: 2.7ms preprocess, 33.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/119.jpg: 384x640 1 knife, 1 pizza, 1 cake, 29.3ms\n",
      "Speed: 2.1ms preprocess, 29.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/120.jpg: 384x640 1 pizza, 46.6ms\n",
      "Speed: 1.9ms preprocess, 46.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/121.jpg: 384x640 2 knifes, 1 pizza, 26.7ms\n",
      "Speed: 1.6ms preprocess, 26.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/122.jpg: 384x640 1 fork, 1 knife, 1 pizza, 32.6ms\n",
      "Speed: 1.6ms preprocess, 32.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/123.jpg: 384x640 1 knife, 1 pizza, 33.8ms\n",
      "Speed: 2.0ms preprocess, 33.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/124.jpg: 384x640 1 bottle, 1 knife, 1 pizza, 38.6ms\n",
      "Speed: 2.4ms preprocess, 38.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/125.jpg: 384x640 2 knifes, 1 pizza, 29.9ms\n",
      "Speed: 1.9ms preprocess, 29.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/126.jpg: 384x640 1 fork, 1 knife, 1 pizza, 27.1ms\n",
      "Speed: 2.3ms preprocess, 27.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/127.jpg: 384x640 1 fork, 1 pizza, 38.5ms\n",
      "Speed: 2.2ms preprocess, 38.5ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/128.jpg: 384x640 1 fork, 1 pizza, 43.7ms\n",
      "Speed: 1.7ms preprocess, 43.7ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/129.jpg: 384x640 1 fork, 1 pizza, 29.4ms\n",
      "Speed: 1.9ms preprocess, 29.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/130.jpg: 384x640 2 knifes, 1 pizza, 26.0ms\n",
      "Speed: 1.8ms preprocess, 26.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/131.jpg: 384x640 1 bottle, 2 knifes, 1 pizza, 42.1ms\n",
      "Speed: 1.8ms preprocess, 42.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/132.jpg: 384x640 1 knife, 1 pizza, 23.0ms\n",
      "Speed: 1.6ms preprocess, 23.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/133.jpg: 384x640 2 forks, 1 knife, 1 pizza, 28.3ms\n",
      "Speed: 2.6ms preprocess, 28.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/134.jpg: 384x640 1 fork, 1 pizza, 1 cake, 35.4ms\n",
      "Speed: 1.6ms preprocess, 35.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/135.jpg: 384x640 1 fork, 1 pizza, 24.3ms\n",
      "Speed: 1.9ms preprocess, 24.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/136.jpg: 384x640 1 pizza, 26.7ms\n",
      "Speed: 1.7ms preprocess, 26.7ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/137.jpg: 384x640 1 fork, 1 pizza, 31.1ms\n",
      "Speed: 3.1ms preprocess, 31.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/138.jpg: 384x640 1 pizza, 37.2ms\n",
      "Speed: 1.8ms preprocess, 37.2ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/139.jpg: 384x640 1 knife, 1 pizza, 49.7ms\n",
      "Speed: 3.2ms preprocess, 49.7ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/140.jpg: 384x640 1 knife, 1 pizza, 1 cake, 45.7ms\n",
      "Speed: 2.6ms preprocess, 45.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/141.jpg: 384x640 1 fork, 2 knifes, 1 pizza, 1 cake, 31.8ms\n",
      "Speed: 2.3ms preprocess, 31.8ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/142.jpg: 384x640 1 knife, 1 pizza, 30.6ms\n",
      "Speed: 2.2ms preprocess, 30.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/143.jpg: 384x640 2 knifes, 1 pizza, 38.4ms\n",
      "Speed: 2.3ms preprocess, 38.4ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/144.jpg: 384x640 2 knifes, 1 pizza, 50.9ms\n",
      "Speed: 2.0ms preprocess, 50.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/145.jpg: 384x640 1 knife, 1 pizza, 36.0ms\n",
      "Speed: 2.3ms preprocess, 36.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/146.jpg: 384x640 2 knifes, 1 pizza, 52.5ms\n",
      "Speed: 3.0ms preprocess, 52.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/147.jpg: 384x640 2 knifes, 1 pizza, 36.0ms\n",
      "Speed: 1.9ms preprocess, 36.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/148.jpg: 384x640 2 knifes, 1 pizza, 39.0ms\n",
      "Speed: 3.0ms preprocess, 39.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/149.jpg: 384x640 2 knifes, 1 pizza, 49.6ms\n",
      "Speed: 1.9ms preprocess, 49.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/150.jpg: 384x640 2 knifes, 1 pizza, 27.7ms\n",
      "Speed: 1.5ms preprocess, 27.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/151.jpg: 384x640 2 knifes, 1 pizza, 28.5ms\n",
      "Speed: 2.3ms preprocess, 28.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/152.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 49.1ms\n",
      "Speed: 2.0ms preprocess, 49.1ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/153.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 39.2ms\n",
      "Speed: 2.1ms preprocess, 39.2ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/154.jpg: 384x640 2 knifes, 1 cake, 32.2ms\n",
      "Speed: 2.0ms preprocess, 32.2ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/155.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 31.2ms\n",
      "Speed: 1.9ms preprocess, 31.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/156.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 30.4ms\n",
      "Speed: 1.8ms preprocess, 30.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/157.jpg: 384x640 1 knife, 1 pizza, 1 cake, 52.4ms\n",
      "Speed: 3.1ms preprocess, 52.4ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/158.jpg: 384x640 1 knife, 1 pizza, 1 cake, 37.6ms\n",
      "Speed: 2.2ms preprocess, 37.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/159.jpg: 384x640 1 knife, 1 pizza, 1 cake, 31.0ms\n",
      "Speed: 1.6ms preprocess, 31.0ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/160.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 37.0ms\n",
      "Speed: 3.9ms preprocess, 37.0ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/161.jpg: 384x640 2 knifes, 1 pizza, 25.9ms\n",
      "Speed: 2.0ms preprocess, 25.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/162.jpg: 384x640 2 knifes, 1 pizza, 30.8ms\n",
      "Speed: 1.9ms preprocess, 30.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/163.jpg: 384x640 2 knifes, 1 pizza, 38.2ms\n",
      "Speed: 2.3ms preprocess, 38.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/164.jpg: 384x640 2 knifes, 1 pizza, 26.8ms\n",
      "Speed: 1.8ms preprocess, 26.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/165.jpg: 384x640 1 bottle, 1 knife, 1 pizza, 28.7ms\n",
      "Speed: 1.8ms preprocess, 28.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/166.jpg: 384x640 2 knifes, 1 pizza, 32.7ms\n",
      "Speed: 2.3ms preprocess, 32.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/167.jpg: 384x640 1 knife, 1 pizza, 28.9ms\n",
      "Speed: 1.9ms preprocess, 28.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/168.jpg: 384x640 1 knife, 1 cake, 32.7ms\n",
      "Speed: 2.2ms preprocess, 32.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/169.jpg: 384x640 1 knife, 1 pizza, 1 cake, 28.2ms\n",
      "Speed: 1.8ms preprocess, 28.2ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/170.jpg: 384x640 1 knife, 1 pizza, 35.5ms\n",
      "Speed: 2.6ms preprocess, 35.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/171.jpg: 384x640 1 knife, 1 pizza, 1 cake, 27.5ms\n",
      "Speed: 3.2ms preprocess, 27.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/172.jpg: 384x640 1 knife, 1 pizza, 1 cake, 26.3ms\n",
      "Speed: 1.7ms preprocess, 26.3ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/173.jpg: 384x640 1 knife, 1 pizza, 51.0ms\n",
      "Speed: 3.8ms preprocess, 51.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/174.jpg: 384x640 1 knife, 1 pizza, 1 cake, 28.4ms\n",
      "Speed: 1.8ms preprocess, 28.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/175.jpg: 384x640 1 knife, 1 pizza, 49.9ms\n",
      "Speed: 2.2ms preprocess, 49.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/176.jpg: 384x640 1 knife, 1 pizza, 1 cake, 34.8ms\n",
      "Speed: 1.9ms preprocess, 34.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/177.jpg: 384x640 1 knife, 1 pizza, 1 cake, 28.3ms\n",
      "Speed: 1.7ms preprocess, 28.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/178.jpg: 384x640 1 knife, 1 pizza, 31.5ms\n",
      "Speed: 1.9ms preprocess, 31.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/179.jpg: 384x640 1 knife, 1 pizza, 1 cake, 29.6ms\n",
      "Speed: 1.7ms preprocess, 29.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/180.jpg: 384x640 1 fork, 1 knife, 1 spoon, 1 pizza, 29.1ms\n",
      "Speed: 1.8ms preprocess, 29.1ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/181.jpg: 384x640 1 knife, 1 pizza, 1 cake, 48.5ms\n",
      "Speed: 1.7ms preprocess, 48.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/182.jpg: 384x640 1 knife, 1 pizza, 47.0ms\n",
      "Speed: 2.6ms preprocess, 47.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/183.jpg: 384x640 1 knife, 1 pizza, 1 cake, 27.2ms\n",
      "Speed: 2.8ms preprocess, 27.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/184.jpg: 384x640 1 knife, 1 pizza, 1 cake, 45.6ms\n",
      "Speed: 2.3ms preprocess, 45.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/185.jpg: 384x640 1 knife, 1 pizza, 1 cake, 38.4ms\n",
      "Speed: 3.0ms preprocess, 38.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/186.jpg: 384x640 1 bottle, 1 knife, 1 pizza, 26.7ms\n",
      "Speed: 1.8ms preprocess, 26.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/187.jpg: 384x640 1 bottle, 1 knife, 1 cake, 40.4ms\n",
      "Speed: 1.7ms preprocess, 40.4ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/188.jpg: 384x640 1 bottle, 1 pizza, 1 cake, 40.3ms\n",
      "Speed: 3.6ms preprocess, 40.3ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/189.jpg: 384x640 1 cake, 30.0ms\n",
      "Speed: 1.8ms preprocess, 30.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/190.jpg: 384x640 1 knife, 1 pizza, 1 cake, 44.5ms\n",
      "Speed: 2.0ms preprocess, 44.5ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/191.jpg: 384x640 1 knife, 1 pizza, 1 cake, 32.0ms\n",
      "Speed: 2.1ms preprocess, 32.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/192.jpg: 384x640 1 knife, 1 pizza, 1 cake, 28.4ms\n",
      "Speed: 2.6ms preprocess, 28.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/193.jpg: 384x640 1 knife, 1 pizza, 1 cake, 35.3ms\n",
      "Speed: 2.0ms preprocess, 35.3ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/194.jpg: 384x640 1 knife, 1 pizza, 1 cake, 37.5ms\n",
      "Speed: 2.4ms preprocess, 37.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/195.jpg: 384x640 1 knife, 1 pizza, 1 cake, 27.9ms\n",
      "Speed: 2.3ms preprocess, 27.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/196.jpg: 384x640 1 knife, 1 pizza, 1 cake, 41.0ms\n",
      "Speed: 1.9ms preprocess, 41.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/197.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 30.0ms\n",
      "Speed: 1.8ms preprocess, 30.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/198.jpg: 384x640 2 knifes, 1 cake, 32.3ms\n",
      "Speed: 1.6ms preprocess, 32.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/199.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 30.9ms\n",
      "Speed: 1.8ms preprocess, 30.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/200.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 38.8ms\n",
      "Speed: 2.0ms preprocess, 38.8ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/201.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 30.8ms\n",
      "Speed: 2.6ms preprocess, 30.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/202.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 29.1ms\n",
      "Speed: 2.2ms preprocess, 29.1ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/203.jpg: 384x640 2 knifes, 1 pizza, 31.0ms\n",
      "Speed: 2.4ms preprocess, 31.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/204.jpg: 384x640 2 knifes, 1 pizza, 45.5ms\n",
      "Speed: 2.3ms preprocess, 45.5ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/205.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 57.0ms\n",
      "Speed: 3.0ms preprocess, 57.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/206.jpg: 384x640 2 knifes, 1 pizza, 43.4ms\n",
      "Speed: 3.0ms preprocess, 43.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/207.jpg: 384x640 2 knifes, 1 pizza, 39.0ms\n",
      "Speed: 2.0ms preprocess, 39.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/208.jpg: 384x640 2 knifes, 1 pizza, 34.4ms\n",
      "Speed: 1.7ms preprocess, 34.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/209.jpg: 384x640 2 knifes, 1 pizza, 36.8ms\n",
      "Speed: 2.5ms preprocess, 36.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/210.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 46.4ms\n",
      "Speed: 1.6ms preprocess, 46.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/211.jpg: 384x640 2 knifes, 1 pizza, 30.7ms\n",
      "Speed: 1.7ms preprocess, 30.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/212.jpg: 384x640 2 knifes, 1 pizza, 30.4ms\n",
      "Speed: 2.2ms preprocess, 30.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/213.jpg: 384x640 2 knifes, 1 pizza, 35.1ms\n",
      "Speed: 1.7ms preprocess, 35.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/214.jpg: 384x640 2 knifes, 1 pizza, 34.1ms\n",
      "Speed: 2.5ms preprocess, 34.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/215.jpg: 384x640 2 knifes, 1 pizza, 28.0ms\n",
      "Speed: 1.9ms preprocess, 28.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/216.jpg: 384x640 2 knifes, 1 pizza, 42.0ms\n",
      "Speed: 2.9ms preprocess, 42.0ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/217.jpg: 384x640 2 knifes, 1 pizza, 30.2ms\n",
      "Speed: 1.9ms preprocess, 30.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/218.jpg: 384x640 2 knifes, 1 pizza, 28.8ms\n",
      "Speed: 1.9ms preprocess, 28.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/219.jpg: 384x640 2 knifes, 1 pizza, 46.7ms\n",
      "Speed: 2.2ms preprocess, 46.7ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/220.jpg: 384x640 2 knifes, 1 pizza, 51.9ms\n",
      "Speed: 2.1ms preprocess, 51.9ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/221.jpg: 384x640 2 knifes, 1 pizza, 31.1ms\n",
      "Speed: 2.0ms preprocess, 31.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/222.jpg: 384x640 2 knifes, 1 pizza, 42.6ms\n",
      "Speed: 2.1ms preprocess, 42.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/223.jpg: 384x640 2 knifes, 1 pizza, 52.2ms\n",
      "Speed: 3.1ms preprocess, 52.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/224.jpg: 384x640 2 knifes, 1 pizza, 42.3ms\n",
      "Speed: 2.1ms preprocess, 42.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/225.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 36.0ms\n",
      "Speed: 2.1ms preprocess, 36.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/226.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 35.0ms\n",
      "Speed: 1.9ms preprocess, 35.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/227.jpg: 384x640 2 knifes, 1 pizza, 1 cake, 28.3ms\n",
      "Speed: 1.6ms preprocess, 28.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/228.jpg: 384x640 2 knifes, 1 pizza, 28.2ms\n",
      "Speed: 1.9ms preprocess, 28.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/229.jpg: 384x640 2 knifes, 1 pizza, 28.2ms\n",
      "Speed: 1.6ms preprocess, 28.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/230.jpg: 384x640 2 knifes, 1 pizza, 35.3ms\n",
      "Speed: 2.2ms preprocess, 35.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/231.jpg: 384x640 1 knife, 1 pizza, 30.2ms\n",
      "Speed: 1.9ms preprocess, 30.2ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/232.jpg: 384x640 1 fork, 1 knife, 1 spoon, 1 pizza, 28.4ms\n",
      "Speed: 1.7ms preprocess, 28.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/233.jpg: 384x640 1 fork, 1 knife, 1 spoon, 1 pizza, 30.5ms\n",
      "Speed: 2.1ms preprocess, 30.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/234.jpg: 384x640 1 fork, 1 spoon, 1 pizza, 34.1ms\n",
      "Speed: 1.7ms preprocess, 34.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/235.jpg: 384x640 1 knife, 1 pizza, 54.5ms\n",
      "Speed: 1.7ms preprocess, 54.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/236.jpg: 384x640 1 knife, 1 pizza, 38.0ms\n",
      "Speed: 2.3ms preprocess, 38.0ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/237.jpg: 384x640 1 knife, 1 pizza, 40.6ms\n",
      "Speed: 3.2ms preprocess, 40.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/238.jpg: 384x640 1 knife, 1 pizza, 61.1ms\n",
      "Speed: 2.0ms preprocess, 61.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/239.jpg: 384x640 1 knife, 1 pizza, 1 cake, 53.6ms\n",
      "Speed: 2.1ms preprocess, 53.6ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/240.jpg: 384x640 1 knife, 1 pizza, 37.4ms\n",
      "Speed: 2.0ms preprocess, 37.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/241.jpg: 384x640 1 knife, 1 pizza, 25.1ms\n",
      "Speed: 1.7ms preprocess, 25.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/242.jpg: 384x640 1 knife, 1 pizza, 44.0ms\n",
      "Speed: 2.2ms preprocess, 44.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/243.jpg: 384x640 1 knife, 1 pizza, 33.3ms\n",
      "Speed: 2.4ms preprocess, 33.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/244.jpg: 384x640 1 knife, 1 pizza, 28.0ms\n",
      "Speed: 1.8ms preprocess, 28.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/245.jpg: 384x640 1 knife, 1 pizza, 34.4ms\n",
      "Speed: 1.8ms preprocess, 34.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/246.jpg: 384x640 1 knife, 1 pizza, 29.5ms\n",
      "Speed: 1.8ms preprocess, 29.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/247.jpg: 384x640 1 knife, 1 pizza, 36.0ms\n",
      "Speed: 1.7ms preprocess, 36.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/248.jpg: 384x640 1 knife, 1 pizza, 1 cake, 35.6ms\n",
      "Speed: 2.7ms preprocess, 35.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/249.jpg: 384x640 1 knife, 1 pizza, 26.5ms\n",
      "Speed: 1.7ms preprocess, 26.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/250.jpg: 384x640 1 knife, 1 pizza, 25.1ms\n",
      "Speed: 1.7ms preprocess, 25.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/251.jpg: 384x640 1 knife, 1 pizza, 50.6ms\n",
      "Speed: 2.2ms preprocess, 50.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/252.jpg: 384x640 1 knife, 1 pizza, 36.6ms\n",
      "Speed: 2.0ms preprocess, 36.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/253.jpg: 384x640 1 knife, 1 pizza, 59.1ms\n",
      "Speed: 2.9ms preprocess, 59.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/254.jpg: 384x640 2 knifes, 1 pizza, 38.0ms\n",
      "Speed: 3.0ms preprocess, 38.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/255.jpg: 384x640 1 knife, 1 pizza, 30.8ms\n",
      "Speed: 1.7ms preprocess, 30.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/256.jpg: 384x640 2 knifes, 1 pizza, 40.0ms\n",
      "Speed: 2.6ms preprocess, 40.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/257.jpg: 384x640 1 knife, 1 pizza, 28.7ms\n",
      "Speed: 1.8ms preprocess, 28.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/258.jpg: 384x640 1 knife, 1 pizza, 31.3ms\n",
      "Speed: 1.7ms preprocess, 31.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/259.jpg: 384x640 1 knife, 1 pizza, 33.7ms\n",
      "Speed: 2.1ms preprocess, 33.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/260.jpg: 384x640 1 knife, 1 pizza, 27.7ms\n",
      "Speed: 1.9ms preprocess, 27.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/261.jpg: 384x640 1 knife, 1 pizza, 26.7ms\n",
      "Speed: 1.8ms preprocess, 26.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/262.jpg: 384x640 1 knife, 1 pizza, 27.3ms\n",
      "Speed: 1.6ms preprocess, 27.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/263.jpg: 384x640 2 knifes, 1 pizza, 34.2ms\n",
      "Speed: 1.9ms preprocess, 34.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/264.jpg: 384x640 2 knifes, 1 pizza, 34.0ms\n",
      "Speed: 1.8ms preprocess, 34.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/265.jpg: 384x640 2 knifes, 1 pizza, 28.6ms\n",
      "Speed: 1.8ms preprocess, 28.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/266.jpg: 384x640 2 knifes, 1 pizza, 35.0ms\n",
      "Speed: 1.7ms preprocess, 35.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/267.jpg: 384x640 2 knifes, 1 pizza, 27.4ms\n",
      "Speed: 1.8ms preprocess, 27.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/268.jpg: 384x640 2 knifes, 1 pizza, 31.7ms\n",
      "Speed: 1.8ms preprocess, 31.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/269.jpg: 384x640 2 knifes, 1 pizza, 36.1ms\n",
      "Speed: 2.3ms preprocess, 36.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/270.jpg: 384x640 2 knifes, 1 pizza, 50.3ms\n",
      "Speed: 2.1ms preprocess, 50.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/271.jpg: 384x640 2 knifes, 1 pizza, 36.9ms\n",
      "Speed: 3.3ms preprocess, 36.9ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/272.jpg: 384x640 1 knife, 1 pizza, 42.3ms\n",
      "Speed: 3.3ms preprocess, 42.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/273.jpg: 384x640 1 knife, 1 pizza, 31.9ms\n",
      "Speed: 1.8ms preprocess, 31.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/274.jpg: 384x640 1 knife, 1 pizza, 32.6ms\n",
      "Speed: 2.2ms preprocess, 32.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/275.jpg: 384x640 1 knife, 1 pizza, 33.2ms\n",
      "Speed: 2.1ms preprocess, 33.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/276.jpg: 384x640 1 knife, 1 pizza, 36.5ms\n",
      "Speed: 1.8ms preprocess, 36.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/277.jpg: 384x640 1 knife, 1 pizza, 38.8ms\n",
      "Speed: 3.0ms preprocess, 38.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/278.jpg: 384x640 1 knife, 1 pizza, 29.9ms\n",
      "Speed: 1.7ms preprocess, 29.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/279.jpg: 384x640 1 knife, 1 pizza, 32.9ms\n",
      "Speed: 3.2ms preprocess, 32.9ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/280.jpg: 384x640 1 knife, 1 pizza, 31.3ms\n",
      "Speed: 1.7ms preprocess, 31.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/281.jpg: 384x640 1 knife, 1 pizza, 27.8ms\n",
      "Speed: 1.6ms preprocess, 27.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/282.jpg: 384x640 1 knife, 1 pizza, 42.7ms\n",
      "Speed: 1.7ms preprocess, 42.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/283.jpg: 384x640 1 knife, 1 pizza, 33.8ms\n",
      "Speed: 2.1ms preprocess, 33.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/284.jpg: 384x640 1 fork, 1 knife, 1 spoon, 1 pizza, 27.8ms\n",
      "Speed: 1.9ms preprocess, 27.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/285.jpg: 384x640 1 fork, 1 knife, 1 pizza, 48.5ms\n",
      "Speed: 2.9ms preprocess, 48.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/286.jpg: 384x640 1 fork, 1 knife, 1 spoon, 1 pizza, 29.3ms\n",
      "Speed: 3.0ms preprocess, 29.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/287.jpg: 384x640 1 spoon, 1 pizza, 37.0ms\n",
      "Speed: 1.7ms preprocess, 37.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/288.jpg: 384x640 1 fork, 1 knife, 1 spoon, 1 pizza, 42.9ms\n",
      "Speed: 1.9ms preprocess, 42.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/289.jpg: 384x640 2 knifes, 1 pizza, 48.8ms\n",
      "Speed: 2.8ms preprocess, 48.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/290.jpg: 384x640 1 knife, 1 pizza, 34.4ms\n",
      "Speed: 1.9ms preprocess, 34.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/291.jpg: 384x640 2 knifes, 1 pizza, 51.3ms\n",
      "Speed: 2.6ms preprocess, 51.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/292.jpg: 384x640 1 knife, 1 pizza, 1 cake, 39.4ms\n",
      "Speed: 3.3ms preprocess, 39.4ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/293.jpg: 384x640 1 bottle, 1 knife, 1 pizza, 39.3ms\n",
      "Speed: 2.0ms preprocess, 39.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/294.jpg: 384x640 1 bottle, 1 knife, 1 pizza, 30.8ms\n",
      "Speed: 1.8ms preprocess, 30.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/295.jpg: 384x640 1 bottle, 1 knife, 1 pizza, 52.3ms\n",
      "Speed: 1.8ms preprocess, 52.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/296.jpg: 384x640 1 knife, 1 pizza, 29.5ms\n",
      "Speed: 1.8ms preprocess, 29.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/297.jpg: 384x640 1 knife, 1 pizza, 32.1ms\n",
      "Speed: 1.7ms preprocess, 32.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/298.jpg: 384x640 1 knife, 1 pizza, 33.4ms\n",
      "Speed: 2.4ms preprocess, 33.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/bg_change/right/299.jpg: 384x640 2 knifes, 1 pizza, 35.3ms\n",
      "Speed: 1.6ms preprocess, 35.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Propagating video frames: 100%|| 300/300 [00:19<00:00, 15.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask propagation completed in 19.11 seconds.\n",
      "Processing predicted masks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing video frames: 300it [00:02, 127.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 300 masks for evaluation.\n",
      "Masks saved to data/masks/yolo11x-seg/val/data-raw-SegSTRONGC_val-val-1-1-bg_change-right.pkl\n",
      "Loading ground truth masks for evaluation...\n",
      "Loaded 300 ground truth masks.\n",
      "Calculating evaluation metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for metrics calculation: 1.76 seconds.\n",
      "Mean IoU for data/raw/SegSTRONGC_val/val/1/1/bg_change/right: 0.1369\n",
      "Mean DSC for data/raw/SegSTRONGC_val/val/1/1/bg_change/right: 0.2391\n",
      "Loading existing results file: data/results/yolo11x-seg/val.json\n",
      "Results saved to data/results/yolo11x-seg/val.json\n",
      "Processing video took 25.64 seconds.\n",
      "==================================================\n",
      "\n",
      "Results for data/raw/SegSTRONGC_val/val/1/1/bg_change:\n",
      "  Left: IoU=0.1956, DSC=0.2985\n",
      "  Right: IoU=0.1369, DSC=0.2391\n",
      "  Overall: IoU=0.1662, DSC=0.2688\n",
      "\n",
      "Processing domain: blood\n",
      "Processing left camera video...\n",
      "==================================================\n",
      "Processing video: data/raw/SegSTRONGC_val/val/1/1/blood/left\n",
      "Domain: blood, Split: val, Camera: left\n",
      "Initializing Yolo for video...\n",
      "Initialization took 0.49 seconds.\n",
      "Starting mask propagation...\n",
      "Total images in video: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/0.jpg: 384x640 1 baseball bat, 75.6ms\n",
      "Speed: 3.6ms preprocess, 75.6ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/1.jpg: 384x640 1 baseball bat, 54.2ms\n",
      "Speed: 3.4ms preprocess, 54.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/2.jpg: 384x640 (no detections), 34.3ms\n",
      "Speed: 2.0ms preprocess, 34.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/3.jpg: 384x640 1 baseball bat, 46.9ms\n",
      "Speed: 2.1ms preprocess, 46.9ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/4.jpg: 384x640 (no detections), 49.7ms\n",
      "Speed: 3.5ms preprocess, 49.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/5.jpg: 384x640 1 baseball bat, 1 bottle, 48.9ms\n",
      "Speed: 3.3ms preprocess, 48.9ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/6.jpg: 384x640 1 baseball bat, 1 bottle, 38.7ms\n",
      "Speed: 2.1ms preprocess, 38.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/7.jpg: 384x640 1 bottle, 33.0ms\n",
      "Speed: 1.8ms preprocess, 33.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/8.jpg: 384x640 (no detections), 55.8ms\n",
      "Speed: 2.1ms preprocess, 55.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/9.jpg: 384x640 (no detections), 33.9ms\n",
      "Speed: 1.9ms preprocess, 33.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/10.jpg: 384x640 (no detections), 36.5ms\n",
      "Speed: 1.8ms preprocess, 36.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/11.jpg: 384x640 (no detections), 39.9ms\n",
      "Speed: 3.2ms preprocess, 39.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/12.jpg: 384x640 (no detections), 31.2ms\n",
      "Speed: 1.8ms preprocess, 31.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/13.jpg: 384x640 1 spoon, 36.6ms\n",
      "Speed: 2.7ms preprocess, 36.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/14.jpg: 384x640 1 bottle, 1 spoon, 1 carrot, 36.9ms\n",
      "Speed: 1.9ms preprocess, 36.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/15.jpg: 384x640 1 bottle, 49.1ms\n",
      "Speed: 1.9ms preprocess, 49.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/16.jpg: 384x640 1 knife, 43.4ms\n",
      "Speed: 1.9ms preprocess, 43.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/17.jpg: 384x640 1 carrot, 28.5ms\n",
      "Speed: 1.9ms preprocess, 28.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/18.jpg: 384x640 (no detections), 41.5ms\n",
      "Speed: 1.7ms preprocess, 41.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/19.jpg: 384x640 (no detections), 29.3ms\n",
      "Speed: 1.8ms preprocess, 29.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/20.jpg: 384x640 1 knife, 28.7ms\n",
      "Speed: 1.8ms preprocess, 28.7ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/21.jpg: 384x640 1 bottle, 30.8ms\n",
      "Speed: 1.8ms preprocess, 30.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/22.jpg: 384x640 (no detections), 39.4ms\n",
      "Speed: 2.0ms preprocess, 39.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/23.jpg: 384x640 1 baseball bat, 59.4ms\n",
      "Speed: 2.2ms preprocess, 59.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/24.jpg: 384x640 1 baseball bat, 1 bottle, 1 carrot, 64.0ms\n",
      "Speed: 2.0ms preprocess, 64.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/25.jpg: 384x640 1 baseball bat, 1 bottle, 79.6ms\n",
      "Speed: 2.0ms preprocess, 79.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/26.jpg: 384x640 (no detections), 45.6ms\n",
      "Speed: 1.9ms preprocess, 45.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/27.jpg: 384x640 1 person, 47.9ms\n",
      "Speed: 1.9ms preprocess, 47.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/28.jpg: 384x640 1 person, 40.5ms\n",
      "Speed: 2.7ms preprocess, 40.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/29.jpg: 384x640 1 baseball bat, 51.9ms\n",
      "Speed: 3.5ms preprocess, 51.9ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/30.jpg: 384x640 2 carrots, 54.7ms\n",
      "Speed: 3.4ms preprocess, 54.7ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/31.jpg: 384x640 1 baseball bat, 49.3ms\n",
      "Speed: 3.1ms preprocess, 49.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/32.jpg: 384x640 1 person, 1 spoon, 1 carrot, 69.5ms\n",
      "Speed: 2.4ms preprocess, 69.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/33.jpg: 384x640 1 spoon, 1 carrot, 56.7ms\n",
      "Speed: 2.0ms preprocess, 56.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/34.jpg: 384x640 1 spoon, 1 carrot, 83.1ms\n",
      "Speed: 2.3ms preprocess, 83.1ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/35.jpg: 384x640 1 spoon, 3 carrots, 63.5ms\n",
      "Speed: 2.2ms preprocess, 63.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/36.jpg: 384x640 1 knife, 1 spoon, 77.4ms\n",
      "Speed: 2.1ms preprocess, 77.4ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/37.jpg: 384x640 1 spoon, 1 carrot, 41.6ms\n",
      "Speed: 2.1ms preprocess, 41.6ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/38.jpg: 384x640 1 spoon, 32.5ms\n",
      "Speed: 2.3ms preprocess, 32.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/39.jpg: 384x640 1 spoon, 49.4ms\n",
      "Speed: 2.6ms preprocess, 49.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/40.jpg: 384x640 (no detections), 39.4ms\n",
      "Speed: 1.7ms preprocess, 39.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/41.jpg: 384x640 2 spoons, 31.5ms\n",
      "Speed: 1.8ms preprocess, 31.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/42.jpg: 384x640 1 baseball bat, 1 spoon, 1 toothbrush, 36.5ms\n",
      "Speed: 2.9ms preprocess, 36.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/43.jpg: 384x640 1 spoon, 28.4ms\n",
      "Speed: 1.7ms preprocess, 28.4ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/44.jpg: 384x640 1 spoon, 39.6ms\n",
      "Speed: 1.9ms preprocess, 39.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/45.jpg: 384x640 1 spoon, 1 carrot, 38.7ms\n",
      "Speed: 3.2ms preprocess, 38.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/46.jpg: 384x640 1 spoon, 1 carrot, 33.9ms\n",
      "Speed: 1.8ms preprocess, 33.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/47.jpg: 384x640 1 knife, 1 carrot, 28.5ms\n",
      "Speed: 1.7ms preprocess, 28.5ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/48.jpg: 384x640 (no detections), 36.6ms\n",
      "Speed: 2.5ms preprocess, 36.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/49.jpg: 384x640 1 bottle, 60.1ms\n",
      "Speed: 3.0ms preprocess, 60.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/50.jpg: 384x640 1 bottle, 30.6ms\n",
      "Speed: 1.8ms preprocess, 30.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/51.jpg: 384x640 1 person, 30.6ms\n",
      "Speed: 2.2ms preprocess, 30.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/52.jpg: 384x640 1 bottle, 32.5ms\n",
      "Speed: 1.4ms preprocess, 32.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/53.jpg: 384x640 (no detections), 33.7ms\n",
      "Speed: 2.0ms preprocess, 33.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/54.jpg: 384x640 (no detections), 32.7ms\n",
      "Speed: 2.0ms preprocess, 32.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/55.jpg: 384x640 1 skateboard, 1 carrot, 38.7ms\n",
      "Speed: 2.2ms preprocess, 38.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/56.jpg: 384x640 1 bottle, 32.1ms\n",
      "Speed: 1.6ms preprocess, 32.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/57.jpg: 384x640 1 bottle, 27.6ms\n",
      "Speed: 1.6ms preprocess, 27.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/58.jpg: 384x640 (no detections), 29.3ms\n",
      "Speed: 2.0ms preprocess, 29.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/59.jpg: 384x640 1 knife, 27.9ms\n",
      "Speed: 1.6ms preprocess, 27.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/60.jpg: 384x640 (no detections), 36.3ms\n",
      "Speed: 2.1ms preprocess, 36.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/61.jpg: 384x640 1 bottle, 37.0ms\n",
      "Speed: 2.1ms preprocess, 37.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/62.jpg: 384x640 (no detections), 43.0ms\n",
      "Speed: 2.4ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/63.jpg: 384x640 1 baseball bat, 1 bottle, 47.3ms\n",
      "Speed: 1.9ms preprocess, 47.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/64.jpg: 384x640 1 knife, 46.1ms\n",
      "Speed: 3.2ms preprocess, 46.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/65.jpg: 384x640 (no detections), 27.4ms\n",
      "Speed: 1.8ms preprocess, 27.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/66.jpg: 384x640 1 bottle, 36.9ms\n",
      "Speed: 2.0ms preprocess, 36.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/67.jpg: 384x640 1 knife, 1 spoon, 34.1ms\n",
      "Speed: 2.3ms preprocess, 34.1ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/68.jpg: 384x640 1 spoon, 44.1ms\n",
      "Speed: 2.2ms preprocess, 44.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/69.jpg: 384x640 1 bottle, 1 spoon, 52.0ms\n",
      "Speed: 2.2ms preprocess, 52.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/70.jpg: 384x640 1 spoon, 32.7ms\n",
      "Speed: 2.2ms preprocess, 32.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/71.jpg: 384x640 1 spoon, 31.8ms\n",
      "Speed: 2.6ms preprocess, 31.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/72.jpg: 384x640 1 spoon, 39.2ms\n",
      "Speed: 1.8ms preprocess, 39.2ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/73.jpg: 384x640 1 spoon, 41.1ms\n",
      "Speed: 1.7ms preprocess, 41.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/74.jpg: 384x640 1 spoon, 58.4ms\n",
      "Speed: 3.1ms preprocess, 58.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/75.jpg: 384x640 1 bottle, 1 spoon, 35.4ms\n",
      "Speed: 1.9ms preprocess, 35.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/76.jpg: 384x640 1 bottle, 1 spoon, 35.5ms\n",
      "Speed: 1.8ms preprocess, 35.5ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/77.jpg: 384x640 1 bottle, 1 spoon, 29.5ms\n",
      "Speed: 1.9ms preprocess, 29.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/78.jpg: 384x640 1 bottle, 1 spoon, 37.1ms\n",
      "Speed: 3.0ms preprocess, 37.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/79.jpg: 384x640 1 spoon, 37.6ms\n",
      "Speed: 2.7ms preprocess, 37.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/80.jpg: 384x640 1 bottle, 1 spoon, 27.3ms\n",
      "Speed: 1.9ms preprocess, 27.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/81.jpg: 384x640 1 bottle, 1 spoon, 45.1ms\n",
      "Speed: 1.8ms preprocess, 45.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/82.jpg: 384x640 1 bottle, 1 spoon, 35.7ms\n",
      "Speed: 1.9ms preprocess, 35.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/83.jpg: 384x640 1 bottle, 1 spoon, 50.1ms\n",
      "Speed: 2.8ms preprocess, 50.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/84.jpg: 384x640 1 bottle, 1 spoon, 31.7ms\n",
      "Speed: 1.9ms preprocess, 31.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/85.jpg: 384x640 1 bottle, 1 knife, 1 spoon, 52.0ms\n",
      "Speed: 2.7ms preprocess, 52.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/86.jpg: 384x640 1 bottle, 1 knife, 1 spoon, 33.9ms\n",
      "Speed: 1.7ms preprocess, 33.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/87.jpg: 384x640 1 bottle, 1 knife, 47.9ms\n",
      "Speed: 1.9ms preprocess, 47.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/88.jpg: 384x640 1 bottle, 1 spoon, 40.0ms\n",
      "Speed: 3.1ms preprocess, 40.0ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/89.jpg: 384x640 1 bottle, 1 spoon, 51.4ms\n",
      "Speed: 3.6ms preprocess, 51.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/90.jpg: 384x640 1 bottle, 1 spoon, 47.2ms\n",
      "Speed: 1.7ms preprocess, 47.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/91.jpg: 384x640 1 bottle, 36.7ms\n",
      "Speed: 2.5ms preprocess, 36.7ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/92.jpg: 384x640 1 bottle, 1 spoon, 41.8ms\n",
      "Speed: 2.1ms preprocess, 41.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/93.jpg: 384x640 1 bottle, 1 spoon, 36.3ms\n",
      "Speed: 1.9ms preprocess, 36.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/94.jpg: 384x640 (no detections), 39.1ms\n",
      "Speed: 2.7ms preprocess, 39.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/95.jpg: 384x640 1 spoon, 1 carrot, 38.7ms\n",
      "Speed: 1.7ms preprocess, 38.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/96.jpg: 384x640 1 spoon, 1 carrot, 29.3ms\n",
      "Speed: 1.7ms preprocess, 29.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/97.jpg: 384x640 1 spoon, 1 carrot, 30.6ms\n",
      "Speed: 1.8ms preprocess, 30.6ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/98.jpg: 384x640 1 spoon, 44.2ms\n",
      "Speed: 2.6ms preprocess, 44.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/99.jpg: 384x640 1 spoon, 2 carrots, 31.8ms\n",
      "Speed: 1.7ms preprocess, 31.8ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/100.jpg: 384x640 1 spoon, 35.1ms\n",
      "Speed: 1.7ms preprocess, 35.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/101.jpg: 384x640 1 spoon, 2 carrots, 45.7ms\n",
      "Speed: 2.9ms preprocess, 45.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/102.jpg: 384x640 (no detections), 43.5ms\n",
      "Speed: 3.4ms preprocess, 43.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/103.jpg: 384x640 1 baseball bat, 31.1ms\n",
      "Speed: 1.7ms preprocess, 31.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/104.jpg: 384x640 1 carrot, 29.8ms\n",
      "Speed: 1.7ms preprocess, 29.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/105.jpg: 384x640 (no detections), 35.6ms\n",
      "Speed: 2.8ms preprocess, 35.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/106.jpg: 384x640 1 baseball bat, 31.6ms\n",
      "Speed: 2.5ms preprocess, 31.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/107.jpg: 384x640 (no detections), 35.0ms\n",
      "Speed: 2.1ms preprocess, 35.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/108.jpg: 384x640 (no detections), 38.1ms\n",
      "Speed: 1.8ms preprocess, 38.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/109.jpg: 384x640 (no detections), 36.7ms\n",
      "Speed: 1.8ms preprocess, 36.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/110.jpg: 384x640 (no detections), 35.6ms\n",
      "Speed: 1.7ms preprocess, 35.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/111.jpg: 384x640 1 knife, 1 spoon, 1 carrot, 34.7ms\n",
      "Speed: 2.0ms preprocess, 34.7ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/112.jpg: 384x640 (no detections), 47.9ms\n",
      "Speed: 2.3ms preprocess, 47.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/113.jpg: 384x640 (no detections), 28.4ms\n",
      "Speed: 1.7ms preprocess, 28.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/114.jpg: 384x640 1 knife, 50.5ms\n",
      "Speed: 2.0ms preprocess, 50.5ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/115.jpg: 384x640 1 knife, 35.8ms\n",
      "Speed: 1.8ms preprocess, 35.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/116.jpg: 384x640 1 person, 1 knife, 40.1ms\n",
      "Speed: 4.1ms preprocess, 40.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/117.jpg: 384x640 (no detections), 37.2ms\n",
      "Speed: 2.9ms preprocess, 37.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/118.jpg: 384x640 (no detections), 37.2ms\n",
      "Speed: 1.9ms preprocess, 37.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/119.jpg: 384x640 1 person, 38.0ms\n",
      "Speed: 2.8ms preprocess, 38.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/120.jpg: 384x640 1 knife, 1 carrot, 29.2ms\n",
      "Speed: 1.7ms preprocess, 29.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/121.jpg: 384x640 1 knife, 51.0ms\n",
      "Speed: 3.0ms preprocess, 51.0ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/122.jpg: 384x640 1 spoon, 33.7ms\n",
      "Speed: 2.0ms preprocess, 33.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/123.jpg: 384x640 1 knife, 31.9ms\n",
      "Speed: 1.8ms preprocess, 31.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/124.jpg: 384x640 1 knife, 45.9ms\n",
      "Speed: 1.9ms preprocess, 45.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/125.jpg: 384x640 1 spoon, 42.5ms\n",
      "Speed: 2.7ms preprocess, 42.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/126.jpg: 384x640 1 spoon, 1 carrot, 39.3ms\n",
      "Speed: 1.9ms preprocess, 39.3ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/127.jpg: 384x640 (no detections), 31.8ms\n",
      "Speed: 1.9ms preprocess, 31.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/128.jpg: 384x640 1 carrot, 28.8ms\n",
      "Speed: 2.0ms preprocess, 28.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/129.jpg: 384x640 1 knife, 37.2ms\n",
      "Speed: 2.0ms preprocess, 37.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/130.jpg: 384x640 1 spoon, 35.6ms\n",
      "Speed: 1.9ms preprocess, 35.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/131.jpg: 384x640 1 bottle, 44.7ms\n",
      "Speed: 1.7ms preprocess, 44.7ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/132.jpg: 384x640 1 bottle, 42.8ms\n",
      "Speed: 1.8ms preprocess, 42.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/133.jpg: 384x640 (no detections), 32.7ms\n",
      "Speed: 1.9ms preprocess, 32.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/134.jpg: 384x640 (no detections), 37.5ms\n",
      "Speed: 1.8ms preprocess, 37.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/135.jpg: 384x640 1 carrot, 72.9ms\n",
      "Speed: 3.3ms preprocess, 72.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/136.jpg: 384x640 1 carrot, 59.9ms\n",
      "Speed: 3.3ms preprocess, 59.9ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/137.jpg: 384x640 1 carrot, 41.7ms\n",
      "Speed: 2.0ms preprocess, 41.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/138.jpg: 384x640 1 carrot, 80.5ms\n",
      "Speed: 2.3ms preprocess, 80.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/139.jpg: 384x640 1 bottle, 1 carrot, 51.0ms\n",
      "Speed: 3.2ms preprocess, 51.0ms inference, 7.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/140.jpg: 384x640 1 bottle, 2 carrots, 47.8ms\n",
      "Speed: 1.9ms preprocess, 47.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/141.jpg: 384x640 1 spoon, 1 carrot, 66.1ms\n",
      "Speed: 2.1ms preprocess, 66.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/142.jpg: 384x640 1 spoon, 1 carrot, 37.4ms\n",
      "Speed: 2.0ms preprocess, 37.4ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/143.jpg: 384x640 (no detections), 43.0ms\n",
      "Speed: 2.0ms preprocess, 43.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/144.jpg: 384x640 1 spoon, 1 carrot, 65.3ms\n",
      "Speed: 3.4ms preprocess, 65.3ms inference, 8.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/145.jpg: 384x640 1 spoon, 1 carrot, 48.9ms\n",
      "Speed: 3.1ms preprocess, 48.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/146.jpg: 384x640 1 bottle, 1 knife, 35.0ms\n",
      "Speed: 1.8ms preprocess, 35.0ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/147.jpg: 384x640 1 knife, 39.5ms\n",
      "Speed: 1.6ms preprocess, 39.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/148.jpg: 384x640 1 knife, 1 carrot, 36.0ms\n",
      "Speed: 2.4ms preprocess, 36.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/149.jpg: 384x640 1 knife, 31.0ms\n",
      "Speed: 1.7ms preprocess, 31.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/150.jpg: 384x640 1 knife, 46.7ms\n",
      "Speed: 2.5ms preprocess, 46.7ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/151.jpg: 384x640 1 knife, 40.4ms\n",
      "Speed: 2.8ms preprocess, 40.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/152.jpg: 384x640 1 spoon, 37.3ms\n",
      "Speed: 1.9ms preprocess, 37.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/153.jpg: 384x640 1 knife, 1 spoon, 28.4ms\n",
      "Speed: 1.9ms preprocess, 28.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/154.jpg: 384x640 1 knife, 1 spoon, 40.9ms\n",
      "Speed: 3.7ms preprocess, 40.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/155.jpg: 384x640 1 knife, 1 spoon, 40.0ms\n",
      "Speed: 2.1ms preprocess, 40.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/156.jpg: 384x640 1 spoon, 1 carrot, 42.1ms\n",
      "Speed: 2.9ms preprocess, 42.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/157.jpg: 384x640 1 spoon, 32.9ms\n",
      "Speed: 2.2ms preprocess, 32.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/158.jpg: 384x640 1 knife, 1 spoon, 31.5ms\n",
      "Speed: 2.0ms preprocess, 31.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/159.jpg: 384x640 1 knife, 1 spoon, 36.3ms\n",
      "Speed: 1.7ms preprocess, 36.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/160.jpg: 384x640 1 knife, 1 spoon, 29.5ms\n",
      "Speed: 2.0ms preprocess, 29.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/161.jpg: 384x640 1 knife, 32.6ms\n",
      "Speed: 1.8ms preprocess, 32.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/162.jpg: 384x640 1 spoon, 42.0ms\n",
      "Speed: 1.8ms preprocess, 42.0ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/163.jpg: 384x640 1 spoon, 31.5ms\n",
      "Speed: 2.2ms preprocess, 31.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/164.jpg: 384x640 1 knife, 1 spoon, 35.2ms\n",
      "Speed: 1.8ms preprocess, 35.2ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/165.jpg: 384x640 1 spoon, 34.6ms\n",
      "Speed: 3.2ms preprocess, 34.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/166.jpg: 384x640 1 knife, 1 spoon, 1 carrot, 40.3ms\n",
      "Speed: 1.8ms preprocess, 40.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/167.jpg: 384x640 1 spoon, 39.9ms\n",
      "Speed: 1.7ms preprocess, 39.9ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/168.jpg: 384x640 1 spoon, 32.4ms\n",
      "Speed: 1.8ms preprocess, 32.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/169.jpg: 384x640 1 spoon, 1 carrot, 29.9ms\n",
      "Speed: 1.9ms preprocess, 29.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/170.jpg: 384x640 2 spoons, 1 carrot, 32.7ms\n",
      "Speed: 1.7ms preprocess, 32.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/171.jpg: 384x640 1 spoon, 35.8ms\n",
      "Speed: 1.7ms preprocess, 35.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/172.jpg: 384x640 1 knife, 1 spoon, 1 carrot, 30.7ms\n",
      "Speed: 1.7ms preprocess, 30.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/173.jpg: 384x640 1 knife, 30.3ms\n",
      "Speed: 1.7ms preprocess, 30.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/174.jpg: 384x640 1 knife, 1 spoon, 1 carrot, 29.6ms\n",
      "Speed: 1.7ms preprocess, 29.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/175.jpg: 384x640 1 spoon, 1 carrot, 33.3ms\n",
      "Speed: 2.8ms preprocess, 33.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/176.jpg: 384x640 1 knife, 1 carrot, 45.5ms\n",
      "Speed: 4.8ms preprocess, 45.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/177.jpg: 384x640 1 knife, 1 spoon, 1 carrot, 35.4ms\n",
      "Speed: 2.8ms preprocess, 35.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/178.jpg: 384x640 1 knife, 1 carrot, 41.8ms\n",
      "Speed: 2.8ms preprocess, 41.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/179.jpg: 384x640 1 carrot, 34.2ms\n",
      "Speed: 1.9ms preprocess, 34.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/180.jpg: 384x640 1 spoon, 1 carrot, 40.0ms\n",
      "Speed: 1.9ms preprocess, 40.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/181.jpg: 384x640 1 baseball bat, 1 carrot, 28.9ms\n",
      "Speed: 2.7ms preprocess, 28.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/182.jpg: 384x640 1 spoon, 1 carrot, 29.3ms\n",
      "Speed: 1.9ms preprocess, 29.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/183.jpg: 384x640 (no detections), 28.4ms\n",
      "Speed: 2.0ms preprocess, 28.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/184.jpg: 384x640 1 knife, 1 carrot, 31.7ms\n",
      "Speed: 1.8ms preprocess, 31.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/185.jpg: 384x640 1 knife, 1 carrot, 32.0ms\n",
      "Speed: 1.9ms preprocess, 32.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/186.jpg: 384x640 1 carrot, 41.6ms\n",
      "Speed: 1.8ms preprocess, 41.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/187.jpg: 384x640 1 knife, 1 carrot, 28.2ms\n",
      "Speed: 1.8ms preprocess, 28.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/188.jpg: 384x640 1 carrot, 33.2ms\n",
      "Speed: 1.6ms preprocess, 33.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/189.jpg: 384x640 1 carrot, 45.5ms\n",
      "Speed: 2.1ms preprocess, 45.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/190.jpg: 384x640 1 carrot, 30.3ms\n",
      "Speed: 1.7ms preprocess, 30.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/191.jpg: 384x640 1 baseball bat, 1 carrot, 39.9ms\n",
      "Speed: 1.8ms preprocess, 39.9ms inference, 8.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/192.jpg: 384x640 1 knife, 1 carrot, 35.0ms\n",
      "Speed: 2.2ms preprocess, 35.0ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/193.jpg: 384x640 1 baseball bat, 1 carrot, 33.4ms\n",
      "Speed: 1.7ms preprocess, 33.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/194.jpg: 384x640 1 baseball bat, 1 carrot, 33.2ms\n",
      "Speed: 2.6ms preprocess, 33.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/195.jpg: 384x640 1 baseball bat, 37.9ms\n",
      "Speed: 2.5ms preprocess, 37.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/196.jpg: 384x640 1 carrot, 40.4ms\n",
      "Speed: 3.5ms preprocess, 40.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/197.jpg: 384x640 1 carrot, 38.7ms\n",
      "Speed: 2.5ms preprocess, 38.7ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/198.jpg: 384x640 (no detections), 32.9ms\n",
      "Speed: 1.6ms preprocess, 32.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/199.jpg: 384x640 1 baseball bat, 45.8ms\n",
      "Speed: 2.0ms preprocess, 45.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/200.jpg: 384x640 1 baseball bat, 1 bottle, 32.5ms\n",
      "Speed: 2.6ms preprocess, 32.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/201.jpg: 384x640 1 baseball bat, 38.8ms\n",
      "Speed: 1.7ms preprocess, 38.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/202.jpg: 384x640 1 person, 1 baseball bat, 39.0ms\n",
      "Speed: 2.0ms preprocess, 39.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/203.jpg: 384x640 2 baseball bats, 65.5ms\n",
      "Speed: 3.3ms preprocess, 65.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/204.jpg: 384x640 1 baseball bat, 34.5ms\n",
      "Speed: 1.9ms preprocess, 34.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/205.jpg: 384x640 1 baseball bat, 1 carrot, 40.4ms\n",
      "Speed: 1.8ms preprocess, 40.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/206.jpg: 384x640 1 baseball bat, 45.2ms\n",
      "Speed: 2.1ms preprocess, 45.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/207.jpg: 384x640 2 baseball bats, 1 carrot, 29.1ms\n",
      "Speed: 3.2ms preprocess, 29.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/208.jpg: 384x640 2 baseball bats, 1 carrot, 42.2ms\n",
      "Speed: 2.1ms preprocess, 42.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/209.jpg: 384x640 1 baseball bat, 1 carrot, 44.0ms\n",
      "Speed: 1.7ms preprocess, 44.0ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/210.jpg: 384x640 2 baseball bats, 1 carrot, 30.9ms\n",
      "Speed: 2.0ms preprocess, 30.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/211.jpg: 384x640 1 baseball bat, 65.5ms\n",
      "Speed: 2.0ms preprocess, 65.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/212.jpg: 384x640 1 person, 27.8ms\n",
      "Speed: 1.8ms preprocess, 27.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/213.jpg: 384x640 1 person, 2 baseball bats, 38.3ms\n",
      "Speed: 2.0ms preprocess, 38.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/214.jpg: 384x640 1 baseball bat, 31.1ms\n",
      "Speed: 1.7ms preprocess, 31.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/215.jpg: 384x640 1 baseball bat, 34.9ms\n",
      "Speed: 1.8ms preprocess, 34.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/216.jpg: 384x640 2 baseball bats, 35.1ms\n",
      "Speed: 2.0ms preprocess, 35.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/217.jpg: 384x640 1 baseball bat, 28.8ms\n",
      "Speed: 2.0ms preprocess, 28.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/218.jpg: 384x640 2 baseball bats, 38.7ms\n",
      "Speed: 1.9ms preprocess, 38.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/219.jpg: 384x640 2 baseball bats, 32.1ms\n",
      "Speed: 2.0ms preprocess, 32.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/220.jpg: 384x640 1 baseball bat, 1 bottle, 58.9ms\n",
      "Speed: 2.0ms preprocess, 58.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/221.jpg: 384x640 2 baseball bats, 1 spoon, 33.8ms\n",
      "Speed: 1.9ms preprocess, 33.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/222.jpg: 384x640 (no detections), 44.6ms\n",
      "Speed: 2.5ms preprocess, 44.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/223.jpg: 384x640 (no detections), 58.0ms\n",
      "Speed: 1.9ms preprocess, 58.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/224.jpg: 384x640 1 spoon, 31.5ms\n",
      "Speed: 2.0ms preprocess, 31.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/225.jpg: 384x640 1 spoon, 1 carrot, 34.8ms\n",
      "Speed: 1.9ms preprocess, 34.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/226.jpg: 384x640 1 spoon, 33.1ms\n",
      "Speed: 1.8ms preprocess, 33.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/227.jpg: 384x640 1 baseball bat, 42.3ms\n",
      "Speed: 3.1ms preprocess, 42.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/228.jpg: 384x640 1 baseball bat, 38.1ms\n",
      "Speed: 1.8ms preprocess, 38.1ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/229.jpg: 384x640 1 baseball bat, 1 carrot, 27.1ms\n",
      "Speed: 1.7ms preprocess, 27.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/230.jpg: 384x640 1 spoon, 1 carrot, 38.2ms\n",
      "Speed: 2.3ms preprocess, 38.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/231.jpg: 384x640 (no detections), 29.8ms\n",
      "Speed: 2.0ms preprocess, 29.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/232.jpg: 384x640 (no detections), 31.4ms\n",
      "Speed: 2.4ms preprocess, 31.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/233.jpg: 384x640 1 spoon, 1 carrot, 42.8ms\n",
      "Speed: 1.9ms preprocess, 42.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/234.jpg: 384x640 1 spoon, 39.7ms\n",
      "Speed: 1.9ms preprocess, 39.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/235.jpg: 384x640 (no detections), 39.8ms\n",
      "Speed: 2.1ms preprocess, 39.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/236.jpg: 384x640 1 person, 1 spoon, 32.0ms\n",
      "Speed: 2.1ms preprocess, 32.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/237.jpg: 384x640 (no detections), 38.0ms\n",
      "Speed: 2.1ms preprocess, 38.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/238.jpg: 384x640 (no detections), 35.7ms\n",
      "Speed: 2.0ms preprocess, 35.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/239.jpg: 384x640 1 person, 37.2ms\n",
      "Speed: 2.8ms preprocess, 37.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/240.jpg: 384x640 (no detections), 62.3ms\n",
      "Speed: 2.5ms preprocess, 62.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/241.jpg: 384x640 1 carrot, 33.9ms\n",
      "Speed: 1.8ms preprocess, 33.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/242.jpg: 384x640 1 carrot, 47.5ms\n",
      "Speed: 1.8ms preprocess, 47.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/243.jpg: 384x640 1 knife, 1 scissors, 30.9ms\n",
      "Speed: 1.7ms preprocess, 30.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/244.jpg: 384x640 1 knife, 1 scissors, 35.7ms\n",
      "Speed: 1.7ms preprocess, 35.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/245.jpg: 384x640 1 knife, 32.0ms\n",
      "Speed: 1.7ms preprocess, 32.0ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/246.jpg: 384x640 (no detections), 40.9ms\n",
      "Speed: 2.9ms preprocess, 40.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/247.jpg: 384x640 1 knife, 49.8ms\n",
      "Speed: 1.7ms preprocess, 49.8ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/248.jpg: 384x640 1 knife, 33.5ms\n",
      "Speed: 2.4ms preprocess, 33.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/249.jpg: 384x640 1 knife, 49.0ms\n",
      "Speed: 2.2ms preprocess, 49.0ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/250.jpg: 384x640 1 knife, 38.2ms\n",
      "Speed: 2.5ms preprocess, 38.2ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/251.jpg: 384x640 1 bottle, 55.9ms\n",
      "Speed: 2.3ms preprocess, 55.9ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/252.jpg: 384x640 1 spoon, 1 carrot, 39.1ms\n",
      "Speed: 2.1ms preprocess, 39.1ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/253.jpg: 384x640 1 bottle, 63.7ms\n",
      "Speed: 2.1ms preprocess, 63.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/254.jpg: 384x640 1 knife, 1 carrot, 39.0ms\n",
      "Speed: 2.0ms preprocess, 39.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/255.jpg: 384x640 1 knife, 42.1ms\n",
      "Speed: 3.0ms preprocess, 42.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/256.jpg: 384x640 1 knife, 48.3ms\n",
      "Speed: 2.0ms preprocess, 48.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/257.jpg: 384x640 1 bottle, 42.6ms\n",
      "Speed: 2.7ms preprocess, 42.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/258.jpg: 384x640 1 knife, 44.9ms\n",
      "Speed: 2.0ms preprocess, 44.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/259.jpg: 384x640 1 knife, 55.6ms\n",
      "Speed: 2.9ms preprocess, 55.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/260.jpg: 384x640 1 knife, 33.3ms\n",
      "Speed: 1.7ms preprocess, 33.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/261.jpg: 384x640 1 baseball bat, 1 bottle, 1 knife, 1 carrot, 40.5ms\n",
      "Speed: 3.0ms preprocess, 40.5ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/262.jpg: 384x640 1 knife, 45.6ms\n",
      "Speed: 3.2ms preprocess, 45.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/263.jpg: 384x640 1 bottle, 1 carrot, 33.6ms\n",
      "Speed: 1.9ms preprocess, 33.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/264.jpg: 384x640 1 carrot, 43.6ms\n",
      "Speed: 2.8ms preprocess, 43.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/265.jpg: 384x640 1 bottle, 37.4ms\n",
      "Speed: 1.8ms preprocess, 37.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/266.jpg: 384x640 1 bottle, 1 carrot, 35.4ms\n",
      "Speed: 2.2ms preprocess, 35.4ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/267.jpg: 384x640 1 bottle, 42.7ms\n",
      "Speed: 1.9ms preprocess, 42.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/268.jpg: 384x640 1 knife, 43.0ms\n",
      "Speed: 3.3ms preprocess, 43.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/269.jpg: 384x640 1 baseball bat, 1 bottle, 1 carrot, 42.4ms\n",
      "Speed: 1.7ms preprocess, 42.4ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/270.jpg: 384x640 (no detections), 33.2ms\n",
      "Speed: 2.1ms preprocess, 33.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/271.jpg: 384x640 1 baseball bat, 30.9ms\n",
      "Speed: 1.8ms preprocess, 30.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/272.jpg: 384x640 1 knife, 34.2ms\n",
      "Speed: 1.8ms preprocess, 34.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/273.jpg: 384x640 1 knife, 30.4ms\n",
      "Speed: 1.7ms preprocess, 30.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/274.jpg: 384x640 1 knife, 37.9ms\n",
      "Speed: 2.0ms preprocess, 37.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/275.jpg: 384x640 1 knife, 35.0ms\n",
      "Speed: 2.0ms preprocess, 35.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/276.jpg: 384x640 1 knife, 28.9ms\n",
      "Speed: 1.9ms preprocess, 28.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/277.jpg: 384x640 1 knife, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/278.jpg: 384x640 1 spoon, 29.9ms\n",
      "Speed: 2.7ms preprocess, 29.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/279.jpg: 384x640 1 knife, 54.5ms\n",
      "Speed: 2.4ms preprocess, 54.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/280.jpg: 384x640 (no detections), 27.5ms\n",
      "Speed: 2.1ms preprocess, 27.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/281.jpg: 384x640 1 bottle, 1 carrot, 46.5ms\n",
      "Speed: 2.1ms preprocess, 46.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/282.jpg: 384x640 1 baseball bat, 1 bottle, 28.0ms\n",
      "Speed: 1.7ms preprocess, 28.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/283.jpg: 384x640 1 carrot, 42.2ms\n",
      "Speed: 1.9ms preprocess, 42.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/284.jpg: 384x640 1 spoon, 1 carrot, 37.9ms\n",
      "Speed: 2.0ms preprocess, 37.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/285.jpg: 384x640 1 spoon, 1 carrot, 38.3ms\n",
      "Speed: 1.8ms preprocess, 38.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/286.jpg: 384x640 1 spoon, 1 carrot, 39.5ms\n",
      "Speed: 2.0ms preprocess, 39.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/287.jpg: 384x640 1 spoon, 40.1ms\n",
      "Speed: 2.8ms preprocess, 40.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/288.jpg: 384x640 (no detections), 42.0ms\n",
      "Speed: 2.1ms preprocess, 42.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/289.jpg: 384x640 (no detections), 39.7ms\n",
      "Speed: 1.7ms preprocess, 39.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/290.jpg: 384x640 1 carrot, 28.8ms\n",
      "Speed: 2.0ms preprocess, 28.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/291.jpg: 384x640 (no detections), 46.3ms\n",
      "Speed: 2.9ms preprocess, 46.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/292.jpg: 384x640 (no detections), 51.3ms\n",
      "Speed: 1.8ms preprocess, 51.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/293.jpg: 384x640 1 carrot, 37.5ms\n",
      "Speed: 2.7ms preprocess, 37.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/294.jpg: 384x640 (no detections), 52.1ms\n",
      "Speed: 1.9ms preprocess, 52.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/295.jpg: 384x640 1 carrot, 48.7ms\n",
      "Speed: 4.1ms preprocess, 48.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/296.jpg: 384x640 1 carrot, 32.8ms\n",
      "Speed: 2.0ms preprocess, 32.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/297.jpg: 384x640 1 carrot, 30.3ms\n",
      "Speed: 1.9ms preprocess, 30.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/298.jpg: 384x640 1 carrot, 34.9ms\n",
      "Speed: 2.0ms preprocess, 34.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/left/299.jpg: 384x640 1 knife, 34.5ms\n",
      "Speed: 2.0ms preprocess, 34.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Propagating video frames: 100%|| 300/300 [00:23<00:00, 12.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask propagation completed in 23.99 seconds.\n",
      "Processing predicted masks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing video frames: 300it [00:01, 267.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 300 masks for evaluation.\n",
      "Masks saved to data/masks/yolo11x-seg/val/data-raw-SegSTRONGC_val-val-1-1-blood-left.pkl\n",
      "Loading ground truth masks for evaluation...\n",
      "Loaded 300 ground truth masks.\n",
      "Calculating evaluation metrics...\n",
      "Time taken for metrics calculation: 1.35 seconds.\n",
      "Mean IoU for data/raw/SegSTRONGC_val/val/1/1/blood/left: 0.2834\n",
      "Mean DSC for data/raw/SegSTRONGC_val/val/1/1/blood/left: 0.3897\n",
      "Loading existing results file: data/results/yolo11x-seg/val.json\n",
      "Results saved to data/results/yolo11x-seg/val.json\n",
      "Processing video took 29.47 seconds.\n",
      "==================================================\n",
      "Processing right camera video...\n",
      "==================================================\n",
      "Processing video: data/raw/SegSTRONGC_val/val/1/1/blood/right\n",
      "Domain: blood, Split: val, Camera: right\n",
      "Initializing Yolo for video...\n",
      "Initialization took 1.23 seconds.\n",
      "Starting mask propagation...\n",
      "Total images in video: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/0.jpg: 384x640 1 spoon, 75.4ms\n",
      "Speed: 2.4ms preprocess, 75.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/1.jpg: 384x640 2 spoons, 48.2ms\n",
      "Speed: 2.2ms preprocess, 48.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/2.jpg: 384x640 1 bottle, 1 spoon, 1 carrot, 45.2ms\n",
      "Speed: 2.6ms preprocess, 45.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/3.jpg: 384x640 1 knife, 1 spoon, 30.4ms\n",
      "Speed: 1.9ms preprocess, 30.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/4.jpg: 384x640 2 spoons, 36.0ms\n",
      "Speed: 1.7ms preprocess, 36.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/5.jpg: 384x640 2 spoons, 27.8ms\n",
      "Speed: 1.8ms preprocess, 27.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/6.jpg: 384x640 2 spoons, 1 carrot, 28.9ms\n",
      "Speed: 1.7ms preprocess, 28.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/7.jpg: 384x640 1 spoon, 1 carrot, 38.0ms\n",
      "Speed: 3.1ms preprocess, 38.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/8.jpg: 384x640 1 spoon, 2 carrots, 36.2ms\n",
      "Speed: 2.2ms preprocess, 36.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/9.jpg: 384x640 1 spoon, 2 carrots, 33.7ms\n",
      "Speed: 3.2ms preprocess, 33.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/10.jpg: 384x640 1 spoon, 2 carrots, 37.7ms\n",
      "Speed: 2.0ms preprocess, 37.7ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/11.jpg: 384x640 1 spoon, 2 carrots, 29.5ms\n",
      "Speed: 1.8ms preprocess, 29.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/12.jpg: 384x640 1 spoon, 1 carrot, 27.6ms\n",
      "Speed: 1.6ms preprocess, 27.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/13.jpg: 384x640 1 carrot, 38.9ms\n",
      "Speed: 2.4ms preprocess, 38.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/14.jpg: 384x640 1 spoon, 4 carrots, 27.7ms\n",
      "Speed: 1.8ms preprocess, 27.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/15.jpg: 384x640 1 spoon, 3 carrots, 36.0ms\n",
      "Speed: 2.8ms preprocess, 36.0ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/16.jpg: 384x640 1 carrot, 30.6ms\n",
      "Speed: 2.1ms preprocess, 30.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/17.jpg: 384x640 1 spoon, 3 carrots, 39.0ms\n",
      "Speed: 1.8ms preprocess, 39.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/18.jpg: 384x640 1 carrot, 42.2ms\n",
      "Speed: 1.8ms preprocess, 42.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/19.jpg: 384x640 1 spoon, 2 carrots, 42.3ms\n",
      "Speed: 1.9ms preprocess, 42.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/20.jpg: 384x640 1 bottle, 2 spoons, 32.8ms\n",
      "Speed: 2.4ms preprocess, 32.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/21.jpg: 384x640 1 baseball bat, 1 bottle, 1 spoon, 3 carrots, 29.6ms\n",
      "Speed: 1.9ms preprocess, 29.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/22.jpg: 384x640 1 bottle, 1 spoon, 32.0ms\n",
      "Speed: 3.2ms preprocess, 32.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/23.jpg: 384x640 1 bottle, 1 spoon, 2 carrots, 33.5ms\n",
      "Speed: 1.9ms preprocess, 33.5ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/24.jpg: 384x640 1 spoon, 37.8ms\n",
      "Speed: 2.0ms preprocess, 37.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/25.jpg: 384x640 1 spoon, 31.4ms\n",
      "Speed: 2.0ms preprocess, 31.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/26.jpg: 384x640 2 spoons, 1 carrot, 33.1ms\n",
      "Speed: 2.0ms preprocess, 33.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/27.jpg: 384x640 1 spoon, 3 carrots, 30.3ms\n",
      "Speed: 1.6ms preprocess, 30.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/28.jpg: 384x640 1 spoon, 1 carrot, 39.9ms\n",
      "Speed: 2.0ms preprocess, 39.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/29.jpg: 384x640 2 spoons, 3 carrots, 28.2ms\n",
      "Speed: 1.9ms preprocess, 28.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/30.jpg: 384x640 2 spoons, 3 carrots, 30.2ms\n",
      "Speed: 1.8ms preprocess, 30.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/31.jpg: 384x640 1 spoon, 5 carrots, 44.0ms\n",
      "Speed: 1.9ms preprocess, 44.0ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/32.jpg: 384x640 3 spoons, 6 carrots, 41.5ms\n",
      "Speed: 2.0ms preprocess, 41.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/33.jpg: 384x640 1 spoon, 5 carrots, 32.3ms\n",
      "Speed: 2.0ms preprocess, 32.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/34.jpg: 384x640 2 spoons, 1 carrot, 54.3ms\n",
      "Speed: 2.2ms preprocess, 54.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/35.jpg: 384x640 3 spoons, 2 carrots, 40.1ms\n",
      "Speed: 2.7ms preprocess, 40.1ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/36.jpg: 384x640 3 spoons, 3 carrots, 47.4ms\n",
      "Speed: 2.7ms preprocess, 47.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/37.jpg: 384x640 1 baseball bat, 2 spoons, 2 carrots, 34.7ms\n",
      "Speed: 2.2ms preprocess, 34.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/38.jpg: 384x640 2 spoons, 3 carrots, 55.5ms\n",
      "Speed: 3.4ms preprocess, 55.5ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/39.jpg: 384x640 2 spoons, 4 carrots, 37.5ms\n",
      "Speed: 2.2ms preprocess, 37.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/40.jpg: 384x640 2 spoons, 1 carrot, 40.1ms\n",
      "Speed: 2.7ms preprocess, 40.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/41.jpg: 384x640 2 spoons, 1 carrot, 37.7ms\n",
      "Speed: 1.8ms preprocess, 37.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/42.jpg: 384x640 2 spoons, 1 carrot, 32.7ms\n",
      "Speed: 1.9ms preprocess, 32.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/43.jpg: 384x640 2 spoons, 2 carrots, 56.1ms\n",
      "Speed: 3.3ms preprocess, 56.1ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/44.jpg: 384x640 1 spoon, 3 carrots, 43.3ms\n",
      "Speed: 1.9ms preprocess, 43.3ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/45.jpg: 384x640 1 spoon, 2 carrots, 28.7ms\n",
      "Speed: 2.1ms preprocess, 28.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/46.jpg: 384x640 1 spoon, 2 carrots, 33.7ms\n",
      "Speed: 3.2ms preprocess, 33.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/47.jpg: 384x640 1 spoon, 4 carrots, 29.9ms\n",
      "Speed: 1.8ms preprocess, 29.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/48.jpg: 384x640 1 spoon, 3 carrots, 43.5ms\n",
      "Speed: 2.4ms preprocess, 43.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/49.jpg: 384x640 2 spoons, 4 carrots, 31.8ms\n",
      "Speed: 2.3ms preprocess, 31.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/50.jpg: 384x640 1 spoon, 3 carrots, 29.6ms\n",
      "Speed: 1.7ms preprocess, 29.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/51.jpg: 384x640 1 spoon, 4 carrots, 34.9ms\n",
      "Speed: 1.9ms preprocess, 34.9ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/52.jpg: 384x640 1 bottle, 1 spoon, 1 carrot, 55.4ms\n",
      "Speed: 2.3ms preprocess, 55.4ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/53.jpg: 384x640 1 spoon, 35.9ms\n",
      "Speed: 2.7ms preprocess, 35.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/54.jpg: 384x640 2 spoons, 47.3ms\n",
      "Speed: 1.8ms preprocess, 47.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/55.jpg: 384x640 1 carrot, 38.7ms\n",
      "Speed: 1.9ms preprocess, 38.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/56.jpg: 384x640 1 knife, 36.3ms\n",
      "Speed: 2.0ms preprocess, 36.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/57.jpg: 384x640 1 spoon, 29.4ms\n",
      "Speed: 1.7ms preprocess, 29.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/58.jpg: 384x640 1 spoon, 53.3ms\n",
      "Speed: 2.3ms preprocess, 53.3ms inference, 7.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/59.jpg: 384x640 1 spoon, 54.1ms\n",
      "Speed: 2.7ms preprocess, 54.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/60.jpg: 384x640 1 spoon, 40.9ms\n",
      "Speed: 2.9ms preprocess, 40.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/61.jpg: 384x640 1 baseball bat, 1 spoon, 41.9ms\n",
      "Speed: 3.1ms preprocess, 41.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/62.jpg: 384x640 1 baseball bat, 1 spoon, 37.1ms\n",
      "Speed: 2.2ms preprocess, 37.1ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/63.jpg: 384x640 1 spoon, 2 carrots, 43.7ms\n",
      "Speed: 4.0ms preprocess, 43.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/64.jpg: 384x640 1 spoon, 47.5ms\n",
      "Speed: 3.1ms preprocess, 47.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/65.jpg: 384x640 1 bottle, 1 spoon, 1 bowl, 61.8ms\n",
      "Speed: 3.3ms preprocess, 61.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/66.jpg: 384x640 1 spoon, 1 carrot, 56.3ms\n",
      "Speed: 2.2ms preprocess, 56.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/67.jpg: 384x640 1 spoon, 35.8ms\n",
      "Speed: 2.1ms preprocess, 35.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/68.jpg: 384x640 1 baseball bat, 1 spoon, 32.9ms\n",
      "Speed: 1.8ms preprocess, 32.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/69.jpg: 384x640 1 spoon, 60.3ms\n",
      "Speed: 3.5ms preprocess, 60.3ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/70.jpg: 384x640 1 baseball bat, 1 spoon, 34.4ms\n",
      "Speed: 2.0ms preprocess, 34.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/71.jpg: 384x640 1 spoon, 55.1ms\n",
      "Speed: 2.1ms preprocess, 55.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/72.jpg: 384x640 1 spoon, 38.5ms\n",
      "Speed: 1.7ms preprocess, 38.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/73.jpg: 384x640 1 bottle, 1 spoon, 31.0ms\n",
      "Speed: 1.8ms preprocess, 31.0ms inference, 8.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/74.jpg: 384x640 1 spoon, 38.5ms\n",
      "Speed: 3.3ms preprocess, 38.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/75.jpg: 384x640 1 baseball bat, 1 spoon, 31.7ms\n",
      "Speed: 2.3ms preprocess, 31.7ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/76.jpg: 384x640 1 spoon, 59.7ms\n",
      "Speed: 3.0ms preprocess, 59.7ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/77.jpg: 384x640 1 spoon, 1 carrot, 40.7ms\n",
      "Speed: 3.2ms preprocess, 40.7ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/78.jpg: 384x640 1 spoon, 55.6ms\n",
      "Speed: 2.1ms preprocess, 55.6ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/79.jpg: 384x640 1 bottle, 1 spoon, 45.9ms\n",
      "Speed: 1.9ms preprocess, 45.9ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/80.jpg: 384x640 1 spoon, 42.1ms\n",
      "Speed: 1.9ms preprocess, 42.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/81.jpg: 384x640 1 bottle, 1 spoon, 35.8ms\n",
      "Speed: 2.0ms preprocess, 35.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/82.jpg: 384x640 1 spoon, 38.3ms\n",
      "Speed: 1.7ms preprocess, 38.3ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/83.jpg: 384x640 1 bottle, 1 spoon, 37.1ms\n",
      "Speed: 1.9ms preprocess, 37.1ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/84.jpg: 384x640 1 bottle, 1 spoon, 38.7ms\n",
      "Speed: 2.9ms preprocess, 38.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/85.jpg: 384x640 1 bottle, 1 spoon, 30.2ms\n",
      "Speed: 2.1ms preprocess, 30.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/86.jpg: 384x640 1 bottle, 1 spoon, 35.8ms\n",
      "Speed: 2.8ms preprocess, 35.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/87.jpg: 384x640 1 bottle, 1 spoon, 60.7ms\n",
      "Speed: 2.1ms preprocess, 60.7ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/88.jpg: 384x640 1 bottle, 1 spoon, 40.8ms\n",
      "Speed: 1.9ms preprocess, 40.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/89.jpg: 384x640 1 bottle, 1 spoon, 46.9ms\n",
      "Speed: 2.1ms preprocess, 46.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/90.jpg: 384x640 1 bottle, 1 spoon, 32.0ms\n",
      "Speed: 1.9ms preprocess, 32.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/91.jpg: 384x640 1 spoon, 35.7ms\n",
      "Speed: 2.9ms preprocess, 35.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/92.jpg: 384x640 1 bottle, 1 spoon, 34.5ms\n",
      "Speed: 1.7ms preprocess, 34.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/93.jpg: 384x640 1 bottle, 1 spoon, 1 carrot, 40.6ms\n",
      "Speed: 2.2ms preprocess, 40.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/94.jpg: 384x640 1 bottle, 1 spoon, 40.3ms\n",
      "Speed: 2.1ms preprocess, 40.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/95.jpg: 384x640 1 spoon, 1 carrot, 50.2ms\n",
      "Speed: 2.0ms preprocess, 50.2ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/96.jpg: 384x640 1 spoon, 3 carrots, 43.0ms\n",
      "Speed: 1.9ms preprocess, 43.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/97.jpg: 384x640 1 spoon, 1 carrot, 30.2ms\n",
      "Speed: 1.9ms preprocess, 30.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/98.jpg: 384x640 1 spoon, 2 carrots, 53.5ms\n",
      "Speed: 1.9ms preprocess, 53.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/99.jpg: 384x640 1 spoon, 3 carrots, 33.4ms\n",
      "Speed: 1.9ms preprocess, 33.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/100.jpg: 384x640 1 fork, 1 spoon, 1 carrot, 54.2ms\n",
      "Speed: 2.9ms preprocess, 54.2ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/101.jpg: 384x640 1 spoon, 4 carrots, 47.3ms\n",
      "Speed: 2.2ms preprocess, 47.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/102.jpg: 384x640 1 spoon, 6 carrots, 31.4ms\n",
      "Speed: 2.4ms preprocess, 31.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/103.jpg: 384x640 1 spoon, 3 carrots, 33.6ms\n",
      "Speed: 2.1ms preprocess, 33.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/104.jpg: 384x640 3 carrots, 35.7ms\n",
      "Speed: 2.1ms preprocess, 35.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/105.jpg: 384x640 1 spoon, 2 carrots, 45.1ms\n",
      "Speed: 2.1ms preprocess, 45.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/106.jpg: 384x640 2 spoons, 3 carrots, 29.1ms\n",
      "Speed: 1.5ms preprocess, 29.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/107.jpg: 384x640 1 spoon, 37.7ms\n",
      "Speed: 2.2ms preprocess, 37.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/108.jpg: 384x640 1 spoon, 3 carrots, 33.9ms\n",
      "Speed: 1.7ms preprocess, 33.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/109.jpg: 384x640 1 spoon, 3 carrots, 46.4ms\n",
      "Speed: 2.1ms preprocess, 46.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/110.jpg: 384x640 1 spoon, 58.7ms\n",
      "Speed: 2.1ms preprocess, 58.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/111.jpg: 384x640 1 spoon, 4 carrots, 29.2ms\n",
      "Speed: 1.7ms preprocess, 29.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/112.jpg: 384x640 1 spoon, 4 carrots, 36.3ms\n",
      "Speed: 2.2ms preprocess, 36.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/113.jpg: 384x640 1 spoon, 3 carrots, 31.8ms\n",
      "Speed: 1.9ms preprocess, 31.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/114.jpg: 384x640 1 spoon, 3 carrots, 36.2ms\n",
      "Speed: 2.8ms preprocess, 36.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/115.jpg: 384x640 1 spoon, 1 carrot, 32.1ms\n",
      "Speed: 1.8ms preprocess, 32.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/116.jpg: 384x640 1 spoon, 5 carrots, 37.9ms\n",
      "Speed: 1.9ms preprocess, 37.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/117.jpg: 384x640 1 fork, 1 spoon, 38.0ms\n",
      "Speed: 2.0ms preprocess, 38.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/118.jpg: 384x640 4 carrots, 33.7ms\n",
      "Speed: 2.0ms preprocess, 33.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/119.jpg: 384x640 (no detections), 34.2ms\n",
      "Speed: 2.0ms preprocess, 34.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/120.jpg: 384x640 3 carrots, 39.6ms\n",
      "Speed: 2.3ms preprocess, 39.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/121.jpg: 384x640 1 fork, 1 spoon, 2 carrots, 29.5ms\n",
      "Speed: 1.8ms preprocess, 29.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/122.jpg: 384x640 1 fork, 3 carrots, 29.6ms\n",
      "Speed: 1.8ms preprocess, 29.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/123.jpg: 384x640 1 spoon, 3 carrots, 29.9ms\n",
      "Speed: 2.5ms preprocess, 29.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/124.jpg: 384x640 1 spoon, 29.5ms\n",
      "Speed: 1.8ms preprocess, 29.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/125.jpg: 384x640 1 spoon, 1 carrot, 38.0ms\n",
      "Speed: 2.0ms preprocess, 38.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/126.jpg: 384x640 1 spoon, 3 carrots, 38.5ms\n",
      "Speed: 3.0ms preprocess, 38.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/127.jpg: 384x640 1 spoon, 1 carrot, 45.1ms\n",
      "Speed: 2.7ms preprocess, 45.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/128.jpg: 384x640 1 spoon, 2 carrots, 49.6ms\n",
      "Speed: 7.6ms preprocess, 49.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/129.jpg: 384x640 1 spoon, 4 carrots, 41.3ms\n",
      "Speed: 2.0ms preprocess, 41.3ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/130.jpg: 384x640 1 spoon, 3 carrots, 37.6ms\n",
      "Speed: 3.3ms preprocess, 37.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/131.jpg: 384x640 1 spoon, 2 carrots, 45.4ms\n",
      "Speed: 2.7ms preprocess, 45.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/132.jpg: 384x640 3 carrots, 38.7ms\n",
      "Speed: 2.5ms preprocess, 38.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/133.jpg: 384x640 2 forks, 2 carrots, 33.3ms\n",
      "Speed: 3.2ms preprocess, 33.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/134.jpg: 384x640 1 fork, 2 carrots, 31.7ms\n",
      "Speed: 1.8ms preprocess, 31.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/135.jpg: 384x640 3 carrots, 48.5ms\n",
      "Speed: 1.7ms preprocess, 48.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/136.jpg: 384x640 2 carrots, 39.4ms\n",
      "Speed: 3.2ms preprocess, 39.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/137.jpg: 384x640 3 carrots, 31.3ms\n",
      "Speed: 1.8ms preprocess, 31.3ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/138.jpg: 384x640 2 carrots, 48.0ms\n",
      "Speed: 2.2ms preprocess, 48.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/139.jpg: 384x640 1 fork, 1 carrot, 31.0ms\n",
      "Speed: 2.0ms preprocess, 31.0ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/140.jpg: 384x640 1 bottle, 2 spoons, 2 carrots, 31.7ms\n",
      "Speed: 1.9ms preprocess, 31.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/141.jpg: 384x640 1 bottle, 4 carrots, 50.4ms\n",
      "Speed: 2.3ms preprocess, 50.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/142.jpg: 384x640 2 spoons, 3 carrots, 36.3ms\n",
      "Speed: 2.3ms preprocess, 36.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/143.jpg: 384x640 1 spoon, 2 carrots, 43.9ms\n",
      "Speed: 2.1ms preprocess, 43.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/144.jpg: 384x640 1 knife, 2 spoons, 5 carrots, 32.3ms\n",
      "Speed: 1.9ms preprocess, 32.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/145.jpg: 384x640 2 spoons, 1 carrot, 36.7ms\n",
      "Speed: 2.3ms preprocess, 36.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/146.jpg: 384x640 2 spoons, 3 carrots, 36.8ms\n",
      "Speed: 1.9ms preprocess, 36.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/147.jpg: 384x640 1 knife, 2 spoons, 1 carrot, 33.3ms\n",
      "Speed: 1.9ms preprocess, 33.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/148.jpg: 384x640 2 spoons, 3 carrots, 45.0ms\n",
      "Speed: 2.0ms preprocess, 45.0ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/149.jpg: 384x640 1 knife, 2 spoons, 2 carrots, 33.9ms\n",
      "Speed: 2.2ms preprocess, 33.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/150.jpg: 384x640 1 baseball bat, 2 spoons, 1 carrot, 52.3ms\n",
      "Speed: 2.0ms preprocess, 52.3ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/151.jpg: 384x640 2 spoons, 35.4ms\n",
      "Speed: 2.0ms preprocess, 35.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/152.jpg: 384x640 2 spoons, 4 carrots, 39.0ms\n",
      "Speed: 1.9ms preprocess, 39.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/153.jpg: 384x640 2 spoons, 2 carrots, 52.6ms\n",
      "Speed: 3.4ms preprocess, 52.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/154.jpg: 384x640 2 spoons, 2 carrots, 34.1ms\n",
      "Speed: 1.8ms preprocess, 34.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/155.jpg: 384x640 1 spoon, 3 carrots, 31.9ms\n",
      "Speed: 1.7ms preprocess, 31.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/156.jpg: 384x640 2 spoons, 3 carrots, 34.4ms\n",
      "Speed: 1.9ms preprocess, 34.4ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/157.jpg: 384x640 2 spoons, 3 carrots, 28.4ms\n",
      "Speed: 2.0ms preprocess, 28.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/158.jpg: 384x640 2 spoons, 3 carrots, 29.6ms\n",
      "Speed: 1.8ms preprocess, 29.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/159.jpg: 384x640 2 spoons, 2 carrots, 56.7ms\n",
      "Speed: 2.2ms preprocess, 56.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/160.jpg: 384x640 1 spoon, 1 carrot, 27.5ms\n",
      "Speed: 1.9ms preprocess, 27.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/161.jpg: 384x640 1 spoon, 3 carrots, 27.8ms\n",
      "Speed: 1.8ms preprocess, 27.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/162.jpg: 384x640 1 spoon, 2 carrots, 32.1ms\n",
      "Speed: 1.7ms preprocess, 32.1ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/163.jpg: 384x640 2 spoons, 56.3ms\n",
      "Speed: 2.8ms preprocess, 56.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/164.jpg: 384x640 2 spoons, 3 carrots, 27.3ms\n",
      "Speed: 1.8ms preprocess, 27.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/165.jpg: 384x640 1 spoon, 6 carrots, 29.7ms\n",
      "Speed: 1.8ms preprocess, 29.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/166.jpg: 384x640 1 spoon, 3 carrots, 52.3ms\n",
      "Speed: 2.4ms preprocess, 52.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/167.jpg: 384x640 1 spoon, 4 carrots, 30.9ms\n",
      "Speed: 2.0ms preprocess, 30.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/168.jpg: 384x640 1 spoon, 6 carrots, 36.1ms\n",
      "Speed: 1.8ms preprocess, 36.1ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/169.jpg: 384x640 1 spoon, 4 carrots, 47.5ms\n",
      "Speed: 1.9ms preprocess, 47.5ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/170.jpg: 384x640 1 spoon, 2 carrots, 35.1ms\n",
      "Speed: 1.9ms preprocess, 35.1ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/171.jpg: 384x640 1 spoon, 4 carrots, 39.2ms\n",
      "Speed: 3.1ms preprocess, 39.2ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/172.jpg: 384x640 1 spoon, 3 carrots, 44.2ms\n",
      "Speed: 2.9ms preprocess, 44.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/173.jpg: 384x640 1 spoon, 3 carrots, 41.3ms\n",
      "Speed: 2.0ms preprocess, 41.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/174.jpg: 384x640 1 spoon, 3 carrots, 28.0ms\n",
      "Speed: 1.9ms preprocess, 28.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/175.jpg: 384x640 1 knife, 1 spoon, 2 carrots, 28.0ms\n",
      "Speed: 1.5ms preprocess, 28.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/176.jpg: 384x640 1 knife, 1 spoon, 2 carrots, 27.6ms\n",
      "Speed: 1.8ms preprocess, 27.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/177.jpg: 384x640 1 knife, 1 spoon, 4 carrots, 28.0ms\n",
      "Speed: 1.7ms preprocess, 28.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/178.jpg: 384x640 1 knife, 1 spoon, 3 carrots, 27.2ms\n",
      "Speed: 1.7ms preprocess, 27.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/179.jpg: 384x640 1 spoon, 3 carrots, 29.3ms\n",
      "Speed: 1.8ms preprocess, 29.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/180.jpg: 384x640 1 spoon, 5 carrots, 30.3ms\n",
      "Speed: 1.7ms preprocess, 30.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/181.jpg: 384x640 3 carrots, 37.4ms\n",
      "Speed: 2.1ms preprocess, 37.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/182.jpg: 384x640 1 carrot, 46.9ms\n",
      "Speed: 2.4ms preprocess, 46.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/183.jpg: 384x640 1 spoon, 40.0ms\n",
      "Speed: 2.5ms preprocess, 40.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/184.jpg: 384x640 1 carrot, 63.4ms\n",
      "Speed: 2.5ms preprocess, 63.4ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/185.jpg: 384x640 (no detections), 60.1ms\n",
      "Speed: 2.2ms preprocess, 60.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/186.jpg: 384x640 1 baseball bat, 1 spoon, 2 carrots, 54.5ms\n",
      "Speed: 2.6ms preprocess, 54.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/187.jpg: 384x640 2 carrots, 33.1ms\n",
      "Speed: 2.6ms preprocess, 33.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/188.jpg: 384x640 1 spoon, 3 carrots, 42.6ms\n",
      "Speed: 2.3ms preprocess, 42.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/189.jpg: 384x640 1 bottle, 1 carrot, 37.5ms\n",
      "Speed: 2.0ms preprocess, 37.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/190.jpg: 384x640 1 spoon, 1 carrot, 30.2ms\n",
      "Speed: 2.0ms preprocess, 30.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/191.jpg: 384x640 3 carrots, 62.5ms\n",
      "Speed: 2.1ms preprocess, 62.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/192.jpg: 384x640 1 knife, 1 spoon, 1 carrot, 43.7ms\n",
      "Speed: 2.1ms preprocess, 43.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/193.jpg: 384x640 1 spoon, 2 carrots, 32.2ms\n",
      "Speed: 2.1ms preprocess, 32.2ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/194.jpg: 384x640 4 carrots, 37.3ms\n",
      "Speed: 2.5ms preprocess, 37.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/195.jpg: 384x640 1 spoon, 3 carrots, 41.2ms\n",
      "Speed: 1.7ms preprocess, 41.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/196.jpg: 384x640 1 spoon, 5 carrots, 28.4ms\n",
      "Speed: 1.9ms preprocess, 28.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/197.jpg: 384x640 1 spoon, 3 carrots, 31.3ms\n",
      "Speed: 1.7ms preprocess, 31.3ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/198.jpg: 384x640 1 spoon, 3 carrots, 27.0ms\n",
      "Speed: 1.7ms preprocess, 27.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/199.jpg: 384x640 1 spoon, 2 carrots, 31.8ms\n",
      "Speed: 2.1ms preprocess, 31.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/200.jpg: 384x640 1 baseball bat, 2 spoons, 1 carrot, 42.5ms\n",
      "Speed: 1.8ms preprocess, 42.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/201.jpg: 384x640 2 spoons, 2 carrots, 39.0ms\n",
      "Speed: 3.3ms preprocess, 39.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/202.jpg: 384x640 2 spoons, 41.9ms\n",
      "Speed: 2.3ms preprocess, 41.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/203.jpg: 384x640 2 spoons, 2 carrots, 49.4ms\n",
      "Speed: 2.1ms preprocess, 49.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/204.jpg: 384x640 2 spoons, 3 carrots, 52.5ms\n",
      "Speed: 2.7ms preprocess, 52.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/205.jpg: 384x640 1 spoon, 4 carrots, 53.3ms\n",
      "Speed: 3.1ms preprocess, 53.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/206.jpg: 384x640 2 spoons, 4 carrots, 45.0ms\n",
      "Speed: 3.0ms preprocess, 45.0ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/207.jpg: 384x640 1 baseball bat, 2 spoons, 3 carrots, 41.8ms\n",
      "Speed: 2.1ms preprocess, 41.8ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/208.jpg: 384x640 2 spoons, 2 carrots, 34.6ms\n",
      "Speed: 2.4ms preprocess, 34.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/209.jpg: 384x640 2 spoons, 3 carrots, 30.7ms\n",
      "Speed: 2.2ms preprocess, 30.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/210.jpg: 384x640 1 baseball bat, 1 spoon, 5 carrots, 31.3ms\n",
      "Speed: 2.0ms preprocess, 31.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/211.jpg: 384x640 2 spoons, 2 carrots, 34.1ms\n",
      "Speed: 1.8ms preprocess, 34.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/212.jpg: 384x640 2 spoons, 3 carrots, 55.5ms\n",
      "Speed: 3.0ms preprocess, 55.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/213.jpg: 384x640 2 spoons, 1 carrot, 54.1ms\n",
      "Speed: 3.2ms preprocess, 54.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/214.jpg: 384x640 1 baseball bat, 1 spoon, 36.3ms\n",
      "Speed: 1.8ms preprocess, 36.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/215.jpg: 384x640 1 baseball bat, 1 spoon, 1 carrot, 29.4ms\n",
      "Speed: 1.7ms preprocess, 29.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/216.jpg: 384x640 2 spoons, 1 carrot, 47.1ms\n",
      "Speed: 2.4ms preprocess, 47.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/217.jpg: 384x640 2 spoons, 3 carrots, 28.1ms\n",
      "Speed: 1.7ms preprocess, 28.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/218.jpg: 384x640 1 knife, 2 spoons, 1 carrot, 40.4ms\n",
      "Speed: 2.1ms preprocess, 40.4ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/219.jpg: 384x640 1 spoon, 55.8ms\n",
      "Speed: 2.6ms preprocess, 55.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/220.jpg: 384x640 1 spoon, 31.4ms\n",
      "Speed: 1.8ms preprocess, 31.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/221.jpg: 384x640 1 knife, 1 spoon, 2 carrots, 35.5ms\n",
      "Speed: 3.2ms preprocess, 35.5ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/222.jpg: 384x640 1 spoon, 3 carrots, 54.7ms\n",
      "Speed: 2.1ms preprocess, 54.7ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/223.jpg: 384x640 2 spoons, 3 carrots, 37.4ms\n",
      "Speed: 3.1ms preprocess, 37.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/224.jpg: 384x640 1 knife, 1 spoon, 1 apple, 3 carrots, 59.2ms\n",
      "Speed: 2.7ms preprocess, 59.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/225.jpg: 384x640 1 spoon, 38.3ms\n",
      "Speed: 2.2ms preprocess, 38.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/226.jpg: 384x640 1 spoon, 2 carrots, 33.8ms\n",
      "Speed: 2.1ms preprocess, 33.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/227.jpg: 384x640 1 spoon, 4 carrots, 35.5ms\n",
      "Speed: 2.0ms preprocess, 35.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/228.jpg: 384x640 2 spoons, 4 carrots, 37.2ms\n",
      "Speed: 1.8ms preprocess, 37.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/229.jpg: 384x640 2 spoons, 3 carrots, 37.0ms\n",
      "Speed: 2.0ms preprocess, 37.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/230.jpg: 384x640 1 spoon, 4 carrots, 29.6ms\n",
      "Speed: 1.6ms preprocess, 29.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/231.jpg: 384x640 1 spoon, 5 carrots, 48.7ms\n",
      "Speed: 2.1ms preprocess, 48.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/232.jpg: 384x640 2 spoons, 4 carrots, 45.4ms\n",
      "Speed: 1.7ms preprocess, 45.4ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/233.jpg: 384x640 1 spoon, 3 carrots, 37.7ms\n",
      "Speed: 1.8ms preprocess, 37.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/234.jpg: 384x640 1 spoon, 2 carrots, 31.1ms\n",
      "Speed: 1.9ms preprocess, 31.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/235.jpg: 384x640 1 knife, 1 carrot, 36.8ms\n",
      "Speed: 1.7ms preprocess, 36.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/236.jpg: 384x640 2 spoons, 41.7ms\n",
      "Speed: 2.8ms preprocess, 41.7ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/237.jpg: 384x640 2 spoons, 3 carrots, 33.7ms\n",
      "Speed: 1.7ms preprocess, 33.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/238.jpg: 384x640 1 knife, 2 spoons, 2 carrots, 33.7ms\n",
      "Speed: 1.8ms preprocess, 33.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/239.jpg: 384x640 1 spoon, 1 carrot, 33.0ms\n",
      "Speed: 2.0ms preprocess, 33.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/240.jpg: 384x640 1 spoon, 1 carrot, 30.5ms\n",
      "Speed: 2.0ms preprocess, 30.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/241.jpg: 384x640 2 spoons, 2 carrots, 44.6ms\n",
      "Speed: 2.9ms preprocess, 44.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/242.jpg: 384x640 1 bottle, 1 spoon, 1 carrot, 29.9ms\n",
      "Speed: 2.2ms preprocess, 29.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/243.jpg: 384x640 1 spoon, 1 carrot, 37.6ms\n",
      "Speed: 1.9ms preprocess, 37.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/244.jpg: 384x640 1 knife, 1 spoon, 30.9ms\n",
      "Speed: 1.8ms preprocess, 30.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/245.jpg: 384x640 1 spoon, 1 carrot, 31.1ms\n",
      "Speed: 2.0ms preprocess, 31.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/246.jpg: 384x640 1 knife, 1 spoon, 46.8ms\n",
      "Speed: 3.7ms preprocess, 46.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/247.jpg: 384x640 1 spoon, 34.7ms\n",
      "Speed: 2.8ms preprocess, 34.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/248.jpg: 384x640 1 knife, 36.0ms\n",
      "Speed: 2.3ms preprocess, 36.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/249.jpg: 384x640 1 spoon, 29.7ms\n",
      "Speed: 1.7ms preprocess, 29.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/250.jpg: 384x640 1 knife, 1 spoon, 30.2ms\n",
      "Speed: 1.9ms preprocess, 30.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/251.jpg: 384x640 1 knife, 2 carrots, 35.8ms\n",
      "Speed: 1.9ms preprocess, 35.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/252.jpg: 384x640 1 carrot, 29.8ms\n",
      "Speed: 2.6ms preprocess, 29.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/253.jpg: 384x640 1 spoon, 4 carrots, 34.9ms\n",
      "Speed: 2.2ms preprocess, 34.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/254.jpg: 384x640 1 knife, 30.9ms\n",
      "Speed: 2.1ms preprocess, 30.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/255.jpg: 384x640 1 spoon, 5 carrots, 28.4ms\n",
      "Speed: 2.1ms preprocess, 28.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/256.jpg: 384x640 1 spoon, 3 carrots, 43.1ms\n",
      "Speed: 3.1ms preprocess, 43.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/257.jpg: 384x640 1 baseball bat, 1 bottle, 4 carrots, 31.5ms\n",
      "Speed: 2.7ms preprocess, 31.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/258.jpg: 384x640 1 spoon, 6 carrots, 32.0ms\n",
      "Speed: 1.9ms preprocess, 32.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/259.jpg: 384x640 1 knife, 4 carrots, 53.9ms\n",
      "Speed: 2.0ms preprocess, 53.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/260.jpg: 384x640 1 knife, 4 carrots, 53.5ms\n",
      "Speed: 2.0ms preprocess, 53.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/261.jpg: 384x640 1 knife, 3 carrots, 46.3ms\n",
      "Speed: 2.6ms preprocess, 46.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/262.jpg: 384x640 1 baseball bat, 1 knife, 3 carrots, 44.9ms\n",
      "Speed: 2.1ms preprocess, 44.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/263.jpg: 384x640 1 knife, 1 carrot, 31.6ms\n",
      "Speed: 1.9ms preprocess, 31.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/264.jpg: 384x640 1 knife, 1 carrot, 31.6ms\n",
      "Speed: 2.8ms preprocess, 31.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/265.jpg: 384x640 1 knife, 2 carrots, 47.7ms\n",
      "Speed: 2.9ms preprocess, 47.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/266.jpg: 384x640 1 spoon, 2 carrots, 47.0ms\n",
      "Speed: 2.1ms preprocess, 47.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/267.jpg: 384x640 1 bottle, 1 spoon, 5 carrots, 31.8ms\n",
      "Speed: 2.2ms preprocess, 31.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/268.jpg: 384x640 1 baseball bat, 1 bottle, 1 carrot, 40.2ms\n",
      "Speed: 2.6ms preprocess, 40.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/269.jpg: 384x640 1 knife, 58.8ms\n",
      "Speed: 2.9ms preprocess, 58.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/270.jpg: 384x640 1 spoon, 2 carrots, 41.7ms\n",
      "Speed: 3.0ms preprocess, 41.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/271.jpg: 384x640 1 knife, 1 spoon, 5 carrots, 32.9ms\n",
      "Speed: 2.6ms preprocess, 32.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/272.jpg: 384x640 1 knife, 1 carrot, 31.8ms\n",
      "Speed: 2.0ms preprocess, 31.8ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/273.jpg: 384x640 1 spoon, 1 carrot, 47.6ms\n",
      "Speed: 2.1ms preprocess, 47.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/274.jpg: 384x640 1 knife, 1 carrot, 31.9ms\n",
      "Speed: 2.2ms preprocess, 31.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/275.jpg: 384x640 1 spoon, 2 carrots, 44.5ms\n",
      "Speed: 2.3ms preprocess, 44.5ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/276.jpg: 384x640 1 carrot, 32.2ms\n",
      "Speed: 2.0ms preprocess, 32.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/277.jpg: 384x640 5 carrots, 57.4ms\n",
      "Speed: 2.5ms preprocess, 57.4ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/278.jpg: 384x640 2 carrots, 39.7ms\n",
      "Speed: 2.9ms preprocess, 39.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/279.jpg: 384x640 1 carrot, 40.2ms\n",
      "Speed: 3.4ms preprocess, 40.2ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/280.jpg: 384x640 1 spoon, 8 carrots, 64.4ms\n",
      "Speed: 2.2ms preprocess, 64.4ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/281.jpg: 384x640 1 knife, 1 carrot, 30.0ms\n",
      "Speed: 2.7ms preprocess, 30.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/282.jpg: 384x640 1 knife, 1 spoon, 1 carrot, 44.6ms\n",
      "Speed: 2.2ms preprocess, 44.6ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/283.jpg: 384x640 1 spoon, 6 carrots, 39.7ms\n",
      "Speed: 2.8ms preprocess, 39.7ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/284.jpg: 384x640 1 spoon, 2 carrots, 45.5ms\n",
      "Speed: 2.1ms preprocess, 45.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/285.jpg: 384x640 1 spoon, 47.2ms\n",
      "Speed: 2.0ms preprocess, 47.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/286.jpg: 384x640 1 spoon, 2 carrots, 42.7ms\n",
      "Speed: 2.1ms preprocess, 42.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/287.jpg: 384x640 1 spoon, 35.7ms\n",
      "Speed: 2.2ms preprocess, 35.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/288.jpg: 384x640 2 carrots, 40.4ms\n",
      "Speed: 2.1ms preprocess, 40.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/289.jpg: 384x640 (no detections), 34.0ms\n",
      "Speed: 1.9ms preprocess, 34.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/290.jpg: 384x640 (no detections), 51.6ms\n",
      "Speed: 2.4ms preprocess, 51.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/291.jpg: 384x640 1 spoon, 2 carrots, 33.9ms\n",
      "Speed: 2.1ms preprocess, 33.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/292.jpg: 384x640 2 carrots, 56.8ms\n",
      "Speed: 3.4ms preprocess, 56.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/293.jpg: 384x640 2 spoons, 2 carrots, 33.9ms\n",
      "Speed: 1.9ms preprocess, 33.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/294.jpg: 384x640 2 spoons, 1 carrot, 50.0ms\n",
      "Speed: 1.9ms preprocess, 50.0ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/295.jpg: 384x640 1 spoon, 3 carrots, 36.2ms\n",
      "Speed: 2.0ms preprocess, 36.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/296.jpg: 384x640 1 spoon, 1 carrot, 41.1ms\n",
      "Speed: 2.3ms preprocess, 41.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/297.jpg: 384x640 1 spoon, 1 carrot, 36.1ms\n",
      "Speed: 2.1ms preprocess, 36.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/298.jpg: 384x640 1 spoon, 40.0ms\n",
      "Speed: 1.9ms preprocess, 40.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/blood/right/299.jpg: 384x640 1 spoon, 2 carrots, 35.9ms\n",
      "Speed: 2.2ms preprocess, 35.9ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Propagating video frames: 100%|| 300/300 [00:23<00:00, 12.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask propagation completed in 23.52 seconds.\n",
      "Processing predicted masks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing video frames: 300it [00:02, 142.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 300 masks for evaluation.\n",
      "Masks saved to data/masks/yolo11x-seg/val/data-raw-SegSTRONGC_val-val-1-1-blood-right.pkl\n",
      "Loading ground truth masks for evaluation...\n",
      "Loaded 300 ground truth masks.\n",
      "Calculating evaluation metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for metrics calculation: 1.36 seconds.\n",
      "Mean IoU for data/raw/SegSTRONGC_val/val/1/1/blood/right: 0.2570\n",
      "Mean DSC for data/raw/SegSTRONGC_val/val/1/1/blood/right: 0.3665\n",
      "Loading existing results file: data/results/yolo11x-seg/val.json\n",
      "Results saved to data/results/yolo11x-seg/val.json\n",
      "Processing video took 29.69 seconds.\n",
      "==================================================\n",
      "\n",
      "Results for data/raw/SegSTRONGC_val/val/1/1/blood:\n",
      "  Left: IoU=0.2834, DSC=0.3897\n",
      "  Right: IoU=0.2570, DSC=0.3665\n",
      "  Overall: IoU=0.2702, DSC=0.3781\n",
      "\n",
      "Processing domain: low_brightness\n",
      "Processing left camera video...\n",
      "==================================================\n",
      "Processing video: data/raw/SegSTRONGC_val/val/1/1/low_brightness/left\n",
      "Domain: low_brightness, Split: val, Camera: left\n",
      "Initializing Yolo for video...\n",
      "Initialization took 0.18 seconds.\n",
      "Starting mask propagation...\n",
      "Total images in video: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/0.jpg: 384x640 (no detections), 68.5ms\n",
      "Speed: 2.0ms preprocess, 68.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/1.jpg: 384x640 (no detections), 24.3ms\n",
      "Speed: 2.1ms preprocess, 24.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/2.jpg: 384x640 (no detections), 33.4ms\n",
      "Speed: 2.5ms preprocess, 33.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/3.jpg: 384x640 (no detections), 24.0ms\n",
      "Speed: 1.5ms preprocess, 24.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/4.jpg: 384x640 (no detections), 25.1ms\n",
      "Speed: 1.6ms preprocess, 25.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/5.jpg: 384x640 (no detections), 40.6ms\n",
      "Speed: 1.7ms preprocess, 40.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/6.jpg: 384x640 (no detections), 22.2ms\n",
      "Speed: 1.5ms preprocess, 22.2ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/7.jpg: 384x640 (no detections), 35.3ms\n",
      "Speed: 1.5ms preprocess, 35.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/8.jpg: 384x640 (no detections), 32.1ms\n",
      "Speed: 1.7ms preprocess, 32.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/9.jpg: 384x640 (no detections), 37.2ms\n",
      "Speed: 1.6ms preprocess, 37.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/10.jpg: 384x640 (no detections), 36.7ms\n",
      "Speed: 2.1ms preprocess, 36.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/11.jpg: 384x640 (no detections), 25.9ms\n",
      "Speed: 2.0ms preprocess, 25.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/12.jpg: 384x640 1 motorcycle, 28.8ms\n",
      "Speed: 1.8ms preprocess, 28.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/13.jpg: 384x640 1 motorcycle, 30.9ms\n",
      "Speed: 1.7ms preprocess, 30.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/14.jpg: 384x640 1 motorcycle, 36.2ms\n",
      "Speed: 1.7ms preprocess, 36.2ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/15.jpg: 384x640 (no detections), 42.1ms\n",
      "Speed: 1.9ms preprocess, 42.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/16.jpg: 384x640 1 motorcycle, 41.2ms\n",
      "Speed: 3.0ms preprocess, 41.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/17.jpg: 384x640 1 motorcycle, 30.4ms\n",
      "Speed: 2.3ms preprocess, 30.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/18.jpg: 384x640 (no detections), 32.1ms\n",
      "Speed: 1.7ms preprocess, 32.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/19.jpg: 384x640 (no detections), 37.0ms\n",
      "Speed: 3.8ms preprocess, 37.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/20.jpg: 384x640 (no detections), 56.3ms\n",
      "Speed: 2.2ms preprocess, 56.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/21.jpg: 384x640 (no detections), 44.0ms\n",
      "Speed: 1.9ms preprocess, 44.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/22.jpg: 384x640 1 motorcycle, 51.3ms\n",
      "Speed: 2.2ms preprocess, 51.3ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/23.jpg: 384x640 1 motorcycle, 39.4ms\n",
      "Speed: 1.8ms preprocess, 39.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/24.jpg: 384x640 1 motorcycle, 44.6ms\n",
      "Speed: 1.8ms preprocess, 44.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/25.jpg: 384x640 (no detections), 36.2ms\n",
      "Speed: 1.8ms preprocess, 36.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/26.jpg: 384x640 1 motorcycle, 32.0ms\n",
      "Speed: 1.9ms preprocess, 32.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/27.jpg: 384x640 (no detections), 37.2ms\n",
      "Speed: 1.8ms preprocess, 37.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/28.jpg: 384x640 (no detections), 37.9ms\n",
      "Speed: 2.8ms preprocess, 37.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/29.jpg: 384x640 (no detections), 37.0ms\n",
      "Speed: 2.5ms preprocess, 37.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/30.jpg: 384x640 (no detections), 39.8ms\n",
      "Speed: 2.3ms preprocess, 39.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/31.jpg: 384x640 (no detections), 31.7ms\n",
      "Speed: 1.9ms preprocess, 31.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/32.jpg: 384x640 (no detections), 34.4ms\n",
      "Speed: 2.3ms preprocess, 34.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/33.jpg: 384x640 (no detections), 30.9ms\n",
      "Speed: 1.7ms preprocess, 30.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/34.jpg: 384x640 (no detections), 31.3ms\n",
      "Speed: 1.9ms preprocess, 31.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/35.jpg: 384x640 1 motorcycle, 58.2ms\n",
      "Speed: 2.3ms preprocess, 58.2ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/36.jpg: 384x640 (no detections), 36.7ms\n",
      "Speed: 2.0ms preprocess, 36.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/37.jpg: 384x640 (no detections), 29.2ms\n",
      "Speed: 1.9ms preprocess, 29.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/38.jpg: 384x640 1 motorcycle, 42.4ms\n",
      "Speed: 1.8ms preprocess, 42.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/39.jpg: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.2ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/40.jpg: 384x640 (no detections), 32.6ms\n",
      "Speed: 2.4ms preprocess, 32.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/41.jpg: 384x640 (no detections), 55.3ms\n",
      "Speed: 2.1ms preprocess, 55.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/42.jpg: 384x640 1 motorcycle, 35.7ms\n",
      "Speed: 1.9ms preprocess, 35.7ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/43.jpg: 384x640 (no detections), 36.8ms\n",
      "Speed: 3.3ms preprocess, 36.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/44.jpg: 384x640 (no detections), 28.9ms\n",
      "Speed: 2.0ms preprocess, 28.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/45.jpg: 384x640 (no detections), 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/46.jpg: 384x640 (no detections), 31.0ms\n",
      "Speed: 1.9ms preprocess, 31.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/47.jpg: 384x640 (no detections), 43.9ms\n",
      "Speed: 2.0ms preprocess, 43.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/48.jpg: 384x640 (no detections), 32.8ms\n",
      "Speed: 1.8ms preprocess, 32.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/49.jpg: 384x640 (no detections), 29.4ms\n",
      "Speed: 1.9ms preprocess, 29.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/50.jpg: 384x640 (no detections), 44.4ms\n",
      "Speed: 2.1ms preprocess, 44.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/51.jpg: 384x640 (no detections), 45.5ms\n",
      "Speed: 3.1ms preprocess, 45.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/52.jpg: 384x640 1 motorcycle, 43.9ms\n",
      "Speed: 3.4ms preprocess, 43.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/53.jpg: 384x640 (no detections), 39.6ms\n",
      "Speed: 2.2ms preprocess, 39.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/54.jpg: 384x640 (no detections), 36.2ms\n",
      "Speed: 2.0ms preprocess, 36.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/55.jpg: 384x640 1 motorcycle, 42.5ms\n",
      "Speed: 2.0ms preprocess, 42.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/56.jpg: 384x640 (no detections), 37.3ms\n",
      "Speed: 2.1ms preprocess, 37.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/57.jpg: 384x640 (no detections), 33.2ms\n",
      "Speed: 1.9ms preprocess, 33.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/58.jpg: 384x640 (no detections), 40.5ms\n",
      "Speed: 3.0ms preprocess, 40.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/59.jpg: 384x640 (no detections), 27.7ms\n",
      "Speed: 1.7ms preprocess, 27.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/60.jpg: 384x640 1 airplane, 34.3ms\n",
      "Speed: 2.3ms preprocess, 34.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/61.jpg: 384x640 (no detections), 35.5ms\n",
      "Speed: 2.0ms preprocess, 35.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/62.jpg: 384x640 1 toothbrush, 44.0ms\n",
      "Speed: 2.1ms preprocess, 44.0ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/63.jpg: 384x640 (no detections), 30.8ms\n",
      "Speed: 2.4ms preprocess, 30.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/64.jpg: 384x640 (no detections), 36.0ms\n",
      "Speed: 2.8ms preprocess, 36.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/65.jpg: 384x640 (no detections), 48.0ms\n",
      "Speed: 2.4ms preprocess, 48.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/66.jpg: 384x640 (no detections), 52.6ms\n",
      "Speed: 1.8ms preprocess, 52.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/67.jpg: 384x640 (no detections), 38.4ms\n",
      "Speed: 2.2ms preprocess, 38.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/68.jpg: 384x640 (no detections), 31.4ms\n",
      "Speed: 2.0ms preprocess, 31.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/69.jpg: 384x640 (no detections), 41.0ms\n",
      "Speed: 2.4ms preprocess, 41.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/70.jpg: 384x640 (no detections), 41.6ms\n",
      "Speed: 3.0ms preprocess, 41.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/71.jpg: 384x640 1 motorcycle, 31.6ms\n",
      "Speed: 2.7ms preprocess, 31.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/72.jpg: 384x640 1 motorcycle, 42.2ms\n",
      "Speed: 2.9ms preprocess, 42.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/73.jpg: 384x640 1 motorcycle, 32.0ms\n",
      "Speed: 1.6ms preprocess, 32.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/74.jpg: 384x640 (no detections), 29.9ms\n",
      "Speed: 1.7ms preprocess, 29.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/75.jpg: 384x640 1 motorcycle, 31.5ms\n",
      "Speed: 2.1ms preprocess, 31.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/76.jpg: 384x640 1 motorcycle, 33.8ms\n",
      "Speed: 2.0ms preprocess, 33.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/77.jpg: 384x640 1 motorcycle, 36.5ms\n",
      "Speed: 2.7ms preprocess, 36.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/78.jpg: 384x640 1 motorcycle, 38.2ms\n",
      "Speed: 1.8ms preprocess, 38.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/79.jpg: 384x640 1 motorcycle, 31.6ms\n",
      "Speed: 1.9ms preprocess, 31.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/80.jpg: 384x640 1 motorcycle, 33.4ms\n",
      "Speed: 1.8ms preprocess, 33.4ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/81.jpg: 384x640 (no detections), 37.0ms\n",
      "Speed: 2.8ms preprocess, 37.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/82.jpg: 384x640 (no detections), 33.2ms\n",
      "Speed: 1.7ms preprocess, 33.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/83.jpg: 384x640 1 motorcycle, 43.6ms\n",
      "Speed: 3.4ms preprocess, 43.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/84.jpg: 384x640 (no detections), 39.2ms\n",
      "Speed: 2.2ms preprocess, 39.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/85.jpg: 384x640 (no detections), 30.6ms\n",
      "Speed: 2.1ms preprocess, 30.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/86.jpg: 384x640 (no detections), 32.1ms\n",
      "Speed: 1.8ms preprocess, 32.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/87.jpg: 384x640 1 motorcycle, 38.7ms\n",
      "Speed: 2.3ms preprocess, 38.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/88.jpg: 384x640 1 motorcycle, 36.4ms\n",
      "Speed: 2.2ms preprocess, 36.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/89.jpg: 384x640 (no detections), 31.6ms\n",
      "Speed: 2.8ms preprocess, 31.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/90.jpg: 384x640 (no detections), 54.4ms\n",
      "Speed: 2.2ms preprocess, 54.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/91.jpg: 384x640 1 motorcycle, 45.5ms\n",
      "Speed: 2.4ms preprocess, 45.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/92.jpg: 384x640 (no detections), 41.8ms\n",
      "Speed: 2.4ms preprocess, 41.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/93.jpg: 384x640 (no detections), 45.6ms\n",
      "Speed: 2.1ms preprocess, 45.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/94.jpg: 384x640 (no detections), 40.7ms\n",
      "Speed: 2.2ms preprocess, 40.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/95.jpg: 384x640 (no detections), 47.8ms\n",
      "Speed: 3.0ms preprocess, 47.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/96.jpg: 384x640 1 motorcycle, 36.3ms\n",
      "Speed: 2.9ms preprocess, 36.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/97.jpg: 384x640 1 motorcycle, 34.9ms\n",
      "Speed: 1.8ms preprocess, 34.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/98.jpg: 384x640 1 motorcycle, 41.5ms\n",
      "Speed: 1.9ms preprocess, 41.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/99.jpg: 384x640 (no detections), 33.5ms\n",
      "Speed: 1.8ms preprocess, 33.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/100.jpg: 384x640 (no detections), 35.4ms\n",
      "Speed: 2.1ms preprocess, 35.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/101.jpg: 384x640 (no detections), 40.0ms\n",
      "Speed: 2.0ms preprocess, 40.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/102.jpg: 384x640 1 motorcycle, 40.6ms\n",
      "Speed: 2.0ms preprocess, 40.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/103.jpg: 384x640 (no detections), 50.0ms\n",
      "Speed: 2.1ms preprocess, 50.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/104.jpg: 384x640 (no detections), 40.7ms\n",
      "Speed: 3.2ms preprocess, 40.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/105.jpg: 384x640 1 toothbrush, 30.1ms\n",
      "Speed: 2.0ms preprocess, 30.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/106.jpg: 384x640 (no detections), 30.0ms\n",
      "Speed: 1.8ms preprocess, 30.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/107.jpg: 384x640 (no detections), 39.3ms\n",
      "Speed: 2.6ms preprocess, 39.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/108.jpg: 384x640 (no detections), 44.3ms\n",
      "Speed: 3.0ms preprocess, 44.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/109.jpg: 384x640 (no detections), 31.5ms\n",
      "Speed: 2.2ms preprocess, 31.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/110.jpg: 384x640 (no detections), 44.1ms\n",
      "Speed: 2.9ms preprocess, 44.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/111.jpg: 384x640 (no detections), 37.1ms\n",
      "Speed: 3.3ms preprocess, 37.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/112.jpg: 384x640 (no detections), 30.5ms\n",
      "Speed: 1.9ms preprocess, 30.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/113.jpg: 384x640 (no detections), 34.5ms\n",
      "Speed: 2.0ms preprocess, 34.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/114.jpg: 384x640 (no detections), 28.2ms\n",
      "Speed: 1.8ms preprocess, 28.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/115.jpg: 384x640 (no detections), 50.6ms\n",
      "Speed: 2.9ms preprocess, 50.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/116.jpg: 384x640 (no detections), 44.4ms\n",
      "Speed: 1.9ms preprocess, 44.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/117.jpg: 384x640 (no detections), 31.6ms\n",
      "Speed: 2.8ms preprocess, 31.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/118.jpg: 384x640 1 airplane, 32.0ms\n",
      "Speed: 1.7ms preprocess, 32.0ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/119.jpg: 384x640 1 airplane, 34.8ms\n",
      "Speed: 2.7ms preprocess, 34.8ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/120.jpg: 384x640 1 airplane, 46.4ms\n",
      "Speed: 1.9ms preprocess, 46.4ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/121.jpg: 384x640 (no detections), 33.3ms\n",
      "Speed: 2.7ms preprocess, 33.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/122.jpg: 384x640 (no detections), 28.0ms\n",
      "Speed: 2.0ms preprocess, 28.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/123.jpg: 384x640 (no detections), 30.2ms\n",
      "Speed: 2.0ms preprocess, 30.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/124.jpg: 384x640 (no detections), 37.4ms\n",
      "Speed: 2.7ms preprocess, 37.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/125.jpg: 384x640 (no detections), 34.7ms\n",
      "Speed: 1.9ms preprocess, 34.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/126.jpg: 384x640 (no detections), 40.7ms\n",
      "Speed: 3.1ms preprocess, 40.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/127.jpg: 384x640 (no detections), 27.8ms\n",
      "Speed: 1.8ms preprocess, 27.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/128.jpg: 384x640 (no detections), 39.5ms\n",
      "Speed: 2.7ms preprocess, 39.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/129.jpg: 384x640 1 airplane, 33.7ms\n",
      "Speed: 2.3ms preprocess, 33.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/130.jpg: 384x640 (no detections), 37.2ms\n",
      "Speed: 2.4ms preprocess, 37.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/131.jpg: 384x640 1 motorcycle, 30.8ms\n",
      "Speed: 1.8ms preprocess, 30.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/132.jpg: 384x640 (no detections), 36.5ms\n",
      "Speed: 2.0ms preprocess, 36.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/133.jpg: 384x640 (no detections), 40.3ms\n",
      "Speed: 1.7ms preprocess, 40.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/134.jpg: 384x640 (no detections), 37.0ms\n",
      "Speed: 3.2ms preprocess, 37.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/135.jpg: 384x640 (no detections), 38.3ms\n",
      "Speed: 2.1ms preprocess, 38.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/136.jpg: 384x640 (no detections), 37.9ms\n",
      "Speed: 2.5ms preprocess, 37.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/137.jpg: 384x640 (no detections), 34.5ms\n",
      "Speed: 2.2ms preprocess, 34.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/138.jpg: 384x640 (no detections), 43.5ms\n",
      "Speed: 2.0ms preprocess, 43.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/139.jpg: 384x640 (no detections), 30.6ms\n",
      "Speed: 1.8ms preprocess, 30.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/140.jpg: 384x640 (no detections), 43.9ms\n",
      "Speed: 2.3ms preprocess, 43.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/141.jpg: 384x640 (no detections), 40.3ms\n",
      "Speed: 3.5ms preprocess, 40.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/142.jpg: 384x640 (no detections), 39.8ms\n",
      "Speed: 2.1ms preprocess, 39.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/143.jpg: 384x640 (no detections), 38.6ms\n",
      "Speed: 1.8ms preprocess, 38.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/144.jpg: 384x640 (no detections), 37.5ms\n",
      "Speed: 2.9ms preprocess, 37.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/145.jpg: 384x640 (no detections), 51.4ms\n",
      "Speed: 2.0ms preprocess, 51.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/146.jpg: 384x640 (no detections), 38.9ms\n",
      "Speed: 1.9ms preprocess, 38.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/147.jpg: 384x640 (no detections), 35.4ms\n",
      "Speed: 2.2ms preprocess, 35.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/148.jpg: 384x640 (no detections), 57.3ms\n",
      "Speed: 2.4ms preprocess, 57.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/149.jpg: 384x640 (no detections), 32.9ms\n",
      "Speed: 2.0ms preprocess, 32.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/150.jpg: 384x640 (no detections), 34.8ms\n",
      "Speed: 3.1ms preprocess, 34.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/151.jpg: 384x640 (no detections), 40.3ms\n",
      "Speed: 2.2ms preprocess, 40.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/152.jpg: 384x640 (no detections), 47.5ms\n",
      "Speed: 3.1ms preprocess, 47.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/153.jpg: 384x640 (no detections), 51.7ms\n",
      "Speed: 3.5ms preprocess, 51.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/154.jpg: 384x640 1 motorcycle, 31.5ms\n",
      "Speed: 1.9ms preprocess, 31.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/155.jpg: 384x640 (no detections), 32.9ms\n",
      "Speed: 1.9ms preprocess, 32.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/156.jpg: 384x640 (no detections), 41.1ms\n",
      "Speed: 2.2ms preprocess, 41.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/157.jpg: 384x640 (no detections), 34.0ms\n",
      "Speed: 2.1ms preprocess, 34.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/158.jpg: 384x640 (no detections), 34.1ms\n",
      "Speed: 1.9ms preprocess, 34.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/159.jpg: 384x640 (no detections), 40.7ms\n",
      "Speed: 1.7ms preprocess, 40.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/160.jpg: 384x640 (no detections), 47.6ms\n",
      "Speed: 1.9ms preprocess, 47.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/161.jpg: 384x640 (no detections), 30.8ms\n",
      "Speed: 1.9ms preprocess, 30.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/162.jpg: 384x640 (no detections), 33.2ms\n",
      "Speed: 1.8ms preprocess, 33.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/163.jpg: 384x640 (no detections), 39.4ms\n",
      "Speed: 3.0ms preprocess, 39.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/164.jpg: 384x640 (no detections), 37.1ms\n",
      "Speed: 2.3ms preprocess, 37.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/165.jpg: 384x640 (no detections), 44.8ms\n",
      "Speed: 2.7ms preprocess, 44.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/166.jpg: 384x640 (no detections), 29.1ms\n",
      "Speed: 1.8ms preprocess, 29.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/167.jpg: 384x640 (no detections), 37.6ms\n",
      "Speed: 3.1ms preprocess, 37.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/168.jpg: 384x640 (no detections), 34.8ms\n",
      "Speed: 3.1ms preprocess, 34.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/169.jpg: 384x640 (no detections), 44.0ms\n",
      "Speed: 3.1ms preprocess, 44.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/170.jpg: 384x640 (no detections), 31.1ms\n",
      "Speed: 2.3ms preprocess, 31.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/171.jpg: 384x640 (no detections), 33.5ms\n",
      "Speed: 2.3ms preprocess, 33.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/172.jpg: 384x640 (no detections), 58.8ms\n",
      "Speed: 2.0ms preprocess, 58.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/173.jpg: 384x640 (no detections), 40.6ms\n",
      "Speed: 3.2ms preprocess, 40.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/174.jpg: 384x640 (no detections), 30.8ms\n",
      "Speed: 3.4ms preprocess, 30.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/175.jpg: 384x640 (no detections), 41.0ms\n",
      "Speed: 2.4ms preprocess, 41.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/176.jpg: 384x640 (no detections), 37.5ms\n",
      "Speed: 2.0ms preprocess, 37.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/177.jpg: 384x640 (no detections), 36.4ms\n",
      "Speed: 2.9ms preprocess, 36.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/178.jpg: 384x640 (no detections), 45.3ms\n",
      "Speed: 2.1ms preprocess, 45.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/179.jpg: 384x640 (no detections), 37.7ms\n",
      "Speed: 2.8ms preprocess, 37.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/180.jpg: 384x640 (no detections), 54.5ms\n",
      "Speed: 2.0ms preprocess, 54.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/181.jpg: 384x640 (no detections), 37.3ms\n",
      "Speed: 2.8ms preprocess, 37.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/182.jpg: 384x640 (no detections), 46.8ms\n",
      "Speed: 2.8ms preprocess, 46.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/183.jpg: 384x640 (no detections), 36.2ms\n",
      "Speed: 2.2ms preprocess, 36.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/184.jpg: 384x640 (no detections), 40.3ms\n",
      "Speed: 3.1ms preprocess, 40.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/185.jpg: 384x640 (no detections), 46.2ms\n",
      "Speed: 1.8ms preprocess, 46.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/186.jpg: 384x640 (no detections), 49.7ms\n",
      "Speed: 2.2ms preprocess, 49.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/187.jpg: 384x640 (no detections), 29.0ms\n",
      "Speed: 1.9ms preprocess, 29.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/188.jpg: 384x640 (no detections), 43.1ms\n",
      "Speed: 2.8ms preprocess, 43.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/189.jpg: 384x640 (no detections), 34.1ms\n",
      "Speed: 1.8ms preprocess, 34.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/190.jpg: 384x640 (no detections), 50.5ms\n",
      "Speed: 3.0ms preprocess, 50.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/191.jpg: 384x640 (no detections), 49.1ms\n",
      "Speed: 2.2ms preprocess, 49.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/192.jpg: 384x640 (no detections), 33.2ms\n",
      "Speed: 1.9ms preprocess, 33.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/193.jpg: 384x640 (no detections), 41.5ms\n",
      "Speed: 1.9ms preprocess, 41.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/194.jpg: 384x640 (no detections), 38.4ms\n",
      "Speed: 2.0ms preprocess, 38.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/195.jpg: 384x640 (no detections), 34.8ms\n",
      "Speed: 1.9ms preprocess, 34.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/196.jpg: 384x640 (no detections), 43.5ms\n",
      "Speed: 1.9ms preprocess, 43.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/197.jpg: 384x640 1 motorcycle, 36.9ms\n",
      "Speed: 1.8ms preprocess, 36.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/198.jpg: 384x640 (no detections), 42.0ms\n",
      "Speed: 2.9ms preprocess, 42.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/199.jpg: 384x640 (no detections), 31.5ms\n",
      "Speed: 1.7ms preprocess, 31.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/200.jpg: 384x640 (no detections), 35.1ms\n",
      "Speed: 1.9ms preprocess, 35.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/201.jpg: 384x640 1 motorcycle, 35.0ms\n",
      "Speed: 2.3ms preprocess, 35.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/202.jpg: 384x640 (no detections), 28.9ms\n",
      "Speed: 2.0ms preprocess, 28.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/203.jpg: 384x640 (no detections), 45.8ms\n",
      "Speed: 2.0ms preprocess, 45.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/204.jpg: 384x640 1 motorcycle, 47.1ms\n",
      "Speed: 2.0ms preprocess, 47.1ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/205.jpg: 384x640 (no detections), 42.9ms\n",
      "Speed: 2.1ms preprocess, 42.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/206.jpg: 384x640 1 motorcycle, 46.8ms\n",
      "Speed: 2.7ms preprocess, 46.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/207.jpg: 384x640 (no detections), 46.2ms\n",
      "Speed: 2.9ms preprocess, 46.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/208.jpg: 384x640 1 motorcycle, 32.3ms\n",
      "Speed: 2.3ms preprocess, 32.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/209.jpg: 384x640 1 motorcycle, 33.5ms\n",
      "Speed: 1.7ms preprocess, 33.5ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/210.jpg: 384x640 (no detections), 43.6ms\n",
      "Speed: 2.3ms preprocess, 43.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/211.jpg: 384x640 (no detections), 34.9ms\n",
      "Speed: 1.7ms preprocess, 34.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/212.jpg: 384x640 (no detections), 34.8ms\n",
      "Speed: 3.0ms preprocess, 34.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/213.jpg: 384x640 (no detections), 34.0ms\n",
      "Speed: 1.9ms preprocess, 34.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/214.jpg: 384x640 (no detections), 43.8ms\n",
      "Speed: 2.0ms preprocess, 43.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/215.jpg: 384x640 (no detections), 44.6ms\n",
      "Speed: 2.2ms preprocess, 44.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/216.jpg: 384x640 (no detections), 35.2ms\n",
      "Speed: 1.9ms preprocess, 35.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/217.jpg: 384x640 (no detections), 35.1ms\n",
      "Speed: 1.7ms preprocess, 35.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/218.jpg: 384x640 (no detections), 49.7ms\n",
      "Speed: 3.3ms preprocess, 49.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/219.jpg: 384x640 (no detections), 30.5ms\n",
      "Speed: 2.4ms preprocess, 30.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/220.jpg: 384x640 (no detections), 36.1ms\n",
      "Speed: 2.4ms preprocess, 36.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/221.jpg: 384x640 (no detections), 28.9ms\n",
      "Speed: 1.9ms preprocess, 28.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/222.jpg: 384x640 (no detections), 40.7ms\n",
      "Speed: 1.9ms preprocess, 40.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/223.jpg: 384x640 (no detections), 53.9ms\n",
      "Speed: 3.6ms preprocess, 53.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/224.jpg: 384x640 (no detections), 43.6ms\n",
      "Speed: 3.0ms preprocess, 43.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/225.jpg: 384x640 (no detections), 41.2ms\n",
      "Speed: 1.9ms preprocess, 41.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/226.jpg: 384x640 (no detections), 33.3ms\n",
      "Speed: 2.9ms preprocess, 33.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/227.jpg: 384x640 (no detections), 31.3ms\n",
      "Speed: 3.1ms preprocess, 31.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/228.jpg: 384x640 (no detections), 36.7ms\n",
      "Speed: 2.0ms preprocess, 36.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/229.jpg: 384x640 (no detections), 37.6ms\n",
      "Speed: 2.0ms preprocess, 37.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/230.jpg: 384x640 (no detections), 46.3ms\n",
      "Speed: 2.1ms preprocess, 46.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/231.jpg: 384x640 (no detections), 51.4ms\n",
      "Speed: 3.3ms preprocess, 51.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/232.jpg: 384x640 (no detections), 33.8ms\n",
      "Speed: 2.0ms preprocess, 33.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/233.jpg: 384x640 1 motorcycle, 31.2ms\n",
      "Speed: 2.7ms preprocess, 31.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/234.jpg: 384x640 (no detections), 46.2ms\n",
      "Speed: 2.5ms preprocess, 46.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/235.jpg: 384x640 (no detections), 50.7ms\n",
      "Speed: 2.0ms preprocess, 50.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/236.jpg: 384x640 (no detections), 43.6ms\n",
      "Speed: 1.9ms preprocess, 43.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/237.jpg: 384x640 (no detections), 43.4ms\n",
      "Speed: 2.4ms preprocess, 43.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/238.jpg: 384x640 1 motorcycle, 36.4ms\n",
      "Speed: 2.0ms preprocess, 36.4ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/239.jpg: 384x640 (no detections), 34.0ms\n",
      "Speed: 3.2ms preprocess, 34.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/240.jpg: 384x640 (no detections), 61.9ms\n",
      "Speed: 2.6ms preprocess, 61.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/241.jpg: 384x640 (no detections), 41.3ms\n",
      "Speed: 2.8ms preprocess, 41.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/242.jpg: 384x640 (no detections), 48.8ms\n",
      "Speed: 2.9ms preprocess, 48.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/243.jpg: 384x640 (no detections), 49.5ms\n",
      "Speed: 3.0ms preprocess, 49.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/244.jpg: 384x640 (no detections), 50.1ms\n",
      "Speed: 2.2ms preprocess, 50.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/245.jpg: 384x640 1 motorcycle, 38.9ms\n",
      "Speed: 1.9ms preprocess, 38.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/246.jpg: 384x640 (no detections), 41.5ms\n",
      "Speed: 2.0ms preprocess, 41.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/247.jpg: 384x640 1 motorcycle, 31.0ms\n",
      "Speed: 2.0ms preprocess, 31.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/248.jpg: 384x640 1 motorcycle, 30.4ms\n",
      "Speed: 1.9ms preprocess, 30.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/249.jpg: 384x640 1 motorcycle, 40.5ms\n",
      "Speed: 2.4ms preprocess, 40.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/250.jpg: 384x640 (no detections), 50.6ms\n",
      "Speed: 2.1ms preprocess, 50.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/251.jpg: 384x640 1 motorcycle, 28.7ms\n",
      "Speed: 2.0ms preprocess, 28.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/252.jpg: 384x640 1 motorcycle, 47.9ms\n",
      "Speed: 1.9ms preprocess, 47.9ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/253.jpg: 384x640 1 motorcycle, 43.5ms\n",
      "Speed: 2.8ms preprocess, 43.5ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/254.jpg: 384x640 1 motorcycle, 29.5ms\n",
      "Speed: 1.9ms preprocess, 29.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/255.jpg: 384x640 (no detections), 58.3ms\n",
      "Speed: 1.9ms preprocess, 58.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/256.jpg: 384x640 (no detections), 29.4ms\n",
      "Speed: 1.9ms preprocess, 29.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/257.jpg: 384x640 (no detections), 51.8ms\n",
      "Speed: 2.9ms preprocess, 51.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/258.jpg: 384x640 (no detections), 43.0ms\n",
      "Speed: 2.6ms preprocess, 43.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/259.jpg: 384x640 (no detections), 35.3ms\n",
      "Speed: 2.0ms preprocess, 35.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/260.jpg: 384x640 1 motorcycle, 31.4ms\n",
      "Speed: 1.7ms preprocess, 31.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/261.jpg: 384x640 (no detections), 39.9ms\n",
      "Speed: 1.9ms preprocess, 39.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/262.jpg: 384x640 (no detections), 36.3ms\n",
      "Speed: 2.5ms preprocess, 36.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/263.jpg: 384x640 (no detections), 34.7ms\n",
      "Speed: 1.7ms preprocess, 34.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/264.jpg: 384x640 (no detections), 53.4ms\n",
      "Speed: 2.5ms preprocess, 53.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/265.jpg: 384x640 (no detections), 47.5ms\n",
      "Speed: 3.2ms preprocess, 47.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/266.jpg: 384x640 (no detections), 36.7ms\n",
      "Speed: 3.0ms preprocess, 36.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/267.jpg: 384x640 (no detections), 31.3ms\n",
      "Speed: 2.2ms preprocess, 31.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/268.jpg: 384x640 (no detections), 42.1ms\n",
      "Speed: 3.4ms preprocess, 42.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/269.jpg: 384x640 (no detections), 48.7ms\n",
      "Speed: 1.9ms preprocess, 48.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/270.jpg: 384x640 (no detections), 32.6ms\n",
      "Speed: 2.1ms preprocess, 32.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/271.jpg: 384x640 (no detections), 35.3ms\n",
      "Speed: 2.0ms preprocess, 35.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/272.jpg: 384x640 (no detections), 43.4ms\n",
      "Speed: 1.7ms preprocess, 43.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/273.jpg: 384x640 (no detections), 45.4ms\n",
      "Speed: 2.8ms preprocess, 45.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/274.jpg: 384x640 (no detections), 40.8ms\n",
      "Speed: 2.2ms preprocess, 40.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/275.jpg: 384x640 (no detections), 41.0ms\n",
      "Speed: 3.2ms preprocess, 41.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/276.jpg: 384x640 1 motorcycle, 42.2ms\n",
      "Speed: 1.9ms preprocess, 42.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/277.jpg: 384x640 1 motorcycle, 33.6ms\n",
      "Speed: 2.9ms preprocess, 33.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/278.jpg: 384x640 1 motorcycle, 35.3ms\n",
      "Speed: 2.3ms preprocess, 35.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/279.jpg: 384x640 1 motorcycle, 37.7ms\n",
      "Speed: 3.2ms preprocess, 37.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/280.jpg: 384x640 1 motorcycle, 31.0ms\n",
      "Speed: 2.2ms preprocess, 31.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/281.jpg: 384x640 2 motorcycles, 39.1ms\n",
      "Speed: 1.9ms preprocess, 39.1ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/282.jpg: 384x640 1 motorcycle, 32.2ms\n",
      "Speed: 1.8ms preprocess, 32.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/283.jpg: 384x640 1 motorcycle, 33.5ms\n",
      "Speed: 2.7ms preprocess, 33.5ms inference, 13.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/284.jpg: 384x640 (no detections), 59.4ms\n",
      "Speed: 3.2ms preprocess, 59.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/285.jpg: 384x640 1 motorcycle, 71.3ms\n",
      "Speed: 2.7ms preprocess, 71.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/286.jpg: 384x640 1 motorcycle, 37.5ms\n",
      "Speed: 2.0ms preprocess, 37.5ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/287.jpg: 384x640 (no detections), 44.5ms\n",
      "Speed: 2.0ms preprocess, 44.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/288.jpg: 384x640 (no detections), 34.7ms\n",
      "Speed: 2.6ms preprocess, 34.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/289.jpg: 384x640 (no detections), 66.1ms\n",
      "Speed: 3.5ms preprocess, 66.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/290.jpg: 384x640 (no detections), 49.8ms\n",
      "Speed: 2.5ms preprocess, 49.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/291.jpg: 384x640 (no detections), 44.0ms\n",
      "Speed: 2.3ms preprocess, 44.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/292.jpg: 384x640 (no detections), 63.2ms\n",
      "Speed: 4.1ms preprocess, 63.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/293.jpg: 384x640 (no detections), 41.0ms\n",
      "Speed: 2.0ms preprocess, 41.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/294.jpg: 384x640 (no detections), 50.1ms\n",
      "Speed: 2.1ms preprocess, 50.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/295.jpg: 384x640 1 motorcycle, 56.1ms\n",
      "Speed: 1.9ms preprocess, 56.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/296.jpg: 384x640 (no detections), 42.9ms\n",
      "Speed: 2.0ms preprocess, 42.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/297.jpg: 384x640 (no detections), 42.5ms\n",
      "Speed: 2.3ms preprocess, 42.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/298.jpg: 384x640 1 motorcycle, 58.1ms\n",
      "Speed: 3.2ms preprocess, 58.1ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/left/299.jpg: 384x640 (no detections), 87.1ms\n",
      "Speed: 2.1ms preprocess, 87.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Propagating video frames: 100%|| 300/300 [00:21<00:00, 13.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask propagation completed in 21.55 seconds.\n",
      "Processing predicted masks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing video frames: 300it [00:00, 748.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 300 masks for evaluation.\n",
      "Masks saved to data/masks/yolo11x-seg/val/data-raw-SegSTRONGC_val-val-1-1-low_brightness-left.pkl\n",
      "Loading ground truth masks for evaluation...\n",
      "Loaded 300 ground truth masks.\n",
      "Calculating evaluation metrics...\n",
      "Time taken for metrics calculation: 1.48 seconds.\n",
      "Mean IoU for data/raw/SegSTRONGC_val/val/1/1/low_brightness/left: 0.0679\n",
      "Mean DSC for data/raw/SegSTRONGC_val/val/1/1/low_brightness/left: 0.1032\n",
      "Loading existing results file: data/results/yolo11x-seg/val.json\n",
      "Results saved to data/results/yolo11x-seg/val.json\n",
      "Processing video took 25.53 seconds.\n",
      "==================================================\n",
      "Processing right camera video...\n",
      "==================================================\n",
      "Processing video: data/raw/SegSTRONGC_val/val/1/1/low_brightness/right\n",
      "Domain: low_brightness, Split: val, Camera: right\n",
      "Initializing Yolo for video...\n",
      "Initialization took 0.12 seconds.\n",
      "Starting mask propagation...\n",
      "Total images in video: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/0.jpg: 384x640 (no detections), 84.0ms\n",
      "Speed: 1.9ms preprocess, 84.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/1.jpg: 384x640 (no detections), 34.0ms\n",
      "Speed: 2.0ms preprocess, 34.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/2.jpg: 384x640 1 sink, 53.5ms\n",
      "Speed: 3.0ms preprocess, 53.5ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/3.jpg: 384x640 (no detections), 24.3ms\n",
      "Speed: 1.3ms preprocess, 24.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/4.jpg: 384x640 (no detections), 28.5ms\n",
      "Speed: 1.7ms preprocess, 28.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/5.jpg: 384x640 (no detections), 27.5ms\n",
      "Speed: 1.5ms preprocess, 27.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/6.jpg: 384x640 (no detections), 29.3ms\n",
      "Speed: 2.2ms preprocess, 29.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/7.jpg: 384x640 (no detections), 26.2ms\n",
      "Speed: 1.6ms preprocess, 26.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/8.jpg: 384x640 (no detections), 44.8ms\n",
      "Speed: 1.6ms preprocess, 44.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/9.jpg: 384x640 (no detections), 22.0ms\n",
      "Speed: 1.8ms preprocess, 22.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/10.jpg: 384x640 (no detections), 26.5ms\n",
      "Speed: 1.9ms preprocess, 26.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/11.jpg: 384x640 (no detections), 25.8ms\n",
      "Speed: 2.0ms preprocess, 25.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/12.jpg: 384x640 (no detections), 22.5ms\n",
      "Speed: 2.1ms preprocess, 22.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/13.jpg: 384x640 (no detections), 24.0ms\n",
      "Speed: 1.6ms preprocess, 24.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/14.jpg: 384x640 (no detections), 26.5ms\n",
      "Speed: 1.5ms preprocess, 26.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/15.jpg: 384x640 (no detections), 29.5ms\n",
      "Speed: 2.2ms preprocess, 29.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/16.jpg: 384x640 (no detections), 31.8ms\n",
      "Speed: 2.0ms preprocess, 31.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/17.jpg: 384x640 (no detections), 53.9ms\n",
      "Speed: 1.7ms preprocess, 53.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/18.jpg: 384x640 (no detections), 28.0ms\n",
      "Speed: 3.0ms preprocess, 28.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/19.jpg: 384x640 (no detections), 28.2ms\n",
      "Speed: 1.6ms preprocess, 28.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/20.jpg: 384x640 (no detections), 53.1ms\n",
      "Speed: 3.3ms preprocess, 53.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/21.jpg: 384x640 (no detections), 26.5ms\n",
      "Speed: 1.7ms preprocess, 26.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/22.jpg: 384x640 (no detections), 24.9ms\n",
      "Speed: 2.5ms preprocess, 24.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/23.jpg: 384x640 (no detections), 45.8ms\n",
      "Speed: 1.8ms preprocess, 45.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/24.jpg: 384x640 (no detections), 30.0ms\n",
      "Speed: 1.8ms preprocess, 30.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/25.jpg: 384x640 (no detections), 38.9ms\n",
      "Speed: 2.1ms preprocess, 38.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/26.jpg: 384x640 (no detections), 35.4ms\n",
      "Speed: 2.1ms preprocess, 35.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/27.jpg: 384x640 1 toothbrush, 56.7ms\n",
      "Speed: 5.8ms preprocess, 56.7ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/28.jpg: 384x640 1 toothbrush, 25.8ms\n",
      "Speed: 2.2ms preprocess, 25.8ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/29.jpg: 384x640 1 sink, 40.4ms\n",
      "Speed: 1.7ms preprocess, 40.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/30.jpg: 384x640 1 sink, 29.7ms\n",
      "Speed: 1.8ms preprocess, 29.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/31.jpg: 384x640 1 sink, 30.5ms\n",
      "Speed: 2.9ms preprocess, 30.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/32.jpg: 384x640 1 sink, 35.4ms\n",
      "Speed: 1.7ms preprocess, 35.4ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/33.jpg: 384x640 1 sink, 30.0ms\n",
      "Speed: 2.9ms preprocess, 30.0ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/34.jpg: 384x640 (no detections), 51.6ms\n",
      "Speed: 2.0ms preprocess, 51.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/35.jpg: 384x640 1 sink, 48.9ms\n",
      "Speed: 2.2ms preprocess, 48.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/36.jpg: 384x640 1 sink, 44.0ms\n",
      "Speed: 3.1ms preprocess, 44.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/37.jpg: 384x640 (no detections), 55.7ms\n",
      "Speed: 2.1ms preprocess, 55.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/38.jpg: 384x640 1 sink, 25.4ms\n",
      "Speed: 1.7ms preprocess, 25.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/39.jpg: 384x640 1 sink, 34.1ms\n",
      "Speed: 3.6ms preprocess, 34.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/40.jpg: 384x640 (no detections), 28.0ms\n",
      "Speed: 2.0ms preprocess, 28.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/41.jpg: 384x640 (no detections), 27.2ms\n",
      "Speed: 1.6ms preprocess, 27.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/42.jpg: 384x640 (no detections), 38.3ms\n",
      "Speed: 1.7ms preprocess, 38.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/43.jpg: 384x640 (no detections), 35.2ms\n",
      "Speed: 2.6ms preprocess, 35.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/44.jpg: 384x640 (no detections), 42.7ms\n",
      "Speed: 1.8ms preprocess, 42.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/45.jpg: 384x640 (no detections), 42.7ms\n",
      "Speed: 2.1ms preprocess, 42.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/46.jpg: 384x640 (no detections), 47.7ms\n",
      "Speed: 1.9ms preprocess, 47.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/47.jpg: 384x640 1 sink, 26.9ms\n",
      "Speed: 1.8ms preprocess, 26.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/48.jpg: 384x640 (no detections), 45.8ms\n",
      "Speed: 2.1ms preprocess, 45.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/49.jpg: 384x640 (no detections), 32.5ms\n",
      "Speed: 1.8ms preprocess, 32.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/50.jpg: 384x640 1 toothbrush, 27.8ms\n",
      "Speed: 2.1ms preprocess, 27.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/51.jpg: 384x640 1 toothbrush, 25.5ms\n",
      "Speed: 1.7ms preprocess, 25.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/52.jpg: 384x640 (no detections), 26.2ms\n",
      "Speed: 1.4ms preprocess, 26.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/53.jpg: 384x640 (no detections), 36.1ms\n",
      "Speed: 1.7ms preprocess, 36.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/54.jpg: 384x640 (no detections), 26.0ms\n",
      "Speed: 1.7ms preprocess, 26.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/55.jpg: 384x640 (no detections), 33.8ms\n",
      "Speed: 2.3ms preprocess, 33.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/56.jpg: 384x640 1 toothbrush, 41.3ms\n",
      "Speed: 2.7ms preprocess, 41.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/57.jpg: 384x640 1 toothbrush, 59.1ms\n",
      "Speed: 2.7ms preprocess, 59.1ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/58.jpg: 384x640 (no detections), 36.5ms\n",
      "Speed: 2.2ms preprocess, 36.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/59.jpg: 384x640 1 toothbrush, 39.6ms\n",
      "Speed: 1.8ms preprocess, 39.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/60.jpg: 384x640 (no detections), 44.3ms\n",
      "Speed: 2.8ms preprocess, 44.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/61.jpg: 384x640 (no detections), 42.7ms\n",
      "Speed: 3.1ms preprocess, 42.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/62.jpg: 384x640 1 toothbrush, 30.5ms\n",
      "Speed: 1.8ms preprocess, 30.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/63.jpg: 384x640 1 toothbrush, 26.8ms\n",
      "Speed: 1.7ms preprocess, 26.8ms inference, 7.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/64.jpg: 384x640 1 toothbrush, 46.1ms\n",
      "Speed: 2.7ms preprocess, 46.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/65.jpg: 384x640 1 toothbrush, 52.8ms\n",
      "Speed: 2.1ms preprocess, 52.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/66.jpg: 384x640 1 toothbrush, 38.6ms\n",
      "Speed: 3.0ms preprocess, 38.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/67.jpg: 384x640 (no detections), 48.5ms\n",
      "Speed: 3.0ms preprocess, 48.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/68.jpg: 384x640 (no detections), 26.6ms\n",
      "Speed: 3.0ms preprocess, 26.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/69.jpg: 384x640 (no detections), 28.9ms\n",
      "Speed: 1.7ms preprocess, 28.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/70.jpg: 384x640 (no detections), 34.0ms\n",
      "Speed: 1.8ms preprocess, 34.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/71.jpg: 384x640 (no detections), 40.7ms\n",
      "Speed: 1.9ms preprocess, 40.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/72.jpg: 384x640 (no detections), 39.0ms\n",
      "Speed: 2.2ms preprocess, 39.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/73.jpg: 384x640 (no detections), 38.3ms\n",
      "Speed: 2.3ms preprocess, 38.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/74.jpg: 384x640 (no detections), 49.4ms\n",
      "Speed: 3.3ms preprocess, 49.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/75.jpg: 384x640 1 toothbrush, 29.2ms\n",
      "Speed: 1.8ms preprocess, 29.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/76.jpg: 384x640 (no detections), 56.5ms\n",
      "Speed: 2.8ms preprocess, 56.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/77.jpg: 384x640 (no detections), 35.2ms\n",
      "Speed: 2.7ms preprocess, 35.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/78.jpg: 384x640 (no detections), 32.2ms\n",
      "Speed: 1.9ms preprocess, 32.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/79.jpg: 384x640 (no detections), 36.8ms\n",
      "Speed: 2.1ms preprocess, 36.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/80.jpg: 384x640 (no detections), 28.7ms\n",
      "Speed: 1.8ms preprocess, 28.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/81.jpg: 384x640 (no detections), 53.7ms\n",
      "Speed: 2.2ms preprocess, 53.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/82.jpg: 384x640 (no detections), 31.1ms\n",
      "Speed: 1.7ms preprocess, 31.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/83.jpg: 384x640 (no detections), 39.8ms\n",
      "Speed: 2.2ms preprocess, 39.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/84.jpg: 384x640 (no detections), 33.2ms\n",
      "Speed: 2.0ms preprocess, 33.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/85.jpg: 384x640 (no detections), 29.4ms\n",
      "Speed: 1.9ms preprocess, 29.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/86.jpg: 384x640 (no detections), 52.8ms\n",
      "Speed: 2.4ms preprocess, 52.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/87.jpg: 384x640 (no detections), 45.0ms\n",
      "Speed: 2.5ms preprocess, 45.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/88.jpg: 384x640 (no detections), 37.0ms\n",
      "Speed: 3.4ms preprocess, 37.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/89.jpg: 384x640 1 motorcycle, 32.9ms\n",
      "Speed: 1.9ms preprocess, 32.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/90.jpg: 384x640 (no detections), 48.0ms\n",
      "Speed: 2.0ms preprocess, 48.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/91.jpg: 384x640 (no detections), 45.1ms\n",
      "Speed: 1.7ms preprocess, 45.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/92.jpg: 384x640 (no detections), 35.4ms\n",
      "Speed: 2.2ms preprocess, 35.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/93.jpg: 384x640 (no detections), 27.3ms\n",
      "Speed: 1.9ms preprocess, 27.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/94.jpg: 384x640 (no detections), 46.9ms\n",
      "Speed: 1.9ms preprocess, 46.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/95.jpg: 384x640 (no detections), 32.2ms\n",
      "Speed: 2.0ms preprocess, 32.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/96.jpg: 384x640 (no detections), 30.2ms\n",
      "Speed: 3.2ms preprocess, 30.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/97.jpg: 384x640 (no detections), 39.2ms\n",
      "Speed: 2.3ms preprocess, 39.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/98.jpg: 384x640 (no detections), 36.2ms\n",
      "Speed: 1.8ms preprocess, 36.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/99.jpg: 384x640 (no detections), 33.1ms\n",
      "Speed: 1.9ms preprocess, 33.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/100.jpg: 384x640 (no detections), 31.3ms\n",
      "Speed: 2.1ms preprocess, 31.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/101.jpg: 384x640 (no detections), 38.2ms\n",
      "Speed: 3.3ms preprocess, 38.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/102.jpg: 384x640 (no detections), 30.5ms\n",
      "Speed: 1.7ms preprocess, 30.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/103.jpg: 384x640 (no detections), 27.2ms\n",
      "Speed: 1.7ms preprocess, 27.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/104.jpg: 384x640 (no detections), 27.5ms\n",
      "Speed: 1.7ms preprocess, 27.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/105.jpg: 384x640 (no detections), 48.7ms\n",
      "Speed: 3.5ms preprocess, 48.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/106.jpg: 384x640 (no detections), 38.2ms\n",
      "Speed: 2.2ms preprocess, 38.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/107.jpg: 384x640 (no detections), 34.3ms\n",
      "Speed: 1.8ms preprocess, 34.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/108.jpg: 384x640 (no detections), 32.5ms\n",
      "Speed: 1.8ms preprocess, 32.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/109.jpg: 384x640 (no detections), 33.4ms\n",
      "Speed: 2.6ms preprocess, 33.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/110.jpg: 384x640 (no detections), 31.3ms\n",
      "Speed: 2.1ms preprocess, 31.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/111.jpg: 384x640 (no detections), 50.6ms\n",
      "Speed: 1.8ms preprocess, 50.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/112.jpg: 384x640 (no detections), 50.8ms\n",
      "Speed: 2.6ms preprocess, 50.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/113.jpg: 384x640 (no detections), 27.3ms\n",
      "Speed: 1.7ms preprocess, 27.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/114.jpg: 384x640 (no detections), 30.6ms\n",
      "Speed: 1.7ms preprocess, 30.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/115.jpg: 384x640 (no detections), 31.0ms\n",
      "Speed: 2.4ms preprocess, 31.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/116.jpg: 384x640 (no detections), 29.5ms\n",
      "Speed: 2.1ms preprocess, 29.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/117.jpg: 384x640 (no detections), 29.0ms\n",
      "Speed: 2.5ms preprocess, 29.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/118.jpg: 384x640 (no detections), 62.7ms\n",
      "Speed: 2.0ms preprocess, 62.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/119.jpg: 384x640 (no detections), 37.4ms\n",
      "Speed: 2.0ms preprocess, 37.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/120.jpg: 384x640 (no detections), 35.9ms\n",
      "Speed: 2.9ms preprocess, 35.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/121.jpg: 384x640 (no detections), 25.4ms\n",
      "Speed: 1.8ms preprocess, 25.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/122.jpg: 384x640 (no detections), 26.5ms\n",
      "Speed: 1.7ms preprocess, 26.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/123.jpg: 384x640 (no detections), 35.1ms\n",
      "Speed: 2.1ms preprocess, 35.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/124.jpg: 384x640 (no detections), 35.2ms\n",
      "Speed: 1.9ms preprocess, 35.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/125.jpg: 384x640 (no detections), 32.2ms\n",
      "Speed: 2.1ms preprocess, 32.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/126.jpg: 384x640 (no detections), 30.5ms\n",
      "Speed: 1.8ms preprocess, 30.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/127.jpg: 384x640 (no detections), 39.9ms\n",
      "Speed: 2.0ms preprocess, 39.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/128.jpg: 384x640 1 boat, 34.8ms\n",
      "Speed: 1.7ms preprocess, 34.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/129.jpg: 384x640 (no detections), 27.4ms\n",
      "Speed: 1.9ms preprocess, 27.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/130.jpg: 384x640 (no detections), 70.3ms\n",
      "Speed: 2.2ms preprocess, 70.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/131.jpg: 384x640 (no detections), 48.9ms\n",
      "Speed: 1.8ms preprocess, 48.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/132.jpg: 384x640 (no detections), 32.3ms\n",
      "Speed: 3.0ms preprocess, 32.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/133.jpg: 384x640 (no detections), 27.9ms\n",
      "Speed: 1.6ms preprocess, 27.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/134.jpg: 384x640 (no detections), 36.2ms\n",
      "Speed: 3.9ms preprocess, 36.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/135.jpg: 384x640 (no detections), 27.8ms\n",
      "Speed: 2.2ms preprocess, 27.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/136.jpg: 384x640 (no detections), 46.1ms\n",
      "Speed: 2.3ms preprocess, 46.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/137.jpg: 384x640 (no detections), 29.2ms\n",
      "Speed: 2.2ms preprocess, 29.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/138.jpg: 384x640 (no detections), 32.2ms\n",
      "Speed: 2.7ms preprocess, 32.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/139.jpg: 384x640 (no detections), 27.5ms\n",
      "Speed: 1.6ms preprocess, 27.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/140.jpg: 384x640 (no detections), 31.2ms\n",
      "Speed: 2.6ms preprocess, 31.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/141.jpg: 384x640 (no detections), 37.5ms\n",
      "Speed: 2.0ms preprocess, 37.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/142.jpg: 384x640 1 toothbrush, 49.8ms\n",
      "Speed: 1.9ms preprocess, 49.8ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/143.jpg: 384x640 (no detections), 39.2ms\n",
      "Speed: 1.9ms preprocess, 39.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/144.jpg: 384x640 1 toothbrush, 46.5ms\n",
      "Speed: 2.9ms preprocess, 46.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/145.jpg: 384x640 (no detections), 31.3ms\n",
      "Speed: 2.1ms preprocess, 31.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/146.jpg: 384x640 (no detections), 28.6ms\n",
      "Speed: 1.9ms preprocess, 28.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/147.jpg: 384x640 (no detections), 27.8ms\n",
      "Speed: 1.6ms preprocess, 27.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/148.jpg: 384x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/149.jpg: 384x640 (no detections), 34.3ms\n",
      "Speed: 1.6ms preprocess, 34.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/150.jpg: 384x640 (no detections), 56.2ms\n",
      "Speed: 3.4ms preprocess, 56.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/151.jpg: 384x640 (no detections), 46.5ms\n",
      "Speed: 3.2ms preprocess, 46.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/152.jpg: 384x640 (no detections), 27.8ms\n",
      "Speed: 2.1ms preprocess, 27.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/153.jpg: 384x640 (no detections), 30.8ms\n",
      "Speed: 1.7ms preprocess, 30.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/154.jpg: 384x640 (no detections), 40.5ms\n",
      "Speed: 2.4ms preprocess, 40.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/155.jpg: 384x640 (no detections), 33.0ms\n",
      "Speed: 2.0ms preprocess, 33.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/156.jpg: 384x640 (no detections), 43.8ms\n",
      "Speed: 2.0ms preprocess, 43.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/157.jpg: 384x640 (no detections), 40.1ms\n",
      "Speed: 2.1ms preprocess, 40.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/158.jpg: 384x640 (no detections), 32.4ms\n",
      "Speed: 2.8ms preprocess, 32.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/159.jpg: 384x640 (no detections), 32.5ms\n",
      "Speed: 2.9ms preprocess, 32.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/160.jpg: 384x640 (no detections), 30.5ms\n",
      "Speed: 2.1ms preprocess, 30.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/161.jpg: 384x640 (no detections), 54.9ms\n",
      "Speed: 2.1ms preprocess, 54.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/162.jpg: 384x640 (no detections), 34.4ms\n",
      "Speed: 1.8ms preprocess, 34.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/163.jpg: 384x640 (no detections), 33.6ms\n",
      "Speed: 1.8ms preprocess, 33.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/164.jpg: 384x640 (no detections), 49.3ms\n",
      "Speed: 2.4ms preprocess, 49.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/165.jpg: 384x640 (no detections), 45.1ms\n",
      "Speed: 2.2ms preprocess, 45.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/166.jpg: 384x640 (no detections), 49.7ms\n",
      "Speed: 2.5ms preprocess, 49.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/167.jpg: 384x640 (no detections), 32.5ms\n",
      "Speed: 2.4ms preprocess, 32.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/168.jpg: 384x640 (no detections), 39.8ms\n",
      "Speed: 2.4ms preprocess, 39.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/169.jpg: 384x640 (no detections), 42.8ms\n",
      "Speed: 2.2ms preprocess, 42.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/170.jpg: 384x640 (no detections), 35.0ms\n",
      "Speed: 2.0ms preprocess, 35.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/171.jpg: 384x640 (no detections), 33.0ms\n",
      "Speed: 1.7ms preprocess, 33.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/172.jpg: 384x640 (no detections), 38.9ms\n",
      "Speed: 3.5ms preprocess, 38.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/173.jpg: 384x640 (no detections), 29.3ms\n",
      "Speed: 1.7ms preprocess, 29.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/174.jpg: 384x640 (no detections), 31.4ms\n",
      "Speed: 2.0ms preprocess, 31.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/175.jpg: 384x640 (no detections), 35.9ms\n",
      "Speed: 2.5ms preprocess, 35.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/176.jpg: 384x640 (no detections), 33.8ms\n",
      "Speed: 1.8ms preprocess, 33.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/177.jpg: 384x640 (no detections), 38.3ms\n",
      "Speed: 2.0ms preprocess, 38.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/178.jpg: 384x640 (no detections), 38.2ms\n",
      "Speed: 2.5ms preprocess, 38.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/179.jpg: 384x640 (no detections), 36.6ms\n",
      "Speed: 1.9ms preprocess, 36.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/180.jpg: 384x640 1 toothbrush, 34.4ms\n",
      "Speed: 2.2ms preprocess, 34.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/181.jpg: 384x640 1 toothbrush, 38.6ms\n",
      "Speed: 1.9ms preprocess, 38.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/182.jpg: 384x640 (no detections), 38.9ms\n",
      "Speed: 2.0ms preprocess, 38.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/183.jpg: 384x640 (no detections), 32.3ms\n",
      "Speed: 2.2ms preprocess, 32.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/184.jpg: 384x640 (no detections), 38.4ms\n",
      "Speed: 2.8ms preprocess, 38.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/185.jpg: 384x640 (no detections), 28.2ms\n",
      "Speed: 2.1ms preprocess, 28.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/186.jpg: 384x640 (no detections), 26.6ms\n",
      "Speed: 2.0ms preprocess, 26.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/187.jpg: 384x640 (no detections), 28.5ms\n",
      "Speed: 1.7ms preprocess, 28.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/188.jpg: 384x640 (no detections), 37.9ms\n",
      "Speed: 3.2ms preprocess, 37.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/189.jpg: 384x640 (no detections), 40.2ms\n",
      "Speed: 1.9ms preprocess, 40.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/190.jpg: 384x640 (no detections), 35.8ms\n",
      "Speed: 2.0ms preprocess, 35.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/191.jpg: 384x640 (no detections), 43.8ms\n",
      "Speed: 2.0ms preprocess, 43.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/192.jpg: 384x640 (no detections), 30.5ms\n",
      "Speed: 1.9ms preprocess, 30.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/193.jpg: 384x640 (no detections), 40.3ms\n",
      "Speed: 3.1ms preprocess, 40.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/194.jpg: 384x640 (no detections), 36.2ms\n",
      "Speed: 2.2ms preprocess, 36.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/195.jpg: 384x640 (no detections), 40.4ms\n",
      "Speed: 1.8ms preprocess, 40.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/196.jpg: 384x640 (no detections), 40.8ms\n",
      "Speed: 1.9ms preprocess, 40.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/197.jpg: 384x640 (no detections), 50.3ms\n",
      "Speed: 1.9ms preprocess, 50.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/198.jpg: 384x640 (no detections), 43.9ms\n",
      "Speed: 3.1ms preprocess, 43.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/199.jpg: 384x640 (no detections), 30.6ms\n",
      "Speed: 2.7ms preprocess, 30.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/200.jpg: 384x640 (no detections), 25.3ms\n",
      "Speed: 1.8ms preprocess, 25.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/201.jpg: 384x640 (no detections), 55.3ms\n",
      "Speed: 2.5ms preprocess, 55.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/202.jpg: 384x640 (no detections), 31.7ms\n",
      "Speed: 1.7ms preprocess, 31.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/203.jpg: 384x640 (no detections), 41.2ms\n",
      "Speed: 2.0ms preprocess, 41.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/204.jpg: 384x640 (no detections), 29.3ms\n",
      "Speed: 2.0ms preprocess, 29.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/205.jpg: 384x640 (no detections), 44.0ms\n",
      "Speed: 1.8ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/206.jpg: 384x640 (no detections), 38.3ms\n",
      "Speed: 1.7ms preprocess, 38.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/207.jpg: 384x640 (no detections), 26.9ms\n",
      "Speed: 1.7ms preprocess, 26.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/208.jpg: 384x640 (no detections), 35.3ms\n",
      "Speed: 2.8ms preprocess, 35.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/209.jpg: 384x640 (no detections), 29.6ms\n",
      "Speed: 2.0ms preprocess, 29.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/210.jpg: 384x640 (no detections), 26.5ms\n",
      "Speed: 1.7ms preprocess, 26.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/211.jpg: 384x640 (no detections), 29.7ms\n",
      "Speed: 1.7ms preprocess, 29.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/212.jpg: 384x640 (no detections), 29.0ms\n",
      "Speed: 1.9ms preprocess, 29.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/213.jpg: 384x640 (no detections), 26.2ms\n",
      "Speed: 2.6ms preprocess, 26.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/214.jpg: 384x640 (no detections), 33.5ms\n",
      "Speed: 1.9ms preprocess, 33.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/215.jpg: 384x640 (no detections), 51.3ms\n",
      "Speed: 1.8ms preprocess, 51.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/216.jpg: 384x640 (no detections), 46.2ms\n",
      "Speed: 2.3ms preprocess, 46.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/217.jpg: 384x640 (no detections), 31.2ms\n",
      "Speed: 1.8ms preprocess, 31.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/218.jpg: 384x640 1 sink, 30.7ms\n",
      "Speed: 2.2ms preprocess, 30.7ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/219.jpg: 384x640 (no detections), 31.2ms\n",
      "Speed: 1.8ms preprocess, 31.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/220.jpg: 384x640 (no detections), 43.4ms\n",
      "Speed: 2.9ms preprocess, 43.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/221.jpg: 384x640 (no detections), 40.1ms\n",
      "Speed: 1.8ms preprocess, 40.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/222.jpg: 384x640 (no detections), 37.8ms\n",
      "Speed: 3.0ms preprocess, 37.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/223.jpg: 384x640 (no detections), 34.2ms\n",
      "Speed: 1.8ms preprocess, 34.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/224.jpg: 384x640 1 sink, 54.2ms\n",
      "Speed: 2.3ms preprocess, 54.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/225.jpg: 384x640 (no detections), 29.9ms\n",
      "Speed: 1.8ms preprocess, 29.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/226.jpg: 384x640 (no detections), 33.4ms\n",
      "Speed: 1.8ms preprocess, 33.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/227.jpg: 384x640 (no detections), 29.6ms\n",
      "Speed: 1.7ms preprocess, 29.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/228.jpg: 384x640 (no detections), 40.2ms\n",
      "Speed: 1.8ms preprocess, 40.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/229.jpg: 384x640 (no detections), 25.8ms\n",
      "Speed: 1.8ms preprocess, 25.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/230.jpg: 384x640 (no detections), 25.3ms\n",
      "Speed: 1.7ms preprocess, 25.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/231.jpg: 384x640 (no detections), 29.9ms\n",
      "Speed: 2.9ms preprocess, 29.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/232.jpg: 384x640 (no detections), 46.3ms\n",
      "Speed: 1.9ms preprocess, 46.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/233.jpg: 384x640 (no detections), 36.5ms\n",
      "Speed: 3.0ms preprocess, 36.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/234.jpg: 384x640 1 toothbrush, 46.3ms\n",
      "Speed: 2.6ms preprocess, 46.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/235.jpg: 384x640 (no detections), 25.5ms\n",
      "Speed: 1.8ms preprocess, 25.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/236.jpg: 384x640 (no detections), 32.3ms\n",
      "Speed: 2.0ms preprocess, 32.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/237.jpg: 384x640 (no detections), 28.9ms\n",
      "Speed: 2.0ms preprocess, 28.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/238.jpg: 384x640 (no detections), 28.3ms\n",
      "Speed: 1.9ms preprocess, 28.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/239.jpg: 384x640 (no detections), 30.6ms\n",
      "Speed: 1.7ms preprocess, 30.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/240.jpg: 384x640 (no detections), 31.5ms\n",
      "Speed: 2.1ms preprocess, 31.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/241.jpg: 384x640 (no detections), 34.4ms\n",
      "Speed: 3.1ms preprocess, 34.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/242.jpg: 384x640 (no detections), 44.3ms\n",
      "Speed: 2.0ms preprocess, 44.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/243.jpg: 384x640 (no detections), 39.1ms\n",
      "Speed: 1.9ms preprocess, 39.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/244.jpg: 384x640 (no detections), 28.8ms\n",
      "Speed: 1.9ms preprocess, 28.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/245.jpg: 384x640 (no detections), 28.4ms\n",
      "Speed: 1.7ms preprocess, 28.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/246.jpg: 384x640 (no detections), 36.7ms\n",
      "Speed: 2.0ms preprocess, 36.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/247.jpg: 384x640 1 toothbrush, 27.3ms\n",
      "Speed: 2.7ms preprocess, 27.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/248.jpg: 384x640 (no detections), 26.7ms\n",
      "Speed: 1.8ms preprocess, 26.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/249.jpg: 384x640 (no detections), 50.4ms\n",
      "Speed: 2.9ms preprocess, 50.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/250.jpg: 384x640 (no detections), 30.0ms\n",
      "Speed: 1.8ms preprocess, 30.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/251.jpg: 384x640 1 toothbrush, 62.7ms\n",
      "Speed: 2.2ms preprocess, 62.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/252.jpg: 384x640 1 motorcycle, 26.7ms\n",
      "Speed: 1.6ms preprocess, 26.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/253.jpg: 384x640 (no detections), 36.6ms\n",
      "Speed: 2.7ms preprocess, 36.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/254.jpg: 384x640 (no detections), 27.0ms\n",
      "Speed: 2.8ms preprocess, 27.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/255.jpg: 384x640 (no detections), 26.9ms\n",
      "Speed: 1.6ms preprocess, 26.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/256.jpg: 384x640 (no detections), 34.3ms\n",
      "Speed: 2.7ms preprocess, 34.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/257.jpg: 384x640 1 toothbrush, 48.9ms\n",
      "Speed: 3.5ms preprocess, 48.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/258.jpg: 384x640 (no detections), 27.9ms\n",
      "Speed: 1.9ms preprocess, 27.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/259.jpg: 384x640 (no detections), 29.9ms\n",
      "Speed: 2.4ms preprocess, 29.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/260.jpg: 384x640 (no detections), 35.1ms\n",
      "Speed: 2.2ms preprocess, 35.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/261.jpg: 384x640 (no detections), 34.5ms\n",
      "Speed: 1.9ms preprocess, 34.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/262.jpg: 384x640 (no detections), 25.1ms\n",
      "Speed: 1.7ms preprocess, 25.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/263.jpg: 384x640 (no detections), 42.3ms\n",
      "Speed: 2.1ms preprocess, 42.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/264.jpg: 384x640 (no detections), 31.5ms\n",
      "Speed: 1.8ms preprocess, 31.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/265.jpg: 384x640 (no detections), 27.3ms\n",
      "Speed: 2.0ms preprocess, 27.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/266.jpg: 384x640 (no detections), 29.2ms\n",
      "Speed: 2.0ms preprocess, 29.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/267.jpg: 384x640 (no detections), 51.1ms\n",
      "Speed: 2.8ms preprocess, 51.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/268.jpg: 384x640 (no detections), 37.8ms\n",
      "Speed: 2.5ms preprocess, 37.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/269.jpg: 384x640 (no detections), 46.6ms\n",
      "Speed: 3.3ms preprocess, 46.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/270.jpg: 384x640 (no detections), 44.2ms\n",
      "Speed: 2.1ms preprocess, 44.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/271.jpg: 384x640 (no detections), 41.5ms\n",
      "Speed: 2.6ms preprocess, 41.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/272.jpg: 384x640 (no detections), 54.3ms\n",
      "Speed: 2.7ms preprocess, 54.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/273.jpg: 384x640 (no detections), 47.2ms\n",
      "Speed: 1.7ms preprocess, 47.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/274.jpg: 384x640 (no detections), 35.9ms\n",
      "Speed: 3.1ms preprocess, 35.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/275.jpg: 384x640 (no detections), 38.2ms\n",
      "Speed: 2.2ms preprocess, 38.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/276.jpg: 384x640 (no detections), 27.6ms\n",
      "Speed: 1.7ms preprocess, 27.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/277.jpg: 384x640 (no detections), 40.4ms\n",
      "Speed: 2.8ms preprocess, 40.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/278.jpg: 384x640 (no detections), 36.9ms\n",
      "Speed: 2.0ms preprocess, 36.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/279.jpg: 384x640 1 motorcycle, 56.0ms\n",
      "Speed: 2.1ms preprocess, 56.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/280.jpg: 384x640 (no detections), 49.3ms\n",
      "Speed: 3.4ms preprocess, 49.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/281.jpg: 384x640 1 motorcycle, 28.8ms\n",
      "Speed: 1.8ms preprocess, 28.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/282.jpg: 384x640 (no detections), 49.8ms\n",
      "Speed: 2.1ms preprocess, 49.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/283.jpg: 384x640 (no detections), 45.6ms\n",
      "Speed: 3.7ms preprocess, 45.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/284.jpg: 384x640 (no detections), 35.9ms\n",
      "Speed: 1.9ms preprocess, 35.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/285.jpg: 384x640 (no detections), 35.5ms\n",
      "Speed: 1.9ms preprocess, 35.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/286.jpg: 384x640 1 toothbrush, 53.9ms\n",
      "Speed: 3.6ms preprocess, 53.9ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/287.jpg: 384x640 (no detections), 42.8ms\n",
      "Speed: 3.0ms preprocess, 42.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/288.jpg: 384x640 (no detections), 32.7ms\n",
      "Speed: 1.9ms preprocess, 32.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/289.jpg: 384x640 (no detections), 44.8ms\n",
      "Speed: 2.5ms preprocess, 44.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/290.jpg: 384x640 (no detections), 28.7ms\n",
      "Speed: 1.8ms preprocess, 28.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/291.jpg: 384x640 (no detections), 44.6ms\n",
      "Speed: 1.9ms preprocess, 44.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/292.jpg: 384x640 (no detections), 27.6ms\n",
      "Speed: 1.9ms preprocess, 27.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/293.jpg: 384x640 (no detections), 28.6ms\n",
      "Speed: 3.1ms preprocess, 28.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/294.jpg: 384x640 (no detections), 31.1ms\n",
      "Speed: 2.1ms preprocess, 31.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/295.jpg: 384x640 (no detections), 45.1ms\n",
      "Speed: 1.8ms preprocess, 45.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/296.jpg: 384x640 (no detections), 31.5ms\n",
      "Speed: 1.9ms preprocess, 31.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/297.jpg: 384x640 (no detections), 55.1ms\n",
      "Speed: 1.8ms preprocess, 55.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/298.jpg: 384x640 (no detections), 30.1ms\n",
      "Speed: 1.9ms preprocess, 30.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/low_brightness/right/299.jpg: 384x640 (no detections), 38.2ms\n",
      "Speed: 2.8ms preprocess, 38.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Propagating video frames: 100%|| 300/300 [00:18<00:00, 15.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask propagation completed in 18.91 seconds.\n",
      "Processing predicted masks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing video frames: 300it [00:00, 1248.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 300 masks for evaluation.\n",
      "Masks saved to data/masks/yolo11x-seg/val/data-raw-SegSTRONGC_val-val-1-1-low_brightness-right.pkl\n",
      "Loading ground truth masks for evaluation...\n",
      "Loaded 300 ground truth masks.\n",
      "Calculating evaluation metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for metrics calculation: 1.94 seconds.\n",
      "Mean IoU for data/raw/SegSTRONGC_val/val/1/1/low_brightness/right: 0.0354\n",
      "Mean DSC for data/raw/SegSTRONGC_val/val/1/1/low_brightness/right: 0.0548\n",
      "Loading existing results file: data/results/yolo11x-seg/val.json\n",
      "Results saved to data/results/yolo11x-seg/val.json\n",
      "Processing video took 22.67 seconds.\n",
      "==================================================\n",
      "\n",
      "Results for data/raw/SegSTRONGC_val/val/1/1/low_brightness:\n",
      "  Left: IoU=0.0679, DSC=0.1032\n",
      "  Right: IoU=0.0354, DSC=0.0548\n",
      "  Overall: IoU=0.0516, DSC=0.0790\n",
      "\n",
      "Processing domain: regular\n",
      "Processing left camera video...\n",
      "==================================================\n",
      "Processing video: data/raw/SegSTRONGC_val/val/1/1/regular/left\n",
      "Domain: regular, Split: val, Camera: left\n",
      "Initializing Yolo for video...\n",
      "Initialization took 0.15 seconds.\n",
      "Starting mask propagation...\n",
      "Total images in video: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/0.jpg: 384x640 2 baseball bats, 1 carrot, 85.2ms\n",
      "Speed: 2.9ms preprocess, 85.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/1.jpg: 384x640 2 baseball bats, 35.6ms\n",
      "Speed: 2.3ms preprocess, 35.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/2.jpg: 384x640 2 baseball bats, 1 carrot, 26.5ms\n",
      "Speed: 1.6ms preprocess, 26.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/3.jpg: 384x640 2 baseball bats, 52.6ms\n",
      "Speed: 2.2ms preprocess, 52.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/4.jpg: 384x640 2 baseball bats, 60.3ms\n",
      "Speed: 2.8ms preprocess, 60.3ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/5.jpg: 384x640 1 baseball bat, 34.3ms\n",
      "Speed: 2.0ms preprocess, 34.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/6.jpg: 384x640 2 baseball bats, 58.1ms\n",
      "Speed: 3.5ms preprocess, 58.1ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/7.jpg: 384x640 2 baseball bats, 31.5ms\n",
      "Speed: 2.1ms preprocess, 31.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/8.jpg: 384x640 (no detections), 36.2ms\n",
      "Speed: 1.9ms preprocess, 36.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/9.jpg: 384x640 (no detections), 36.5ms\n",
      "Speed: 2.0ms preprocess, 36.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/10.jpg: 384x640 (no detections), 28.6ms\n",
      "Speed: 2.0ms preprocess, 28.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/11.jpg: 384x640 1 spoon, 54.4ms\n",
      "Speed: 2.0ms preprocess, 54.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/12.jpg: 384x640 (no detections), 44.5ms\n",
      "Speed: 2.3ms preprocess, 44.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/13.jpg: 384x640 1 knife, 1 carrot, 66.0ms\n",
      "Speed: 2.1ms preprocess, 66.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/14.jpg: 384x640 1 carrot, 33.3ms\n",
      "Speed: 2.2ms preprocess, 33.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/15.jpg: 384x640 1 baseball bat, 1 carrot, 30.7ms\n",
      "Speed: 2.8ms preprocess, 30.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/16.jpg: 384x640 1 carrot, 30.4ms\n",
      "Speed: 2.1ms preprocess, 30.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/17.jpg: 384x640 1 baseball bat, 1 carrot, 59.9ms\n",
      "Speed: 1.8ms preprocess, 59.9ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/18.jpg: 384x640 1 baseball bat, 43.5ms\n",
      "Speed: 2.2ms preprocess, 43.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/19.jpg: 384x640 1 spoon, 29.1ms\n",
      "Speed: 2.0ms preprocess, 29.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/20.jpg: 384x640 1 bottle, 29.1ms\n",
      "Speed: 2.0ms preprocess, 29.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/21.jpg: 384x640 1 bottle, 39.8ms\n",
      "Speed: 3.2ms preprocess, 39.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/22.jpg: 384x640 1 baseball bat, 1 carrot, 40.6ms\n",
      "Speed: 1.9ms preprocess, 40.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/23.jpg: 384x640 2 baseball bats, 61.3ms\n",
      "Speed: 3.1ms preprocess, 61.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/24.jpg: 384x640 2 baseball bats, 1 carrot, 42.7ms\n",
      "Speed: 2.1ms preprocess, 42.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/25.jpg: 384x640 2 baseball bats, 63.7ms\n",
      "Speed: 3.4ms preprocess, 63.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/26.jpg: 384x640 2 baseball bats, 72.9ms\n",
      "Speed: 3.6ms preprocess, 72.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/27.jpg: 384x640 2 spoons, 4 carrots, 46.2ms\n",
      "Speed: 3.3ms preprocess, 46.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/28.jpg: 384x640 1 person, 2 baseball bats, 38.8ms\n",
      "Speed: 2.9ms preprocess, 38.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/29.jpg: 384x640 2 baseball bats, 1 carrot, 33.6ms\n",
      "Speed: 2.0ms preprocess, 33.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/30.jpg: 384x640 2 baseball bats, 1 carrot, 33.9ms\n",
      "Speed: 3.0ms preprocess, 33.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/31.jpg: 384x640 1 baseball bat, 1 spoon, 1 carrot, 37.4ms\n",
      "Speed: 2.3ms preprocess, 37.4ms inference, 6.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/32.jpg: 384x640 2 baseball bats, 1 carrot, 37.4ms\n",
      "Speed: 2.5ms preprocess, 37.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/33.jpg: 384x640 2 baseball bats, 1 carrot, 31.1ms\n",
      "Speed: 2.1ms preprocess, 31.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/34.jpg: 384x640 1 baseball bat, 1 spoon, 1 carrot, 37.9ms\n",
      "Speed: 2.4ms preprocess, 37.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/35.jpg: 384x640 2 baseball bats, 1 carrot, 29.5ms\n",
      "Speed: 1.9ms preprocess, 29.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/36.jpg: 384x640 2 baseball bats, 2 carrots, 27.4ms\n",
      "Speed: 1.7ms preprocess, 27.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/37.jpg: 384x640 2 baseball bats, 1 carrot, 39.1ms\n",
      "Speed: 2.2ms preprocess, 39.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/38.jpg: 384x640 2 baseball bats, 1 carrot, 48.3ms\n",
      "Speed: 1.7ms preprocess, 48.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/39.jpg: 384x640 2 baseball bats, 31.5ms\n",
      "Speed: 1.7ms preprocess, 31.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/40.jpg: 384x640 1 knife, 38.7ms\n",
      "Speed: 2.3ms preprocess, 38.7ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/41.jpg: 384x640 2 knifes, 50.0ms\n",
      "Speed: 2.2ms preprocess, 50.0ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/42.jpg: 384x640 2 baseball bats, 34.6ms\n",
      "Speed: 3.0ms preprocess, 34.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/43.jpg: 384x640 1 baseball bat, 1 carrot, 41.1ms\n",
      "Speed: 1.9ms preprocess, 41.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/44.jpg: 384x640 2 baseball bats, 1 carrot, 49.3ms\n",
      "Speed: 2.6ms preprocess, 49.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/45.jpg: 384x640 1 baseball bat, 32.9ms\n",
      "Speed: 3.1ms preprocess, 32.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/46.jpg: 384x640 2 baseball bats, 1 carrot, 35.3ms\n",
      "Speed: 2.1ms preprocess, 35.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/47.jpg: 384x640 1 baseball bat, 1 carrot, 30.2ms\n",
      "Speed: 2.1ms preprocess, 30.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/48.jpg: 384x640 1 baseball bat, 1 knife, 1 carrot, 33.6ms\n",
      "Speed: 1.9ms preprocess, 33.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/49.jpg: 384x640 1 baseball bat, 1 bottle, 1 carrot, 50.1ms\n",
      "Speed: 2.1ms preprocess, 50.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/50.jpg: 384x640 1 baseball bat, 1 bottle, 1 carrot, 31.1ms\n",
      "Speed: 2.7ms preprocess, 31.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/51.jpg: 384x640 1 bottle, 1 carrot, 59.7ms\n",
      "Speed: 2.7ms preprocess, 59.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/52.jpg: 384x640 1 carrot, 30.6ms\n",
      "Speed: 3.1ms preprocess, 30.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/53.jpg: 384x640 1 knife, 34.2ms\n",
      "Speed: 1.8ms preprocess, 34.2ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/54.jpg: 384x640 1 bottle, 36.2ms\n",
      "Speed: 2.8ms preprocess, 36.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/55.jpg: 384x640 1 bottle, 39.1ms\n",
      "Speed: 2.2ms preprocess, 39.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/56.jpg: 384x640 1 bottle, 49.9ms\n",
      "Speed: 2.8ms preprocess, 49.9ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/57.jpg: 384x640 (no detections), 30.0ms\n",
      "Speed: 1.9ms preprocess, 30.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/58.jpg: 384x640 (no detections), 35.8ms\n",
      "Speed: 3.2ms preprocess, 35.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/59.jpg: 384x640 1 baseball bat, 1 knife, 50.9ms\n",
      "Speed: 3.0ms preprocess, 50.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/60.jpg: 384x640 1 baseball bat, 1 spoon, 26.1ms\n",
      "Speed: 1.6ms preprocess, 26.1ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/61.jpg: 384x640 1 baseball bat, 1 bottle, 27.8ms\n",
      "Speed: 1.8ms preprocess, 27.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/62.jpg: 384x640 2 baseball bats, 1 bottle, 28.6ms\n",
      "Speed: 1.8ms preprocess, 28.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/63.jpg: 384x640 1 knife, 30.9ms\n",
      "Speed: 2.7ms preprocess, 30.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/64.jpg: 384x640 1 baseball bat, 1 bottle, 54.6ms\n",
      "Speed: 1.9ms preprocess, 54.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/65.jpg: 384x640 1 baseball bat, 1 bottle, 1 spoon, 48.1ms\n",
      "Speed: 2.3ms preprocess, 48.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/66.jpg: 384x640 1 knife, 30.5ms\n",
      "Speed: 2.9ms preprocess, 30.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/67.jpg: 384x640 (no detections), 39.1ms\n",
      "Speed: 1.9ms preprocess, 39.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/68.jpg: 384x640 2 baseball bats, 1 spoon, 26.6ms\n",
      "Speed: 1.9ms preprocess, 26.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/69.jpg: 384x640 1 baseball bat, 1 knife, 1 spoon, 39.3ms\n",
      "Speed: 2.0ms preprocess, 39.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/70.jpg: 384x640 1 baseball bat, 1 knife, 49.7ms\n",
      "Speed: 2.9ms preprocess, 49.7ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/71.jpg: 384x640 1 baseball bat, 1 knife, 41.7ms\n",
      "Speed: 1.9ms preprocess, 41.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/72.jpg: 384x640 2 baseball bats, 38.0ms\n",
      "Speed: 2.9ms preprocess, 38.0ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/73.jpg: 384x640 1 baseball bat, 59.6ms\n",
      "Speed: 2.5ms preprocess, 59.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/74.jpg: 384x640 1 knife, 1 spoon, 50.6ms\n",
      "Speed: 2.7ms preprocess, 50.6ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/75.jpg: 384x640 1 spoon, 30.2ms\n",
      "Speed: 2.0ms preprocess, 30.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/76.jpg: 384x640 2 baseball bats, 26.2ms\n",
      "Speed: 2.8ms preprocess, 26.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/77.jpg: 384x640 1 knife, 28.5ms\n",
      "Speed: 2.0ms preprocess, 28.5ms inference, 9.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/78.jpg: 384x640 1 knife, 28.2ms\n",
      "Speed: 1.8ms preprocess, 28.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/79.jpg: 384x640 1 knife, 1 spoon, 33.9ms\n",
      "Speed: 1.9ms preprocess, 33.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/80.jpg: 384x640 1 baseball bat, 1 bottle, 1 knife, 29.0ms\n",
      "Speed: 1.7ms preprocess, 29.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/81.jpg: 384x640 1 baseball bat, 1 spoon, 26.2ms\n",
      "Speed: 2.4ms preprocess, 26.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/82.jpg: 384x640 1 baseball bat, 1 knife, 1 spoon, 37.5ms\n",
      "Speed: 2.0ms preprocess, 37.5ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/83.jpg: 384x640 1 baseball bat, 1 spoon, 28.7ms\n",
      "Speed: 1.8ms preprocess, 28.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/84.jpg: 384x640 1 knife, 32.2ms\n",
      "Speed: 2.1ms preprocess, 32.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/85.jpg: 384x640 1 knife, 31.6ms\n",
      "Speed: 2.6ms preprocess, 31.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/86.jpg: 384x640 1 baseball bat, 1 spoon, 33.7ms\n",
      "Speed: 1.9ms preprocess, 33.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/87.jpg: 384x640 1 baseball bat, 1 knife, 1 spoon, 50.5ms\n",
      "Speed: 2.3ms preprocess, 50.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/88.jpg: 384x640 1 baseball bat, 1 knife, 1 spoon, 46.2ms\n",
      "Speed: 1.7ms preprocess, 46.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/89.jpg: 384x640 1 baseball bat, 1 bottle, 1 spoon, 34.8ms\n",
      "Speed: 2.3ms preprocess, 34.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/90.jpg: 384x640 1 baseball bat, 1 bottle, 1 spoon, 36.5ms\n",
      "Speed: 1.7ms preprocess, 36.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/91.jpg: 384x640 1 baseball bat, 1 bottle, 1 spoon, 46.2ms\n",
      "Speed: 2.3ms preprocess, 46.2ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/92.jpg: 384x640 1 bottle, 1 spoon, 46.5ms\n",
      "Speed: 3.0ms preprocess, 46.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/93.jpg: 384x640 2 baseball bats, 1 bottle, 1 spoon, 31.4ms\n",
      "Speed: 2.6ms preprocess, 31.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/94.jpg: 384x640 1 person, 1 baseball bat, 34.7ms\n",
      "Speed: 2.2ms preprocess, 34.7ms inference, 7.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/95.jpg: 384x640 (no detections), 33.8ms\n",
      "Speed: 2.6ms preprocess, 33.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/96.jpg: 384x640 1 spoon, 31.4ms\n",
      "Speed: 1.7ms preprocess, 31.4ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/97.jpg: 384x640 1 spoon, 24.9ms\n",
      "Speed: 1.8ms preprocess, 24.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/98.jpg: 384x640 1 fork, 1 spoon, 1 carrot, 27.4ms\n",
      "Speed: 1.8ms preprocess, 27.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/99.jpg: 384x640 1 fork, 1 spoon, 1 carrot, 44.2ms\n",
      "Speed: 2.0ms preprocess, 44.2ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/100.jpg: 384x640 1 spoon, 29.8ms\n",
      "Speed: 1.9ms preprocess, 29.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/101.jpg: 384x640 (no detections), 36.4ms\n",
      "Speed: 1.7ms preprocess, 36.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/102.jpg: 384x640 1 person, 1 baseball bat, 1 bottle, 50.7ms\n",
      "Speed: 1.9ms preprocess, 50.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/103.jpg: 384x640 1 bottle, 31.6ms\n",
      "Speed: 1.8ms preprocess, 31.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/104.jpg: 384x640 1 baseball bat, 28.5ms\n",
      "Speed: 1.8ms preprocess, 28.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/105.jpg: 384x640 (no detections), 44.6ms\n",
      "Speed: 2.3ms preprocess, 44.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/106.jpg: 384x640 (no detections), 39.6ms\n",
      "Speed: 1.8ms preprocess, 39.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/107.jpg: 384x640 (no detections), 53.0ms\n",
      "Speed: 2.6ms preprocess, 53.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/108.jpg: 384x640 (no detections), 42.0ms\n",
      "Speed: 2.2ms preprocess, 42.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/109.jpg: 384x640 (no detections), 36.0ms\n",
      "Speed: 1.9ms preprocess, 36.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/110.jpg: 384x640 (no detections), 59.0ms\n",
      "Speed: 3.2ms preprocess, 59.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/111.jpg: 384x640 (no detections), 32.7ms\n",
      "Speed: 2.0ms preprocess, 32.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/112.jpg: 384x640 (no detections), 41.7ms\n",
      "Speed: 2.2ms preprocess, 41.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/113.jpg: 384x640 1 fork, 1 spoon, 28.5ms\n",
      "Speed: 2.2ms preprocess, 28.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/114.jpg: 384x640 1 knife, 38.9ms\n",
      "Speed: 1.7ms preprocess, 38.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/115.jpg: 384x640 1 fork, 1 knife, 42.3ms\n",
      "Speed: 2.9ms preprocess, 42.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/116.jpg: 384x640 (no detections), 41.7ms\n",
      "Speed: 1.8ms preprocess, 41.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/117.jpg: 384x640 (no detections), 37.7ms\n",
      "Speed: 2.6ms preprocess, 37.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/118.jpg: 384x640 1 knife, 34.3ms\n",
      "Speed: 1.9ms preprocess, 34.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/119.jpg: 384x640 1 knife, 31.0ms\n",
      "Speed: 1.7ms preprocess, 31.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/120.jpg: 384x640 1 knife, 30.0ms\n",
      "Speed: 1.9ms preprocess, 30.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/121.jpg: 384x640 1 knife, 1 spoon, 34.3ms\n",
      "Speed: 1.8ms preprocess, 34.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/122.jpg: 384x640 1 knife, 40.8ms\n",
      "Speed: 1.8ms preprocess, 40.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/123.jpg: 384x640 1 fork, 1 knife, 40.5ms\n",
      "Speed: 2.9ms preprocess, 40.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/124.jpg: 384x640 1 knife, 37.9ms\n",
      "Speed: 2.8ms preprocess, 37.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/125.jpg: 384x640 1 knife, 45.9ms\n",
      "Speed: 2.8ms preprocess, 45.9ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/126.jpg: 384x640 1 fork, 1 spoon, 31.1ms\n",
      "Speed: 2.1ms preprocess, 31.1ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/127.jpg: 384x640 1 spoon, 1 carrot, 42.4ms\n",
      "Speed: 4.3ms preprocess, 42.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/128.jpg: 384x640 1 spoon, 33.7ms\n",
      "Speed: 1.8ms preprocess, 33.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/129.jpg: 384x640 1 spoon, 30.8ms\n",
      "Speed: 1.9ms preprocess, 30.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/130.jpg: 384x640 1 cake, 41.2ms\n",
      "Speed: 1.7ms preprocess, 41.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/131.jpg: 384x640 1 bottle, 1 carrot, 38.1ms\n",
      "Speed: 2.3ms preprocess, 38.1ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/132.jpg: 384x640 1 fork, 35.6ms\n",
      "Speed: 2.5ms preprocess, 35.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/133.jpg: 384x640 1 fork, 39.4ms\n",
      "Speed: 3.0ms preprocess, 39.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/134.jpg: 384x640 (no detections), 52.8ms\n",
      "Speed: 2.8ms preprocess, 52.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/135.jpg: 384x640 (no detections), 51.6ms\n",
      "Speed: 2.1ms preprocess, 51.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/136.jpg: 384x640 (no detections), 63.0ms\n",
      "Speed: 2.9ms preprocess, 63.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/137.jpg: 384x640 (no detections), 41.0ms\n",
      "Speed: 2.9ms preprocess, 41.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/138.jpg: 384x640 1 carrot, 43.8ms\n",
      "Speed: 2.0ms preprocess, 43.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/139.jpg: 384x640 1 baseball bat, 1 bottle, 49.2ms\n",
      "Speed: 2.0ms preprocess, 49.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/140.jpg: 384x640 1 bottle, 1 carrot, 31.6ms\n",
      "Speed: 1.7ms preprocess, 31.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/141.jpg: 384x640 1 carrot, 38.6ms\n",
      "Speed: 1.7ms preprocess, 38.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/142.jpg: 384x640 1 baseball bat, 1 carrot, 37.5ms\n",
      "Speed: 1.8ms preprocess, 37.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/143.jpg: 384x640 1 knife, 1 spoon, 1 carrot, 38.2ms\n",
      "Speed: 2.1ms preprocess, 38.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/144.jpg: 384x640 1 baseball bat, 1 bottle, 35.4ms\n",
      "Speed: 1.9ms preprocess, 35.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/145.jpg: 384x640 1 baseball bat, 1 spoon, 2 carrots, 40.6ms\n",
      "Speed: 2.6ms preprocess, 40.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/146.jpg: 384x640 1 spoon, 64.7ms\n",
      "Speed: 3.1ms preprocess, 64.7ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/147.jpg: 384x640 1 knife, 1 spoon, 2 carrots, 38.4ms\n",
      "Speed: 3.0ms preprocess, 38.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/148.jpg: 384x640 1 baseball bat, 1 knife, 35.5ms\n",
      "Speed: 1.9ms preprocess, 35.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/149.jpg: 384x640 1 baseball bat, 1 knife, 35.5ms\n",
      "Speed: 1.7ms preprocess, 35.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/150.jpg: 384x640 1 knife, 27.8ms\n",
      "Speed: 1.8ms preprocess, 27.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/151.jpg: 384x640 1 baseball bat, 42.2ms\n",
      "Speed: 1.8ms preprocess, 42.2ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/152.jpg: 384x640 1 baseball bat, 1 carrot, 41.4ms\n",
      "Speed: 2.0ms preprocess, 41.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/153.jpg: 384x640 1 baseball bat, 57.6ms\n",
      "Speed: 3.0ms preprocess, 57.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/154.jpg: 384x640 (no detections), 37.3ms\n",
      "Speed: 2.3ms preprocess, 37.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/155.jpg: 384x640 (no detections), 39.6ms\n",
      "Speed: 1.9ms preprocess, 39.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/156.jpg: 384x640 1 baseball bat, 1 spoon, 30.3ms\n",
      "Speed: 2.9ms preprocess, 30.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/157.jpg: 384x640 1 knife, 1 spoon, 38.0ms\n",
      "Speed: 1.9ms preprocess, 38.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/158.jpg: 384x640 1 knife, 1 spoon, 35.6ms\n",
      "Speed: 1.9ms preprocess, 35.6ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/159.jpg: 384x640 1 baseball bat, 1 spoon, 41.9ms\n",
      "Speed: 1.9ms preprocess, 41.9ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/160.jpg: 384x640 1 spoon, 31.2ms\n",
      "Speed: 1.8ms preprocess, 31.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/161.jpg: 384x640 1 knife, 1 spoon, 37.9ms\n",
      "Speed: 2.2ms preprocess, 37.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/162.jpg: 384x640 1 knife, 1 spoon, 32.0ms\n",
      "Speed: 1.8ms preprocess, 32.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/163.jpg: 384x640 1 knife, 1 spoon, 34.1ms\n",
      "Speed: 2.3ms preprocess, 34.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/164.jpg: 384x640 1 spoon, 35.0ms\n",
      "Speed: 1.9ms preprocess, 35.0ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/165.jpg: 384x640 1 knife, 1 spoon, 32.5ms\n",
      "Speed: 2.0ms preprocess, 32.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/166.jpg: 384x640 1 spoon, 1 carrot, 33.6ms\n",
      "Speed: 1.9ms preprocess, 33.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/167.jpg: 384x640 1 spoon, 49.9ms\n",
      "Speed: 2.9ms preprocess, 49.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/168.jpg: 384x640 1 spoon, 1 carrot, 58.4ms\n",
      "Speed: 2.9ms preprocess, 58.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/169.jpg: 384x640 1 spoon, 2 carrots, 35.7ms\n",
      "Speed: 2.3ms preprocess, 35.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/170.jpg: 384x640 1 baseball bat, 29.8ms\n",
      "Speed: 2.1ms preprocess, 29.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/171.jpg: 384x640 1 spoon, 1 carrot, 32.8ms\n",
      "Speed: 2.0ms preprocess, 32.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/172.jpg: 384x640 1 baseball bat, 1 carrot, 34.6ms\n",
      "Speed: 2.0ms preprocess, 34.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/173.jpg: 384x640 1 baseball bat, 30.7ms\n",
      "Speed: 1.8ms preprocess, 30.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/174.jpg: 384x640 1 baseball bat, 34.6ms\n",
      "Speed: 2.1ms preprocess, 34.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/175.jpg: 384x640 1 baseball bat, 1 carrot, 47.7ms\n",
      "Speed: 4.3ms preprocess, 47.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/176.jpg: 384x640 1 spoon, 3 carrots, 34.6ms\n",
      "Speed: 1.8ms preprocess, 34.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/177.jpg: 384x640 1 baseball bat, 42.4ms\n",
      "Speed: 1.9ms preprocess, 42.4ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/178.jpg: 384x640 1 baseball bat, 39.9ms\n",
      "Speed: 2.1ms preprocess, 39.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/179.jpg: 384x640 1 bottle, 39.8ms\n",
      "Speed: 2.7ms preprocess, 39.8ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/180.jpg: 384x640 1 spoon, 1 carrot, 37.3ms\n",
      "Speed: 2.7ms preprocess, 37.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/181.jpg: 384x640 1 baseball bat, 1 bottle, 1 carrot, 40.5ms\n",
      "Speed: 2.3ms preprocess, 40.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/182.jpg: 384x640 1 baseball bat, 32.2ms\n",
      "Speed: 2.3ms preprocess, 32.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/183.jpg: 384x640 1 baseball bat, 1 carrot, 40.4ms\n",
      "Speed: 1.9ms preprocess, 40.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/184.jpg: 384x640 1 baseball bat, 1 carrot, 31.6ms\n",
      "Speed: 2.3ms preprocess, 31.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/185.jpg: 384x640 1 baseball bat, 1 carrot, 68.3ms\n",
      "Speed: 2.8ms preprocess, 68.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/186.jpg: 384x640 1 baseball bat, 1 carrot, 31.1ms\n",
      "Speed: 1.8ms preprocess, 31.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/187.jpg: 384x640 (no detections), 33.9ms\n",
      "Speed: 3.7ms preprocess, 33.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/188.jpg: 384x640 1 baseball bat, 1 carrot, 29.8ms\n",
      "Speed: 1.8ms preprocess, 29.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/189.jpg: 384x640 1 carrot, 38.3ms\n",
      "Speed: 2.6ms preprocess, 38.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/190.jpg: 384x640 1 baseball bat, 1 carrot, 26.9ms\n",
      "Speed: 2.1ms preprocess, 26.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/191.jpg: 384x640 1 baseball bat, 1 carrot, 42.9ms\n",
      "Speed: 1.7ms preprocess, 42.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/192.jpg: 384x640 1 baseball bat, 45.0ms\n",
      "Speed: 2.8ms preprocess, 45.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/193.jpg: 384x640 1 baseball bat, 1 bottle, 1 carrot, 50.5ms\n",
      "Speed: 2.1ms preprocess, 50.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/194.jpg: 384x640 1 bottle, 1 carrot, 27.6ms\n",
      "Speed: 1.8ms preprocess, 27.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/195.jpg: 384x640 1 baseball bat, 1 carrot, 36.2ms\n",
      "Speed: 1.7ms preprocess, 36.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/196.jpg: 384x640 1 baseball bat, 1 bottle, 1 carrot, 51.7ms\n",
      "Speed: 1.9ms preprocess, 51.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/197.jpg: 384x640 (no detections), 34.3ms\n",
      "Speed: 1.8ms preprocess, 34.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/198.jpg: 384x640 1 baseball bat, 1 carrot, 42.5ms\n",
      "Speed: 2.6ms preprocess, 42.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/199.jpg: 384x640 1 baseball bat, 1 carrot, 34.0ms\n",
      "Speed: 1.8ms preprocess, 34.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/200.jpg: 384x640 2 baseball bats, 39.5ms\n",
      "Speed: 2.8ms preprocess, 39.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/201.jpg: 384x640 1 baseball bat, 31.6ms\n",
      "Speed: 3.1ms preprocess, 31.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/202.jpg: 384x640 1 baseball bat, 26.4ms\n",
      "Speed: 1.6ms preprocess, 26.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/203.jpg: 384x640 2 baseball bats, 1 carrot, 32.4ms\n",
      "Speed: 2.3ms preprocess, 32.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/204.jpg: 384x640 2 baseball bats, 35.0ms\n",
      "Speed: 2.5ms preprocess, 35.0ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/205.jpg: 384x640 1 baseball bat, 41.3ms\n",
      "Speed: 1.8ms preprocess, 41.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/206.jpg: 384x640 2 baseball bats, 42.4ms\n",
      "Speed: 2.7ms preprocess, 42.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/207.jpg: 384x640 2 baseball bats, 45.1ms\n",
      "Speed: 2.1ms preprocess, 45.1ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/208.jpg: 384x640 2 baseball bats, 33.7ms\n",
      "Speed: 1.9ms preprocess, 33.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/209.jpg: 384x640 2 baseball bats, 35.9ms\n",
      "Speed: 1.7ms preprocess, 35.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/210.jpg: 384x640 2 baseball bats, 1 carrot, 29.5ms\n",
      "Speed: 2.1ms preprocess, 29.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/211.jpg: 384x640 2 baseball bats, 41.0ms\n",
      "Speed: 2.9ms preprocess, 41.0ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/212.jpg: 384x640 1 baseball bat, 34.0ms\n",
      "Speed: 1.9ms preprocess, 34.0ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/213.jpg: 384x640 1 person, 2 baseball bats, 37.2ms\n",
      "Speed: 2.2ms preprocess, 37.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/214.jpg: 384x640 1 baseball bat, 28.2ms\n",
      "Speed: 2.0ms preprocess, 28.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/215.jpg: 384x640 (no detections), 34.5ms\n",
      "Speed: 2.0ms preprocess, 34.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/216.jpg: 384x640 2 baseball bats, 43.7ms\n",
      "Speed: 1.8ms preprocess, 43.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/217.jpg: 384x640 2 baseball bats, 32.6ms\n",
      "Speed: 2.7ms preprocess, 32.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/218.jpg: 384x640 2 baseball bats, 31.8ms\n",
      "Speed: 1.6ms preprocess, 31.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/219.jpg: 384x640 2 baseball bats, 36.6ms\n",
      "Speed: 1.9ms preprocess, 36.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/220.jpg: 384x640 1 baseball bat, 29.2ms\n",
      "Speed: 1.8ms preprocess, 29.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/221.jpg: 384x640 1 baseball bat, 50.0ms\n",
      "Speed: 2.8ms preprocess, 50.0ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/222.jpg: 384x640 1 baseball bat, 34.3ms\n",
      "Speed: 2.4ms preprocess, 34.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/223.jpg: 384x640 (no detections), 31.5ms\n",
      "Speed: 1.8ms preprocess, 31.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/224.jpg: 384x640 1 knife, 1 spoon, 1 carrot, 35.3ms\n",
      "Speed: 2.4ms preprocess, 35.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/225.jpg: 384x640 1 baseball bat, 52.8ms\n",
      "Speed: 4.8ms preprocess, 52.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/226.jpg: 384x640 1 baseball bat, 3 carrots, 35.6ms\n",
      "Speed: 2.1ms preprocess, 35.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/227.jpg: 384x640 1 baseball bat, 37.0ms\n",
      "Speed: 1.8ms preprocess, 37.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/228.jpg: 384x640 1 baseball bat, 39.8ms\n",
      "Speed: 1.9ms preprocess, 39.8ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/229.jpg: 384x640 1 baseball bat, 33.1ms\n",
      "Speed: 1.8ms preprocess, 33.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/230.jpg: 384x640 1 baseball bat, 35.2ms\n",
      "Speed: 2.7ms preprocess, 35.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/231.jpg: 384x640 1 baseball bat, 39.0ms\n",
      "Speed: 1.8ms preprocess, 39.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/232.jpg: 384x640 1 baseball bat, 1 spoon, 1 carrot, 56.9ms\n",
      "Speed: 2.8ms preprocess, 56.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/233.jpg: 384x640 1 spoon, 1 carrot, 37.7ms\n",
      "Speed: 1.9ms preprocess, 37.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/234.jpg: 384x640 1 spoon, 1 carrot, 64.9ms\n",
      "Speed: 2.1ms preprocess, 64.9ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/235.jpg: 384x640 1 person, 1 baseball bat, 27.4ms\n",
      "Speed: 1.9ms preprocess, 27.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/236.jpg: 384x640 (no detections), 37.0ms\n",
      "Speed: 1.9ms preprocess, 37.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/237.jpg: 384x640 1 baseball bat, 39.9ms\n",
      "Speed: 2.6ms preprocess, 39.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/238.jpg: 384x640 1 baseball bat, 33.2ms\n",
      "Speed: 2.0ms preprocess, 33.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/239.jpg: 384x640 1 baseball bat, 43.8ms\n",
      "Speed: 2.1ms preprocess, 43.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/240.jpg: 384x640 1 baseball bat, 31.0ms\n",
      "Speed: 2.3ms preprocess, 31.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/241.jpg: 384x640 (no detections), 37.1ms\n",
      "Speed: 1.9ms preprocess, 37.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/242.jpg: 384x640 (no detections), 38.5ms\n",
      "Speed: 2.1ms preprocess, 38.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/243.jpg: 384x640 1 baseball bat, 1 fork, 1 carrot, 35.2ms\n",
      "Speed: 2.1ms preprocess, 35.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/244.jpg: 384x640 1 person, 1 baseball bat, 36.9ms\n",
      "Speed: 1.8ms preprocess, 36.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/245.jpg: 384x640 1 person, 1 baseball bat, 30.2ms\n",
      "Speed: 2.1ms preprocess, 30.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/246.jpg: 384x640 1 person, 1 knife, 32.0ms\n",
      "Speed: 1.8ms preprocess, 32.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/247.jpg: 384x640 1 baseball bat, 35.9ms\n",
      "Speed: 2.9ms preprocess, 35.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/248.jpg: 384x640 1 knife, 33.3ms\n",
      "Speed: 2.1ms preprocess, 33.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/249.jpg: 384x640 1 baseball bat, 47.9ms\n",
      "Speed: 2.9ms preprocess, 47.9ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/250.jpg: 384x640 1 baseball bat, 66.9ms\n",
      "Speed: 2.6ms preprocess, 66.9ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/251.jpg: 384x640 1 baseball bat, 49.7ms\n",
      "Speed: 3.4ms preprocess, 49.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/252.jpg: 384x640 (no detections), 35.0ms\n",
      "Speed: 2.2ms preprocess, 35.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/253.jpg: 384x640 1 baseball bat, 36.9ms\n",
      "Speed: 2.0ms preprocess, 36.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/254.jpg: 384x640 1 baseball bat, 1 carrot, 65.2ms\n",
      "Speed: 2.1ms preprocess, 65.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/255.jpg: 384x640 1 baseball bat, 1 carrot, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/256.jpg: 384x640 1 baseball bat, 1 knife, 1 carrot, 41.7ms\n",
      "Speed: 2.7ms preprocess, 41.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/257.jpg: 384x640 2 baseball bats, 1 bottle, 1 carrot, 26.7ms\n",
      "Speed: 1.8ms preprocess, 26.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/258.jpg: 384x640 1 baseball bat, 1 carrot, 32.3ms\n",
      "Speed: 1.9ms preprocess, 32.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/259.jpg: 384x640 2 baseball bats, 1 carrot, 31.6ms\n",
      "Speed: 1.7ms preprocess, 31.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/260.jpg: 384x640 2 baseball bats, 1 carrot, 36.7ms\n",
      "Speed: 2.1ms preprocess, 36.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/261.jpg: 384x640 1 baseball bat, 1 carrot, 33.0ms\n",
      "Speed: 1.8ms preprocess, 33.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/262.jpg: 384x640 1 baseball bat, 1 carrot, 36.3ms\n",
      "Speed: 2.0ms preprocess, 36.3ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/263.jpg: 384x640 1 knife, 1 carrot, 39.9ms\n",
      "Speed: 2.7ms preprocess, 39.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/264.jpg: 384x640 2 baseball bats, 1 carrot, 34.9ms\n",
      "Speed: 2.7ms preprocess, 34.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/265.jpg: 384x640 2 baseball bats, 1 carrot, 38.9ms\n",
      "Speed: 2.0ms preprocess, 38.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/266.jpg: 384x640 2 baseball bats, 39.6ms\n",
      "Speed: 1.9ms preprocess, 39.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/267.jpg: 384x640 2 baseball bats, 40.4ms\n",
      "Speed: 2.0ms preprocess, 40.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/268.jpg: 384x640 2 baseball bats, 36.5ms\n",
      "Speed: 2.0ms preprocess, 36.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/269.jpg: 384x640 1 baseball bat, 40.2ms\n",
      "Speed: 2.1ms preprocess, 40.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/270.jpg: 384x640 1 baseball bat, 44.8ms\n",
      "Speed: 2.6ms preprocess, 44.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/271.jpg: 384x640 1 baseball bat, 32.5ms\n",
      "Speed: 3.3ms preprocess, 32.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/272.jpg: 384x640 1 carrot, 56.0ms\n",
      "Speed: 2.6ms preprocess, 56.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/273.jpg: 384x640 1 baseball bat, 42.1ms\n",
      "Speed: 1.9ms preprocess, 42.1ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/274.jpg: 384x640 1 baseball bat, 1 knife, 1 carrot, 44.0ms\n",
      "Speed: 2.6ms preprocess, 44.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/275.jpg: 384x640 1 carrot, 33.4ms\n",
      "Speed: 2.8ms preprocess, 33.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/276.jpg: 384x640 1 baseball bat, 1 carrot, 39.7ms\n",
      "Speed: 2.8ms preprocess, 39.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/277.jpg: 384x640 2 baseball bats, 41.1ms\n",
      "Speed: 3.0ms preprocess, 41.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/278.jpg: 384x640 (no detections), 36.2ms\n",
      "Speed: 2.1ms preprocess, 36.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/279.jpg: 384x640 (no detections), 39.0ms\n",
      "Speed: 3.0ms preprocess, 39.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/280.jpg: 384x640 1 knife, 45.9ms\n",
      "Speed: 2.3ms preprocess, 45.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/281.jpg: 384x640 1 baseball bat, 1 carrot, 29.7ms\n",
      "Speed: 1.8ms preprocess, 29.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/282.jpg: 384x640 1 baseball bat, 1 carrot, 40.2ms\n",
      "Speed: 3.0ms preprocess, 40.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/283.jpg: 384x640 1 carrot, 36.0ms\n",
      "Speed: 1.9ms preprocess, 36.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/284.jpg: 384x640 1 fork, 1 spoon, 1 carrot, 40.0ms\n",
      "Speed: 1.8ms preprocess, 40.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/285.jpg: 384x640 1 spoon, 1 carrot, 34.8ms\n",
      "Speed: 2.0ms preprocess, 34.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/286.jpg: 384x640 1 spoon, 1 carrot, 27.3ms\n",
      "Speed: 1.8ms preprocess, 27.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/287.jpg: 384x640 1 spoon, 57.3ms\n",
      "Speed: 2.4ms preprocess, 57.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/288.jpg: 384x640 1 person, 36.4ms\n",
      "Speed: 2.1ms preprocess, 36.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/289.jpg: 384x640 1 baseball bat, 32.8ms\n",
      "Speed: 1.8ms preprocess, 32.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/290.jpg: 384x640 1 carrot, 31.0ms\n",
      "Speed: 2.2ms preprocess, 31.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/291.jpg: 384x640 1 carrot, 27.7ms\n",
      "Speed: 1.8ms preprocess, 27.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/292.jpg: 384x640 (no detections), 31.5ms\n",
      "Speed: 2.0ms preprocess, 31.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/293.jpg: 384x640 1 baseball bat, 49.0ms\n",
      "Speed: 2.7ms preprocess, 49.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/294.jpg: 384x640 (no detections), 37.0ms\n",
      "Speed: 2.8ms preprocess, 37.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/295.jpg: 384x640 2 carrots, 42.7ms\n",
      "Speed: 2.2ms preprocess, 42.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/296.jpg: 384x640 1 spoon, 1 carrot, 29.1ms\n",
      "Speed: 2.1ms preprocess, 29.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/297.jpg: 384x640 1 carrot, 36.2ms\n",
      "Speed: 2.2ms preprocess, 36.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/298.jpg: 384x640 1 carrot, 54.5ms\n",
      "Speed: 2.8ms preprocess, 54.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/left/299.jpg: 384x640 1 knife, 1 carrot, 39.2ms\n",
      "Speed: 2.0ms preprocess, 39.2ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Propagating video frames: 100%|| 300/300 [00:21<00:00, 14.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask propagation completed in 21.43 seconds.\n",
      "Processing predicted masks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing video frames: 300it [00:01, 233.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 300 masks for evaluation.\n",
      "Masks saved to data/masks/yolo11x-seg/val/data-raw-SegSTRONGC_val-val-1-1-regular-left.pkl\n",
      "Loading ground truth masks for evaluation...\n",
      "Loaded 300 ground truth masks.\n",
      "Calculating evaluation metrics...\n",
      "Time taken for metrics calculation: 1.36 seconds.\n",
      "Mean IoU for data/raw/SegSTRONGC_val/val/1/1/regular/left: 0.3290\n",
      "Mean DSC for data/raw/SegSTRONGC_val/val/1/1/regular/left: 0.4394\n",
      "Loading existing results file: data/results/yolo11x-seg/val.json\n",
      "Results saved to data/results/yolo11x-seg/val.json\n",
      "Processing video took 25.42 seconds.\n",
      "==================================================\n",
      "Processing right camera video...\n",
      "==================================================\n",
      "Processing video: data/raw/SegSTRONGC_val/val/1/1/regular/right\n",
      "Domain: regular, Split: val, Camera: right\n",
      "Initializing Yolo for video...\n",
      "Initialization took 0.14 seconds.\n",
      "Starting mask propagation...\n",
      "Total images in video: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/0.jpg: 384x640 2 baseball bats, 1 carrot, 25.0ms\n",
      "Speed: 1.6ms preprocess, 25.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/1.jpg: 384x640 2 baseball bats, 1 spoon, 2 carrots, 29.1ms\n",
      "Speed: 1.5ms preprocess, 29.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/2.jpg: 384x640 2 baseball bats, 1 carrot, 26.1ms\n",
      "Speed: 1.7ms preprocess, 26.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/3.jpg: 384x640 2 baseball bats, 1 carrot, 28.3ms\n",
      "Speed: 1.8ms preprocess, 28.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/4.jpg: 384x640 2 baseball bats, 1 carrot, 23.6ms\n",
      "Speed: 1.6ms preprocess, 23.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/5.jpg: 384x640 1 baseball bat, 2 carrots, 26.0ms\n",
      "Speed: 1.8ms preprocess, 26.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/6.jpg: 384x640 2 spoons, 3 carrots, 32.8ms\n",
      "Speed: 1.6ms preprocess, 32.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/7.jpg: 384x640 1 baseball bat, 32.6ms\n",
      "Speed: 1.8ms preprocess, 32.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/8.jpg: 384x640 1 baseball bat, 1 spoon, 1 carrot, 26.2ms\n",
      "Speed: 1.7ms preprocess, 26.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/9.jpg: 384x640 1 spoon, 2 carrots, 28.1ms\n",
      "Speed: 2.2ms preprocess, 28.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/10.jpg: 384x640 1 spoon, 27.2ms\n",
      "Speed: 1.5ms preprocess, 27.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/11.jpg: 384x640 1 spoon, 1 carrot, 41.0ms\n",
      "Speed: 1.7ms preprocess, 41.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/12.jpg: 384x640 2 bottles, 1 carrot, 26.1ms\n",
      "Speed: 1.5ms preprocess, 26.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/13.jpg: 384x640 1 baseball bat, 2 bottles, 1 spoon, 1 carrot, 30.4ms\n",
      "Speed: 1.5ms preprocess, 30.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/14.jpg: 384x640 2 baseball bats, 2 carrots, 23.3ms\n",
      "Speed: 1.7ms preprocess, 23.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/15.jpg: 384x640 2 baseball bats, 2 carrots, 27.7ms\n",
      "Speed: 4.2ms preprocess, 27.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/16.jpg: 384x640 1 spoon, 1 carrot, 31.3ms\n",
      "Speed: 1.8ms preprocess, 31.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/17.jpg: 384x640 1 baseball bat, 1 spoon, 1 carrot, 36.4ms\n",
      "Speed: 1.8ms preprocess, 36.4ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/18.jpg: 384x640 1 spoon, 2 carrots, 33.4ms\n",
      "Speed: 1.7ms preprocess, 33.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/19.jpg: 384x640 1 spoon, 2 carrots, 25.6ms\n",
      "Speed: 1.9ms preprocess, 25.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/20.jpg: 384x640 2 baseball bats, 28.4ms\n",
      "Speed: 1.3ms preprocess, 28.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/21.jpg: 384x640 1 baseball bat, 1 spoon, 1 carrot, 28.1ms\n",
      "Speed: 1.8ms preprocess, 28.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/22.jpg: 384x640 2 baseball bats, 25.4ms\n",
      "Speed: 1.6ms preprocess, 25.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/23.jpg: 384x640 2 baseball bats, 24.8ms\n",
      "Speed: 1.8ms preprocess, 24.8ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/24.jpg: 384x640 1 baseball bat, 1 spoon, 1 carrot, 32.3ms\n",
      "Speed: 2.0ms preprocess, 32.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/25.jpg: 384x640 2 spoons, 3 carrots, 32.6ms\n",
      "Speed: 2.7ms preprocess, 32.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/26.jpg: 384x640 2 baseball bats, 1 spoon, 1 carrot, 34.0ms\n",
      "Speed: 1.8ms preprocess, 34.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/27.jpg: 384x640 2 baseball bats, 1 carrot, 34.9ms\n",
      "Speed: 3.7ms preprocess, 34.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/28.jpg: 384x640 2 baseball bats, 3 carrots, 27.6ms\n",
      "Speed: 1.6ms preprocess, 27.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/29.jpg: 384x640 1 baseball bat, 1 spoon, 4 carrots, 25.2ms\n",
      "Speed: 1.6ms preprocess, 25.2ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/30.jpg: 384x640 1 baseball bat, 1 spoon, 3 carrots, 25.2ms\n",
      "Speed: 1.8ms preprocess, 25.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/31.jpg: 384x640 1 baseball bat, 2 spoons, 6 carrots, 23.7ms\n",
      "Speed: 1.8ms preprocess, 23.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/32.jpg: 384x640 2 baseball bats, 2 carrots, 49.2ms\n",
      "Speed: 1.5ms preprocess, 49.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/33.jpg: 384x640 2 baseball bats, 1 spoon, 3 carrots, 32.9ms\n",
      "Speed: 1.9ms preprocess, 32.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/34.jpg: 384x640 1 baseball bat, 2 spoons, 3 carrots, 28.5ms\n",
      "Speed: 2.0ms preprocess, 28.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/35.jpg: 384x640 2 spoons, 4 carrots, 27.1ms\n",
      "Speed: 2.3ms preprocess, 27.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/36.jpg: 384x640 2 baseball bats, 1 spoon, 4 carrots, 27.6ms\n",
      "Speed: 2.0ms preprocess, 27.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/37.jpg: 384x640 2 baseball bats, 1 carrot, 27.8ms\n",
      "Speed: 1.4ms preprocess, 27.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/38.jpg: 384x640 2 baseball bats, 3 carrots, 29.3ms\n",
      "Speed: 2.9ms preprocess, 29.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/39.jpg: 384x640 2 baseball bats, 1 spoon, 2 carrots, 27.9ms\n",
      "Speed: 1.5ms preprocess, 27.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/40.jpg: 384x640 2 baseball bats, 35.7ms\n",
      "Speed: 2.5ms preprocess, 35.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/41.jpg: 384x640 2 spoons, 1 carrot, 26.5ms\n",
      "Speed: 1.9ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/42.jpg: 384x640 2 baseball bats, 1 spoon, 1 carrot, 48.5ms\n",
      "Speed: 2.0ms preprocess, 48.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/43.jpg: 384x640 2 spoons, 1 carrot, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/44.jpg: 384x640 1 spoon, 2 carrots, 23.8ms\n",
      "Speed: 1.7ms preprocess, 23.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/45.jpg: 384x640 1 baseball bat, 1 spoon, 2 carrots, 36.7ms\n",
      "Speed: 1.8ms preprocess, 36.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/46.jpg: 384x640 1 spoon, 2 carrots, 43.7ms\n",
      "Speed: 2.0ms preprocess, 43.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/47.jpg: 384x640 1 baseball bat, 1 carrot, 30.2ms\n",
      "Speed: 2.2ms preprocess, 30.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/48.jpg: 384x640 1 spoon, 3 carrots, 29.5ms\n",
      "Speed: 1.7ms preprocess, 29.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/49.jpg: 384x640 1 baseball bat, 1 spoon, 2 carrots, 37.3ms\n",
      "Speed: 2.4ms preprocess, 37.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/50.jpg: 384x640 1 spoon, 5 carrots, 26.0ms\n",
      "Speed: 1.8ms preprocess, 26.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/51.jpg: 384x640 1 spoon, 5 carrots, 46.0ms\n",
      "Speed: 2.5ms preprocess, 46.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/52.jpg: 384x640 1 spoon, 3 carrots, 40.6ms\n",
      "Speed: 1.9ms preprocess, 40.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/53.jpg: 384x640 1 spoon, 2 carrots, 39.7ms\n",
      "Speed: 3.5ms preprocess, 39.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/54.jpg: 384x640 1 knife, 42.2ms\n",
      "Speed: 2.0ms preprocess, 42.2ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/55.jpg: 384x640 1 bottle, 1 carrot, 27.2ms\n",
      "Speed: 2.0ms preprocess, 27.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/56.jpg: 384x640 1 carrot, 44.5ms\n",
      "Speed: 1.7ms preprocess, 44.5ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/57.jpg: 384x640 1 bottle, 33.1ms\n",
      "Speed: 2.2ms preprocess, 33.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/58.jpg: 384x640 1 bottle, 43.5ms\n",
      "Speed: 1.9ms preprocess, 43.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/59.jpg: 384x640 1 baseball bat, 1 bottle, 52.0ms\n",
      "Speed: 1.9ms preprocess, 52.0ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/60.jpg: 384x640 1 baseball bat, 1 spoon, 30.2ms\n",
      "Speed: 2.4ms preprocess, 30.2ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/61.jpg: 384x640 1 baseball bat, 1 spoon, 42.7ms\n",
      "Speed: 2.6ms preprocess, 42.7ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/62.jpg: 384x640 1 baseball bat, 1 spoon, 24.4ms\n",
      "Speed: 1.7ms preprocess, 24.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/63.jpg: 384x640 2 baseball bats, 1 bottle, 1 carrot, 33.8ms\n",
      "Speed: 2.1ms preprocess, 33.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/64.jpg: 384x640 1 baseball bat, 1 spoon, 1 bowl, 29.7ms\n",
      "Speed: 2.1ms preprocess, 29.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/65.jpg: 384x640 1 baseball bat, 1 spoon, 1 carrot, 33.5ms\n",
      "Speed: 1.9ms preprocess, 33.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/66.jpg: 384x640 1 baseball bat, 1 spoon, 30.8ms\n",
      "Speed: 2.0ms preprocess, 30.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/67.jpg: 384x640 1 baseball bat, 1 spoon, 36.7ms\n",
      "Speed: 1.8ms preprocess, 36.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/68.jpg: 384x640 2 baseball bats, 2 carrots, 49.9ms\n",
      "Speed: 2.0ms preprocess, 49.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/69.jpg: 384x640 1 baseball bat, 1 spoon, 3 carrots, 33.1ms\n",
      "Speed: 1.9ms preprocess, 33.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/70.jpg: 384x640 1 baseball bat, 1 spoon, 27.7ms\n",
      "Speed: 1.7ms preprocess, 27.7ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/71.jpg: 384x640 1 baseball bat, 1 spoon, 1 carrot, 34.1ms\n",
      "Speed: 1.7ms preprocess, 34.1ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/72.jpg: 384x640 1 baseball bat, 42.1ms\n",
      "Speed: 1.9ms preprocess, 42.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/73.jpg: 384x640 1 baseball bat, 1 spoon, 42.0ms\n",
      "Speed: 3.1ms preprocess, 42.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/74.jpg: 384x640 1 baseball bat, 1 spoon, 2 carrots, 73.1ms\n",
      "Speed: 3.4ms preprocess, 73.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/75.jpg: 384x640 1 baseball bat, 1 spoon, 63.1ms\n",
      "Speed: 2.1ms preprocess, 63.1ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/76.jpg: 384x640 1 baseball bat, 1 spoon, 56.9ms\n",
      "Speed: 3.3ms preprocess, 56.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/77.jpg: 384x640 1 baseball bat, 1 spoon, 2 carrots, 42.0ms\n",
      "Speed: 2.9ms preprocess, 42.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/78.jpg: 384x640 1 spoon, 2 carrots, 43.9ms\n",
      "Speed: 2.2ms preprocess, 43.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/79.jpg: 384x640 1 baseball bat, 1 spoon, 40.0ms\n",
      "Speed: 3.3ms preprocess, 40.0ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/80.jpg: 384x640 1 spoon, 42.0ms\n",
      "Speed: 2.0ms preprocess, 42.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/81.jpg: 384x640 1 spoon, 49.1ms\n",
      "Speed: 2.1ms preprocess, 49.1ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/82.jpg: 384x640 1 spoon, 26.5ms\n",
      "Speed: 1.9ms preprocess, 26.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/83.jpg: 384x640 1 bottle, 1 spoon, 32.2ms\n",
      "Speed: 1.8ms preprocess, 32.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/84.jpg: 384x640 2 spoons, 31.3ms\n",
      "Speed: 1.9ms preprocess, 31.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/85.jpg: 384x640 1 knife, 1 spoon, 65.6ms\n",
      "Speed: 2.8ms preprocess, 65.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/86.jpg: 384x640 1 spoon, 32.2ms\n",
      "Speed: 1.7ms preprocess, 32.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/87.jpg: 384x640 1 spoon, 51.2ms\n",
      "Speed: 1.9ms preprocess, 51.2ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/88.jpg: 384x640 2 spoons, 35.4ms\n",
      "Speed: 2.3ms preprocess, 35.4ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/89.jpg: 384x640 1 spoon, 40.5ms\n",
      "Speed: 1.9ms preprocess, 40.5ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/90.jpg: 384x640 1 spoon, 32.5ms\n",
      "Speed: 2.9ms preprocess, 32.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/91.jpg: 384x640 1 spoon, 38.5ms\n",
      "Speed: 1.8ms preprocess, 38.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/92.jpg: 384x640 1 baseball bat, 1 spoon, 32.5ms\n",
      "Speed: 1.8ms preprocess, 32.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/93.jpg: 384x640 1 bottle, 1 spoon, 33.2ms\n",
      "Speed: 1.9ms preprocess, 33.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/94.jpg: 384x640 1 spoon, 1 carrot, 27.9ms\n",
      "Speed: 1.7ms preprocess, 27.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/95.jpg: 384x640 1 spoon, 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/96.jpg: 384x640 1 spoon, 1 carrot, 35.0ms\n",
      "Speed: 1.7ms preprocess, 35.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/97.jpg: 384x640 1 spoon, 1 carrot, 50.7ms\n",
      "Speed: 3.0ms preprocess, 50.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/98.jpg: 384x640 1 spoon, 4 carrots, 42.3ms\n",
      "Speed: 2.0ms preprocess, 42.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/99.jpg: 384x640 1 spoon, 1 carrot, 26.5ms\n",
      "Speed: 1.7ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/100.jpg: 384x640 1 fork, 1 spoon, 2 carrots, 39.0ms\n",
      "Speed: 2.0ms preprocess, 39.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/101.jpg: 384x640 1 spoon, 2 carrots, 27.1ms\n",
      "Speed: 2.3ms preprocess, 27.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/102.jpg: 384x640 1 spoon, 3 carrots, 39.9ms\n",
      "Speed: 1.8ms preprocess, 39.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/103.jpg: 384x640 (no detections), 36.8ms\n",
      "Speed: 2.7ms preprocess, 36.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/104.jpg: 384x640 1 spoon, 40.8ms\n",
      "Speed: 2.7ms preprocess, 40.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/105.jpg: 384x640 1 spoon, 28.9ms\n",
      "Speed: 2.1ms preprocess, 28.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/106.jpg: 384x640 1 baseball bat, 1 spoon, 36.4ms\n",
      "Speed: 2.0ms preprocess, 36.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/107.jpg: 384x640 1 baseball bat, 1 spoon, 3 carrots, 28.7ms\n",
      "Speed: 1.7ms preprocess, 28.7ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/108.jpg: 384x640 1 baseball bat, 2 spoons, 32.7ms\n",
      "Speed: 3.0ms preprocess, 32.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/109.jpg: 384x640 1 baseball bat, 1 spoon, 33.1ms\n",
      "Speed: 1.7ms preprocess, 33.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/110.jpg: 384x640 1 baseball bat, 1 spoon, 2 carrots, 34.1ms\n",
      "Speed: 2.1ms preprocess, 34.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/111.jpg: 384x640 1 baseball bat, 2 spoons, 3 carrots, 49.4ms\n",
      "Speed: 2.6ms preprocess, 49.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/112.jpg: 384x640 1 baseball bat, 1 spoon, 2 carrots, 51.7ms\n",
      "Speed: 2.9ms preprocess, 51.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/113.jpg: 384x640 1 spoon, 2 carrots, 32.2ms\n",
      "Speed: 1.9ms preprocess, 32.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/114.jpg: 384x640 1 spoon, 1 carrot, 35.9ms\n",
      "Speed: 1.9ms preprocess, 35.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/115.jpg: 384x640 1 spoon, 2 carrots, 37.2ms\n",
      "Speed: 1.9ms preprocess, 37.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/116.jpg: 384x640 1 bottle, 3 carrots, 44.9ms\n",
      "Speed: 3.5ms preprocess, 44.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/117.jpg: 384x640 (no detections), 28.5ms\n",
      "Speed: 1.8ms preprocess, 28.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/118.jpg: 384x640 2 carrots, 33.5ms\n",
      "Speed: 2.7ms preprocess, 33.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/119.jpg: 384x640 1 spoon, 39.1ms\n",
      "Speed: 2.7ms preprocess, 39.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/120.jpg: 384x640 1 spoon, 36.7ms\n",
      "Speed: 3.2ms preprocess, 36.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/121.jpg: 384x640 1 spoon, 35.7ms\n",
      "Speed: 2.0ms preprocess, 35.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/122.jpg: 384x640 (no detections), 55.3ms\n",
      "Speed: 2.9ms preprocess, 55.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/123.jpg: 384x640 1 fork, 1 spoon, 2 carrots, 37.5ms\n",
      "Speed: 1.8ms preprocess, 37.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/124.jpg: 384x640 1 fork, 1 spoon, 2 carrots, 38.8ms\n",
      "Speed: 2.1ms preprocess, 38.8ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/125.jpg: 384x640 1 spoon, 2 carrots, 36.4ms\n",
      "Speed: 1.9ms preprocess, 36.4ms inference, 11.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/126.jpg: 384x640 2 spoons, 2 carrots, 28.2ms\n",
      "Speed: 1.8ms preprocess, 28.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/127.jpg: 384x640 1 fork, 1 spoon, 4 carrots, 34.4ms\n",
      "Speed: 1.7ms preprocess, 34.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/128.jpg: 384x640 1 spoon, 4 carrots, 41.5ms\n",
      "Speed: 2.1ms preprocess, 41.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/129.jpg: 384x640 1 fork, 1 spoon, 4 carrots, 31.7ms\n",
      "Speed: 3.4ms preprocess, 31.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/130.jpg: 384x640 1 spoon, 2 carrots, 29.5ms\n",
      "Speed: 1.9ms preprocess, 29.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/131.jpg: 384x640 1 spoon, 3 carrots, 34.4ms\n",
      "Speed: 1.8ms preprocess, 34.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/132.jpg: 384x640 1 bottle, 1 fork, 2 carrots, 50.3ms\n",
      "Speed: 3.3ms preprocess, 50.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/133.jpg: 384x640 1 fork, 1 carrot, 31.7ms\n",
      "Speed: 2.5ms preprocess, 31.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/134.jpg: 384x640 2 carrots, 63.7ms\n",
      "Speed: 3.1ms preprocess, 63.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/135.jpg: 384x640 (no detections), 36.5ms\n",
      "Speed: 1.9ms preprocess, 36.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/136.jpg: 384x640 1 carrot, 35.3ms\n",
      "Speed: 2.0ms preprocess, 35.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/137.jpg: 384x640 1 fork, 3 carrots, 34.4ms\n",
      "Speed: 2.2ms preprocess, 34.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/138.jpg: 384x640 3 carrots, 40.9ms\n",
      "Speed: 1.8ms preprocess, 40.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/139.jpg: 384x640 3 carrots, 28.8ms\n",
      "Speed: 1.9ms preprocess, 28.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/140.jpg: 384x640 1 bottle, 3 carrots, 29.6ms\n",
      "Speed: 2.0ms preprocess, 29.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/141.jpg: 384x640 1 fork, 2 spoons, 3 carrots, 31.8ms\n",
      "Speed: 1.9ms preprocess, 31.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/142.jpg: 384x640 2 spoons, 4 carrots, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/143.jpg: 384x640 1 spoon, 3 carrots, 47.1ms\n",
      "Speed: 2.2ms preprocess, 47.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/144.jpg: 384x640 1 spoon, 3 carrots, 53.8ms\n",
      "Speed: 2.2ms preprocess, 53.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/145.jpg: 384x640 1 baseball bat, 1 spoon, 1 carrot, 42.7ms\n",
      "Speed: 2.8ms preprocess, 42.7ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/146.jpg: 384x640 2 spoons, 5 carrots, 32.7ms\n",
      "Speed: 1.9ms preprocess, 32.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/147.jpg: 384x640 2 spoons, 4 carrots, 33.2ms\n",
      "Speed: 2.0ms preprocess, 33.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/148.jpg: 384x640 2 spoons, 3 carrots, 34.5ms\n",
      "Speed: 1.8ms preprocess, 34.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/149.jpg: 384x640 2 spoons, 5 carrots, 39.7ms\n",
      "Speed: 2.8ms preprocess, 39.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/150.jpg: 384x640 2 spoons, 4 carrots, 33.6ms\n",
      "Speed: 1.9ms preprocess, 33.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/151.jpg: 384x640 1 spoon, 4 carrots, 49.1ms\n",
      "Speed: 3.1ms preprocess, 49.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/152.jpg: 384x640 1 spoon, 2 carrots, 33.7ms\n",
      "Speed: 1.8ms preprocess, 33.7ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/153.jpg: 384x640 1 spoon, 3 carrots, 32.2ms\n",
      "Speed: 2.9ms preprocess, 32.2ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/154.jpg: 384x640 1 spoon, 3 carrots, 32.8ms\n",
      "Speed: 2.2ms preprocess, 32.8ms inference, 6.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/155.jpg: 384x640 2 spoons, 4 carrots, 28.9ms\n",
      "Speed: 2.0ms preprocess, 28.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/156.jpg: 384x640 2 spoons, 2 carrots, 38.7ms\n",
      "Speed: 2.5ms preprocess, 38.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/157.jpg: 384x640 1 spoon, 4 carrots, 26.7ms\n",
      "Speed: 1.8ms preprocess, 26.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/158.jpg: 384x640 1 spoon, 3 carrots, 33.8ms\n",
      "Speed: 1.9ms preprocess, 33.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/159.jpg: 384x640 1 spoon, 2 carrots, 33.0ms\n",
      "Speed: 2.8ms preprocess, 33.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/160.jpg: 384x640 1 spoon, 4 carrots, 30.6ms\n",
      "Speed: 2.4ms preprocess, 30.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/161.jpg: 384x640 1 spoon, 3 carrots, 31.9ms\n",
      "Speed: 1.8ms preprocess, 31.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/162.jpg: 384x640 2 spoons, 4 carrots, 39.3ms\n",
      "Speed: 3.4ms preprocess, 39.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/163.jpg: 384x640 1 spoon, 3 carrots, 36.6ms\n",
      "Speed: 2.5ms preprocess, 36.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/164.jpg: 384x640 1 spoon, 3 carrots, 59.1ms\n",
      "Speed: 1.8ms preprocess, 59.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/165.jpg: 384x640 2 spoons, 4 carrots, 40.7ms\n",
      "Speed: 2.2ms preprocess, 40.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/166.jpg: 384x640 1 spoon, 5 carrots, 38.1ms\n",
      "Speed: 2.0ms preprocess, 38.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/167.jpg: 384x640 1 spoon, 4 carrots, 29.1ms\n",
      "Speed: 2.8ms preprocess, 29.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/168.jpg: 384x640 1 spoon, 5 carrots, 33.3ms\n",
      "Speed: 2.0ms preprocess, 33.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/169.jpg: 384x640 2 spoons, 5 carrots, 51.0ms\n",
      "Speed: 3.0ms preprocess, 51.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/170.jpg: 384x640 1 spoon, 6 carrots, 34.2ms\n",
      "Speed: 2.0ms preprocess, 34.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/171.jpg: 384x640 1 spoon, 3 carrots, 33.9ms\n",
      "Speed: 2.8ms preprocess, 33.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/172.jpg: 384x640 2 spoons, 3 carrots, 43.6ms\n",
      "Speed: 2.6ms preprocess, 43.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/173.jpg: 384x640 1 spoon, 2 carrots, 33.2ms\n",
      "Speed: 1.8ms preprocess, 33.2ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/174.jpg: 384x640 1 spoon, 3 carrots, 40.8ms\n",
      "Speed: 1.9ms preprocess, 40.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/175.jpg: 384x640 1 spoon, 2 carrots, 37.8ms\n",
      "Speed: 2.9ms preprocess, 37.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/176.jpg: 384x640 1 spoon, 1 carrot, 49.1ms\n",
      "Speed: 2.5ms preprocess, 49.1ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/177.jpg: 384x640 1 baseball bat, 1 spoon, 4 carrots, 33.5ms\n",
      "Speed: 2.1ms preprocess, 33.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/178.jpg: 384x640 1 spoon, 2 carrots, 36.6ms\n",
      "Speed: 1.8ms preprocess, 36.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/179.jpg: 384x640 1 spoon, 3 carrots, 40.3ms\n",
      "Speed: 2.1ms preprocess, 40.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/180.jpg: 384x640 1 spoon, 2 carrots, 33.3ms\n",
      "Speed: 2.0ms preprocess, 33.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/181.jpg: 384x640 1 baseball bat, 1 spoon, 1 carrot, 46.5ms\n",
      "Speed: 2.3ms preprocess, 46.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/182.jpg: 384x640 1 spoon, 5 carrots, 31.2ms\n",
      "Speed: 1.9ms preprocess, 31.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/183.jpg: 384x640 2 spoons, 3 carrots, 40.9ms\n",
      "Speed: 3.0ms preprocess, 40.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/184.jpg: 384x640 1 baseball bat, 1 spoon, 1 carrot, 41.4ms\n",
      "Speed: 2.5ms preprocess, 41.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/185.jpg: 384x640 1 baseball bat, 4 carrots, 49.7ms\n",
      "Speed: 2.1ms preprocess, 49.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/186.jpg: 384x640 1 baseball bat, 1 spoon, 3 carrots, 35.5ms\n",
      "Speed: 2.0ms preprocess, 35.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/187.jpg: 384x640 1 baseball bat, 1 carrot, 37.0ms\n",
      "Speed: 2.1ms preprocess, 37.0ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/188.jpg: 384x640 1 baseball bat, 1 carrot, 40.7ms\n",
      "Speed: 1.9ms preprocess, 40.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/189.jpg: 384x640 1 baseball bat, 2 carrots, 34.3ms\n",
      "Speed: 2.7ms preprocess, 34.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/190.jpg: 384x640 1 baseball bat, 1 spoon, 2 carrots, 30.0ms\n",
      "Speed: 1.8ms preprocess, 30.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/191.jpg: 384x640 1 baseball bat, 3 carrots, 35.0ms\n",
      "Speed: 2.8ms preprocess, 35.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/192.jpg: 384x640 1 baseball bat, 1 bottle, 1 spoon, 4 carrots, 34.3ms\n",
      "Speed: 1.9ms preprocess, 34.3ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/193.jpg: 384x640 1 baseball bat, 1 bottle, 1 spoon, 2 carrots, 35.5ms\n",
      "Speed: 1.7ms preprocess, 35.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/194.jpg: 384x640 1 baseball bat, 2 carrots, 35.0ms\n",
      "Speed: 2.0ms preprocess, 35.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/195.jpg: 384x640 1 spoon, 1 carrot, 40.1ms\n",
      "Speed: 2.0ms preprocess, 40.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/196.jpg: 384x640 1 spoon, 4 carrots, 32.8ms\n",
      "Speed: 2.6ms preprocess, 32.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/197.jpg: 384x640 2 spoons, 1 carrot, 48.0ms\n",
      "Speed: 2.1ms preprocess, 48.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/198.jpg: 384x640 1 spoon, 2 carrots, 38.6ms\n",
      "Speed: 1.9ms preprocess, 38.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/199.jpg: 384x640 2 spoons, 3 carrots, 32.0ms\n",
      "Speed: 1.9ms preprocess, 32.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/200.jpg: 384x640 2 spoons, 40.9ms\n",
      "Speed: 2.0ms preprocess, 40.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/201.jpg: 384x640 2 spoons, 1 carrot, 28.7ms\n",
      "Speed: 1.9ms preprocess, 28.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/202.jpg: 384x640 2 baseball bats, 2 spoons, 1 carrot, 33.3ms\n",
      "Speed: 1.4ms preprocess, 33.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/203.jpg: 384x640 2 baseball bats, 1 carrot, 26.4ms\n",
      "Speed: 1.8ms preprocess, 26.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/204.jpg: 384x640 2 baseball bats, 2 spoons, 2 carrots, 30.4ms\n",
      "Speed: 1.6ms preprocess, 30.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/205.jpg: 384x640 2 baseball bats, 2 spoons, 3 carrots, 37.4ms\n",
      "Speed: 2.0ms preprocess, 37.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/206.jpg: 384x640 2 baseball bats, 1 spoon, 1 carrot, 30.6ms\n",
      "Speed: 1.9ms preprocess, 30.6ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/207.jpg: 384x640 2 spoons, 3 carrots, 43.0ms\n",
      "Speed: 2.5ms preprocess, 43.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/208.jpg: 384x640 1 baseball bat, 2 spoons, 3 carrots, 35.0ms\n",
      "Speed: 2.3ms preprocess, 35.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/209.jpg: 384x640 2 baseball bats, 1 spoon, 1 carrot, 53.1ms\n",
      "Speed: 2.1ms preprocess, 53.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/210.jpg: 384x640 2 baseball bats, 3 carrots, 42.8ms\n",
      "Speed: 2.3ms preprocess, 42.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/211.jpg: 384x640 2 spoons, 2 carrots, 34.8ms\n",
      "Speed: 2.2ms preprocess, 34.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/212.jpg: 384x640 2 baseball bats, 1 carrot, 58.6ms\n",
      "Speed: 3.0ms preprocess, 58.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/213.jpg: 384x640 1 baseball bat, 2 spoons, 2 carrots, 53.0ms\n",
      "Speed: 2.1ms preprocess, 53.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/214.jpg: 384x640 2 spoons, 1 carrot, 39.8ms\n",
      "Speed: 3.0ms preprocess, 39.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/215.jpg: 384x640 2 baseball bats, 1 carrot, 34.6ms\n",
      "Speed: 2.9ms preprocess, 34.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/216.jpg: 384x640 2 spoons, 4 carrots, 38.3ms\n",
      "Speed: 2.1ms preprocess, 38.3ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/217.jpg: 384x640 1 baseball bat, 1 spoon, 2 carrots, 49.1ms\n",
      "Speed: 1.7ms preprocess, 49.1ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/218.jpg: 384x640 1 spoon, 3 carrots, 40.5ms\n",
      "Speed: 2.1ms preprocess, 40.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/219.jpg: 384x640 1 spoon, 2 carrots, 38.1ms\n",
      "Speed: 2.5ms preprocess, 38.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/220.jpg: 384x640 1 spoon, 3 carrots, 56.0ms\n",
      "Speed: 1.9ms preprocess, 56.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/221.jpg: 384x640 1 spoon, 4 carrots, 31.8ms\n",
      "Speed: 1.7ms preprocess, 31.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/222.jpg: 384x640 1 spoon, 3 carrots, 29.9ms\n",
      "Speed: 2.0ms preprocess, 29.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/223.jpg: 384x640 2 spoons, 4 carrots, 32.5ms\n",
      "Speed: 1.8ms preprocess, 32.5ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/224.jpg: 384x640 2 spoons, 4 carrots, 45.4ms\n",
      "Speed: 3.1ms preprocess, 45.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/225.jpg: 384x640 1 spoon, 3 carrots, 35.5ms\n",
      "Speed: 2.2ms preprocess, 35.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/226.jpg: 384x640 1 spoon, 4 carrots, 33.6ms\n",
      "Speed: 2.2ms preprocess, 33.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/227.jpg: 384x640 1 spoon, 2 carrots, 27.9ms\n",
      "Speed: 1.8ms preprocess, 27.9ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/228.jpg: 384x640 1 baseball bat, 1 spoon, 3 carrots, 29.9ms\n",
      "Speed: 1.6ms preprocess, 29.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/229.jpg: 384x640 1 spoon, 4 carrots, 34.0ms\n",
      "Speed: 3.7ms preprocess, 34.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/230.jpg: 384x640 1 baseball bat, 1 spoon, 5 carrots, 32.2ms\n",
      "Speed: 3.1ms preprocess, 32.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/231.jpg: 384x640 2 spoons, 4 carrots, 33.3ms\n",
      "Speed: 2.0ms preprocess, 33.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/232.jpg: 384x640 1 baseball bat, 2 spoons, 4 carrots, 27.4ms\n",
      "Speed: 1.7ms preprocess, 27.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/233.jpg: 384x640 1 spoon, 3 carrots, 28.6ms\n",
      "Speed: 1.6ms preprocess, 28.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/234.jpg: 384x640 1 spoon, 2 carrots, 50.6ms\n",
      "Speed: 2.1ms preprocess, 50.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/235.jpg: 384x640 1 baseball bat, 1 spoon, 1 carrot, 42.7ms\n",
      "Speed: 2.7ms preprocess, 42.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/236.jpg: 384x640 1 baseball bat, 1 spoon, 25.0ms\n",
      "Speed: 1.6ms preprocess, 25.0ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/237.jpg: 384x640 1 baseball bat, 1 spoon, 3 carrots, 63.3ms\n",
      "Speed: 1.9ms preprocess, 63.3ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/238.jpg: 384x640 2 spoons, 2 carrots, 26.5ms\n",
      "Speed: 1.7ms preprocess, 26.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/239.jpg: 384x640 1 baseball bat, 1 spoon, 1 carrot, 50.5ms\n",
      "Speed: 1.9ms preprocess, 50.5ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/240.jpg: 384x640 1 baseball bat, 1 spoon, 2 carrots, 36.1ms\n",
      "Speed: 1.7ms preprocess, 36.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/241.jpg: 384x640 1 baseball bat, 1 spoon, 1 carrot, 52.8ms\n",
      "Speed: 1.7ms preprocess, 52.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/242.jpg: 384x640 1 spoon, 43.1ms\n",
      "Speed: 3.0ms preprocess, 43.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/243.jpg: 384x640 1 spoon, 2 carrots, 35.0ms\n",
      "Speed: 2.9ms preprocess, 35.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/244.jpg: 384x640 (no detections), 33.9ms\n",
      "Speed: 1.7ms preprocess, 33.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/245.jpg: 384x640 1 spoon, 1 carrot, 49.1ms\n",
      "Speed: 1.9ms preprocess, 49.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/246.jpg: 384x640 1 knife, 1 spoon, 44.7ms\n",
      "Speed: 1.7ms preprocess, 44.7ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/247.jpg: 384x640 1 spoon, 29.7ms\n",
      "Speed: 3.1ms preprocess, 29.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/248.jpg: 384x640 1 carrot, 25.9ms\n",
      "Speed: 1.7ms preprocess, 25.9ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/249.jpg: 384x640 1 spoon, 31.9ms\n",
      "Speed: 1.9ms preprocess, 31.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/250.jpg: 384x640 1 baseball bat, 38.8ms\n",
      "Speed: 2.9ms preprocess, 38.8ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/251.jpg: 384x640 1 baseball bat, 1 spoon, 1 carrot, 39.3ms\n",
      "Speed: 1.6ms preprocess, 39.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/252.jpg: 384x640 1 spoon, 31.1ms\n",
      "Speed: 1.7ms preprocess, 31.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/253.jpg: 384x640 1 spoon, 1 carrot, 59.9ms\n",
      "Speed: 3.6ms preprocess, 59.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/254.jpg: 384x640 1 baseball bat, 1 spoon, 2 carrots, 41.0ms\n",
      "Speed: 1.8ms preprocess, 41.0ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/255.jpg: 384x640 1 spoon, 1 carrot, 34.5ms\n",
      "Speed: 1.8ms preprocess, 34.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/256.jpg: 384x640 2 baseball bats, 1 spoon, 4 carrots, 31.8ms\n",
      "Speed: 1.9ms preprocess, 31.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/257.jpg: 384x640 1 knife, 1 spoon, 1 carrot, 41.0ms\n",
      "Speed: 1.8ms preprocess, 41.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/258.jpg: 384x640 1 baseball bat, 1 spoon, 3 carrots, 28.8ms\n",
      "Speed: 1.8ms preprocess, 28.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/259.jpg: 384x640 1 baseball bat, 1 knife, 1 carrot, 29.2ms\n",
      "Speed: 1.8ms preprocess, 29.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/260.jpg: 384x640 1 baseball bat, 1 spoon, 3 carrots, 43.3ms\n",
      "Speed: 1.8ms preprocess, 43.3ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/261.jpg: 384x640 1 spoon, 3 carrots, 34.7ms\n",
      "Speed: 1.9ms preprocess, 34.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/262.jpg: 384x640 1 spoon, 2 carrots, 31.4ms\n",
      "Speed: 1.9ms preprocess, 31.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/263.jpg: 384x640 1 spoon, 33.4ms\n",
      "Speed: 1.9ms preprocess, 33.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/264.jpg: 384x640 1 baseball bat, 1 spoon, 1 carrot, 36.3ms\n",
      "Speed: 2.6ms preprocess, 36.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/265.jpg: 384x640 1 spoon, 1 carrot, 54.5ms\n",
      "Speed: 1.9ms preprocess, 54.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/266.jpg: 384x640 1 baseball bat, 1 spoon, 1 carrot, 42.4ms\n",
      "Speed: 1.9ms preprocess, 42.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/267.jpg: 384x640 1 baseball bat, 1 spoon, 1 carrot, 40.9ms\n",
      "Speed: 2.0ms preprocess, 40.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/268.jpg: 384x640 1 spoon, 2 carrots, 62.2ms\n",
      "Speed: 3.0ms preprocess, 62.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/269.jpg: 384x640 1 spoon, 70.1ms\n",
      "Speed: 3.1ms preprocess, 70.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/270.jpg: 384x640 1 spoon, 1 carrot, 40.9ms\n",
      "Speed: 2.7ms preprocess, 40.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/271.jpg: 384x640 1 spoon, 2 carrots, 35.4ms\n",
      "Speed: 2.2ms preprocess, 35.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/272.jpg: 384x640 1 baseball bat, 1 carrot, 28.2ms\n",
      "Speed: 1.9ms preprocess, 28.2ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/273.jpg: 384x640 1 baseball bat, 3 carrots, 26.6ms\n",
      "Speed: 1.7ms preprocess, 26.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/274.jpg: 384x640 1 baseball bat, 1 bottle, 1 carrot, 35.3ms\n",
      "Speed: 1.7ms preprocess, 35.3ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/275.jpg: 384x640 1 baseball bat, 1 spoon, 1 carrot, 28.6ms\n",
      "Speed: 1.7ms preprocess, 28.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/276.jpg: 384x640 1 knife, 3 carrots, 30.8ms\n",
      "Speed: 1.6ms preprocess, 30.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/277.jpg: 384x640 1 spoon, 1 carrot, 27.9ms\n",
      "Speed: 1.7ms preprocess, 27.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/278.jpg: 384x640 1 spoon, 2 carrots, 46.1ms\n",
      "Speed: 2.4ms preprocess, 46.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/279.jpg: 384x640 2 carrots, 43.0ms\n",
      "Speed: 2.0ms preprocess, 43.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/280.jpg: 384x640 1 spoon, 1 carrot, 31.8ms\n",
      "Speed: 2.7ms preprocess, 31.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/281.jpg: 384x640 1 spoon, 1 carrot, 35.7ms\n",
      "Speed: 2.5ms preprocess, 35.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/282.jpg: 384x640 1 spoon, 36.5ms\n",
      "Speed: 2.2ms preprocess, 36.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/283.jpg: 384x640 1 baseball bat, 1 spoon, 2 carrots, 38.0ms\n",
      "Speed: 2.9ms preprocess, 38.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/284.jpg: 384x640 1 spoon, 2 carrots, 44.7ms\n",
      "Speed: 2.1ms preprocess, 44.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/285.jpg: 384x640 1 spoon, 1 carrot, 32.1ms\n",
      "Speed: 3.1ms preprocess, 32.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/286.jpg: 384x640 1 spoon, 2 carrots, 36.3ms\n",
      "Speed: 2.6ms preprocess, 36.3ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/287.jpg: 384x640 1 spoon, 2 carrots, 38.1ms\n",
      "Speed: 1.9ms preprocess, 38.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/288.jpg: 384x640 1 spoon, 2 carrots, 28.3ms\n",
      "Speed: 2.0ms preprocess, 28.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/289.jpg: 384x640 1 bottle, 36.4ms\n",
      "Speed: 2.0ms preprocess, 36.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/290.jpg: 384x640 1 spoon, 1 carrot, 34.0ms\n",
      "Speed: 2.7ms preprocess, 34.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/291.jpg: 384x640 3 carrots, 45.7ms\n",
      "Speed: 2.1ms preprocess, 45.7ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/292.jpg: 384x640 3 carrots, 36.4ms\n",
      "Speed: 3.3ms preprocess, 36.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/293.jpg: 384x640 1 spoon, 2 carrots, 42.6ms\n",
      "Speed: 1.9ms preprocess, 42.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/294.jpg: 384x640 2 carrots, 35.3ms\n",
      "Speed: 1.9ms preprocess, 35.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/295.jpg: 384x640 1 spoon, 3 carrots, 29.2ms\n",
      "Speed: 2.2ms preprocess, 29.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/296.jpg: 384x640 1 baseball bat, 1 spoon, 3 carrots, 42.0ms\n",
      "Speed: 3.1ms preprocess, 42.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/297.jpg: 384x640 1 spoon, 2 carrots, 43.5ms\n",
      "Speed: 2.2ms preprocess, 43.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/298.jpg: 384x640 2 carrots, 35.5ms\n",
      "Speed: 2.1ms preprocess, 35.5ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/regular/right/299.jpg: 384x640 1 spoon, 1 carrot, 35.9ms\n",
      "Speed: 2.3ms preprocess, 35.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Propagating video frames: 100%|| 300/300 [00:19<00:00, 15.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask propagation completed in 19.77 seconds.\n",
      "Processing predicted masks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing video frames: 300it [00:02, 127.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 300 masks for evaluation.\n",
      "Masks saved to data/masks/yolo11x-seg/val/data-raw-SegSTRONGC_val-val-1-1-regular-right.pkl\n",
      "Loading ground truth masks for evaluation...\n",
      "Loaded 300 ground truth masks.\n",
      "Calculating evaluation metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for metrics calculation: 1.38 seconds.\n",
      "Mean IoU for data/raw/SegSTRONGC_val/val/1/1/regular/right: 0.2198\n",
      "Mean DSC for data/raw/SegSTRONGC_val/val/1/1/regular/right: 0.3280\n",
      "Loading existing results file: data/results/yolo11x-seg/val.json\n",
      "Results saved to data/results/yolo11x-seg/val.json\n",
      "Processing video took 24.71 seconds.\n",
      "==================================================\n",
      "\n",
      "Results for data/raw/SegSTRONGC_val/val/1/1/regular:\n",
      "  Left: IoU=0.3290, DSC=0.4394\n",
      "  Right: IoU=0.2198, DSC=0.3280\n",
      "  Overall: IoU=0.2744, DSC=0.3837\n",
      "\n",
      "Processing domain: smoke\n",
      "Processing left camera video...\n",
      "==================================================\n",
      "Processing video: data/raw/SegSTRONGC_val/val/1/1/smoke/left\n",
      "Domain: smoke, Split: val, Camera: left\n",
      "Initializing Yolo for video...\n",
      "Initialization took 0.15 seconds.\n",
      "Starting mask propagation...\n",
      "Total images in video: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/0.jpg: 384x640 1 person, 1 airplane, 60.1ms\n",
      "Speed: 1.9ms preprocess, 60.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/1.jpg: 384x640 (no detections), 38.3ms\n",
      "Speed: 1.6ms preprocess, 38.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/2.jpg: 384x640 2 airplanes, 49.3ms\n",
      "Speed: 3.5ms preprocess, 49.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/3.jpg: 384x640 (no detections), 38.3ms\n",
      "Speed: 1.5ms preprocess, 38.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/4.jpg: 384x640 1 person, 1 airplane, 24.1ms\n",
      "Speed: 1.6ms preprocess, 24.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/5.jpg: 384x640 2 baseball bats, 31.5ms\n",
      "Speed: 1.7ms preprocess, 31.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/6.jpg: 384x640 (no detections), 23.8ms\n",
      "Speed: 1.6ms preprocess, 23.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/7.jpg: 384x640 1 person, 1 bird, 32.8ms\n",
      "Speed: 1.8ms preprocess, 32.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/8.jpg: 384x640 (no detections), 41.0ms\n",
      "Speed: 2.3ms preprocess, 41.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/9.jpg: 384x640 (no detections), 46.7ms\n",
      "Speed: 2.5ms preprocess, 46.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/10.jpg: 384x640 1 airplane, 36.7ms\n",
      "Speed: 1.5ms preprocess, 36.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/11.jpg: 384x640 (no detections), 27.7ms\n",
      "Speed: 1.6ms preprocess, 27.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/12.jpg: 384x640 1 airplane, 27.0ms\n",
      "Speed: 1.8ms preprocess, 27.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/13.jpg: 384x640 (no detections), 23.7ms\n",
      "Speed: 1.6ms preprocess, 23.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/14.jpg: 384x640 (no detections), 24.4ms\n",
      "Speed: 1.7ms preprocess, 24.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/15.jpg: 384x640 (no detections), 28.1ms\n",
      "Speed: 1.6ms preprocess, 28.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/16.jpg: 384x640 2 airplanes, 1 boat, 27.3ms\n",
      "Speed: 1.7ms preprocess, 27.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/17.jpg: 384x640 1 airplane, 32.9ms\n",
      "Speed: 1.9ms preprocess, 32.9ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/18.jpg: 384x640 1 airplane, 24.5ms\n",
      "Speed: 1.7ms preprocess, 24.5ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/19.jpg: 384x640 1 airplane, 41.6ms\n",
      "Speed: 2.8ms preprocess, 41.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/20.jpg: 384x640 (no detections), 48.1ms\n",
      "Speed: 2.0ms preprocess, 48.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/21.jpg: 384x640 1 baseball bat, 1 bottle, 53.5ms\n",
      "Speed: 2.7ms preprocess, 53.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/22.jpg: 384x640 3 airplanes, 30.6ms\n",
      "Speed: 1.5ms preprocess, 30.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/23.jpg: 384x640 (no detections), 27.9ms\n",
      "Speed: 1.6ms preprocess, 27.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/24.jpg: 384x640 (no detections), 32.9ms\n",
      "Speed: 1.6ms preprocess, 32.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/25.jpg: 384x640 (no detections), 31.0ms\n",
      "Speed: 1.9ms preprocess, 31.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/26.jpg: 384x640 (no detections), 38.1ms\n",
      "Speed: 2.2ms preprocess, 38.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/27.jpg: 384x640 (no detections), 33.5ms\n",
      "Speed: 3.2ms preprocess, 33.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/28.jpg: 384x640 (no detections), 25.5ms\n",
      "Speed: 1.7ms preprocess, 25.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/29.jpg: 384x640 2 baseball bats, 1 carrot, 44.4ms\n",
      "Speed: 2.9ms preprocess, 44.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/30.jpg: 384x640 (no detections), 38.8ms\n",
      "Speed: 1.7ms preprocess, 38.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/31.jpg: 384x640 1 airplane, 32.6ms\n",
      "Speed: 1.7ms preprocess, 32.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/32.jpg: 384x640 1 airplane, 24.9ms\n",
      "Speed: 1.4ms preprocess, 24.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/33.jpg: 384x640 1 airplane, 25.4ms\n",
      "Speed: 1.5ms preprocess, 25.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/34.jpg: 384x640 1 baseball bat, 1 spoon, 37.0ms\n",
      "Speed: 2.0ms preprocess, 37.0ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/35.jpg: 384x640 1 airplane, 32.1ms\n",
      "Speed: 2.4ms preprocess, 32.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/36.jpg: 384x640 (no detections), 25.5ms\n",
      "Speed: 2.1ms preprocess, 25.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/37.jpg: 384x640 1 airplane, 24.0ms\n",
      "Speed: 1.7ms preprocess, 24.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/38.jpg: 384x640 (no detections), 26.0ms\n",
      "Speed: 1.7ms preprocess, 26.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/39.jpg: 384x640 1 airplane, 26.7ms\n",
      "Speed: 1.8ms preprocess, 26.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/40.jpg: 384x640 (no detections), 26.2ms\n",
      "Speed: 1.6ms preprocess, 26.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/41.jpg: 384x640 (no detections), 28.5ms\n",
      "Speed: 1.9ms preprocess, 28.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/42.jpg: 384x640 (no detections), 29.8ms\n",
      "Speed: 2.9ms preprocess, 29.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/43.jpg: 384x640 (no detections), 24.6ms\n",
      "Speed: 1.8ms preprocess, 24.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/44.jpg: 384x640 (no detections), 29.4ms\n",
      "Speed: 2.0ms preprocess, 29.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/45.jpg: 384x640 (no detections), 25.4ms\n",
      "Speed: 1.9ms preprocess, 25.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/46.jpg: 384x640 1 airplane, 41.1ms\n",
      "Speed: 2.6ms preprocess, 41.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/47.jpg: 384x640 1 boat, 27.3ms\n",
      "Speed: 3.1ms preprocess, 27.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/48.jpg: 384x640 (no detections), 28.2ms\n",
      "Speed: 1.9ms preprocess, 28.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/49.jpg: 384x640 (no detections), 50.0ms\n",
      "Speed: 2.0ms preprocess, 50.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/50.jpg: 384x640 1 boat, 29.8ms\n",
      "Speed: 2.0ms preprocess, 29.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/51.jpg: 384x640 (no detections), 27.8ms\n",
      "Speed: 1.8ms preprocess, 27.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/52.jpg: 384x640 1 airplane, 33.0ms\n",
      "Speed: 2.2ms preprocess, 33.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/53.jpg: 384x640 (no detections), 33.7ms\n",
      "Speed: 1.7ms preprocess, 33.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/54.jpg: 384x640 1 airplane, 29.6ms\n",
      "Speed: 3.0ms preprocess, 29.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/55.jpg: 384x640 1 airplane, 32.1ms\n",
      "Speed: 2.1ms preprocess, 32.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/56.jpg: 384x640 1 airplane, 26.2ms\n",
      "Speed: 1.8ms preprocess, 26.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/57.jpg: 384x640 (no detections), 25.4ms\n",
      "Speed: 1.7ms preprocess, 25.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/58.jpg: 384x640 1 toothbrush, 28.2ms\n",
      "Speed: 1.8ms preprocess, 28.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/59.jpg: 384x640 (no detections), 29.3ms\n",
      "Speed: 1.8ms preprocess, 29.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/60.jpg: 384x640 1 airplane, 28.5ms\n",
      "Speed: 2.5ms preprocess, 28.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/61.jpg: 384x640 1 person, 37.0ms\n",
      "Speed: 1.8ms preprocess, 37.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/62.jpg: 384x640 1 airplane, 34.8ms\n",
      "Speed: 2.6ms preprocess, 34.8ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/63.jpg: 384x640 2 airplanes, 29.9ms\n",
      "Speed: 1.7ms preprocess, 29.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/64.jpg: 384x640 1 airplane, 28.5ms\n",
      "Speed: 1.7ms preprocess, 28.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/65.jpg: 384x640 1 airplane, 37.0ms\n",
      "Speed: 2.0ms preprocess, 37.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/66.jpg: 384x640 1 airplane, 47.8ms\n",
      "Speed: 1.5ms preprocess, 47.8ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/67.jpg: 384x640 1 sink, 31.7ms\n",
      "Speed: 1.6ms preprocess, 31.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/68.jpg: 384x640 1 airplane, 27.5ms\n",
      "Speed: 1.7ms preprocess, 27.5ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/69.jpg: 384x640 (no detections), 27.2ms\n",
      "Speed: 1.7ms preprocess, 27.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/70.jpg: 384x640 1 airplane, 35.9ms\n",
      "Speed: 2.3ms preprocess, 35.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/71.jpg: 384x640 (no detections), 36.4ms\n",
      "Speed: 1.6ms preprocess, 36.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/72.jpg: 384x640 (no detections), 35.6ms\n",
      "Speed: 2.0ms preprocess, 35.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/73.jpg: 384x640 (no detections), 34.8ms\n",
      "Speed: 2.0ms preprocess, 34.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/74.jpg: 384x640 (no detections), 54.1ms\n",
      "Speed: 2.2ms preprocess, 54.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/75.jpg: 384x640 (no detections), 64.8ms\n",
      "Speed: 3.0ms preprocess, 64.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/76.jpg: 384x640 (no detections), 45.2ms\n",
      "Speed: 2.9ms preprocess, 45.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/77.jpg: 384x640 (no detections), 40.8ms\n",
      "Speed: 2.5ms preprocess, 40.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/78.jpg: 384x640 (no detections), 61.1ms\n",
      "Speed: 4.0ms preprocess, 61.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/79.jpg: 384x640 (no detections), 34.2ms\n",
      "Speed: 2.1ms preprocess, 34.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/80.jpg: 384x640 (no detections), 28.7ms\n",
      "Speed: 1.8ms preprocess, 28.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/81.jpg: 384x640 (no detections), 34.8ms\n",
      "Speed: 1.8ms preprocess, 34.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/82.jpg: 384x640 (no detections), 31.9ms\n",
      "Speed: 1.7ms preprocess, 31.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/83.jpg: 384x640 1 knife, 48.2ms\n",
      "Speed: 2.0ms preprocess, 48.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/84.jpg: 384x640 (no detections), 32.3ms\n",
      "Speed: 2.7ms preprocess, 32.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/85.jpg: 384x640 1 person, 1 airplane, 31.5ms\n",
      "Speed: 2.8ms preprocess, 31.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/86.jpg: 384x640 (no detections), 34.8ms\n",
      "Speed: 2.7ms preprocess, 34.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/87.jpg: 384x640 (no detections), 37.2ms\n",
      "Speed: 3.0ms preprocess, 37.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/88.jpg: 384x640 (no detections), 46.0ms\n",
      "Speed: 3.2ms preprocess, 46.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/89.jpg: 384x640 1 knife, 35.6ms\n",
      "Speed: 1.8ms preprocess, 35.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/90.jpg: 384x640 (no detections), 52.7ms\n",
      "Speed: 2.3ms preprocess, 52.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/91.jpg: 384x640 (no detections), 29.1ms\n",
      "Speed: 1.6ms preprocess, 29.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/92.jpg: 384x640 (no detections), 30.3ms\n",
      "Speed: 2.3ms preprocess, 30.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/93.jpg: 384x640 (no detections), 29.1ms\n",
      "Speed: 1.6ms preprocess, 29.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/94.jpg: 384x640 (no detections), 33.1ms\n",
      "Speed: 3.0ms preprocess, 33.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/95.jpg: 384x640 (no detections), 29.9ms\n",
      "Speed: 1.8ms preprocess, 29.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/96.jpg: 384x640 (no detections), 33.2ms\n",
      "Speed: 2.7ms preprocess, 33.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/97.jpg: 384x640 1 person, 39.4ms\n",
      "Speed: 3.0ms preprocess, 39.4ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/98.jpg: 384x640 (no detections), 37.0ms\n",
      "Speed: 1.9ms preprocess, 37.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/99.jpg: 384x640 (no detections), 40.8ms\n",
      "Speed: 3.2ms preprocess, 40.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/100.jpg: 384x640 (no detections), 30.5ms\n",
      "Speed: 1.8ms preprocess, 30.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/101.jpg: 384x640 (no detections), 28.5ms\n",
      "Speed: 1.9ms preprocess, 28.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/102.jpg: 384x640 5 airplanes, 36.6ms\n",
      "Speed: 2.3ms preprocess, 36.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/103.jpg: 384x640 1 sink, 43.9ms\n",
      "Speed: 2.8ms preprocess, 43.9ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/104.jpg: 384x640 (no detections), 33.8ms\n",
      "Speed: 2.8ms preprocess, 33.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/105.jpg: 384x640 (no detections), 28.4ms\n",
      "Speed: 1.9ms preprocess, 28.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/106.jpg: 384x640 2 persons, 4 airplanes, 28.5ms\n",
      "Speed: 2.2ms preprocess, 28.5ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/107.jpg: 384x640 (no detections), 28.2ms\n",
      "Speed: 1.9ms preprocess, 28.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/108.jpg: 384x640 (no detections), 33.3ms\n",
      "Speed: 2.5ms preprocess, 33.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/109.jpg: 384x640 (no detections), 33.9ms\n",
      "Speed: 2.4ms preprocess, 33.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/110.jpg: 384x640 (no detections), 32.0ms\n",
      "Speed: 2.2ms preprocess, 32.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/111.jpg: 384x640 (no detections), 33.3ms\n",
      "Speed: 2.8ms preprocess, 33.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/112.jpg: 384x640 2 airplanes, 34.5ms\n",
      "Speed: 1.9ms preprocess, 34.5ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/113.jpg: 384x640 2 airplanes, 30.8ms\n",
      "Speed: 2.0ms preprocess, 30.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/114.jpg: 384x640 (no detections), 28.7ms\n",
      "Speed: 1.8ms preprocess, 28.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/115.jpg: 384x640 (no detections), 28.7ms\n",
      "Speed: 1.8ms preprocess, 28.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/116.jpg: 384x640 (no detections), 28.4ms\n",
      "Speed: 2.1ms preprocess, 28.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/117.jpg: 384x640 2 persons, 1 boat, 36.1ms\n",
      "Speed: 2.0ms preprocess, 36.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/118.jpg: 384x640 (no detections), 39.3ms\n",
      "Speed: 1.8ms preprocess, 39.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/119.jpg: 384x640 2 persons, 41.4ms\n",
      "Speed: 2.1ms preprocess, 41.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/120.jpg: 384x640 (no detections), 38.0ms\n",
      "Speed: 2.1ms preprocess, 38.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/121.jpg: 384x640 1 knife, 27.9ms\n",
      "Speed: 1.8ms preprocess, 27.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/122.jpg: 384x640 1 knife, 39.4ms\n",
      "Speed: 2.4ms preprocess, 39.4ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/123.jpg: 384x640 2 persons, 30.4ms\n",
      "Speed: 2.0ms preprocess, 30.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/124.jpg: 384x640 (no detections), 27.8ms\n",
      "Speed: 1.6ms preprocess, 27.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/125.jpg: 384x640 (no detections), 27.8ms\n",
      "Speed: 1.9ms preprocess, 27.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/126.jpg: 384x640 (no detections), 31.8ms\n",
      "Speed: 2.2ms preprocess, 31.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/127.jpg: 384x640 1 airplane, 40.6ms\n",
      "Speed: 3.0ms preprocess, 40.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/128.jpg: 384x640 2 airplanes, 40.4ms\n",
      "Speed: 2.1ms preprocess, 40.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/129.jpg: 384x640 (no detections), 27.9ms\n",
      "Speed: 2.2ms preprocess, 27.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/130.jpg: 384x640 (no detections), 32.3ms\n",
      "Speed: 2.3ms preprocess, 32.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/131.jpg: 384x640 1 airplane, 35.1ms\n",
      "Speed: 1.8ms preprocess, 35.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/132.jpg: 384x640 (no detections), 28.4ms\n",
      "Speed: 2.6ms preprocess, 28.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/133.jpg: 384x640 (no detections), 29.6ms\n",
      "Speed: 2.6ms preprocess, 29.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/134.jpg: 384x640 (no detections), 27.1ms\n",
      "Speed: 2.6ms preprocess, 27.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/135.jpg: 384x640 (no detections), 34.1ms\n",
      "Speed: 2.1ms preprocess, 34.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/136.jpg: 384x640 (no detections), 26.3ms\n",
      "Speed: 1.9ms preprocess, 26.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/137.jpg: 384x640 (no detections), 36.0ms\n",
      "Speed: 2.3ms preprocess, 36.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/138.jpg: 384x640 1 knife, 24.8ms\n",
      "Speed: 1.8ms preprocess, 24.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/139.jpg: 384x640 (no detections), 40.0ms\n",
      "Speed: 2.1ms preprocess, 40.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/140.jpg: 384x640 1 toothbrush, 27.3ms\n",
      "Speed: 1.7ms preprocess, 27.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/141.jpg: 384x640 (no detections), 32.4ms\n",
      "Speed: 2.8ms preprocess, 32.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/142.jpg: 384x640 (no detections), 53.4ms\n",
      "Speed: 2.1ms preprocess, 53.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/143.jpg: 384x640 (no detections), 34.4ms\n",
      "Speed: 2.0ms preprocess, 34.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/144.jpg: 384x640 1 person, 27.1ms\n",
      "Speed: 1.7ms preprocess, 27.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/145.jpg: 384x640 (no detections), 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/146.jpg: 384x640 3 persons, 1 airplane, 39.3ms\n",
      "Speed: 1.9ms preprocess, 39.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/147.jpg: 384x640 (no detections), 44.7ms\n",
      "Speed: 2.2ms preprocess, 44.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/148.jpg: 384x640 4 airplanes, 31.3ms\n",
      "Speed: 2.7ms preprocess, 31.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/149.jpg: 384x640 (no detections), 31.4ms\n",
      "Speed: 2.1ms preprocess, 31.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/150.jpg: 384x640 (no detections), 35.9ms\n",
      "Speed: 1.9ms preprocess, 35.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/151.jpg: 384x640 (no detections), 30.2ms\n",
      "Speed: 1.7ms preprocess, 30.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/152.jpg: 384x640 (no detections), 45.5ms\n",
      "Speed: 2.6ms preprocess, 45.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/153.jpg: 384x640 (no detections), 26.6ms\n",
      "Speed: 1.9ms preprocess, 26.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/154.jpg: 384x640 1 knife, 1 sink, 39.3ms\n",
      "Speed: 2.6ms preprocess, 39.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/155.jpg: 384x640 (no detections), 27.9ms\n",
      "Speed: 2.2ms preprocess, 27.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/156.jpg: 384x640 1 sink, 29.3ms\n",
      "Speed: 2.5ms preprocess, 29.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/157.jpg: 384x640 (no detections), 26.8ms\n",
      "Speed: 1.5ms preprocess, 26.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/158.jpg: 384x640 (no detections), 41.5ms\n",
      "Speed: 4.1ms preprocess, 41.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/159.jpg: 384x640 (no detections), 45.2ms\n",
      "Speed: 2.1ms preprocess, 45.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/160.jpg: 384x640 1 spoon, 31.0ms\n",
      "Speed: 1.5ms preprocess, 31.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/161.jpg: 384x640 (no detections), 38.9ms\n",
      "Speed: 1.8ms preprocess, 38.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/162.jpg: 384x640 (no detections), 28.6ms\n",
      "Speed: 1.8ms preprocess, 28.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/163.jpg: 384x640 (no detections), 43.4ms\n",
      "Speed: 2.6ms preprocess, 43.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/164.jpg: 384x640 (no detections), 34.0ms\n",
      "Speed: 2.0ms preprocess, 34.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/165.jpg: 384x640 (no detections), 51.3ms\n",
      "Speed: 2.2ms preprocess, 51.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/166.jpg: 384x640 (no detections), 33.3ms\n",
      "Speed: 1.6ms preprocess, 33.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/167.jpg: 384x640 (no detections), 31.2ms\n",
      "Speed: 1.9ms preprocess, 31.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/168.jpg: 384x640 (no detections), 49.2ms\n",
      "Speed: 5.0ms preprocess, 49.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/169.jpg: 384x640 (no detections), 28.6ms\n",
      "Speed: 2.3ms preprocess, 28.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/170.jpg: 384x640 (no detections), 30.4ms\n",
      "Speed: 2.0ms preprocess, 30.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/171.jpg: 384x640 (no detections), 34.6ms\n",
      "Speed: 2.6ms preprocess, 34.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/172.jpg: 384x640 (no detections), 37.7ms\n",
      "Speed: 1.7ms preprocess, 37.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/173.jpg: 384x640 (no detections), 29.1ms\n",
      "Speed: 2.1ms preprocess, 29.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/174.jpg: 384x640 (no detections), 30.2ms\n",
      "Speed: 1.7ms preprocess, 30.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/175.jpg: 384x640 (no detections), 54.9ms\n",
      "Speed: 2.4ms preprocess, 54.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/176.jpg: 384x640 1 knife, 35.3ms\n",
      "Speed: 2.0ms preprocess, 35.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/177.jpg: 384x640 1 knife, 1 sink, 61.2ms\n",
      "Speed: 4.9ms preprocess, 61.2ms inference, 6.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/178.jpg: 384x640 (no detections), 39.7ms\n",
      "Speed: 2.3ms preprocess, 39.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/179.jpg: 384x640 (no detections), 62.0ms\n",
      "Speed: 2.7ms preprocess, 62.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/180.jpg: 384x640 (no detections), 48.5ms\n",
      "Speed: 3.4ms preprocess, 48.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/181.jpg: 384x640 (no detections), 43.6ms\n",
      "Speed: 3.2ms preprocess, 43.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/182.jpg: 384x640 (no detections), 42.9ms\n",
      "Speed: 2.6ms preprocess, 42.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/183.jpg: 384x640 (no detections), 30.0ms\n",
      "Speed: 3.0ms preprocess, 30.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/184.jpg: 384x640 (no detections), 27.1ms\n",
      "Speed: 2.0ms preprocess, 27.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/185.jpg: 384x640 (no detections), 37.2ms\n",
      "Speed: 2.0ms preprocess, 37.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/186.jpg: 384x640 (no detections), 45.7ms\n",
      "Speed: 2.9ms preprocess, 45.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/187.jpg: 384x640 (no detections), 48.3ms\n",
      "Speed: 2.9ms preprocess, 48.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/188.jpg: 384x640 (no detections), 28.3ms\n",
      "Speed: 3.0ms preprocess, 28.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/189.jpg: 384x640 1 airplane, 30.1ms\n",
      "Speed: 2.1ms preprocess, 30.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/190.jpg: 384x640 (no detections), 39.9ms\n",
      "Speed: 3.7ms preprocess, 39.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/191.jpg: 384x640 (no detections), 65.4ms\n",
      "Speed: 2.2ms preprocess, 65.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/192.jpg: 384x640 (no detections), 29.7ms\n",
      "Speed: 2.4ms preprocess, 29.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/193.jpg: 384x640 (no detections), 30.9ms\n",
      "Speed: 2.0ms preprocess, 30.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/194.jpg: 384x640 (no detections), 26.3ms\n",
      "Speed: 1.9ms preprocess, 26.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/195.jpg: 384x640 (no detections), 30.9ms\n",
      "Speed: 2.0ms preprocess, 30.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/196.jpg: 384x640 4 airplanes, 29.5ms\n",
      "Speed: 1.9ms preprocess, 29.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/197.jpg: 384x640 (no detections), 28.0ms\n",
      "Speed: 3.2ms preprocess, 28.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/198.jpg: 384x640 (no detections), 45.8ms\n",
      "Speed: 3.4ms preprocess, 45.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/199.jpg: 384x640 1 person, 1 surfboard, 28.6ms\n",
      "Speed: 3.4ms preprocess, 28.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/200.jpg: 384x640 2 airplanes, 53.2ms\n",
      "Speed: 1.7ms preprocess, 53.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/201.jpg: 384x640 (no detections), 31.8ms\n",
      "Speed: 1.8ms preprocess, 31.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/202.jpg: 384x640 (no detections), 27.8ms\n",
      "Speed: 2.1ms preprocess, 27.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/203.jpg: 384x640 1 baseball bat, 28.4ms\n",
      "Speed: 2.7ms preprocess, 28.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/204.jpg: 384x640 (no detections), 26.1ms\n",
      "Speed: 2.2ms preprocess, 26.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/205.jpg: 384x640 (no detections), 38.1ms\n",
      "Speed: 2.3ms preprocess, 38.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/206.jpg: 384x640 1 person, 1 airplane, 1 boat, 43.7ms\n",
      "Speed: 2.0ms preprocess, 43.7ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/207.jpg: 384x640 2 baseball bats, 42.8ms\n",
      "Speed: 2.1ms preprocess, 42.8ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/208.jpg: 384x640 (no detections), 29.5ms\n",
      "Speed: 2.2ms preprocess, 29.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/209.jpg: 384x640 3 baseball bats, 26.5ms\n",
      "Speed: 2.2ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/210.jpg: 384x640 (no detections), 32.8ms\n",
      "Speed: 2.5ms preprocess, 32.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/211.jpg: 384x640 1 airplane, 37.7ms\n",
      "Speed: 2.0ms preprocess, 37.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/212.jpg: 384x640 2 airplanes, 29.0ms\n",
      "Speed: 1.7ms preprocess, 29.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/213.jpg: 384x640 1 airplane, 35.2ms\n",
      "Speed: 1.6ms preprocess, 35.2ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/214.jpg: 384x640 (no detections), 41.9ms\n",
      "Speed: 2.1ms preprocess, 41.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/215.jpg: 384x640 (no detections), 29.8ms\n",
      "Speed: 2.2ms preprocess, 29.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/216.jpg: 384x640 2 airplanes, 27.0ms\n",
      "Speed: 2.0ms preprocess, 27.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/217.jpg: 384x640 (no detections), 27.5ms\n",
      "Speed: 1.9ms preprocess, 27.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/218.jpg: 384x640 (no detections), 25.3ms\n",
      "Speed: 1.7ms preprocess, 25.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/219.jpg: 384x640 (no detections), 30.0ms\n",
      "Speed: 3.3ms preprocess, 30.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/220.jpg: 384x640 (no detections), 44.6ms\n",
      "Speed: 3.0ms preprocess, 44.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/221.jpg: 384x640 1 knife, 54.1ms\n",
      "Speed: 3.5ms preprocess, 54.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/222.jpg: 384x640 (no detections), 42.1ms\n",
      "Speed: 2.8ms preprocess, 42.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/223.jpg: 384x640 (no detections), 39.4ms\n",
      "Speed: 3.0ms preprocess, 39.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/224.jpg: 384x640 1 sink, 30.4ms\n",
      "Speed: 2.2ms preprocess, 30.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/225.jpg: 384x640 (no detections), 39.5ms\n",
      "Speed: 2.3ms preprocess, 39.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/226.jpg: 384x640 1 person, 35.6ms\n",
      "Speed: 1.8ms preprocess, 35.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/227.jpg: 384x640 (no detections), 27.9ms\n",
      "Speed: 2.2ms preprocess, 27.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/228.jpg: 384x640 (no detections), 31.8ms\n",
      "Speed: 1.8ms preprocess, 31.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/229.jpg: 384x640 1 baseball bat, 36.9ms\n",
      "Speed: 1.9ms preprocess, 36.9ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/230.jpg: 384x640 1 person, 28.7ms\n",
      "Speed: 3.8ms preprocess, 28.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/231.jpg: 384x640 (no detections), 46.9ms\n",
      "Speed: 2.9ms preprocess, 46.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/232.jpg: 384x640 (no detections), 31.8ms\n",
      "Speed: 2.0ms preprocess, 31.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/233.jpg: 384x640 (no detections), 39.8ms\n",
      "Speed: 2.1ms preprocess, 39.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/234.jpg: 384x640 (no detections), 45.4ms\n",
      "Speed: 1.8ms preprocess, 45.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/235.jpg: 384x640 (no detections), 28.8ms\n",
      "Speed: 2.8ms preprocess, 28.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/236.jpg: 384x640 1 person, 29.7ms\n",
      "Speed: 2.5ms preprocess, 29.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/237.jpg: 384x640 (no detections), 28.5ms\n",
      "Speed: 1.9ms preprocess, 28.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/238.jpg: 384x640 (no detections), 26.2ms\n",
      "Speed: 1.8ms preprocess, 26.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/239.jpg: 384x640 1 airplane, 29.6ms\n",
      "Speed: 1.9ms preprocess, 29.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/240.jpg: 384x640 1 person, 30.8ms\n",
      "Speed: 1.7ms preprocess, 30.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/241.jpg: 384x640 (no detections), 38.7ms\n",
      "Speed: 1.9ms preprocess, 38.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/242.jpg: 384x640 (no detections), 32.4ms\n",
      "Speed: 1.9ms preprocess, 32.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/243.jpg: 384x640 (no detections), 44.0ms\n",
      "Speed: 2.5ms preprocess, 44.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/244.jpg: 384x640 (no detections), 45.6ms\n",
      "Speed: 1.9ms preprocess, 45.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/245.jpg: 384x640 (no detections), 59.9ms\n",
      "Speed: 2.1ms preprocess, 59.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/246.jpg: 384x640 (no detections), 27.6ms\n",
      "Speed: 2.3ms preprocess, 27.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/247.jpg: 384x640 (no detections), 39.7ms\n",
      "Speed: 2.2ms preprocess, 39.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/248.jpg: 384x640 (no detections), 36.5ms\n",
      "Speed: 1.7ms preprocess, 36.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/249.jpg: 384x640 1 person, 1 airplane, 36.0ms\n",
      "Speed: 3.2ms preprocess, 36.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/250.jpg: 384x640 (no detections), 37.9ms\n",
      "Speed: 2.4ms preprocess, 37.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/251.jpg: 384x640 (no detections), 34.9ms\n",
      "Speed: 1.9ms preprocess, 34.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/252.jpg: 384x640 1 knife, 1 sink, 42.4ms\n",
      "Speed: 2.1ms preprocess, 42.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/253.jpg: 384x640 1 knife, 28.2ms\n",
      "Speed: 1.9ms preprocess, 28.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/254.jpg: 384x640 (no detections), 30.8ms\n",
      "Speed: 2.1ms preprocess, 30.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/255.jpg: 384x640 2 airplanes, 28.5ms\n",
      "Speed: 2.0ms preprocess, 28.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/256.jpg: 384x640 (no detections), 30.7ms\n",
      "Speed: 2.1ms preprocess, 30.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/257.jpg: 384x640 (no detections), 31.9ms\n",
      "Speed: 1.8ms preprocess, 31.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/258.jpg: 384x640 2 persons, 1 airplane, 36.2ms\n",
      "Speed: 2.0ms preprocess, 36.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/259.jpg: 384x640 1 person, 34.8ms\n",
      "Speed: 3.1ms preprocess, 34.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/260.jpg: 384x640 1 person, 32.0ms\n",
      "Speed: 1.9ms preprocess, 32.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/261.jpg: 384x640 (no detections), 43.5ms\n",
      "Speed: 3.2ms preprocess, 43.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/262.jpg: 384x640 1 airplane, 53.2ms\n",
      "Speed: 2.2ms preprocess, 53.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/263.jpg: 384x640 (no detections), 31.2ms\n",
      "Speed: 1.8ms preprocess, 31.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/264.jpg: 384x640 1 person, 30.7ms\n",
      "Speed: 1.9ms preprocess, 30.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/265.jpg: 384x640 (no detections), 28.8ms\n",
      "Speed: 1.6ms preprocess, 28.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/266.jpg: 384x640 (no detections), 32.4ms\n",
      "Speed: 1.9ms preprocess, 32.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/267.jpg: 384x640 (no detections), 29.0ms\n",
      "Speed: 1.7ms preprocess, 29.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/268.jpg: 384x640 1 person, 30.9ms\n",
      "Speed: 2.0ms preprocess, 30.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/269.jpg: 384x640 (no detections), 45.8ms\n",
      "Speed: 1.8ms preprocess, 45.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/270.jpg: 384x640 (no detections), 30.5ms\n",
      "Speed: 3.2ms preprocess, 30.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/271.jpg: 384x640 (no detections), 28.6ms\n",
      "Speed: 1.7ms preprocess, 28.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/272.jpg: 384x640 1 person, 40.5ms\n",
      "Speed: 2.1ms preprocess, 40.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/273.jpg: 384x640 2 airplanes, 36.4ms\n",
      "Speed: 2.9ms preprocess, 36.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/274.jpg: 384x640 (no detections), 44.0ms\n",
      "Speed: 2.9ms preprocess, 44.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/275.jpg: 384x640 (no detections), 38.4ms\n",
      "Speed: 2.4ms preprocess, 38.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/276.jpg: 384x640 (no detections), 27.1ms\n",
      "Speed: 1.8ms preprocess, 27.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/277.jpg: 384x640 (no detections), 29.2ms\n",
      "Speed: 1.9ms preprocess, 29.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/278.jpg: 384x640 (no detections), 29.0ms\n",
      "Speed: 2.6ms preprocess, 29.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/279.jpg: 384x640 (no detections), 27.5ms\n",
      "Speed: 2.6ms preprocess, 27.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/280.jpg: 384x640 (no detections), 36.5ms\n",
      "Speed: 2.0ms preprocess, 36.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/281.jpg: 384x640 (no detections), 33.0ms\n",
      "Speed: 1.9ms preprocess, 33.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/282.jpg: 384x640 (no detections), 46.3ms\n",
      "Speed: 2.3ms preprocess, 46.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/283.jpg: 384x640 1 person, 34.2ms\n",
      "Speed: 1.9ms preprocess, 34.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/284.jpg: 384x640 (no detections), 34.2ms\n",
      "Speed: 1.9ms preprocess, 34.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/285.jpg: 384x640 3 airplanes, 28.3ms\n",
      "Speed: 1.9ms preprocess, 28.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/286.jpg: 384x640 (no detections), 25.1ms\n",
      "Speed: 2.4ms preprocess, 25.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/287.jpg: 384x640 1 person, 28.9ms\n",
      "Speed: 1.9ms preprocess, 28.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/288.jpg: 384x640 1 airplane, 46.8ms\n",
      "Speed: 1.9ms preprocess, 46.8ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/289.jpg: 384x640 (no detections), 38.5ms\n",
      "Speed: 2.7ms preprocess, 38.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/290.jpg: 384x640 1 sink, 31.1ms\n",
      "Speed: 2.2ms preprocess, 31.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/291.jpg: 384x640 (no detections), 28.2ms\n",
      "Speed: 1.9ms preprocess, 28.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/292.jpg: 384x640 (no detections), 42.9ms\n",
      "Speed: 3.1ms preprocess, 42.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/293.jpg: 384x640 1 kite, 33.9ms\n",
      "Speed: 1.7ms preprocess, 33.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/294.jpg: 384x640 (no detections), 45.4ms\n",
      "Speed: 1.8ms preprocess, 45.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/295.jpg: 384x640 (no detections), 30.4ms\n",
      "Speed: 1.7ms preprocess, 30.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/296.jpg: 384x640 1 airplane, 43.9ms\n",
      "Speed: 1.9ms preprocess, 43.9ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/297.jpg: 384x640 (no detections), 27.8ms\n",
      "Speed: 1.8ms preprocess, 27.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/298.jpg: 384x640 (no detections), 27.9ms\n",
      "Speed: 2.3ms preprocess, 27.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/left/299.jpg: 384x640 (no detections), 28.8ms\n",
      "Speed: 2.1ms preprocess, 28.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Propagating video frames: 100%|| 300/300 [00:21<00:00, 13.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask propagation completed in 21.51 seconds.\n",
      "Processing predicted masks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing video frames: 300it [00:00, 535.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 300 masks for evaluation.\n",
      "Masks saved to data/masks/yolo11x-seg/val/data-raw-SegSTRONGC_val-val-1-1-smoke-left.pkl\n",
      "Loading ground truth masks for evaluation...\n",
      "Loaded 300 ground truth masks.\n",
      "Calculating evaluation metrics...\n",
      "Time taken for metrics calculation: 1.38 seconds.\n",
      "Mean IoU for data/raw/SegSTRONGC_val/val/1/1/smoke/left: 0.0529\n",
      "Mean DSC for data/raw/SegSTRONGC_val/val/1/1/smoke/left: 0.0759\n",
      "Loading existing results file: data/results/yolo11x-seg/val.json\n",
      "Results saved to data/results/yolo11x-seg/val.json\n",
      "Processing video took 24.66 seconds.\n",
      "==================================================\n",
      "Processing right camera video...\n",
      "==================================================\n",
      "Processing video: data/raw/SegSTRONGC_val/val/1/1/smoke/right\n",
      "Domain: smoke, Split: val, Camera: right\n",
      "Initializing Yolo for video...\n",
      "Initialization took 0.13 seconds.\n",
      "Starting mask propagation...\n",
      "Total images in video: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/0.jpg: 384x640 (no detections), 28.9ms\n",
      "Speed: 1.9ms preprocess, 28.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/1.jpg: 384x640 (no detections), 24.7ms\n",
      "Speed: 1.6ms preprocess, 24.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/2.jpg: 384x640 (no detections), 24.1ms\n",
      "Speed: 3.6ms preprocess, 24.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/3.jpg: 384x640 (no detections), 29.8ms\n",
      "Speed: 2.5ms preprocess, 29.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/4.jpg: 384x640 (no detections), 31.7ms\n",
      "Speed: 1.9ms preprocess, 31.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/5.jpg: 384x640 1 knife, 23.4ms\n",
      "Speed: 2.0ms preprocess, 23.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/6.jpg: 384x640 (no detections), 35.0ms\n",
      "Speed: 1.7ms preprocess, 35.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/7.jpg: 384x640 (no detections), 23.1ms\n",
      "Speed: 1.6ms preprocess, 23.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/8.jpg: 384x640 (no detections), 27.5ms\n",
      "Speed: 3.2ms preprocess, 27.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/9.jpg: 384x640 (no detections), 23.5ms\n",
      "Speed: 1.7ms preprocess, 23.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/10.jpg: 384x640 (no detections), 33.0ms\n",
      "Speed: 2.0ms preprocess, 33.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/11.jpg: 384x640 (no detections), 29.3ms\n",
      "Speed: 2.0ms preprocess, 29.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/12.jpg: 384x640 (no detections), 25.3ms\n",
      "Speed: 2.4ms preprocess, 25.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/13.jpg: 384x640 (no detections), 28.1ms\n",
      "Speed: 1.6ms preprocess, 28.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/14.jpg: 384x640 (no detections), 40.9ms\n",
      "Speed: 1.7ms preprocess, 40.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/15.jpg: 384x640 (no detections), 44.9ms\n",
      "Speed: 2.1ms preprocess, 44.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/16.jpg: 384x640 (no detections), 27.4ms\n",
      "Speed: 1.9ms preprocess, 27.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/17.jpg: 384x640 (no detections), 35.0ms\n",
      "Speed: 1.7ms preprocess, 35.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/18.jpg: 384x640 (no detections), 46.7ms\n",
      "Speed: 1.9ms preprocess, 46.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/19.jpg: 384x640 (no detections), 24.8ms\n",
      "Speed: 2.5ms preprocess, 24.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/20.jpg: 384x640 (no detections), 33.9ms\n",
      "Speed: 2.8ms preprocess, 33.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/21.jpg: 384x640 1 baseball bat, 1 spoon, 1 toothbrush, 31.8ms\n",
      "Speed: 1.6ms preprocess, 31.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/22.jpg: 384x640 (no detections), 46.9ms\n",
      "Speed: 2.3ms preprocess, 46.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/23.jpg: 384x640 (no detections), 38.5ms\n",
      "Speed: 3.3ms preprocess, 38.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/24.jpg: 384x640 (no detections), 29.6ms\n",
      "Speed: 1.8ms preprocess, 29.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/25.jpg: 384x640 (no detections), 43.5ms\n",
      "Speed: 2.7ms preprocess, 43.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/26.jpg: 384x640 (no detections), 27.1ms\n",
      "Speed: 2.3ms preprocess, 27.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/27.jpg: 384x640 (no detections), 61.2ms\n",
      "Speed: 1.6ms preprocess, 61.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/28.jpg: 384x640 (no detections), 26.6ms\n",
      "Speed: 2.0ms preprocess, 26.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/29.jpg: 384x640 1 baseball bat, 2 spoons, 2 carrots, 23.2ms\n",
      "Speed: 1.7ms preprocess, 23.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/30.jpg: 384x640 (no detections), 29.2ms\n",
      "Speed: 1.7ms preprocess, 29.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/31.jpg: 384x640 (no detections), 30.6ms\n",
      "Speed: 1.6ms preprocess, 30.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/32.jpg: 384x640 (no detections), 38.2ms\n",
      "Speed: 1.8ms preprocess, 38.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/33.jpg: 384x640 (no detections), 26.5ms\n",
      "Speed: 1.6ms preprocess, 26.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/34.jpg: 384x640 1 spoon, 1 bowl, 25.6ms\n",
      "Speed: 1.6ms preprocess, 25.6ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/35.jpg: 384x640 (no detections), 27.7ms\n",
      "Speed: 1.6ms preprocess, 27.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/36.jpg: 384x640 2 spoons, 34.6ms\n",
      "Speed: 1.6ms preprocess, 34.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/37.jpg: 384x640 1 spoon, 1 toothbrush, 28.5ms\n",
      "Speed: 2.8ms preprocess, 28.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/38.jpg: 384x640 (no detections), 38.6ms\n",
      "Speed: 2.5ms preprocess, 38.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/39.jpg: 384x640 (no detections), 42.7ms\n",
      "Speed: 1.9ms preprocess, 42.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/40.jpg: 384x640 (no detections), 33.3ms\n",
      "Speed: 1.6ms preprocess, 33.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/41.jpg: 384x640 (no detections), 26.2ms\n",
      "Speed: 1.9ms preprocess, 26.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/42.jpg: 384x640 (no detections), 37.5ms\n",
      "Speed: 2.1ms preprocess, 37.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/43.jpg: 384x640 (no detections), 24.2ms\n",
      "Speed: 1.6ms preprocess, 24.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/44.jpg: 384x640 (no detections), 29.3ms\n",
      "Speed: 1.6ms preprocess, 29.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/45.jpg: 384x640 1 airplane, 34.3ms\n",
      "Speed: 2.2ms preprocess, 34.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/46.jpg: 384x640 (no detections), 27.3ms\n",
      "Speed: 1.7ms preprocess, 27.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/47.jpg: 384x640 (no detections), 48.4ms\n",
      "Speed: 3.4ms preprocess, 48.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/48.jpg: 384x640 (no detections), 29.7ms\n",
      "Speed: 1.6ms preprocess, 29.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/49.jpg: 384x640 1 airplane, 29.0ms\n",
      "Speed: 1.7ms preprocess, 29.0ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/50.jpg: 384x640 (no detections), 29.4ms\n",
      "Speed: 1.8ms preprocess, 29.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/51.jpg: 384x640 (no detections), 30.0ms\n",
      "Speed: 2.3ms preprocess, 30.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/52.jpg: 384x640 (no detections), 30.3ms\n",
      "Speed: 2.3ms preprocess, 30.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/53.jpg: 384x640 1 airplane, 38.1ms\n",
      "Speed: 1.7ms preprocess, 38.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/54.jpg: 384x640 (no detections), 28.1ms\n",
      "Speed: 1.9ms preprocess, 28.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/55.jpg: 384x640 1 airplane, 35.4ms\n",
      "Speed: 2.0ms preprocess, 35.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/56.jpg: 384x640 (no detections), 42.3ms\n",
      "Speed: 2.7ms preprocess, 42.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/57.jpg: 384x640 1 toothbrush, 49.0ms\n",
      "Speed: 1.7ms preprocess, 49.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/58.jpg: 384x640 1 sink, 30.6ms\n",
      "Speed: 1.9ms preprocess, 30.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/59.jpg: 384x640 (no detections), 30.1ms\n",
      "Speed: 2.0ms preprocess, 30.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/60.jpg: 384x640 (no detections), 33.6ms\n",
      "Speed: 1.8ms preprocess, 33.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/61.jpg: 384x640 1 airplane, 35.3ms\n",
      "Speed: 2.5ms preprocess, 35.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/62.jpg: 384x640 1 airplane, 39.5ms\n",
      "Speed: 2.9ms preprocess, 39.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/63.jpg: 384x640 1 baseball bat, 1 spoon, 1 sink, 30.1ms\n",
      "Speed: 1.9ms preprocess, 30.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/64.jpg: 384x640 1 toothbrush, 30.9ms\n",
      "Speed: 1.9ms preprocess, 30.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/65.jpg: 384x640 1 airplane, 53.4ms\n",
      "Speed: 2.3ms preprocess, 53.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/66.jpg: 384x640 (no detections), 34.7ms\n",
      "Speed: 1.8ms preprocess, 34.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/67.jpg: 384x640 1 baseball bat, 1 spoon, 1 sink, 30.3ms\n",
      "Speed: 1.7ms preprocess, 30.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/68.jpg: 384x640 1 sink, 34.5ms\n",
      "Speed: 1.8ms preprocess, 34.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/69.jpg: 384x640 1 toothbrush, 58.9ms\n",
      "Speed: 2.6ms preprocess, 58.9ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/70.jpg: 384x640 (no detections), 36.1ms\n",
      "Speed: 2.7ms preprocess, 36.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/71.jpg: 384x640 (no detections), 48.1ms\n",
      "Speed: 2.5ms preprocess, 48.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/72.jpg: 384x640 1 toothbrush, 42.7ms\n",
      "Speed: 1.9ms preprocess, 42.7ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/73.jpg: 384x640 1 toothbrush, 41.6ms\n",
      "Speed: 1.9ms preprocess, 41.6ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/74.jpg: 384x640 (no detections), 30.2ms\n",
      "Speed: 1.9ms preprocess, 30.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/75.jpg: 384x640 (no detections), 34.7ms\n",
      "Speed: 1.9ms preprocess, 34.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/76.jpg: 384x640 (no detections), 29.7ms\n",
      "Speed: 2.0ms preprocess, 29.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/77.jpg: 384x640 1 sink, 36.9ms\n",
      "Speed: 2.8ms preprocess, 36.9ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/78.jpg: 384x640 1 spoon, 32.6ms\n",
      "Speed: 1.9ms preprocess, 32.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/79.jpg: 384x640 (no detections), 29.4ms\n",
      "Speed: 1.8ms preprocess, 29.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/80.jpg: 384x640 (no detections), 34.2ms\n",
      "Speed: 1.8ms preprocess, 34.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/81.jpg: 384x640 (no detections), 29.9ms\n",
      "Speed: 1.8ms preprocess, 29.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/82.jpg: 384x640 (no detections), 28.2ms\n",
      "Speed: 2.2ms preprocess, 28.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/83.jpg: 384x640 1 knife, 1 spoon, 1 toothbrush, 33.3ms\n",
      "Speed: 2.8ms preprocess, 33.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/84.jpg: 384x640 (no detections), 32.6ms\n",
      "Speed: 2.1ms preprocess, 32.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/85.jpg: 384x640 (no detections), 49.9ms\n",
      "Speed: 3.2ms preprocess, 49.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/86.jpg: 384x640 1 spoon, 1 sink, 1 toothbrush, 47.3ms\n",
      "Speed: 2.3ms preprocess, 47.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/87.jpg: 384x640 (no detections), 53.7ms\n",
      "Speed: 2.0ms preprocess, 53.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/88.jpg: 384x640 1 toothbrush, 43.8ms\n",
      "Speed: 3.1ms preprocess, 43.8ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/89.jpg: 384x640 1 spoon, 29.4ms\n",
      "Speed: 3.0ms preprocess, 29.4ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/90.jpg: 384x640 (no detections), 29.7ms\n",
      "Speed: 2.0ms preprocess, 29.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/91.jpg: 384x640 (no detections), 48.4ms\n",
      "Speed: 2.9ms preprocess, 48.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/92.jpg: 384x640 1 spoon, 32.7ms\n",
      "Speed: 3.1ms preprocess, 32.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/93.jpg: 384x640 (no detections), 54.2ms\n",
      "Speed: 1.9ms preprocess, 54.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/94.jpg: 384x640 (no detections), 37.7ms\n",
      "Speed: 2.0ms preprocess, 37.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/95.jpg: 384x640 (no detections), 30.5ms\n",
      "Speed: 2.3ms preprocess, 30.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/96.jpg: 384x640 (no detections), 32.9ms\n",
      "Speed: 3.2ms preprocess, 32.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/97.jpg: 384x640 1 toothbrush, 27.2ms\n",
      "Speed: 1.9ms preprocess, 27.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/98.jpg: 384x640 (no detections), 35.6ms\n",
      "Speed: 1.9ms preprocess, 35.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/99.jpg: 384x640 (no detections), 38.1ms\n",
      "Speed: 1.8ms preprocess, 38.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/100.jpg: 384x640 (no detections), 60.4ms\n",
      "Speed: 2.2ms preprocess, 60.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/101.jpg: 384x640 1 motorcycle, 40.9ms\n",
      "Speed: 3.2ms preprocess, 40.9ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/102.jpg: 384x640 1 motorcycle, 36.9ms\n",
      "Speed: 1.9ms preprocess, 36.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/103.jpg: 384x640 1 sink, 1 toothbrush, 32.9ms\n",
      "Speed: 2.9ms preprocess, 32.9ms inference, 5.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/104.jpg: 384x640 (no detections), 46.6ms\n",
      "Speed: 1.9ms preprocess, 46.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/105.jpg: 384x640 (no detections), 26.4ms\n",
      "Speed: 2.0ms preprocess, 26.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/106.jpg: 384x640 (no detections), 30.3ms\n",
      "Speed: 2.0ms preprocess, 30.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/107.jpg: 384x640 (no detections), 28.9ms\n",
      "Speed: 1.9ms preprocess, 28.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/108.jpg: 384x640 (no detections), 47.6ms\n",
      "Speed: 2.8ms preprocess, 47.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/109.jpg: 384x640 (no detections), 39.8ms\n",
      "Speed: 2.8ms preprocess, 39.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/110.jpg: 384x640 (no detections), 29.1ms\n",
      "Speed: 2.0ms preprocess, 29.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/111.jpg: 384x640 1 car, 27.2ms\n",
      "Speed: 2.1ms preprocess, 27.2ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/112.jpg: 384x640 (no detections), 38.3ms\n",
      "Speed: 1.9ms preprocess, 38.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/113.jpg: 384x640 (no detections), 32.9ms\n",
      "Speed: 1.8ms preprocess, 32.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/114.jpg: 384x640 (no detections), 56.0ms\n",
      "Speed: 2.5ms preprocess, 56.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/115.jpg: 384x640 (no detections), 52.9ms\n",
      "Speed: 2.5ms preprocess, 52.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/116.jpg: 384x640 (no detections), 43.4ms\n",
      "Speed: 2.6ms preprocess, 43.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/117.jpg: 384x640 1 toothbrush, 31.2ms\n",
      "Speed: 2.1ms preprocess, 31.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/118.jpg: 384x640 (no detections), 28.6ms\n",
      "Speed: 2.2ms preprocess, 28.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/119.jpg: 384x640 (no detections), 37.1ms\n",
      "Speed: 2.5ms preprocess, 37.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/120.jpg: 384x640 (no detections), 42.6ms\n",
      "Speed: 1.7ms preprocess, 42.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/121.jpg: 384x640 1 spoon, 31.0ms\n",
      "Speed: 3.1ms preprocess, 31.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/122.jpg: 384x640 (no detections), 35.4ms\n",
      "Speed: 2.7ms preprocess, 35.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/123.jpg: 384x640 (no detections), 42.5ms\n",
      "Speed: 2.8ms preprocess, 42.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/124.jpg: 384x640 1 toothbrush, 39.5ms\n",
      "Speed: 2.3ms preprocess, 39.5ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/125.jpg: 384x640 (no detections), 28.8ms\n",
      "Speed: 1.7ms preprocess, 28.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/126.jpg: 384x640 (no detections), 33.5ms\n",
      "Speed: 1.7ms preprocess, 33.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/127.jpg: 384x640 (no detections), 33.5ms\n",
      "Speed: 3.3ms preprocess, 33.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/128.jpg: 384x640 (no detections), 38.0ms\n",
      "Speed: 3.0ms preprocess, 38.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/129.jpg: 384x640 (no detections), 36.6ms\n",
      "Speed: 2.0ms preprocess, 36.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/130.jpg: 384x640 (no detections), 48.9ms\n",
      "Speed: 1.8ms preprocess, 48.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/131.jpg: 384x640 (no detections), 61.5ms\n",
      "Speed: 1.9ms preprocess, 61.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/132.jpg: 384x640 (no detections), 38.1ms\n",
      "Speed: 3.0ms preprocess, 38.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/133.jpg: 384x640 (no detections), 34.3ms\n",
      "Speed: 1.8ms preprocess, 34.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/134.jpg: 384x640 (no detections), 50.3ms\n",
      "Speed: 3.3ms preprocess, 50.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/135.jpg: 384x640 (no detections), 30.8ms\n",
      "Speed: 2.2ms preprocess, 30.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/136.jpg: 384x640 (no detections), 27.8ms\n",
      "Speed: 1.7ms preprocess, 27.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/137.jpg: 384x640 (no detections), 28.4ms\n",
      "Speed: 1.8ms preprocess, 28.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/138.jpg: 384x640 1 fork, 2 carrots, 29.6ms\n",
      "Speed: 2.8ms preprocess, 29.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/139.jpg: 384x640 (no detections), 47.1ms\n",
      "Speed: 1.9ms preprocess, 47.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/140.jpg: 384x640 (no detections), 31.5ms\n",
      "Speed: 2.9ms preprocess, 31.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/141.jpg: 384x640 (no detections), 35.7ms\n",
      "Speed: 3.3ms preprocess, 35.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/142.jpg: 384x640 1 car, 30.1ms\n",
      "Speed: 2.0ms preprocess, 30.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/143.jpg: 384x640 (no detections), 42.8ms\n",
      "Speed: 2.1ms preprocess, 42.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/144.jpg: 384x640 (no detections), 46.5ms\n",
      "Speed: 1.9ms preprocess, 46.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/145.jpg: 384x640 (no detections), 48.0ms\n",
      "Speed: 2.1ms preprocess, 48.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/146.jpg: 384x640 1 car, 34.6ms\n",
      "Speed: 2.5ms preprocess, 34.6ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/147.jpg: 384x640 (no detections), 32.6ms\n",
      "Speed: 2.0ms preprocess, 32.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/148.jpg: 384x640 (no detections), 30.2ms\n",
      "Speed: 2.1ms preprocess, 30.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/149.jpg: 384x640 (no detections), 29.9ms\n",
      "Speed: 2.5ms preprocess, 29.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/150.jpg: 384x640 (no detections), 34.1ms\n",
      "Speed: 2.1ms preprocess, 34.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/151.jpg: 384x640 (no detections), 33.0ms\n",
      "Speed: 3.1ms preprocess, 33.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/152.jpg: 384x640 (no detections), 38.5ms\n",
      "Speed: 2.2ms preprocess, 38.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/153.jpg: 384x640 1 airplane, 26.4ms\n",
      "Speed: 1.9ms preprocess, 26.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/154.jpg: 384x640 2 spoons, 31.0ms\n",
      "Speed: 2.0ms preprocess, 31.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/155.jpg: 384x640 1 spoon, 1 carrot, 25.1ms\n",
      "Speed: 2.2ms preprocess, 25.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/156.jpg: 384x640 1 knife, 1 sink, 34.7ms\n",
      "Speed: 2.6ms preprocess, 34.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/157.jpg: 384x640 (no detections), 33.4ms\n",
      "Speed: 2.5ms preprocess, 33.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/158.jpg: 384x640 (no detections), 29.9ms\n",
      "Speed: 1.7ms preprocess, 29.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/159.jpg: 384x640 (no detections), 26.4ms\n",
      "Speed: 1.8ms preprocess, 26.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/160.jpg: 384x640 1 spoon, 33.6ms\n",
      "Speed: 1.9ms preprocess, 33.6ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/161.jpg: 384x640 (no detections), 29.1ms\n",
      "Speed: 2.5ms preprocess, 29.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/162.jpg: 384x640 (no detections), 34.7ms\n",
      "Speed: 2.0ms preprocess, 34.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/163.jpg: 384x640 (no detections), 36.5ms\n",
      "Speed: 1.8ms preprocess, 36.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/164.jpg: 384x640 1 car, 28.8ms\n",
      "Speed: 2.4ms preprocess, 28.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/165.jpg: 384x640 (no detections), 33.0ms\n",
      "Speed: 1.9ms preprocess, 33.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/166.jpg: 384x640 (no detections), 26.3ms\n",
      "Speed: 1.7ms preprocess, 26.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/167.jpg: 384x640 (no detections), 32.2ms\n",
      "Speed: 1.7ms preprocess, 32.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/168.jpg: 384x640 (no detections), 28.8ms\n",
      "Speed: 1.9ms preprocess, 28.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/169.jpg: 384x640 (no detections), 47.0ms\n",
      "Speed: 3.0ms preprocess, 47.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/170.jpg: 384x640 1 car, 26.8ms\n",
      "Speed: 1.8ms preprocess, 26.8ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/171.jpg: 384x640 (no detections), 36.5ms\n",
      "Speed: 2.4ms preprocess, 36.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/172.jpg: 384x640 (no detections), 31.9ms\n",
      "Speed: 1.7ms preprocess, 31.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/173.jpg: 384x640 (no detections), 25.9ms\n",
      "Speed: 1.9ms preprocess, 25.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/174.jpg: 384x640 (no detections), 28.6ms\n",
      "Speed: 1.8ms preprocess, 28.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/175.jpg: 384x640 (no detections), 39.4ms\n",
      "Speed: 2.3ms preprocess, 39.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/176.jpg: 384x640 1 spoon, 31.3ms\n",
      "Speed: 1.9ms preprocess, 31.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/177.jpg: 384x640 1 knife, 1 spoon, 25.3ms\n",
      "Speed: 1.7ms preprocess, 25.3ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/178.jpg: 384x640 (no detections), 32.4ms\n",
      "Speed: 2.0ms preprocess, 32.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/179.jpg: 384x640 (no detections), 41.2ms\n",
      "Speed: 2.6ms preprocess, 41.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/180.jpg: 384x640 (no detections), 30.0ms\n",
      "Speed: 1.6ms preprocess, 30.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/181.jpg: 384x640 (no detections), 26.2ms\n",
      "Speed: 1.7ms preprocess, 26.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/182.jpg: 384x640 (no detections), 27.9ms\n",
      "Speed: 1.9ms preprocess, 27.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/183.jpg: 384x640 (no detections), 34.7ms\n",
      "Speed: 2.8ms preprocess, 34.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/184.jpg: 384x640 (no detections), 28.6ms\n",
      "Speed: 1.8ms preprocess, 28.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/185.jpg: 384x640 (no detections), 28.4ms\n",
      "Speed: 1.7ms preprocess, 28.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/186.jpg: 384x640 1 airplane, 30.3ms\n",
      "Speed: 2.6ms preprocess, 30.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/187.jpg: 384x640 (no detections), 26.7ms\n",
      "Speed: 2.3ms preprocess, 26.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/188.jpg: 384x640 (no detections), 25.8ms\n",
      "Speed: 3.1ms preprocess, 25.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/189.jpg: 384x640 (no detections), 43.8ms\n",
      "Speed: 1.8ms preprocess, 43.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/190.jpg: 384x640 (no detections), 29.1ms\n",
      "Speed: 2.7ms preprocess, 29.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/191.jpg: 384x640 (no detections), 31.2ms\n",
      "Speed: 2.1ms preprocess, 31.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/192.jpg: 384x640 (no detections), 38.7ms\n",
      "Speed: 1.8ms preprocess, 38.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/193.jpg: 384x640 (no detections), 30.4ms\n",
      "Speed: 2.2ms preprocess, 30.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/194.jpg: 384x640 (no detections), 35.7ms\n",
      "Speed: 1.7ms preprocess, 35.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/195.jpg: 384x640 1 baseball bat, 1 sink, 37.3ms\n",
      "Speed: 1.9ms preprocess, 37.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/196.jpg: 384x640 (no detections), 29.1ms\n",
      "Speed: 2.2ms preprocess, 29.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/197.jpg: 384x640 (no detections), 27.7ms\n",
      "Speed: 1.8ms preprocess, 27.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/198.jpg: 384x640 (no detections), 30.2ms\n",
      "Speed: 2.1ms preprocess, 30.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/199.jpg: 384x640 1 airplane, 27.7ms\n",
      "Speed: 2.5ms preprocess, 27.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/200.jpg: 384x640 (no detections), 33.2ms\n",
      "Speed: 2.8ms preprocess, 33.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/201.jpg: 384x640 (no detections), 27.2ms\n",
      "Speed: 1.6ms preprocess, 27.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/202.jpg: 384x640 (no detections), 38.6ms\n",
      "Speed: 1.6ms preprocess, 38.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/203.jpg: 384x640 1 baseball bat, 35.0ms\n",
      "Speed: 2.5ms preprocess, 35.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/204.jpg: 384x640 1 baseball bat, 2 spoons, 38.6ms\n",
      "Speed: 2.2ms preprocess, 38.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/205.jpg: 384x640 (no detections), 29.4ms\n",
      "Speed: 1.8ms preprocess, 29.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/206.jpg: 384x640 1 toothbrush, 46.0ms\n",
      "Speed: 2.0ms preprocess, 46.0ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/207.jpg: 384x640 1 baseball bat, 2 spoons, 1 carrot, 36.3ms\n",
      "Speed: 1.8ms preprocess, 36.3ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/208.jpg: 384x640 1 baseball bat, 63.2ms\n",
      "Speed: 2.1ms preprocess, 63.2ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/209.jpg: 384x640 1 baseball bat, 2 spoons, 58.3ms\n",
      "Speed: 2.3ms preprocess, 58.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/210.jpg: 384x640 (no detections), 43.7ms\n",
      "Speed: 2.0ms preprocess, 43.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/211.jpg: 384x640 1 clock, 49.7ms\n",
      "Speed: 3.1ms preprocess, 49.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/212.jpg: 384x640 (no detections), 45.7ms\n",
      "Speed: 2.5ms preprocess, 45.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/213.jpg: 384x640 1 toothbrush, 39.0ms\n",
      "Speed: 2.8ms preprocess, 39.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/214.jpg: 384x640 1 airplane, 42.0ms\n",
      "Speed: 2.3ms preprocess, 42.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/215.jpg: 384x640 (no detections), 33.1ms\n",
      "Speed: 1.7ms preprocess, 33.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/216.jpg: 384x640 (no detections), 48.2ms\n",
      "Speed: 2.7ms preprocess, 48.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/217.jpg: 384x640 (no detections), 27.9ms\n",
      "Speed: 1.9ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/218.jpg: 384x640 (no detections), 30.0ms\n",
      "Speed: 2.3ms preprocess, 30.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/219.jpg: 384x640 (no detections), 58.8ms\n",
      "Speed: 2.0ms preprocess, 58.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/220.jpg: 384x640 (no detections), 56.8ms\n",
      "Speed: 3.1ms preprocess, 56.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/221.jpg: 384x640 1 sink, 1 toothbrush, 35.1ms\n",
      "Speed: 1.9ms preprocess, 35.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/222.jpg: 384x640 (no detections), 29.1ms\n",
      "Speed: 1.9ms preprocess, 29.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/223.jpg: 384x640 (no detections), 36.7ms\n",
      "Speed: 2.1ms preprocess, 36.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/224.jpg: 384x640 1 bottle, 1 knife, 1 spoon, 1 sink, 32.5ms\n",
      "Speed: 2.0ms preprocess, 32.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/225.jpg: 384x640 (no detections), 34.5ms\n",
      "Speed: 2.9ms preprocess, 34.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/226.jpg: 384x640 1 bottle, 1 sink, 2 toothbrushs, 36.8ms\n",
      "Speed: 2.7ms preprocess, 36.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/227.jpg: 384x640 (no detections), 44.8ms\n",
      "Speed: 3.5ms preprocess, 44.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/228.jpg: 384x640 (no detections), 33.9ms\n",
      "Speed: 2.0ms preprocess, 33.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/229.jpg: 384x640 1 bottle, 35.4ms\n",
      "Speed: 2.0ms preprocess, 35.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/230.jpg: 384x640 1 spoon, 1 apple, 1 toothbrush, 34.3ms\n",
      "Speed: 2.0ms preprocess, 34.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/231.jpg: 384x640 (no detections), 44.5ms\n",
      "Speed: 3.1ms preprocess, 44.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/232.jpg: 384x640 (no detections), 38.6ms\n",
      "Speed: 2.7ms preprocess, 38.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/233.jpg: 384x640 (no detections), 38.2ms\n",
      "Speed: 2.1ms preprocess, 38.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/234.jpg: 384x640 1 spoon, 1 sink, 1 toothbrush, 31.7ms\n",
      "Speed: 2.1ms preprocess, 31.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/235.jpg: 384x640 (no detections), 52.8ms\n",
      "Speed: 3.7ms preprocess, 52.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/236.jpg: 384x640 (no detections), 34.6ms\n",
      "Speed: 2.1ms preprocess, 34.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/237.jpg: 384x640 (no detections), 28.0ms\n",
      "Speed: 1.8ms preprocess, 28.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/238.jpg: 384x640 (no detections), 32.1ms\n",
      "Speed: 2.7ms preprocess, 32.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/239.jpg: 384x640 (no detections), 39.3ms\n",
      "Speed: 2.7ms preprocess, 39.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/240.jpg: 384x640 (no detections), 34.7ms\n",
      "Speed: 2.8ms preprocess, 34.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/241.jpg: 384x640 2 apples, 31.6ms\n",
      "Speed: 1.8ms preprocess, 31.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/242.jpg: 384x640 (no detections), 31.5ms\n",
      "Speed: 2.1ms preprocess, 31.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/243.jpg: 384x640 (no detections), 27.2ms\n",
      "Speed: 1.7ms preprocess, 27.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/244.jpg: 384x640 1 airplane, 31.6ms\n",
      "Speed: 2.2ms preprocess, 31.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/245.jpg: 384x640 (no detections), 32.2ms\n",
      "Speed: 2.6ms preprocess, 32.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/246.jpg: 384x640 (no detections), 40.4ms\n",
      "Speed: 3.1ms preprocess, 40.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/247.jpg: 384x640 (no detections), 29.2ms\n",
      "Speed: 2.5ms preprocess, 29.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/248.jpg: 384x640 1 knife, 43.5ms\n",
      "Speed: 4.0ms preprocess, 43.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/249.jpg: 384x640 1 knife, 29.6ms\n",
      "Speed: 1.7ms preprocess, 29.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/250.jpg: 384x640 (no detections), 43.8ms\n",
      "Speed: 3.0ms preprocess, 43.8ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/251.jpg: 384x640 (no detections), 50.6ms\n",
      "Speed: 2.9ms preprocess, 50.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/252.jpg: 384x640 1 knife, 1 sink, 29.4ms\n",
      "Speed: 2.0ms preprocess, 29.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/253.jpg: 384x640 1 knife, 1 apple, 1 sink, 33.4ms\n",
      "Speed: 2.4ms preprocess, 33.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/254.jpg: 384x640 1 knife, 41.9ms\n",
      "Speed: 2.2ms preprocess, 41.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/255.jpg: 384x640 (no detections), 36.7ms\n",
      "Speed: 2.0ms preprocess, 36.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/256.jpg: 384x640 (no detections), 34.6ms\n",
      "Speed: 1.9ms preprocess, 34.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/257.jpg: 384x640 1 bottle, 1 apple, 55.1ms\n",
      "Speed: 2.3ms preprocess, 55.1ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/258.jpg: 384x640 (no detections), 42.6ms\n",
      "Speed: 2.9ms preprocess, 42.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/259.jpg: 384x640 (no detections), 39.4ms\n",
      "Speed: 2.8ms preprocess, 39.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/260.jpg: 384x640 (no detections), 45.5ms\n",
      "Speed: 3.3ms preprocess, 45.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/261.jpg: 384x640 (no detections), 30.0ms\n",
      "Speed: 2.3ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/262.jpg: 384x640 (no detections), 32.9ms\n",
      "Speed: 2.0ms preprocess, 32.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/263.jpg: 384x640 1 knife, 1 sink, 34.2ms\n",
      "Speed: 2.7ms preprocess, 34.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/264.jpg: 384x640 (no detections), 37.0ms\n",
      "Speed: 2.0ms preprocess, 37.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/265.jpg: 384x640 (no detections), 31.4ms\n",
      "Speed: 2.0ms preprocess, 31.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/266.jpg: 384x640 (no detections), 27.8ms\n",
      "Speed: 1.8ms preprocess, 27.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/267.jpg: 384x640 (no detections), 42.8ms\n",
      "Speed: 2.7ms preprocess, 42.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/268.jpg: 384x640 (no detections), 47.0ms\n",
      "Speed: 3.0ms preprocess, 47.0ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/269.jpg: 384x640 (no detections), 49.0ms\n",
      "Speed: 2.2ms preprocess, 49.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/270.jpg: 384x640 (no detections), 30.8ms\n",
      "Speed: 2.2ms preprocess, 30.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/271.jpg: 384x640 (no detections), 42.9ms\n",
      "Speed: 2.6ms preprocess, 42.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/272.jpg: 384x640 (no detections), 39.9ms\n",
      "Speed: 1.8ms preprocess, 39.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/273.jpg: 384x640 (no detections), 52.1ms\n",
      "Speed: 3.3ms preprocess, 52.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/274.jpg: 384x640 (no detections), 41.1ms\n",
      "Speed: 2.5ms preprocess, 41.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/275.jpg: 384x640 1 sink, 1 toothbrush, 43.8ms\n",
      "Speed: 2.1ms preprocess, 43.8ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/276.jpg: 384x640 (no detections), 46.1ms\n",
      "Speed: 1.8ms preprocess, 46.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/277.jpg: 384x640 (no detections), 33.7ms\n",
      "Speed: 2.6ms preprocess, 33.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/278.jpg: 384x640 (no detections), 33.5ms\n",
      "Speed: 2.3ms preprocess, 33.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/279.jpg: 384x640 (no detections), 37.5ms\n",
      "Speed: 2.1ms preprocess, 37.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/280.jpg: 384x640 (no detections), 34.2ms\n",
      "Speed: 2.5ms preprocess, 34.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/281.jpg: 384x640 (no detections), 30.1ms\n",
      "Speed: 2.6ms preprocess, 30.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/282.jpg: 384x640 (no detections), 40.2ms\n",
      "Speed: 2.2ms preprocess, 40.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/283.jpg: 384x640 (no detections), 43.4ms\n",
      "Speed: 3.3ms preprocess, 43.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/284.jpg: 384x640 (no detections), 34.1ms\n",
      "Speed: 2.1ms preprocess, 34.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/285.jpg: 384x640 (no detections), 32.8ms\n",
      "Speed: 2.0ms preprocess, 32.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/286.jpg: 384x640 (no detections), 31.8ms\n",
      "Speed: 2.7ms preprocess, 31.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/287.jpg: 384x640 (no detections), 34.6ms\n",
      "Speed: 1.9ms preprocess, 34.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/288.jpg: 384x640 (no detections), 37.6ms\n",
      "Speed: 2.5ms preprocess, 37.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/289.jpg: 384x640 (no detections), 50.8ms\n",
      "Speed: 2.3ms preprocess, 50.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/290.jpg: 384x640 (no detections), 32.1ms\n",
      "Speed: 3.1ms preprocess, 32.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/291.jpg: 384x640 (no detections), 27.2ms\n",
      "Speed: 2.4ms preprocess, 27.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/292.jpg: 384x640 (no detections), 34.2ms\n",
      "Speed: 1.9ms preprocess, 34.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/293.jpg: 384x640 (no detections), 47.6ms\n",
      "Speed: 1.8ms preprocess, 47.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/294.jpg: 384x640 (no detections), 34.4ms\n",
      "Speed: 1.5ms preprocess, 34.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/295.jpg: 384x640 1 person, 28.3ms\n",
      "Speed: 2.4ms preprocess, 28.3ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/296.jpg: 384x640 (no detections), 43.2ms\n",
      "Speed: 3.6ms preprocess, 43.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/297.jpg: 384x640 1 bottle, 29.6ms\n",
      "Speed: 1.8ms preprocess, 29.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/298.jpg: 384x640 (no detections), 30.5ms\n",
      "Speed: 2.0ms preprocess, 30.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/nitish/Desktop/Personal/fyp/data/raw/SegSTRONGC_val/val/1/1/smoke/right/299.jpg: 384x640 (no detections), 26.3ms\n",
      "Speed: 2.2ms preprocess, 26.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Propagating video frames: 100%|| 300/300 [00:20<00:00, 14.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask propagation completed in 20.95 seconds.\n",
      "Processing predicted masks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "Processing video frames: 300it [00:00, 575.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 300 masks for evaluation.\n",
      "Masks saved to data/masks/yolo11x-seg/val/data-raw-SegSTRONGC_val-val-1-1-smoke-right.pkl\n",
      "Loading ground truth masks for evaluation...\n",
      "Loaded 300 ground truth masks.\n",
      "Calculating evaluation metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing domains: 100%|| 5/5 [04:15<00:00, 51.08s/it]\n",
      "Processing sub-directories: 100%|| 3/3 [12:39<00:00, 253.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for metrics calculation: 1.77 seconds.\n",
      "Mean IoU for data/raw/SegSTRONGC_val/val/1/1/smoke/right: 0.0784\n",
      "Mean DSC for data/raw/SegSTRONGC_val/val/1/1/smoke/right: 0.1128\n",
      "Loading existing results file: data/results/yolo11x-seg/val.json\n",
      "Results saved to data/results/yolo11x-seg/val.json\n",
      "Processing video took 24.51 seconds.\n",
      "==================================================\n",
      "\n",
      "Results for data/raw/SegSTRONGC_val/val/1/1/smoke:\n",
      "  Left: IoU=0.0529, DSC=0.0759\n",
      "  Right: IoU=0.0784, DSC=0.1128\n",
      "  Overall: IoU=0.0657, DSC=0.0944\n",
      "\n",
      "============================================================\n",
      "SUMMARY RESULTS FOR SPLIT: val\n",
      "============================================================\n",
      "\n",
      "Domain-wise Results:\n",
      "\n",
      "Domain: bg_change\n",
      "  Left Frame IoU: 0.3125\n",
      "  Right Frame IoU: 0.3543\n",
      "  Overall IoU: 0.3334\n",
      "  Left Frame DSC: 0.4261\n",
      "  Right Frame DSC: 0.4685\n",
      "  Overall DSC: 0.4473\n",
      "\n",
      "Domain: blood\n",
      "  Left Frame IoU: 0.3280\n",
      "  Right Frame IoU: 0.2926\n",
      "  Overall IoU: 0.3103\n",
      "  Left Frame DSC: 0.4279\n",
      "  Right Frame DSC: 0.3938\n",
      "  Overall DSC: 0.4109\n",
      "\n",
      "Domain: low_brightness\n",
      "  Left Frame IoU: 0.0676\n",
      "  Right Frame IoU: 0.0788\n",
      "  Overall IoU: 0.0732\n",
      "  Left Frame DSC: 0.1022\n",
      "  Right Frame DSC: 0.1199\n",
      "  Overall DSC: 0.1110\n",
      "\n",
      "Domain: regular\n",
      "  Left Frame IoU: 0.3367\n",
      "  Right Frame IoU: 0.2804\n",
      "  Overall IoU: 0.3086\n",
      "  Left Frame DSC: 0.4332\n",
      "  Right Frame DSC: 0.3791\n",
      "  Overall DSC: 0.4061\n",
      "\n",
      "Domain: smoke\n",
      "  Left Frame IoU: 0.1053\n",
      "  Right Frame IoU: 0.1368\n",
      "  Overall IoU: 0.1211\n",
      "  Left Frame DSC: 0.1450\n",
      "  Right Frame DSC: 0.1833\n",
      "  Overall DSC: 0.1642\n",
      "\n",
      "------------------------------------------------------------\n",
      "FINAL RESULTS ACROSS ALL DOMAINS AND SUB-DIRECTORIES:\n",
      "  Left Frame IoU: 0.2300\n",
      "  Right Frame IoU: 0.2286\n",
      "  Overall IoU: 0.2293\n",
      "  Left Frame DSC: 0.3069\n",
      "  Right Frame DSC: 0.3089\n",
      "  Overall DSC: 0.3079\n",
      "\n",
      "Total time taken for split val: 759.96 seconds (12.67 minutes)\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def process_video(frames_path, sub_dir, domain, split, is_left):\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Processing video: {frames_path}\")\n",
    "    print(f\"Domain: {domain}, Split: {split}, Camera: {'left' if is_left else 'right'}\")\n",
    "    logger.info(f\"Processing video: {frames_path} (Domain: {domain}, Split: {split}, Camera: {'left' if is_left else 'right'})\")\n",
    "    stereo_dir = \"left\" if is_left else \"right\"\n",
    "    ground_truth_masks_path = sub_dir + \"/ground_truth/\" + stereo_dir\n",
    "\n",
    "    overall_start = time.time()\n",
    "    mask_storage_data, predicted_masks = run_inference(model, frames_path, split)\n",
    "    \n",
    "    print(f\"Generated {len(predicted_masks)} masks for evaluation.\")\n",
    "    logger.info(f\"Generated {len(predicted_masks)} masks for {frames_path}\")\n",
    "\n",
    "    # Save the masks\n",
    "    masks_split_dir = masks_dir + f\"/{model}\" + f\"/{split}\"\n",
    "    if not os.path.exists(masks_split_dir):\n",
    "        os.makedirs(masks_split_dir)\n",
    "\n",
    "    masks_file = masks_split_dir + f\"/{frames_path.replace('/', '-')}.pkl\"\n",
    "\n",
    "    data = {}\n",
    "    data[frames_path] = mask_storage_data\n",
    "\n",
    "    with open(masks_file, \"wb\") as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f\"Masks saved to {masks_file}\")\n",
    "\n",
    "    print(\"Loading ground truth masks for evaluation...\")\n",
    "    ground_truth_masks = []\n",
    "    for i in range(len(predicted_masks)):\n",
    "        ground_truth_mask = cv2.imread(ground_truth_masks_path + \"/\" + str(i) + \".jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "        ground_truth_mask = (ground_truth_mask > 0).astype(np.bool_)\n",
    "        ground_truth_masks.append(ground_truth_mask)\n",
    "    print(f\"Loaded {len(ground_truth_masks)} ground truth masks.\")\n",
    "\n",
    "    print(\"Calculating evaluation metrics...\")\n",
    "    start = time.time()\n",
    "    miou = calculate_miou(predicted_masks, ground_truth_masks)\n",
    "    mdsc = calculate_mdsc(predicted_masks, ground_truth_masks)\n",
    "    end = time.time()\n",
    "    eval_time = end - start\n",
    "    print(f\"Time taken for metrics calculation: {eval_time:.2f} seconds.\")\n",
    "    logger.info(f\"Time taken for metrics calculation: {eval_time:.2f} seconds.\")\n",
    "\n",
    "    print(f\"Mean IoU for {sub_dir}/{domain}/{stereo_dir}: {miou:.4f}\")\n",
    "    print(f\"Mean DSC for {sub_dir}/{domain}/{stereo_dir}: {mdsc:.4f}\")\n",
    "\n",
    "    logger.info(f\"Mean IoU for {sub_dir}/{domain}/{stereo_dir}: {miou:.4f}\")\n",
    "    logger.info(f\"Mean DSC for {sub_dir}/{domain}/{stereo_dir}: {mdsc:.4f}\")\n",
    "\n",
    "    results_file = results_dir + f\"/{model}\" + f\"/{split}.json\"\n",
    "    if os.path.exists(results_file):\n",
    "        print(f\"Loading existing results file: {results_file}\")\n",
    "        with open(results_file, \"r\") as f:\n",
    "            all_results = json.load(f)\n",
    "    else:\n",
    "        print(f\"Creating new results file: {results_file}\")\n",
    "        all_results = {}\n",
    "    \n",
    "    all_results[frames_path] = {\n",
    "        \"miou\": miou,\n",
    "        \"mdsc\": mdsc\n",
    "    }\n",
    "\n",
    "    with open(results_file, \"w\") as f:\n",
    "        json.dump(all_results, f)\n",
    "    print(f\"Results saved to {results_file}\")\n",
    "\n",
    "    overall_end = time.time()\n",
    "    total_time = overall_end - overall_start\n",
    "    print(f\"Processing video took {total_time:.2f} seconds.\")\n",
    "    logger.info(f\"Results for {sub_dir}/{domain}/{stereo_dir} saved.\")\n",
    "    logger.info(f\"Processing video took {total_time:.2f} seconds.\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    return miou, mdsc\n",
    "\n",
    "def process_split(sub_dirs, domains, split):\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Running inference for split: {split}\")\n",
    "    logger.info(f\"Using Model: {model}\")\n",
    "    logger.info(f\"Annotation mode: {'manual' if is_manual_annotation else 'auto'}\")\n",
    "    if not is_manual_annotation:\n",
    "        logger.info(f\"Number of point annotations per tool: {num_auto_points_per_tool}\")\n",
    "\n",
    "    print(\"=\"*80)\n",
    "    logger.info(f\"----------------Running inference for split {split}-------------\")\n",
    "    overall_start = time.time()\n",
    "    \n",
    "    print(f\"Processing {len(sub_dirs)} sub-directories and {len(domains)} domains\")\n",
    "    logger.info(f\"Processing {len(sub_dirs)} sub-directories and {len(domains)} domains for split {split}\")\n",
    "        \n",
    "    sub_dir_results = {}\n",
    "    for sub_dir in tqdm(sub_dirs, desc=f\"Processing sub-directories\"):\n",
    "        print(\"\\n\" + \"-\"*60)\n",
    "        print(f\"Processing sub-directory: {sub_dir}\")\n",
    "        logger.info(f\"Processing sub-directory: {sub_dir}\")\n",
    "        domain_results = {}\n",
    "        for domain in tqdm(domains, desc=f\"Processing domains\"):\n",
    "            print(f\"\\nProcessing domain: {domain}\")\n",
    "            logger.info(f\"Processing domain: {domain} in {sub_dir}\")\n",
    "            left_video_frames_path = sub_dir + \"/\" + domain + \"/left\"\n",
    "            right_video_frames_path = sub_dir + \"/\" + domain + \"/right\"\n",
    "\n",
    "            print(f\"Processing left camera video...\")\n",
    "            left_miou, left_msdc = process_video(left_video_frames_path, sub_dir, domain, split, True)\n",
    "            \n",
    "            print(f\"Processing right camera video...\")\n",
    "            right_miou, right_msdc = process_video(right_video_frames_path, sub_dir, domain, split, False)\n",
    "\n",
    "            overall_miou = (left_miou + right_miou) / 2\n",
    "            overall_msdc = (left_msdc + right_msdc) / 2\n",
    "\n",
    "            print(f\"\\nResults for {sub_dir}/{domain}:\")\n",
    "            print(f\"  Left: IoU={left_miou:.4f}, DSC={left_msdc:.4f}\")\n",
    "            print(f\"  Right: IoU={right_miou:.4f}, DSC={right_msdc:.4f}\")\n",
    "            print(f\"  Overall: IoU={overall_miou:.4f}, DSC={overall_msdc:.4f}\")\n",
    "            \n",
    "            logger.info(f\"Results for {sub_dir}/{domain}: Left IoU={left_miou:.4f}, Right IoU={right_miou:.4f}, Overall IoU={overall_miou:.4f}\")\n",
    "\n",
    "            domain_results[domain] = {\n",
    "                \"left_miou\": left_miou,\n",
    "                \"left_msdc\": left_msdc,\n",
    "                \"right_miou\": right_miou,\n",
    "                \"right_msdc\": right_msdc,\n",
    "                \"overall_miou\": overall_miou,\n",
    "                \"overall_msdc\": overall_msdc\n",
    "            }\n",
    "\n",
    "        sub_dir_results[sub_dir] = domain_results\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"SUMMARY RESULTS FOR SPLIT: {split}\")\n",
    "    print(\"=\"*60)\n",
    "    logger.info(f\"SUMMARY RESULTS FOR SPLIT: {split}\")\n",
    "    logger.info(f\"Using Model: {model}\")\n",
    "    logger.info(f\"Annotation mode: {'manual' if is_manual_annotation else 'auto'}\")\n",
    "    if not is_manual_annotation:\n",
    "        logger.info(f\"Number of point annotations per tool: {num_auto_points_per_tool}\")\n",
    "\n",
    "    # Domain-wise results\n",
    "    print(\"\\nDomain-wise Results:\")\n",
    "    logger.info(\"Domain-wise Results:\")\n",
    "    for domain in domains:\n",
    "        left_mious = [sub_dir_results[sub_dir][domain][\"left_miou\"] for sub_dir in sub_dirs]\n",
    "        right_mious = [sub_dir_results[sub_dir][domain][\"right_miou\"] for sub_dir in sub_dirs]\n",
    "        overall_mious = [sub_dir_results[sub_dir][domain][\"overall_miou\"] for sub_dir in sub_dirs]\n",
    "\n",
    "        left_msdcs = [sub_dir_results[sub_dir][domain][\"left_msdc\"] for sub_dir in sub_dirs]\n",
    "        right_msdcs = [sub_dir_results[sub_dir][domain][\"right_msdc\"] for sub_dir in sub_dirs]\n",
    "        overall_msdcs = [sub_dir_results[sub_dir][domain][\"overall_msdc\"] for sub_dir in sub_dirs]\n",
    "\n",
    "        print(f\"\\nDomain: {domain}\")\n",
    "        print(f\"  Left Frame IoU: {np.mean(left_mious):.4f}\")\n",
    "        print(f\"  Right Frame IoU: {np.mean(right_mious):.4f}\")\n",
    "        print(f\"  Overall IoU: {np.mean(overall_mious):.4f}\")\n",
    "        print(f\"  Left Frame DSC: {np.mean(left_msdcs):.4f}\")\n",
    "        print(f\"  Right Frame DSC: {np.mean(right_msdcs):.4f}\")\n",
    "        print(f\"  Overall DSC: {np.mean(overall_msdcs):.4f}\")\n",
    "        \n",
    "        logger.info(f\"Domain {domain} - Left IoU: {np.mean(left_mious):.4f}, Right IoU: {np.mean(right_mious):.4f}, Overall IoU: {np.mean(overall_mious):.4f}\")\n",
    "        logger.info(f\"Domain {domain} - Left DSC: {np.mean(left_msdcs):.4f}, Right DSC: {np.mean(right_msdcs):.4f}, Overall DSC: {np.mean(overall_msdcs):.4f}\")\n",
    "\n",
    "    # Overall results across all domains and sub-dirs\n",
    "    left_mious = [np.mean([sub_dir_results[sub_dir][domain][\"left_miou\"] for domain in domains]) for sub_dir in sub_dirs]\n",
    "    right_mious = [np.mean([sub_dir_results[sub_dir][domain][\"right_miou\"] for domain in domains]) for sub_dir in sub_dirs]\n",
    "    overall_mious = [np.mean([sub_dir_results[sub_dir][domain][\"overall_miou\"] for domain in domains]) for sub_dir in sub_dirs]\n",
    "\n",
    "    left_msdcs = [np.mean([sub_dir_results[sub_dir][domain][\"left_msdc\"] for domain in domains]) for sub_dir in sub_dirs]\n",
    "    right_msdcs = [np.mean([sub_dir_results[sub_dir][domain][\"right_msdc\"] for domain in domains]) for sub_dir in sub_dirs]\n",
    "    overall_msdcs = [np.mean([sub_dir_results[sub_dir][domain][\"overall_msdc\"] for domain in domains]) for sub_dir in sub_dirs]\n",
    "\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"FINAL RESULTS ACROSS ALL DOMAINS AND SUB-DIRECTORIES:\")\n",
    "    print(f\"  Left Frame IoU: {np.mean(left_mious):.4f}\")\n",
    "    print(f\"  Right Frame IoU: {np.mean(right_mious):.4f}\")\n",
    "    print(f\"  Overall IoU: {np.mean(overall_mious):.4f}\")\n",
    "    print(f\"  Left Frame DSC: {np.mean(left_msdcs):.4f}\")\n",
    "    print(f\"  Right Frame DSC: {np.mean(right_msdcs):.4f}\")\n",
    "    print(f\"  Overall DSC: {np.mean(overall_msdcs):.4f}\")\n",
    "\n",
    "    logger.info(\"FINAL RESULTS ACROSS ALL DOMAINS AND SUB-DIRECTORIES:\")\n",
    "    logger.info(f\"Left Frame IoU: {np.mean(left_mious):.4f}\")\n",
    "    logger.info(f\"Right Frame IoU: {np.mean(right_mious):.4f}\")\n",
    "    logger.info(f\"Overall IoU: {np.mean(overall_mious):.4f}\")\n",
    "    logger.info(f\"Left Frame DSC: {np.mean(left_msdcs):.4f}\")\n",
    "    logger.info(f\"Right Frame DSC: {np.mean(right_msdcs):.4f}\")\n",
    "    logger.info(f\"Overall DSC: {np.mean(overall_msdcs):.4f}\")\n",
    "\n",
    "    overall_end = time.time()\n",
    "    total_time = overall_end - overall_start\n",
    "    print(f\"\\nTotal time taken for split {split}: {total_time:.2f} seconds ({total_time/60:.2f} minutes)\")\n",
    "    logger.info(f\"Total time taken for split {split}: {total_time:.2f} seconds ({total_time/60:.2f} minutes)\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "\n",
    "process_split(sub_dirs, domains, \"val\")\n",
    "# process_split(test_sub_dirs, test_domains, \"test\")\n",
    "# process_split(train_sub_dirs, train_domains, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = ['bg_change', 'blood', 'low_brightness', 'regular', 'smoke']\n",
    "annotations = None\n",
    "with open('data/annotations/auto/val.json', 'r') as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "path = \"data/masks/sam2.1_hiera_base_plus/val/data-raw-SegSTRONGC_val-val-1-2-bg_change-right.pkl\"\n",
    "with open(path, 'rb') as f:\n",
    "    mass = pickle.load(f)\n",
    "    for video_path, video_data in mass.items():\n",
    "        # print(video_path, video_data)\n",
    "        for frame_id, frame_data in video_data.items():\n",
    "            overall_mask = np.zeros((1080, 1920), dtype=bool)\n",
    "            for data in frame_data:\n",
    "                for object_id, mask in data.items():\n",
    "                    overall_mask = np.logical_or(overall_mask, mask[0])\n",
    "\n",
    "            ground_truth_masks_path = video_path\n",
    "            for domain in domains:\n",
    "                if domain in video_path:\n",
    "                    ground_truth_masks_path = video_path.replace(domain, 'ground_truth')\n",
    "                    break\n",
    "            ground_truth_masks_path = ground_truth_masks_path + \"/\" + str(frame_id) + \".jpg\"\n",
    "            ground_truth_mask = cv2.imread(ground_truth_masks_path, cv2.IMREAD_GRAYSCALE)\n",
    "            ground_truth_mask = (ground_truth_mask > 0).astype(np.bool_)\n",
    "\n",
    "            original_image = cv2.imread(video_path + \"/\" + str(frame_id) + \".jpg\")\n",
    "            original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # frame_annotations = annotations[video_path.replace(\"/left\", \"\").replace(\"/right\", \"\")]\n",
    "            frame_annotations = annotations[video_path]\n",
    "\n",
    "            # place dots in the original image for each annotation\n",
    "            for object_id, object_annotations in frame_annotations.items():\n",
    "                # print(object_annotations)\n",
    "                for annotation in object_annotations:\n",
    "                    x = annotation['x']\n",
    "                    y = annotation['y']\n",
    "                    label = annotation['label']\n",
    "                    if object_id == \"0\":\n",
    "                        original_image = cv2.circle(original_image, (x, y), 10, (0, 255, 0), -1)\n",
    "                    else:\n",
    "                        original_image = cv2.circle(original_image, (x, y), 10, (255, 0, 0), -1)\n",
    "\n",
    "            #show the masks and the original image\n",
    "            fig, axs = plt.subplots(1, 3, figsize=(30, 15))\n",
    "            axs[0].imshow(original_image)\n",
    "            axs[0].set_title(\"Original Image\")\n",
    "            axs[1].imshow(overall_mask)\n",
    "            axs[1].set_title(\"Overall Mask\")\n",
    "            axs[2].imshow(ground_truth_mask)\n",
    "            axs[2].set_title(\"Ground Truth Mask\")\n",
    "            plt.show()\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
