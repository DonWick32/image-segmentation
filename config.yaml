notes: "LoRA naive CL baseline"
entity: "frozenwolf"
device: cuda
batch_size: 2
num_workers: 0
learning_rate: 0.0001
epochs: 10
distributed: true

# output_dir: "output"
output_dir: "/scratch/gokuladethya.cse.nitt/fyp/output"

model:
  # checkpoint: "checkpoints/sam2.1_hiera_small.pt" 
  checkpoint: "checkpoints/sam2.1_hiera_base_plus.pt"

dataset:
  # path: "../segstrong"
  path: "../"
  max_frames: 4 # nbatches = 300/(max_frames//2)
  max_frame_interval_skip: 3
  annotation_path:  "annotations/auto/"

loss_weights:
  loss_mask: 20
  loss_dice: 1
  loss_iou: 1  ### for kd its set to 0, other losses are used tho
  loss_class: 1
  knowledge_distillation: 0.1

loss_config:
  supervise_all_iou: true
  iou_use_l1_loss: true
  pred_obj_scores: true
  focal_gamma_obj_score: 0.0
  focal_alpha_obj_score: -1.0

cl_config:
  evaluate_every_n_epochs: 10

lora:
  decoder: false
  image_encoder: true
  rank: 8