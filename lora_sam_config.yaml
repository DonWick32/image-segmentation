notes: "LoRA naive training sam-base"
entity: "frozenwolf"
device: cuda
batch_size: 1
num_workers: 0
learning_rate: 0.0001
epochs: 100
distributed: true
evaluate_every_n_epochs: 5

# output_dir: "output"
output_dir: "/scratch/gokuladethya.cse.nitt/fyp/output"

model:
  # checkpoint: "checkpoints/sam2.1_hiera_small.pt" 
  checkpoint: "checkpoints/sam2.1_hiera_base_plus.pt"

dataset:
  # path: "../segstrong"
  path: "../"
  max_frames: 9 # nbatches = 300/(max_frames//2)
  max_frame_interval_skip: 3
  annotation_path:  "annotations/auto/"

loss_weights:
  loss_mask: 20
  loss_dice: 1
  loss_iou: 1
  loss_class: 1

loss_config:
  supervise_all_iou: true
  iou_use_l1_loss: true
  pred_obj_scores: true
  focal_gamma_obj_score: 0.0
  focal_alpha_obj_score: -1.0
